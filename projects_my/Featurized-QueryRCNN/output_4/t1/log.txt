[03/05 10:33:24] detectron2 INFO: Rank of current process: 0. World size: 1
[03/05 10:33:26] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/05 10:33:26] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=False)
[03/05 10:33:26] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
# OWOD:
#   PREV_INTRODUCED_CLS: 0
#   CUR_INTRODUCED_CLS: 20

[03/05 10:33:26] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/05 10:33:26] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/05 10:35:41] detectron2 INFO: Rank of current process: 0. World size: 1
[03/05 10:35:42] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/05 10:35:42] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=False)
[03/05 10:35:42] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
# OWOD:
#   PREV_INTRODUCED_CLS: 0
#   CUR_INTRODUCED_CLS: 20

[03/05 10:35:42] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/05 10:35:42] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/05 10:35:47] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/05 10:58:48] detectron2 INFO: Rank of current process: 0. World size: 1
[03/05 10:58:49] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/05 10:58:49] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=False)
[03/05 10:58:49] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
# OWOD:
#   PREV_INTRODUCED_CLS: 0
#   CUR_INTRODUCED_CLS: 20

[03/05 10:58:49] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/05 10:58:49] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/05 10:58:54] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/05 10:58:55] d2.data.build INFO: Valid classes: range(0, 20)
[03/05 10:58:55] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/05 10:58:56] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/05 10:58:56] d2.data.build INFO: Number of datapoints: 16551
[03/05 10:58:56] d2.data.build INFO: Using training sampler TrainingSampler
[03/05 10:58:56] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/05 10:58:56] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/05 10:58:56] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/05 11:06:11] detectron2 INFO: Rank of current process: 0. World size: 1
[03/05 11:06:12] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/05 11:06:12] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=False)
[03/05 11:06:12] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
# OWOD:
#   PREV_INTRODUCED_CLS: 0
#   CUR_INTRODUCED_CLS: 20

[03/05 11:06:12] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/05 11:06:12] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/05 11:06:18] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/05 11:06:19] d2.data.build INFO: Valid classes: range(0, 20)
[03/05 11:06:19] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/05 11:06:20] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/05 11:06:20] d2.data.build INFO: Number of datapoints: 16551
[03/05 11:06:20] d2.data.build INFO: Using training sampler TrainingSampler
[03/05 11:06:20] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/05 11:06:20] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/05 11:06:20] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/05 11:06:20] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[03/05 11:06:20] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/wxf/.torch/iopath_cache/detectron2/ImageNetPretrained/torchvision/R-50.pkl ...
[03/05 11:06:20] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[03/05 11:06:21] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[03/05 11:06:21] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mhead.head_series.0.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.0.class_logits.{bias, weight}[0m
[34mhead.head_series.0.cls_module.0.weight[0m
[34mhead.head_series.0.cls_module.1.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.0.linear1.{bias, weight}[0m
[34mhead.head_series.0.linear2.{bias, weight}[0m
[34mhead.head_series.0.norm1.{bias, weight}[0m
[34mhead.head_series.0.norm2.{bias, weight}[0m
[34mhead.head_series.0.norm3.{bias, weight}[0m
[34mhead.head_series.0.reg_module.0.weight[0m
[34mhead.head_series.0.reg_module.1.{bias, weight}[0m
[34mhead.head_series.0.reg_module.3.weight[0m
[34mhead.head_series.0.reg_module.4.{bias, weight}[0m
[34mhead.head_series.0.reg_module.6.weight[0m
[34mhead.head_series.0.reg_module.7.{bias, weight}[0m
[34mhead.head_series.0.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.1.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.1.class_logits.{bias, weight}[0m
[34mhead.head_series.1.cls_module.0.weight[0m
[34mhead.head_series.1.cls_module.1.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.1.linear1.{bias, weight}[0m
[34mhead.head_series.1.linear2.{bias, weight}[0m
[34mhead.head_series.1.norm1.{bias, weight}[0m
[34mhead.head_series.1.norm2.{bias, weight}[0m
[34mhead.head_series.1.norm3.{bias, weight}[0m
[34mhead.head_series.1.norm4.{bias, weight}[0m
[34mhead.head_series.1.reg_module.0.weight[0m
[34mhead.head_series.1.reg_module.1.{bias, weight}[0m
[34mhead.head_series.1.reg_module.3.weight[0m
[34mhead.head_series.1.reg_module.4.{bias, weight}[0m
[34mhead.head_series.1.reg_module.6.weight[0m
[34mhead.head_series.1.reg_module.7.{bias, weight}[0m
[34mhead.head_series.1.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.1.self_attn_post.out_proj.{bias, weight}[0m
[34mhead.head_series.1.self_attn_post.{in_proj_bias, in_proj_weight}[0m
[34mrpn_head.rpn_head.anchor_deltas.{bias, weight}[0m
[34mrpn_head.rpn_head.conv.{bias, weight}[0m
[34mrpn_head.rpn_head.objectness_logits.{bias, weight}[0m
[34mrpn_head.rpn_head.proposal_feats.{bias, weight}[0m
[34mrpn_head.rpn_head.scales.0.scale[0m
[34mrpn_head.rpn_head.scales.1.scale[0m
[34mrpn_head.rpn_head.scales.2.scale[0m
[34mrpn_head.rpn_head.scales.3.scale[0m
[34mrpn_head.rpn_head.scales.4.scale[0m
[03/05 11:06:21] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[03/05 11:06:21] d2.engine.train_loop INFO: Starting training from iteration 0
[03/05 11:06:28] d2.utils.events INFO:  eta: 6:35:40  iter: 19  total_loss: 20.12  loss_ce: 1.978  loss_giou: 2  loss_bbox: 4.676  loss_ce_0: 1.927  loss_giou_0: 2  loss_bbox_0: 4.686  loss_rpn_cls: 1.132  loss_rpn_reg: 2  time: 0.3535  last_time: 0.4328  data_time: 0.0226  last_data_time: 0.0020   lr: 5.2025e-06  max_mem: 1772M
[03/05 11:06:33] d2.utils.events INFO:  eta: 4:25:26  iter: 39  total_loss: 21.38  loss_ce: 1.596  loss_giou: 2  loss_bbox: 5.907  loss_ce_0: 1.595  loss_giou_0: 2  loss_bbox_0: 5.893  loss_rpn_cls: 1.13  loss_rpn_reg: 2  time: 0.2901  last_time: 0.1324  data_time: 0.0021  last_data_time: 0.0022   lr: 1.0152e-05  max_mem: 1772M
[03/05 11:06:36] d2.utils.events INFO:  eta: 1:59:07  iter: 59  total_loss: 19.44  loss_ce: 1.358  loss_giou: 2  loss_bbox: 4.861  loss_ce_0: 1.298  loss_giou_0: 2  loss_bbox_0: 4.898  loss_rpn_cls: 1.128  loss_rpn_reg: 2  time: 0.2333  last_time: 0.1158  data_time: 0.0020  last_data_time: 0.0020   lr: 1.5102e-05  max_mem: 1808M
[03/05 11:06:38] d2.utils.events INFO:  eta: 1:55:13  iter: 79  total_loss: 18.07  loss_ce: 1.625  loss_giou: 1.999  loss_bbox: 3.124  loss_ce_0: 1.721  loss_giou_0: 2  loss_bbox_0: 4.107  loss_rpn_cls: 1.124  loss_rpn_reg: 1.999  time: 0.2048  last_time: 0.1152  data_time: 0.0020  last_data_time: 0.0018   lr: 2.0053e-05  max_mem: 1854M
[03/05 11:06:41] d2.utils.events INFO:  eta: 1:54:11  iter: 99  total_loss: 16.93  loss_ce: 1.786  loss_giou: 2.052  loss_bbox: 2.908  loss_ce_0: 1.718  loss_giou_0: 1.995  loss_bbox_0: 3.267  loss_rpn_cls: 1.118  loss_rpn_reg: 1.998  time: 0.1881  last_time: 0.1107  data_time: 0.0020  last_data_time: 0.0017   lr: 2.5002e-05  max_mem: 1854M
[03/05 11:06:43] d2.utils.events INFO:  eta: 1:52:26  iter: 119  total_loss: 16.91  loss_ce: 1.706  loss_giou: 2.173  loss_bbox: 3.699  loss_ce_0: 1.77  loss_giou_0: 1.604  loss_bbox_0: 2.277  loss_rpn_cls: 1.1  loss_rpn_reg: 1.989  time: 0.1771  last_time: 0.1075  data_time: 0.0020  last_data_time: 0.0019   lr: 2.9953e-05  max_mem: 1854M
[03/05 11:06:46] d2.utils.events INFO:  eta: 1:50:35  iter: 139  total_loss: 14.66  loss_ce: 1.816  loss_giou: 1.676  loss_bbox: 2.591  loss_ce_0: 1.731  loss_giou_0: 1.353  loss_bbox_0: 1.883  loss_rpn_cls: 1.049  loss_rpn_reg: 1.962  time: 0.1688  last_time: 0.1129  data_time: 0.0020  last_data_time: 0.0017   lr: 3.4902e-05  max_mem: 1854M
[03/05 11:06:48] d2.utils.events INFO:  eta: 1:50:25  iter: 159  total_loss: 13.25  loss_ce: 1.566  loss_giou: 1.485  loss_bbox: 2.317  loss_ce_0: 1.407  loss_giou_0: 1.143  loss_bbox_0: 1.887  loss_rpn_cls: 1  loss_rpn_reg: 1.924  time: 0.1630  last_time: 0.1146  data_time: 0.0018  last_data_time: 0.0017   lr: 3.9852e-05  max_mem: 1854M
[03/05 11:06:51] d2.utils.events INFO:  eta: 1:49:25  iter: 179  total_loss: 13.47  loss_ce: 1.899  loss_giou: 1.492  loss_bbox: 2.387  loss_ce_0: 2.071  loss_giou_0: 1.248  loss_bbox_0: 2.487  loss_rpn_cls: 0.4757  loss_rpn_reg: 1.427  time: 0.1581  last_time: 0.1373  data_time: 0.0018  last_data_time: 0.0016   lr: 4.4802e-05  max_mem: 1854M
[03/05 11:06:53] d2.utils.events INFO:  eta: 1:49:01  iter: 199  total_loss: 13.47  loss_ce: 1.737  loss_giou: 1.662  loss_bbox: 2.934  loss_ce_0: 1.888  loss_giou_0: 1.549  loss_bbox_0: 2.186  loss_rpn_cls: 0.4409  loss_rpn_reg: 1.614  time: 0.1542  last_time: 0.1241  data_time: 0.0019  last_data_time: 0.0020   lr: 4.9752e-05  max_mem: 1854M
[03/05 11:06:55] d2.utils.events INFO:  eta: 1:48:56  iter: 219  total_loss: 13.39  loss_ce: 1.639  loss_giou: 1.239  loss_bbox: 2.346  loss_ce_0: 1.637  loss_giou_0: 1.471  loss_bbox_0: 2.639  loss_rpn_cls: 0.4804  loss_rpn_reg: 1.429  time: 0.1511  last_time: 0.1263  data_time: 0.0019  last_data_time: 0.0019   lr: 5e-05  max_mem: 1854M
[03/05 11:06:58] d2.utils.events INFO:  eta: 1:48:50  iter: 239  total_loss: 12.12  loss_ce: 1.655  loss_giou: 1.476  loss_bbox: 2.164  loss_ce_0: 1.627  loss_giou_0: 1.299  loss_bbox_0: 2.141  loss_rpn_cls: 0.4881  loss_rpn_reg: 1.139  time: 0.1486  last_time: 0.1352  data_time: 0.0018  last_data_time: 0.0016   lr: 5e-05  max_mem: 1854M
[03/05 11:07:00] d2.utils.events INFO:  eta: 1:48:51  iter: 259  total_loss: 11.63  loss_ce: 1.507  loss_giou: 1.262  loss_bbox: 2.085  loss_ce_0: 1.546  loss_giou_0: 1.32  loss_bbox_0: 2.011  loss_rpn_cls: 0.5921  loss_rpn_reg: 1.236  time: 0.1465  last_time: 0.1420  data_time: 0.0018  last_data_time: 0.0018   lr: 5e-05  max_mem: 1854M
[03/05 11:07:03] d2.utils.events INFO:  eta: 1:48:41  iter: 279  total_loss: 11.98  loss_ce: 1.641  loss_giou: 1.304  loss_bbox: 2.137  loss_ce_0: 1.663  loss_giou_0: 1.307  loss_bbox_0: 1.885  loss_rpn_cls: 0.7045  loss_rpn_reg: 1.222  time: 0.1446  last_time: 0.1368  data_time: 0.0019  last_data_time: 0.0016   lr: 5e-05  max_mem: 1854M
[03/05 11:07:05] d2.utils.events INFO:  eta: 1:48:27  iter: 299  total_loss: 12.22  loss_ce: 1.405  loss_giou: 1.522  loss_bbox: 2.468  loss_ce_0: 1.384  loss_giou_0: 1.446  loss_bbox_0: 1.698  loss_rpn_cls: 0.7535  loss_rpn_reg: 1.226  time: 0.1429  last_time: 0.1092  data_time: 0.0019  last_data_time: 0.0017   lr: 5e-05  max_mem: 1854M
[03/05 11:07:08] d2.utils.events INFO:  eta: 1:48:20  iter: 319  total_loss: 10.78  loss_ce: 1.667  loss_giou: 1.21  loss_bbox: 1.69  loss_ce_0: 1.744  loss_giou_0: 1.186  loss_bbox_0: 1.758  loss_rpn_cls: 0.6319  loss_rpn_reg: 0.9751  time: 0.1414  last_time: 0.1118  data_time: 0.0019  last_data_time: 0.0019   lr: 5e-05  max_mem: 1854M
[03/05 11:07:10] d2.utils.events INFO:  eta: 1:48:27  iter: 339  total_loss: 11.8  loss_ce: 1.638  loss_giou: 1.402  loss_bbox: 2.291  loss_ce_0: 1.651  loss_giou_0: 1.134  loss_bbox_0: 1.481  loss_rpn_cls: 0.538  loss_rpn_reg: 0.9853  time: 0.1405  last_time: 0.1205  data_time: 0.0022  last_data_time: 0.0027   lr: 5e-05  max_mem: 1854M
[03/05 11:07:13] d2.utils.events INFO:  eta: 1:48:10  iter: 359  total_loss: 9.928  loss_ce: 1.612  loss_giou: 1.128  loss_bbox: 1.702  loss_ce_0: 1.612  loss_giou_0: 1.037  loss_bbox_0: 1.512  loss_rpn_cls: 0.5338  loss_rpn_reg: 1.012  time: 0.1392  last_time: 0.1094  data_time: 0.0020  last_data_time: 0.0018   lr: 5e-05  max_mem: 1854M
[03/05 11:07:15] d2.utils.events INFO:  eta: 1:48:06  iter: 379  total_loss: 11.66  loss_ce: 1.467  loss_giou: 1.364  loss_bbox: 2.009  loss_ce_0: 1.511  loss_giou_0: 1.185  loss_bbox_0: 2.089  loss_rpn_cls: 0.5934  loss_rpn_reg: 1.174  time: 0.1383  last_time: 0.1226  data_time: 0.0020  last_data_time: 0.0021   lr: 5e-05  max_mem: 1854M
[03/05 11:07:18] d2.utils.events INFO:  eta: 1:48:03  iter: 399  total_loss: 11.65  loss_ce: 1.692  loss_giou: 1.123  loss_bbox: 2.397  loss_ce_0: 1.677  loss_giou_0: 1.178  loss_bbox_0: 1.896  loss_rpn_cls: 0.6873  loss_rpn_reg: 1.3  time: 0.1375  last_time: 0.1150  data_time: 0.0021  last_data_time: 0.0020   lr: 5e-05  max_mem: 1854M
[03/05 11:07:20] d2.utils.events INFO:  eta: 1:47:39  iter: 419  total_loss: 10.82  loss_ce: 1.643  loss_giou: 1.154  loss_bbox: 1.907  loss_ce_0: 1.462  loss_giou_0: 1.083  loss_bbox_0: 1.715  loss_rpn_cls: 0.6042  loss_rpn_reg: 1.146  time: 0.1366  last_time: 0.1238  data_time: 0.0020  last_data_time: 0.0017   lr: 5e-05  max_mem: 1854M
[03/05 11:07:21] d2.engine.hooks INFO: Overall training speed: 428 iterations in 0:00:58 (0.1364 s / it)
[03/05 11:07:21] d2.engine.hooks INFO: Total training time: 0:00:59 (0:00:01 on hooks)
[03/05 11:07:21] d2.utils.events INFO:  eta: 1:47:30  iter: 430  total_loss: 10.53  loss_ce: 1.674  loss_giou: 1.11  loss_bbox: 1.834  loss_ce_0: 1.607  loss_giou_0: 1.051  loss_bbox_0: 1.594  loss_rpn_cls: 0.6034  loss_rpn_reg: 1.049  time: 0.1362  last_time: 0.1054  data_time: 0.0020  last_data_time: 0.0019   lr: 5e-05  max_mem: 1854M
[03/05 11:08:02] detectron2 INFO: Rank of current process: 0. World size: 2
[03/05 11:08:03] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/05 11:08:03] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4'], resume=False)
[03/05 11:08:03] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/05 11:08:03] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/05 11:08:03] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/05 11:08:05] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/05 11:08:07] d2.data.build INFO: Valid classes: range(0, 20)
[03/05 11:08:07] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/05 11:08:07] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/05 11:08:07] d2.data.build INFO: Number of datapoints: 16551
[03/05 11:08:07] d2.data.build INFO: Using training sampler TrainingSampler
[03/05 11:08:07] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/05 11:08:07] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/05 11:08:07] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/05 11:08:07] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[03/05 11:08:07] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/wxf/.torch/iopath_cache/detectron2/ImageNetPretrained/torchvision/R-50.pkl ...
[03/05 11:08:07] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[03/05 11:08:08] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[03/05 11:08:08] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mhead.head_series.0.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.0.class_logits.{bias, weight}[0m
[34mhead.head_series.0.cls_module.0.weight[0m
[34mhead.head_series.0.cls_module.1.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.0.linear1.{bias, weight}[0m
[34mhead.head_series.0.linear2.{bias, weight}[0m
[34mhead.head_series.0.norm1.{bias, weight}[0m
[34mhead.head_series.0.norm2.{bias, weight}[0m
[34mhead.head_series.0.norm3.{bias, weight}[0m
[34mhead.head_series.0.reg_module.0.weight[0m
[34mhead.head_series.0.reg_module.1.{bias, weight}[0m
[34mhead.head_series.0.reg_module.3.weight[0m
[34mhead.head_series.0.reg_module.4.{bias, weight}[0m
[34mhead.head_series.0.reg_module.6.weight[0m
[34mhead.head_series.0.reg_module.7.{bias, weight}[0m
[34mhead.head_series.0.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.1.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.1.class_logits.{bias, weight}[0m
[34mhead.head_series.1.cls_module.0.weight[0m
[34mhead.head_series.1.cls_module.1.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.1.linear1.{bias, weight}[0m
[34mhead.head_series.1.linear2.{bias, weight}[0m
[34mhead.head_series.1.norm1.{bias, weight}[0m
[34mhead.head_series.1.norm2.{bias, weight}[0m
[34mhead.head_series.1.norm3.{bias, weight}[0m
[34mhead.head_series.1.norm4.{bias, weight}[0m
[34mhead.head_series.1.reg_module.0.weight[0m
[34mhead.head_series.1.reg_module.1.{bias, weight}[0m
[34mhead.head_series.1.reg_module.3.weight[0m
[34mhead.head_series.1.reg_module.4.{bias, weight}[0m
[34mhead.head_series.1.reg_module.6.weight[0m
[34mhead.head_series.1.reg_module.7.{bias, weight}[0m
[34mhead.head_series.1.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.1.self_attn_post.out_proj.{bias, weight}[0m
[34mhead.head_series.1.self_attn_post.{in_proj_bias, in_proj_weight}[0m
[34mrpn_head.rpn_head.anchor_deltas.{bias, weight}[0m
[34mrpn_head.rpn_head.conv.{bias, weight}[0m
[34mrpn_head.rpn_head.objectness_logits.{bias, weight}[0m
[34mrpn_head.rpn_head.proposal_feats.{bias, weight}[0m
[34mrpn_head.rpn_head.scales.0.scale[0m
[34mrpn_head.rpn_head.scales.1.scale[0m
[34mrpn_head.rpn_head.scales.2.scale[0m
[34mrpn_head.rpn_head.scales.3.scale[0m
[34mrpn_head.rpn_head.scales.4.scale[0m
[03/05 11:08:08] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[03/05 11:08:08] d2.engine.train_loop INFO: Starting training from iteration 0
[03/05 11:08:20] d2.utils.events INFO:  eta: 7:39:05  iter: 19  total_loss: 18.92  loss_ce: 1.961  loss_giou: 2.015  loss_bbox: 4.12  loss_ce_0: 1.769  loss_giou_0: 2.016  loss_bbox_0: 4.123  loss_rpn_cls: 1.132  loss_rpn_reg: 1.999  time: 0.5195  last_time: 0.4976  data_time: 0.1178  last_data_time: 0.0081   lr: 5.2025e-06  max_mem: 2906M
[03/05 11:08:27] d2.utils.events INFO:  eta: 7:30:40  iter: 39  total_loss: 18.73  loss_ce: 1.461  loss_giou: 2.012  loss_bbox: 4.105  loss_ce_0: 1.511  loss_giou_0: 2.01  loss_bbox_0: 4.115  loss_rpn_cls: 1.131  loss_rpn_reg: 1.999  time: 0.4205  last_time: 0.2095  data_time: 0.0048  last_data_time: 0.0044   lr: 1.0152e-05  max_mem: 2906M
[03/05 11:08:32] d2.utils.events INFO:  eta: 5:22:52  iter: 59  total_loss: 18.47  loss_ce: 1.774  loss_giou: 2.123  loss_bbox: 2.995  loss_ce_0: 1.568  loss_giou_0: 2.018  loss_bbox_0: 4.28  loss_rpn_cls: 1.128  loss_rpn_reg: 1.999  time: 0.3570  last_time: 0.2183  data_time: 0.0049  last_data_time: 0.0083   lr: 1.5102e-05  max_mem: 2906M
[03/05 11:08:36] d2.utils.events INFO:  eta: 3:05:11  iter: 79  total_loss: 16.25  loss_ce: 1.476  loss_giou: 2.057  loss_bbox: 2.368  loss_ce_0: 1.431  loss_giou_0: 2.075  loss_bbox_0: 3.748  loss_rpn_cls: 1.126  loss_rpn_reg: 2  time: 0.3155  last_time: 0.1720  data_time: 0.0052  last_data_time: 0.0055   lr: 2.0053e-05  max_mem: 2930M
[03/05 11:08:40] d2.utils.events INFO:  eta: 3:03:12  iter: 99  total_loss: 14.78  loss_ce: 1.512  loss_giou: 1.548  loss_bbox: 2.069  loss_ce_0: 1.482  loss_giou_0: 1.993  loss_bbox_0: 2.748  loss_rpn_cls: 1.118  loss_rpn_reg: 1.999  time: 0.2928  last_time: 0.2089  data_time: 0.0057  last_data_time: 0.0025   lr: 2.5002e-05  max_mem: 3029M
[03/05 11:08:44] d2.utils.events INFO:  eta: 2:59:48  iter: 119  total_loss: 14.42  loss_ce: 1.62  loss_giou: 1.734  loss_bbox: 2.422  loss_ce_0: 1.632  loss_giou_0: 1.543  loss_bbox_0: 1.929  loss_rpn_cls: 1.105  loss_rpn_reg: 1.998  time: 0.2758  last_time: 0.1875  data_time: 0.0055  last_data_time: 0.0051   lr: 2.9953e-05  max_mem: 3029M
[03/05 11:08:48] d2.utils.events INFO:  eta: 2:58:33  iter: 139  total_loss: 12.97  loss_ce: 1.515  loss_giou: 1.518  loss_bbox: 2.132  loss_ce_0: 1.589  loss_giou_0: 1.347  loss_bbox_0: 1.637  loss_rpn_cls: 1.054  loss_rpn_reg: 1.977  time: 0.2642  last_time: 0.2051  data_time: 0.0053  last_data_time: 0.0048   lr: 3.4902e-05  max_mem: 3029M
[03/05 11:08:52] d2.utils.events INFO:  eta: 2:58:25  iter: 159  total_loss: 11.62  loss_ce: 1.532  loss_giou: 1.407  loss_bbox: 1.99  loss_ce_0: 1.612  loss_giou_0: 1.344  loss_bbox_0: 1.905  loss_rpn_cls: 0.6896  loss_rpn_reg: 1.28  time: 0.2557  last_time: 0.2137  data_time: 0.0053  last_data_time: 0.0055   lr: 3.9852e-05  max_mem: 3029M
[03/05 11:08:55] d2.engine.hooks INFO: Overall training speed: 174 iterations in 0:00:43 (0.2510 s / it)
[03/05 11:08:55] d2.engine.hooks INFO: Total training time: 0:00:44 (0:00:00 on hooks)
[03/05 11:08:55] d2.utils.events INFO:  eta: 2:58:37  iter: 176  total_loss: 11.52  loss_ce: 1.455  loss_giou: 1.468  loss_bbox: 2.07  loss_ce_0: 1.505  loss_giou_0: 1.351  loss_bbox_0: 1.711  loss_rpn_cls: 0.6268  loss_rpn_reg: 1.198  time: 0.2505  last_time: 0.1832  data_time: 0.0050  last_data_time: 0.0032   lr: 4.3812e-05  max_mem: 3029M
[03/05 11:09:54] detectron2 INFO: Rank of current process: 0. World size: 2
[03/05 11:09:56] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/05 11:09:56] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[03/05 11:09:56] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/05 11:09:56] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/05 11:09:56] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/05 11:09:57] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/05 11:09:59] d2.data.build INFO: Valid classes: range(0, 20)
[03/05 11:09:59] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/05 11:09:59] d2.data.build INFO: Distribution of instances among all 81 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |
[03/05 11:09:59] d2.data.build INFO: Number of datapoints: 16551
[03/05 11:09:59] d2.data.build INFO: Using training sampler TrainingSampler
[03/05 11:09:59] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/05 11:09:59] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/05 11:09:59] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/05 11:10:00] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[03/05 11:10:00] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/wxf/.torch/iopath_cache/detectron2/ImageNetPretrained/torchvision/R-50.pkl ...
[03/05 11:10:00] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[03/05 11:10:00] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[03/05 11:10:00] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.fpn_lateral2.{bias, weight}
backbone.fpn_lateral3.{bias, weight}
backbone.fpn_lateral4.{bias, weight}
backbone.fpn_lateral5.{bias, weight}
backbone.fpn_output2.{bias, weight}
backbone.fpn_output3.{bias, weight}
backbone.fpn_output4.{bias, weight}
backbone.fpn_output5.{bias, weight}
backbone.top_block.p6.{bias, weight}
backbone.top_block.p7.{bias, weight}
head.head_series.0.bboxes_delta.{bias, weight}
head.head_series.0.class_logits.{bias, weight}
head.head_series.0.cls_module.0.weight
head.head_series.0.cls_module.1.{bias, weight}
head.head_series.0.inst_interact.dynamic_layer.{bias, weight}
head.head_series.0.inst_interact.norm1.{bias, weight}
head.head_series.0.inst_interact.norm2.{bias, weight}
head.head_series.0.inst_interact.norm3.{bias, weight}
head.head_series.0.inst_interact.out_layer.{bias, weight}
head.head_series.0.linear1.{bias, weight}
head.head_series.0.linear2.{bias, weight}
head.head_series.0.norm1.{bias, weight}
head.head_series.0.norm2.{bias, weight}
head.head_series.0.norm3.{bias, weight}
head.head_series.0.reg_module.0.weight
head.head_series.0.reg_module.1.{bias, weight}
head.head_series.0.reg_module.3.weight
head.head_series.0.reg_module.4.{bias, weight}
head.head_series.0.reg_module.6.weight
head.head_series.0.reg_module.7.{bias, weight}
head.head_series.0.self_attn.out_proj.{bias, weight}
head.head_series.0.self_attn.{in_proj_bias, in_proj_weight}
head.head_series.1.bboxes_delta.{bias, weight}
head.head_series.1.class_logits.{bias, weight}
head.head_series.1.cls_module.0.weight
head.head_series.1.cls_module.1.{bias, weight}
head.head_series.1.inst_interact.dynamic_layer.{bias, weight}
head.head_series.1.inst_interact.norm1.{bias, weight}
head.head_series.1.inst_interact.norm2.{bias, weight}
head.head_series.1.inst_interact.norm3.{bias, weight}
head.head_series.1.inst_interact.out_layer.{bias, weight}
head.head_series.1.linear1.{bias, weight}
head.head_series.1.linear2.{bias, weight}
head.head_series.1.norm1.{bias, weight}
head.head_series.1.norm2.{bias, weight}
head.head_series.1.norm3.{bias, weight}
head.head_series.1.norm4.{bias, weight}
head.head_series.1.reg_module.0.weight
head.head_series.1.reg_module.1.{bias, weight}
head.head_series.1.reg_module.3.weight
head.head_series.1.reg_module.4.{bias, weight}
head.head_series.1.reg_module.6.weight
head.head_series.1.reg_module.7.{bias, weight}
head.head_series.1.self_attn.out_proj.{bias, weight}
head.head_series.1.self_attn.{in_proj_bias, in_proj_weight}
head.head_series.1.self_attn_post.out_proj.{bias, weight}
head.head_series.1.self_attn_post.{in_proj_bias, in_proj_weight}
rpn_head.rpn_head.anchor_deltas.{bias, weight}
rpn_head.rpn_head.conv.{bias, weight}
rpn_head.rpn_head.objectness_logits.{bias, weight}
rpn_head.rpn_head.proposal_feats.{bias, weight}
rpn_head.rpn_head.scales.0.scale
rpn_head.rpn_head.scales.1.scale
rpn_head.rpn_head.scales.2.scale
rpn_head.rpn_head.scales.3.scale
rpn_head.rpn_head.scales.4.scale
[03/05 11:10:00] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  stem.fc.{bias, weight}
[03/05 11:10:00] d2.engine.train_loop INFO: Starting training from iteration 0
[03/05 11:10:14] d2.utils.events INFO:  eta: 9:12:10  iter: 19  total_loss: 19.47  loss_ce: 1.821  loss_giou: 2.074  loss_bbox: 4.236  loss_ce_0: 1.832  loss_giou_0: 2.085  loss_bbox_0: 4.233  loss_rpn_cls: 1.133  loss_rpn_reg: 1.999  time: 0.6125  last_time: 0.6066  data_time: 0.1265  last_data_time: 0.0104   lr: 5.2025e-06  max_mem: 4604M
[03/05 11:10:24] d2.utils.events INFO:  eta: 9:06:36  iter: 39  total_loss: 18.37  loss_ce: 1.508  loss_giou: 2.045  loss_bbox: 3.902  loss_ce_0: 1.499  loss_giou_0: 2.054  loss_bbox_0: 4.104  loss_rpn_cls: 1.131  loss_rpn_reg: 2  time: 0.5383  last_time: 0.3273  data_time: 0.0151  last_data_time: 0.0156   lr: 1.0152e-05  max_mem: 4724M
[03/05 11:10:30] d2.utils.events INFO:  eta: 6:09:27  iter: 59  total_loss: 17.4  loss_ce: 1.499  loss_giou: 2.197  loss_bbox: 2.778  loss_ce_0: 1.424  loss_giou_0: 2.088  loss_bbox_0: 4.16  loss_rpn_cls: 1.125  loss_rpn_reg: 1.999  time: 0.4665  last_time: 0.2650  data_time: 0.0140  last_data_time: 0.0093   lr: 1.5102e-05  max_mem: 4724M
[03/05 11:10:37] d2.utils.events INFO:  eta: 4:59:53  iter: 79  total_loss: 14.95  loss_ce: 1.486  loss_giou: 1.643  loss_bbox: 2.086  loss_ce_0: 1.457  loss_giou_0: 2.159  loss_bbox_0: 2.889  loss_rpn_cls: 1.117  loss_rpn_reg: 1.999  time: 0.4310  last_time: 0.2838  data_time: 0.0140  last_data_time: 0.0188   lr: 2.0053e-05  max_mem: 4724M
[03/05 11:10:44] d2.utils.events INFO:  eta: 4:54:18  iter: 99  total_loss: 13.49  loss_ce: 1.688  loss_giou: 1.486  loss_bbox: 2.006  loss_ce_0: 1.552  loss_giou_0: 1.439  loss_bbox_0: 1.847  loss_rpn_cls: 1.084  loss_rpn_reg: 1.995  time: 0.4111  last_time: 0.3051  data_time: 0.0134  last_data_time: 0.0145   lr: 2.5002e-05  max_mem: 4724M
[03/05 11:10:51] d2.utils.events INFO:  eta: 4:52:15  iter: 119  total_loss: 11.97  loss_ce: 1.573  loss_giou: 1.366  loss_bbox: 1.765  loss_ce_0: 1.515  loss_giou_0: 1.24  loss_bbox_0: 1.544  loss_rpn_cls: 0.9815  loss_rpn_reg: 1.983  time: 0.3982  last_time: 0.2975  data_time: 0.0113  last_data_time: 0.0141   lr: 2.9953e-05  max_mem: 4724M
[03/05 11:10:57] d2.utils.events INFO:  eta: 4:49:41  iter: 139  total_loss: 11.57  loss_ce: 1.559  loss_giou: 1.338  loss_bbox: 1.852  loss_ce_0: 1.504  loss_giou_0: 1.155  loss_bbox_0: 1.662  loss_rpn_cls: 0.5329  loss_rpn_reg: 1.802  time: 0.3892  last_time: 0.4293  data_time: 0.0115  last_data_time: 0.0117   lr: 3.4902e-05  max_mem: 4724M
[03/05 11:11:04] d2.utils.events INFO:  eta: 4:46:42  iter: 159  total_loss: 10.53  loss_ce: 1.497  loss_giou: 1.272  loss_bbox: 1.486  loss_ce_0: 1.637  loss_giou_0: 1.158  loss_bbox_0: 1.454  loss_rpn_cls: 0.504  loss_rpn_reg: 1.298  time: 0.3813  last_time: 0.2785  data_time: 0.0107  last_data_time: 0.0115   lr: 3.9852e-05  max_mem: 4724M
[03/05 11:11:11] d2.utils.events INFO:  eta: 4:48:47  iter: 179  total_loss: 10.99  loss_ce: 1.516  loss_giou: 1.352  loss_bbox: 1.856  loss_ce_0: 1.504  loss_giou_0: 1.255  loss_bbox_0: 1.696  loss_rpn_cls: 0.5104  loss_rpn_reg: 1.091  time: 0.3772  last_time: 0.4351  data_time: 0.0102  last_data_time: 0.0086   lr: 4.4802e-05  max_mem: 4724M
[03/05 11:11:18] d2.utils.events INFO:  eta: 4:46:18  iter: 199  total_loss: 10.55  loss_ce: 1.431  loss_giou: 1.301  loss_bbox: 1.731  loss_ce_0: 1.448  loss_giou_0: 1.251  loss_bbox_0: 1.47  loss_rpn_cls: 0.5584  loss_rpn_reg: 1.01  time: 0.3725  last_time: 0.4127  data_time: 0.0115  last_data_time: 0.0026   lr: 4.9752e-05  max_mem: 4724M
[03/05 11:11:25] d2.utils.events INFO:  eta: 4:46:22  iter: 219  total_loss: 9.533  loss_ce: 1.469  loss_giou: 1.227  loss_bbox: 1.553  loss_ce_0: 1.513  loss_giou_0: 1.05  loss_bbox_0: 1.37  loss_rpn_cls: 0.5093  loss_rpn_reg: 0.9384  time: 0.3705  last_time: 0.4729  data_time: 0.0117  last_data_time: 0.0120   lr: 5e-05  max_mem: 4724M
[03/05 11:11:31] d2.utils.events INFO:  eta: 4:45:41  iter: 239  total_loss: 9.554  loss_ce: 1.413  loss_giou: 1.216  loss_bbox: 1.606  loss_ce_0: 1.466  loss_giou_0: 1.098  loss_bbox_0: 1.3  loss_rpn_cls: 0.5192  loss_rpn_reg: 0.9189  time: 0.3655  last_time: 0.3199  data_time: 0.0106  last_data_time: 0.0117   lr: 5e-05  max_mem: 4724M
[03/05 11:11:38] d2.utils.events INFO:  eta: 4:45:17  iter: 259  total_loss: 8.781  loss_ce: 1.346  loss_giou: 1.188  loss_bbox: 1.261  loss_ce_0: 1.354  loss_giou_0: 1.085  loss_bbox_0: 1.113  loss_rpn_cls: 0.5431  loss_rpn_reg: 0.8703  time: 0.3637  last_time: 0.3071  data_time: 0.0107  last_data_time: 0.0131   lr: 5e-05  max_mem: 4724M
[03/05 11:11:45] d2.utils.events INFO:  eta: 4:45:31  iter: 279  total_loss: 8.497  loss_ce: 1.357  loss_giou: 1.033  loss_bbox: 1.277  loss_ce_0: 1.296  loss_giou_0: 1.034  loss_bbox_0: 1.124  loss_rpn_cls: 0.5885  loss_rpn_reg: 0.8809  time: 0.3627  last_time: 0.4347  data_time: 0.0105  last_data_time: 0.0111   lr: 5e-05  max_mem: 4724M
[03/05 11:11:52] d2.utils.events INFO:  eta: 4:44:59  iter: 299  total_loss: 8.248  loss_ce: 1.413  loss_giou: 0.9517  loss_bbox: 1.1  loss_ce_0: 1.397  loss_giou_0: 0.9126  loss_bbox_0: 1.032  loss_rpn_cls: 0.5385  loss_rpn_reg: 0.8137  time: 0.3607  last_time: 0.3051  data_time: 0.0123  last_data_time: 0.0132   lr: 5e-05  max_mem: 4724M
[03/05 11:11:59] d2.utils.events INFO:  eta: 4:44:49  iter: 319  total_loss: 8.831  loss_ce: 1.389  loss_giou: 1.19  loss_bbox: 1.182  loss_ce_0: 1.331  loss_giou_0: 1.073  loss_bbox_0: 1.177  loss_rpn_cls: 0.6215  loss_rpn_reg: 0.8474  time: 0.3594  last_time: 0.3169  data_time: 0.0111  last_data_time: 0.0131   lr: 5e-05  max_mem: 4724M
[03/05 11:12:06] d2.utils.events INFO:  eta: 4:44:42  iter: 339  total_loss: 8.422  loss_ce: 1.431  loss_giou: 1.014  loss_bbox: 1.223  loss_ce_0: 1.362  loss_giou_0: 0.9705  loss_bbox_0: 1.263  loss_rpn_cls: 0.5774  loss_rpn_reg: 0.8006  time: 0.3579  last_time: 0.3072  data_time: 0.0111  last_data_time: 0.0118   lr: 5e-05  max_mem: 4724M
[03/05 11:12:13] d2.utils.events INFO:  eta: 4:45:27  iter: 359  total_loss: 8.628  loss_ce: 1.376  loss_giou: 1.213  loss_bbox: 1.385  loss_ce_0: 1.319  loss_giou_0: 1.108  loss_bbox_0: 1.135  loss_rpn_cls: 0.5549  loss_rpn_reg: 0.793  time: 0.3571  last_time: 0.3422  data_time: 0.0104  last_data_time: 0.0070   lr: 5e-05  max_mem: 4724M
[03/05 11:12:20] d2.utils.events INFO:  eta: 4:45:17  iter: 379  total_loss: 8.122  loss_ce: 1.368  loss_giou: 0.9641  loss_bbox: 1.15  loss_ce_0: 1.307  loss_giou_0: 0.8657  loss_bbox_0: 1.009  loss_rpn_cls: 0.5002  loss_rpn_reg: 0.7889  time: 0.3565  last_time: 0.3353  data_time: 0.0093  last_data_time: 0.0115   lr: 5e-05  max_mem: 4724M
[03/05 11:12:27] d2.utils.events INFO:  eta: 4:44:27  iter: 399  total_loss: 7.802  loss_ce: 1.383  loss_giou: 0.9224  loss_bbox: 1.01  loss_ce_0: 1.306  loss_giou_0: 0.8873  loss_bbox_0: 0.9886  loss_rpn_cls: 0.5611  loss_rpn_reg: 0.7609  time: 0.3554  last_time: 0.4433  data_time: 0.0099  last_data_time: 0.0080   lr: 5e-05  max_mem: 4724M
[03/05 11:12:33] d2.utils.events INFO:  eta: 4:44:15  iter: 419  total_loss: 7.888  loss_ce: 1.354  loss_giou: 0.907  loss_bbox: 1.12  loss_ce_0: 1.309  loss_giou_0: 0.8419  loss_bbox_0: 0.9927  loss_rpn_cls: 0.5613  loss_rpn_reg: 0.7531  time: 0.3545  last_time: 0.2893  data_time: 0.0096  last_data_time: 0.0094   lr: 5e-05  max_mem: 4724M
[03/05 11:12:40] d2.utils.events INFO:  eta: 4:44:03  iter: 439  total_loss: 7.943  loss_ce: 1.347  loss_giou: 0.9254  loss_bbox: 1.102  loss_ce_0: 1.288  loss_giou_0: 0.878  loss_bbox_0: 1.004  loss_rpn_cls: 0.5473  loss_rpn_reg: 0.75  time: 0.3529  last_time: 0.2988  data_time: 0.0098  last_data_time: 0.0070   lr: 5e-05  max_mem: 4724M
[03/05 11:12:47] d2.utils.events INFO:  eta: 4:43:52  iter: 459  total_loss: 7.55  loss_ce: 1.311  loss_giou: 0.9799  loss_bbox: 1.053  loss_ce_0: 1.305  loss_giou_0: 0.8943  loss_bbox_0: 0.879  loss_rpn_cls: 0.5542  loss_rpn_reg: 0.787  time: 0.3517  last_time: 0.3219  data_time: 0.0125  last_data_time: 0.0174   lr: 5e-05  max_mem: 4724M
[03/05 11:12:53] d2.utils.events INFO:  eta: 4:43:38  iter: 479  total_loss: 8.101  loss_ce: 1.291  loss_giou: 0.9904  loss_bbox: 1.123  loss_ce_0: 1.226  loss_giou_0: 0.9147  loss_bbox_0: 1.049  loss_rpn_cls: 0.5501  loss_rpn_reg: 0.7465  time: 0.3509  last_time: 0.4283  data_time: 0.0100  last_data_time: 0.0057   lr: 5e-05  max_mem: 4724M
[03/05 11:13:00] d2.utils.events INFO:  eta: 4:43:31  iter: 499  total_loss: 7.627  loss_ce: 1.294  loss_giou: 0.8698  loss_bbox: 1.034  loss_ce_0: 1.267  loss_giou_0: 0.8321  loss_bbox_0: 0.9251  loss_rpn_cls: 0.5321  loss_rpn_reg: 0.7371  time: 0.3505  last_time: 0.3327  data_time: 0.0102  last_data_time: 0.0083   lr: 5e-05  max_mem: 4724M
[03/05 11:13:07] d2.utils.events INFO:  eta: 4:43:39  iter: 519  total_loss: 7.45  loss_ce: 1.285  loss_giou: 0.803  loss_bbox: 0.9829  loss_ce_0: 1.246  loss_giou_0: 0.807  loss_bbox_0: 0.9108  loss_rpn_cls: 0.5298  loss_rpn_reg: 0.7569  time: 0.3507  last_time: 0.3338  data_time: 0.0100  last_data_time: 0.0084   lr: 5e-05  max_mem: 4724M
[03/05 11:13:14] d2.utils.events INFO:  eta: 4:43:32  iter: 539  total_loss: 7.298  loss_ce: 1.307  loss_giou: 0.8351  loss_bbox: 0.9498  loss_ce_0: 1.267  loss_giou_0: 0.8166  loss_bbox_0: 0.8713  loss_rpn_cls: 0.5216  loss_rpn_reg: 0.7445  time: 0.3503  last_time: 0.3429  data_time: 0.0112  last_data_time: 0.0048   lr: 5e-05  max_mem: 4724M
[03/05 11:13:22] d2.utils.events INFO:  eta: 4:43:30  iter: 559  total_loss: 7.53  loss_ce: 1.282  loss_giou: 0.9055  loss_bbox: 1.069  loss_ce_0: 1.244  loss_giou_0: 0.8254  loss_bbox_0: 0.9135  loss_rpn_cls: 0.5149  loss_rpn_reg: 0.7142  time: 0.3505  last_time: 0.3263  data_time: 0.0117  last_data_time: 0.0084   lr: 5e-05  max_mem: 4724M
[03/05 11:13:28] d2.utils.events INFO:  eta: 4:43:26  iter: 579  total_loss: 7.59  loss_ce: 1.307  loss_giou: 0.9342  loss_bbox: 0.9788  loss_ce_0: 1.243  loss_giou_0: 0.888  loss_bbox_0: 0.9293  loss_rpn_cls: 0.548  loss_rpn_reg: 0.7763  time: 0.3500  last_time: 0.3255  data_time: 0.0110  last_data_time: 0.0122   lr: 5e-05  max_mem: 4724M
[03/05 11:13:35] d2.utils.events INFO:  eta: 4:43:13  iter: 599  total_loss: 7.572  loss_ce: 1.264  loss_giou: 0.9204  loss_bbox: 0.9895  loss_ce_0: 1.223  loss_giou_0: 0.8945  loss_bbox_0: 0.9978  loss_rpn_cls: 0.5521  loss_rpn_reg: 0.7373  time: 0.3491  last_time: 0.3179  data_time: 0.0108  last_data_time: 0.0082   lr: 5e-05  max_mem: 4724M
[03/05 11:13:42] d2.utils.events INFO:  eta: 4:43:02  iter: 619  total_loss: 7.44  loss_ce: 1.19  loss_giou: 0.9706  loss_bbox: 0.9623  loss_ce_0: 1.185  loss_giou_0: 0.9072  loss_bbox_0: 0.8677  loss_rpn_cls: 0.4823  loss_rpn_reg: 0.7497  time: 0.3488  last_time: 0.3272  data_time: 0.0097  last_data_time: 0.0088   lr: 5e-05  max_mem: 4724M
[03/05 11:13:48] d2.utils.events INFO:  eta: 4:42:30  iter: 639  total_loss: 7.402  loss_ce: 1.217  loss_giou: 0.8955  loss_bbox: 0.9138  loss_ce_0: 1.177  loss_giou_0: 0.8779  loss_bbox_0: 0.8679  loss_rpn_cls: 0.5253  loss_rpn_reg: 0.7655  time: 0.3480  last_time: 0.2794  data_time: 0.0102  last_data_time: 0.0084   lr: 5e-05  max_mem: 4724M
[03/05 11:13:55] d2.utils.events INFO:  eta: 4:42:40  iter: 659  total_loss: 6.995  loss_ce: 1.256  loss_giou: 0.8794  loss_bbox: 0.8496  loss_ce_0: 1.222  loss_giou_0: 0.8888  loss_bbox_0: 0.8638  loss_rpn_cls: 0.5141  loss_rpn_reg: 0.7292  time: 0.3476  last_time: 0.3268  data_time: 0.0112  last_data_time: 0.0163   lr: 5e-05  max_mem: 4724M
[03/05 11:14:02] d2.utils.events INFO:  eta: 4:42:18  iter: 679  total_loss: 7.635  loss_ce: 1.249  loss_giou: 0.9114  loss_bbox: 1.045  loss_ce_0: 1.243  loss_giou_0: 0.8558  loss_bbox_0: 0.9878  loss_rpn_cls: 0.5445  loss_rpn_reg: 0.7584  time: 0.3466  last_time: 0.3221  data_time: 0.0101  last_data_time: 0.0113   lr: 5e-05  max_mem: 4724M
[03/05 11:14:09] d2.utils.events INFO:  eta: 4:42:16  iter: 699  total_loss: 7.105  loss_ce: 1.193  loss_giou: 0.8821  loss_bbox: 0.9071  loss_ce_0: 1.166  loss_giou_0: 0.8566  loss_bbox_0: 0.8946  loss_rpn_cls: 0.4951  loss_rpn_reg: 0.7486  time: 0.3465  last_time: 0.3354  data_time: 0.0109  last_data_time: 0.0150   lr: 5e-05  max_mem: 4724M
[03/05 11:14:16] d2.utils.events INFO:  eta: 4:42:15  iter: 719  total_loss: 6.944  loss_ce: 1.208  loss_giou: 0.817  loss_bbox: 0.8722  loss_ce_0: 1.179  loss_giou_0: 0.7717  loss_bbox_0: 0.8397  loss_rpn_cls: 0.4964  loss_rpn_reg: 0.7213  time: 0.3466  last_time: 0.3276  data_time: 0.0117  last_data_time: 0.0073   lr: 5e-05  max_mem: 4724M
[03/05 11:14:23] d2.utils.events INFO:  eta: 4:42:29  iter: 739  total_loss: 7.103  loss_ce: 1.166  loss_giou: 0.8533  loss_bbox: 0.9229  loss_ce_0: 1.131  loss_giou_0: 0.8202  loss_bbox_0: 0.8833  loss_rpn_cls: 0.469  loss_rpn_reg: 0.7257  time: 0.3472  last_time: 0.2959  data_time: 0.0121  last_data_time: 0.0101   lr: 5e-05  max_mem: 4724M
[03/05 11:14:30] d2.utils.events INFO:  eta: 4:42:32  iter: 759  total_loss: 6.763  loss_ce: 1.244  loss_giou: 0.8006  loss_bbox: 0.8711  loss_ce_0: 1.179  loss_giou_0: 0.7761  loss_bbox_0: 0.8469  loss_rpn_cls: 0.486  loss_rpn_reg: 0.7149  time: 0.3472  last_time: 0.2835  data_time: 0.0111  last_data_time: 0.0093   lr: 5e-05  max_mem: 4724M
[03/05 11:14:37] d2.utils.events INFO:  eta: 4:42:22  iter: 779  total_loss: 6.781  loss_ce: 1.197  loss_giou: 0.7761  loss_bbox: 0.8597  loss_ce_0: 1.11  loss_giou_0: 0.7355  loss_bbox_0: 0.8333  loss_rpn_cls: 0.4603  loss_rpn_reg: 0.6535  time: 0.3465  last_time: 0.3147  data_time: 0.0092  last_data_time: 0.0112   lr: 5e-05  max_mem: 4724M
[03/05 11:14:44] d2.utils.events INFO:  eta: 4:42:20  iter: 799  total_loss: 6.865  loss_ce: 1.118  loss_giou: 0.8029  loss_bbox: 0.8449  loss_ce_0: 1.094  loss_giou_0: 0.7735  loss_bbox_0: 0.872  loss_rpn_cls: 0.5405  loss_rpn_reg: 0.7673  time: 0.3465  last_time: 0.3380  data_time: 0.0101  last_data_time: 0.0101   lr: 5e-05  max_mem: 4724M
[03/05 11:14:51] d2.utils.events INFO:  eta: 4:42:13  iter: 819  total_loss: 7.469  loss_ce: 1.224  loss_giou: 0.8664  loss_bbox: 0.9397  loss_ce_0: 1.201  loss_giou_0: 0.8518  loss_bbox_0: 0.9255  loss_rpn_cls: 0.5466  loss_rpn_reg: 0.7306  time: 0.3464  last_time: 0.3000  data_time: 0.0095  last_data_time: 0.0107   lr: 5e-05  max_mem: 4724M
[03/05 11:14:58] d2.utils.events INFO:  eta: 4:42:15  iter: 839  total_loss: 6.71  loss_ce: 1.163  loss_giou: 0.817  loss_bbox: 0.814  loss_ce_0: 1.11  loss_giou_0: 0.8151  loss_bbox_0: 0.7694  loss_rpn_cls: 0.5023  loss_rpn_reg: 0.7093  time: 0.3461  last_time: 0.3068  data_time: 0.0109  last_data_time: 0.0152   lr: 5e-05  max_mem: 4724M
[03/05 11:15:05] d2.utils.events INFO:  eta: 4:42:09  iter: 859  total_loss: 6.506  loss_ce: 1.182  loss_giou: 0.744  loss_bbox: 0.8139  loss_ce_0: 1.121  loss_giou_0: 0.7399  loss_bbox_0: 0.7663  loss_rpn_cls: 0.4758  loss_rpn_reg: 0.6525  time: 0.3465  last_time: 0.3101  data_time: 0.0112  last_data_time: 0.0080   lr: 5e-05  max_mem: 4724M
[03/05 11:15:11] d2.utils.events INFO:  eta: 4:41:51  iter: 879  total_loss: 7.016  loss_ce: 1.112  loss_giou: 0.939  loss_bbox: 0.823  loss_ce_0: 1.082  loss_giou_0: 0.8842  loss_bbox_0: 0.7853  loss_rpn_cls: 0.5336  loss_rpn_reg: 0.7227  time: 0.3457  last_time: 0.3327  data_time: 0.0107  last_data_time: 0.0127   lr: 5e-05  max_mem: 4724M
[03/05 11:15:18] d2.utils.events INFO:  eta: 4:41:48  iter: 899  total_loss: 6.605  loss_ce: 1.11  loss_giou: 0.8377  loss_bbox: 0.8449  loss_ce_0: 1.068  loss_giou_0: 0.8153  loss_bbox_0: 0.7845  loss_rpn_cls: 0.5178  loss_rpn_reg: 0.6922  time: 0.3456  last_time: 0.3299  data_time: 0.0103  last_data_time: 0.0143   lr: 5e-05  max_mem: 4724M
[03/05 11:15:25] d2.utils.events INFO:  eta: 4:41:59  iter: 919  total_loss: 7.114  loss_ce: 1.143  loss_giou: 0.8877  loss_bbox: 1.054  loss_ce_0: 1.103  loss_giou_0: 0.8332  loss_bbox_0: 0.8634  loss_rpn_cls: 0.4885  loss_rpn_reg: 0.7312  time: 0.3458  last_time: 0.3026  data_time: 0.0111  last_data_time: 0.0087   lr: 5e-05  max_mem: 4724M
[03/05 11:15:33] d2.utils.events INFO:  eta: 4:42:11  iter: 939  total_loss: 6.927  loss_ce: 1.117  loss_giou: 0.8191  loss_bbox: 0.8934  loss_ce_0: 1.088  loss_giou_0: 0.8096  loss_bbox_0: 0.9099  loss_rpn_cls: 0.4698  loss_rpn_reg: 0.7201  time: 0.3461  last_time: 0.3091  data_time: 0.0124  last_data_time: 0.0223   lr: 5e-05  max_mem: 4724M
[03/05 11:15:39] d2.utils.events INFO:  eta: 4:42:05  iter: 959  total_loss: 6.374  loss_ce: 1.094  loss_giou: 0.7874  loss_bbox: 0.815  loss_ce_0: 1.055  loss_giou_0: 0.7152  loss_bbox_0: 0.7594  loss_rpn_cls: 0.4807  loss_rpn_reg: 0.6971  time: 0.3459  last_time: 0.4328  data_time: 0.0121  last_data_time: 0.0123   lr: 5e-05  max_mem: 4724M
[03/05 11:15:46] d2.utils.events INFO:  eta: 4:41:30  iter: 979  total_loss: 6.957  loss_ce: 1.108  loss_giou: 0.8563  loss_bbox: 0.8563  loss_ce_0: 1.077  loss_giou_0: 0.8159  loss_bbox_0: 0.8614  loss_rpn_cls: 0.5049  loss_rpn_reg: 0.709  time: 0.3454  last_time: 0.2847  data_time: 0.0104  last_data_time: 0.0067   lr: 5e-05  max_mem: 4724M
[03/05 11:15:53] d2.utils.events INFO:  eta: 4:41:12  iter: 999  total_loss: 6.487  loss_ce: 1.092  loss_giou: 0.7646  loss_bbox: 0.7943  loss_ce_0: 1.045  loss_giou_0: 0.7819  loss_bbox_0: 0.7215  loss_rpn_cls: 0.4565  loss_rpn_reg: 0.7153  time: 0.3450  last_time: 0.3567  data_time: 0.0098  last_data_time: 0.0113   lr: 5e-05  max_mem: 4724M
[03/05 11:15:59] d2.utils.events INFO:  eta: 4:40:54  iter: 1019  total_loss: 6.412  loss_ce: 1.152  loss_giou: 0.811  loss_bbox: 0.8414  loss_ce_0: 1.088  loss_giou_0: 0.7827  loss_bbox_0: 0.7668  loss_rpn_cls: 0.4632  loss_rpn_reg: 0.6694  time: 0.3449  last_time: 0.3201  data_time: 0.0133  last_data_time: 0.0086   lr: 5e-05  max_mem: 4724M
[03/05 11:16:07] d2.utils.events INFO:  eta: 4:40:38  iter: 1039  total_loss: 6.914  loss_ce: 1.17  loss_giou: 0.7877  loss_bbox: 0.9322  loss_ce_0: 1.149  loss_giou_0: 0.7508  loss_bbox_0: 0.9  loss_rpn_cls: 0.4568  loss_rpn_reg: 0.7392  time: 0.3450  last_time: 0.3339  data_time: 0.0124  last_data_time: 0.0125   lr: 5e-05  max_mem: 4724M
[03/05 11:16:14] d2.utils.events INFO:  eta: 4:40:30  iter: 1059  total_loss: 6.671  loss_ce: 1.084  loss_giou: 0.9042  loss_bbox: 0.8962  loss_ce_0: 1.01  loss_giou_0: 0.8685  loss_bbox_0: 0.8236  loss_rpn_cls: 0.474  loss_rpn_reg: 0.7013  time: 0.3450  last_time: 0.3110  data_time: 0.0120  last_data_time: 0.0166   lr: 5e-05  max_mem: 4724M
[03/05 11:16:20] d2.utils.events INFO:  eta: 4:40:20  iter: 1079  total_loss: 6.118  loss_ce: 1.105  loss_giou: 0.7585  loss_bbox: 0.7629  loss_ce_0: 1.073  loss_giou_0: 0.7504  loss_bbox_0: 0.7355  loss_rpn_cls: 0.4921  loss_rpn_reg: 0.6911  time: 0.3446  last_time: 0.3198  data_time: 0.0117  last_data_time: 0.0217   lr: 5e-05  max_mem: 4724M
[03/05 11:16:27] d2.utils.events INFO:  eta: 4:40:24  iter: 1099  total_loss: 6.245  loss_ce: 1.088  loss_giou: 0.73  loss_bbox: 0.7505  loss_ce_0: 1.065  loss_giou_0: 0.7379  loss_bbox_0: 0.7166  loss_rpn_cls: 0.4875  loss_rpn_reg: 0.6621  time: 0.3447  last_time: 0.2933  data_time: 0.0102  last_data_time: 0.0036   lr: 5e-05  max_mem: 4724M
[03/05 11:16:34] d2.utils.events INFO:  eta: 4:40:18  iter: 1119  total_loss: 6.419  loss_ce: 1.075  loss_giou: 0.8198  loss_bbox: 0.7301  loss_ce_0: 1.052  loss_giou_0: 0.812  loss_bbox_0: 0.7733  loss_rpn_cls: 0.4701  loss_rpn_reg: 0.6915  time: 0.3445  last_time: 0.2985  data_time: 0.0105  last_data_time: 0.0075   lr: 5e-05  max_mem: 4724M
[03/05 11:16:41] d2.utils.events INFO:  eta: 4:40:08  iter: 1139  total_loss: 6.132  loss_ce: 1.105  loss_giou: 0.7538  loss_bbox: 0.7303  loss_ce_0: 1.03  loss_giou_0: 0.7422  loss_bbox_0: 0.7118  loss_rpn_cls: 0.4428  loss_rpn_reg: 0.7022  time: 0.3441  last_time: 0.3065  data_time: 0.0121  last_data_time: 0.0229   lr: 5e-05  max_mem: 4724M
[03/05 11:16:48] d2.utils.events INFO:  eta: 4:40:17  iter: 1159  total_loss: 6.249  loss_ce: 1.076  loss_giou: 0.7577  loss_bbox: 0.7467  loss_ce_0: 0.9975  loss_giou_0: 0.7097  loss_bbox_0: 0.7078  loss_rpn_cls: 0.4495  loss_rpn_reg: 0.6818  time: 0.3442  last_time: 0.4062  data_time: 0.0109  last_data_time: 0.0100   lr: 5e-05  max_mem: 4724M
[03/05 11:16:54] d2.utils.events INFO:  eta: 4:40:05  iter: 1179  total_loss: 6.863  loss_ce: 1.085  loss_giou: 0.9377  loss_bbox: 0.8061  loss_ce_0: 1.027  loss_giou_0: 0.9215  loss_bbox_0: 0.808  loss_rpn_cls: 0.5003  loss_rpn_reg: 0.6975  time: 0.3438  last_time: 0.3287  data_time: 0.0111  last_data_time: 0.0125   lr: 5e-05  max_mem: 4724M
[03/05 11:17:01] d2.utils.events INFO:  eta: 4:40:27  iter: 1199  total_loss: 6.357  loss_ce: 1.089  loss_giou: 0.7005  loss_bbox: 0.7744  loss_ce_0: 1.071  loss_giou_0: 0.698  loss_bbox_0: 0.8225  loss_rpn_cls: 0.4553  loss_rpn_reg: 0.7042  time: 0.3439  last_time: 0.3535  data_time: 0.0115  last_data_time: 0.0169   lr: 5e-05  max_mem: 4724M
[03/05 11:17:09] d2.utils.events INFO:  eta: 4:40:14  iter: 1219  total_loss: 5.981  loss_ce: 1.092  loss_giou: 0.6182  loss_bbox: 0.7125  loss_ce_0: 1.033  loss_giou_0: 0.6314  loss_bbox_0: 0.685  loss_rpn_cls: 0.4747  loss_rpn_reg: 0.6789  time: 0.3442  last_time: 0.2854  data_time: 0.0112  last_data_time: 0.0152   lr: 5e-05  max_mem: 4724M
[03/05 11:17:15] d2.utils.events INFO:  eta: 4:40:30  iter: 1239  total_loss: 6.152  loss_ce: 1.114  loss_giou: 0.7591  loss_bbox: 0.7402  loss_ce_0: 1.032  loss_giou_0: 0.743  loss_bbox_0: 0.7149  loss_rpn_cls: 0.4587  loss_rpn_reg: 0.6679  time: 0.3440  last_time: 0.3562  data_time: 0.0101  last_data_time: 0.0029   lr: 5e-05  max_mem: 4724M
[03/05 11:17:22] d2.utils.events INFO:  eta: 4:40:29  iter: 1259  total_loss: 6.351  loss_ce: 1.025  loss_giou: 0.7403  loss_bbox: 0.8227  loss_ce_0: 0.9976  loss_giou_0: 0.7432  loss_bbox_0: 0.7651  loss_rpn_cls: 0.4542  loss_rpn_reg: 0.6784  time: 0.3439  last_time: 0.2978  data_time: 0.0103  last_data_time: 0.0188   lr: 5e-05  max_mem: 4724M
[03/05 11:17:29] d2.utils.events INFO:  eta: 4:40:23  iter: 1279  total_loss: 6.151  loss_ce: 1.031  loss_giou: 0.7592  loss_bbox: 0.7391  loss_ce_0: 0.9692  loss_giou_0: 0.7432  loss_bbox_0: 0.7515  loss_rpn_cls: 0.4549  loss_rpn_reg: 0.6833  time: 0.3440  last_time: 0.3345  data_time: 0.0101  last_data_time: 0.0133   lr: 5e-05  max_mem: 4724M
[03/05 11:17:36] d2.utils.events INFO:  eta: 4:40:20  iter: 1299  total_loss: 5.855  loss_ce: 1.013  loss_giou: 0.7845  loss_bbox: 0.614  loss_ce_0: 0.9575  loss_giou_0: 0.7696  loss_bbox_0: 0.6318  loss_rpn_cls: 0.4585  loss_rpn_reg: 0.6737  time: 0.3440  last_time: 0.3201  data_time: 0.0102  last_data_time: 0.0122   lr: 5e-05  max_mem: 4724M
[03/05 11:17:43] d2.utils.events INFO:  eta: 4:40:17  iter: 1319  total_loss: 6.144  loss_ce: 1.005  loss_giou: 0.7894  loss_bbox: 0.7506  loss_ce_0: 0.9583  loss_giou_0: 0.7528  loss_bbox_0: 0.748  loss_rpn_cls: 0.4369  loss_rpn_reg: 0.7357  time: 0.3438  last_time: 0.4284  data_time: 0.0126  last_data_time: 0.0153   lr: 5e-05  max_mem: 4724M
[03/05 11:17:50] d2.utils.events INFO:  eta: 4:40:11  iter: 1339  total_loss: 5.98  loss_ce: 0.9963  loss_giou: 0.6967  loss_bbox: 0.7248  loss_ce_0: 0.9955  loss_giou_0: 0.6781  loss_bbox_0: 0.7219  loss_rpn_cls: 0.4078  loss_rpn_reg: 0.6782  time: 0.3438  last_time: 0.3170  data_time: 0.0105  last_data_time: 0.0083   lr: 5e-05  max_mem: 4724M
[03/05 11:17:57] d2.utils.events INFO:  eta: 4:39:59  iter: 1359  total_loss: 5.721  loss_ce: 1.034  loss_giou: 0.7056  loss_bbox: 0.6267  loss_ce_0: 0.9666  loss_giou_0: 0.7101  loss_bbox_0: 0.6288  loss_rpn_cls: 0.4538  loss_rpn_reg: 0.6578  time: 0.3437  last_time: 0.3283  data_time: 0.0111  last_data_time: 0.0104   lr: 5e-05  max_mem: 4724M
[03/05 11:18:04] d2.utils.events INFO:  eta: 4:39:56  iter: 1379  total_loss: 6.103  loss_ce: 1.052  loss_giou: 0.6973  loss_bbox: 0.7821  loss_ce_0: 1.003  loss_giou_0: 0.6792  loss_bbox_0: 0.7458  loss_rpn_cls: 0.4404  loss_rpn_reg: 0.6886  time: 0.3436  last_time: 0.3025  data_time: 0.0123  last_data_time: 0.0099   lr: 5e-05  max_mem: 4724M
[03/05 11:18:10] d2.utils.events INFO:  eta: 4:39:54  iter: 1399  total_loss: 5.982  loss_ce: 1.038  loss_giou: 0.6469  loss_bbox: 0.6994  loss_ce_0: 0.9845  loss_giou_0: 0.6433  loss_bbox_0: 0.7143  loss_rpn_cls: 0.4575  loss_rpn_reg: 0.6998  time: 0.3435  last_time: 0.3003  data_time: 0.0113  last_data_time: 0.0104   lr: 5e-05  max_mem: 4724M
[03/05 11:18:17] d2.utils.events INFO:  eta: 4:39:55  iter: 1419  total_loss: 5.763  loss_ce: 1.029  loss_giou: 0.6876  loss_bbox: 0.6578  loss_ce_0: 1.033  loss_giou_0: 0.727  loss_bbox_0: 0.6543  loss_rpn_cls: 0.4366  loss_rpn_reg: 0.6845  time: 0.3434  last_time: 0.2825  data_time: 0.0102  last_data_time: 0.0082   lr: 5e-05  max_mem: 4724M
[03/05 11:18:24] d2.utils.events INFO:  eta: 4:39:53  iter: 1439  total_loss: 5.88  loss_ce: 1.004  loss_giou: 0.6856  loss_bbox: 0.683  loss_ce_0: 0.9792  loss_giou_0: 0.6808  loss_bbox_0: 0.6435  loss_rpn_cls: 0.4195  loss_rpn_reg: 0.6757  time: 0.3435  last_time: 0.4449  data_time: 0.0107  last_data_time: 0.0123   lr: 5e-05  max_mem: 4724M
[03/05 11:18:31] d2.utils.events INFO:  eta: 4:39:51  iter: 1459  total_loss: 6.17  loss_ce: 1.057  loss_giou: 0.7117  loss_bbox: 0.7303  loss_ce_0: 0.9935  loss_giou_0: 0.6974  loss_bbox_0: 0.6959  loss_rpn_cls: 0.4464  loss_rpn_reg: 0.6834  time: 0.3433  last_time: 0.3407  data_time: 0.0102  last_data_time: 0.0089   lr: 5e-05  max_mem: 4724M
[03/05 11:18:38] d2.utils.events INFO:  eta: 4:39:46  iter: 1479  total_loss: 5.812  loss_ce: 1.04  loss_giou: 0.6831  loss_bbox: 0.611  loss_ce_0: 1.003  loss_giou_0: 0.7292  loss_bbox_0: 0.6408  loss_rpn_cls: 0.4665  loss_rpn_reg: 0.6632  time: 0.3430  last_time: 0.3012  data_time: 0.0093  last_data_time: 0.0070   lr: 5e-05  max_mem: 4724M
[03/05 11:18:45] d2.utils.events INFO:  eta: 4:40:03  iter: 1499  total_loss: 6.283  loss_ce: 1.052  loss_giou: 0.7459  loss_bbox: 0.6961  loss_ce_0: 1.03  loss_giou_0: 0.7247  loss_bbox_0: 0.7196  loss_rpn_cls: 0.463  loss_rpn_reg: 0.6569  time: 0.3431  last_time: 0.3938  data_time: 0.0097  last_data_time: 0.0102   lr: 5e-05  max_mem: 4724M
[03/05 11:18:51] d2.utils.events INFO:  eta: 4:39:41  iter: 1519  total_loss: 5.942  loss_ce: 1.089  loss_giou: 0.6792  loss_bbox: 0.6804  loss_ce_0: 1.039  loss_giou_0: 0.6805  loss_bbox_0: 0.6791  loss_rpn_cls: 0.4493  loss_rpn_reg: 0.6804  time: 0.3430  last_time: 0.3042  data_time: 0.0093  last_data_time: 0.0072   lr: 5e-05  max_mem: 4724M
[03/05 11:18:58] d2.utils.events INFO:  eta: 4:39:14  iter: 1539  total_loss: 5.732  loss_ce: 1.054  loss_giou: 0.6322  loss_bbox: 0.5527  loss_ce_0: 1.007  loss_giou_0: 0.6628  loss_bbox_0: 0.5977  loss_rpn_cls: 0.4277  loss_rpn_reg: 0.6601  time: 0.3426  last_time: 0.3331  data_time: 0.0108  last_data_time: 0.0169   lr: 5e-05  max_mem: 4724M
[03/05 11:19:05] d2.utils.events INFO:  eta: 4:39:07  iter: 1559  total_loss: 5.863  loss_ce: 0.9797  loss_giou: 0.6415  loss_bbox: 0.603  loss_ce_0: 0.9415  loss_giou_0: 0.6816  loss_bbox_0: 0.6853  loss_rpn_cls: 0.4368  loss_rpn_reg: 0.6904  time: 0.3425  last_time: 0.3183  data_time: 0.0102  last_data_time: 0.0117   lr: 5e-05  max_mem: 4724M
[03/05 11:19:12] d2.utils.events INFO:  eta: 4:39:02  iter: 1579  total_loss: 5.778  loss_ce: 0.9729  loss_giou: 0.6717  loss_bbox: 0.6457  loss_ce_0: 0.9514  loss_giou_0: 0.7117  loss_bbox_0: 0.7107  loss_rpn_cls: 0.4553  loss_rpn_reg: 0.6922  time: 0.3426  last_time: 0.2841  data_time: 0.0094  last_data_time: 0.0055   lr: 5e-05  max_mem: 4724M
[03/05 11:19:18] d2.utils.events INFO:  eta: 4:39:11  iter: 1599  total_loss: 5.617  loss_ce: 0.9882  loss_giou: 0.6635  loss_bbox: 0.6259  loss_ce_0: 0.9607  loss_giou_0: 0.6699  loss_bbox_0: 0.6559  loss_rpn_cls: 0.4051  loss_rpn_reg: 0.6602  time: 0.3424  last_time: 0.3313  data_time: 0.0105  last_data_time: 0.0082   lr: 5e-05  max_mem: 4724M
[03/05 11:19:25] d2.utils.events INFO:  eta: 4:39:05  iter: 1619  total_loss: 5.86  loss_ce: 1.015  loss_giou: 0.6963  loss_bbox: 0.7082  loss_ce_0: 0.9873  loss_giou_0: 0.69  loss_bbox_0: 0.7199  loss_rpn_cls: 0.4037  loss_rpn_reg: 0.6777  time: 0.3422  last_time: 0.3192  data_time: 0.0103  last_data_time: 0.0100   lr: 5e-05  max_mem: 4724M
[03/05 11:19:32] d2.utils.events INFO:  eta: 4:39:22  iter: 1639  total_loss: 5.38  loss_ce: 0.9795  loss_giou: 0.5836  loss_bbox: 0.6651  loss_ce_0: 0.9173  loss_giou_0: 0.5926  loss_bbox_0: 0.6897  loss_rpn_cls: 0.3931  loss_rpn_reg: 0.6427  time: 0.3421  last_time: 0.2986  data_time: 0.0090  last_data_time: 0.0065   lr: 5e-05  max_mem: 4724M
[03/05 11:19:39] d2.utils.events INFO:  eta: 4:39:15  iter: 1659  total_loss: 5.553  loss_ce: 0.987  loss_giou: 0.6303  loss_bbox: 0.5767  loss_ce_0: 0.9611  loss_giou_0: 0.6513  loss_bbox_0: 0.6312  loss_rpn_cls: 0.4181  loss_rpn_reg: 0.662  time: 0.3421  last_time: 0.2966  data_time: 0.0124  last_data_time: 0.0090   lr: 5e-05  max_mem: 4724M
[03/05 11:19:45] d2.utils.events INFO:  eta: 4:39:10  iter: 1679  total_loss: 5.872  loss_ce: 0.9777  loss_giou: 0.7353  loss_bbox: 0.6661  loss_ce_0: 0.9417  loss_giou_0: 0.7583  loss_bbox_0: 0.6608  loss_rpn_cls: 0.4379  loss_rpn_reg: 0.6613  time: 0.3419  last_time: 0.3159  data_time: 0.0109  last_data_time: 0.0051   lr: 5e-05  max_mem: 4724M
[03/05 11:19:52] d2.utils.events INFO:  eta: 4:38:59  iter: 1699  total_loss: 5.645  loss_ce: 0.9904  loss_giou: 0.6696  loss_bbox: 0.634  loss_ce_0: 0.9687  loss_giou_0: 0.6591  loss_bbox_0: 0.656  loss_rpn_cls: 0.4171  loss_rpn_reg: 0.6741  time: 0.3417  last_time: 0.2893  data_time: 0.0099  last_data_time: 0.0127   lr: 5e-05  max_mem: 4724M
[03/05 11:19:59] d2.utils.events INFO:  eta: 4:38:44  iter: 1719  total_loss: 5.384  loss_ce: 0.9252  loss_giou: 0.6431  loss_bbox: 0.6352  loss_ce_0: 0.901  loss_giou_0: 0.6409  loss_bbox_0: 0.6405  loss_rpn_cls: 0.4286  loss_rpn_reg: 0.624  time: 0.3416  last_time: 0.3136  data_time: 0.0110  last_data_time: 0.0081   lr: 5e-05  max_mem: 4724M
[03/05 11:20:06] d2.utils.events INFO:  eta: 4:38:22  iter: 1739  total_loss: 5.648  loss_ce: 0.9334  loss_giou: 0.6406  loss_bbox: 0.6891  loss_ce_0: 0.93  loss_giou_0: 0.6541  loss_bbox_0: 0.6906  loss_rpn_cls: 0.4241  loss_rpn_reg: 0.6209  time: 0.3419  last_time: 0.3134  data_time: 0.0115  last_data_time: 0.0107   lr: 5e-05  max_mem: 4724M
[03/05 11:20:13] d2.utils.events INFO:  eta: 4:38:02  iter: 1759  total_loss: 5.553  loss_ce: 0.9129  loss_giou: 0.6396  loss_bbox: 0.6601  loss_ce_0: 0.9021  loss_giou_0: 0.6525  loss_bbox_0: 0.6599  loss_rpn_cls: 0.4371  loss_rpn_reg: 0.6519  time: 0.3418  last_time: 0.3314  data_time: 0.0107  last_data_time: 0.0147   lr: 5e-05  max_mem: 4724M
[03/05 11:20:19] d2.utils.events INFO:  eta: 4:37:54  iter: 1779  total_loss: 5.586  loss_ce: 0.9201  loss_giou: 0.6611  loss_bbox: 0.7053  loss_ce_0: 0.8706  loss_giou_0: 0.6515  loss_bbox_0: 0.7081  loss_rpn_cls: 0.4206  loss_rpn_reg: 0.6612  time: 0.3415  last_time: 0.3061  data_time: 0.0111  last_data_time: 0.0224   lr: 5e-05  max_mem: 4724M
[03/05 11:20:26] d2.utils.events INFO:  eta: 4:37:43  iter: 1799  total_loss: 5.418  loss_ce: 0.9926  loss_giou: 0.6319  loss_bbox: 0.5999  loss_ce_0: 0.9302  loss_giou_0: 0.6101  loss_bbox_0: 0.6215  loss_rpn_cls: 0.3913  loss_rpn_reg: 0.6457  time: 0.3416  last_time: 0.4343  data_time: 0.0111  last_data_time: 0.0162   lr: 5e-05  max_mem: 4724M
[03/05 11:20:33] d2.utils.events INFO:  eta: 4:37:39  iter: 1819  total_loss: 5.7  loss_ce: 1.004  loss_giou: 0.6469  loss_bbox: 0.6555  loss_ce_0: 0.9429  loss_giou_0: 0.6793  loss_bbox_0: 0.6369  loss_rpn_cls: 0.4054  loss_rpn_reg: 0.6685  time: 0.3417  last_time: 0.3041  data_time: 0.0095  last_data_time: 0.0079   lr: 5e-05  max_mem: 4724M
[03/05 11:20:40] d2.utils.events INFO:  eta: 4:37:25  iter: 1839  total_loss: 5.283  loss_ce: 0.9306  loss_giou: 0.6001  loss_bbox: 0.6144  loss_ce_0: 0.8995  loss_giou_0: 0.6107  loss_bbox_0: 0.6187  loss_rpn_cls: 0.4127  loss_rpn_reg: 0.6556  time: 0.3416  last_time: 0.2887  data_time: 0.0117  last_data_time: 0.0071   lr: 5e-05  max_mem: 4724M
[03/05 11:20:47] d2.utils.events INFO:  eta: 4:37:11  iter: 1859  total_loss: 5.63  loss_ce: 0.9949  loss_giou: 0.6659  loss_bbox: 0.6681  loss_ce_0: 0.9319  loss_giou_0: 0.663  loss_bbox_0: 0.6538  loss_rpn_cls: 0.417  loss_rpn_reg: 0.6584  time: 0.3416  last_time: 0.3271  data_time: 0.0129  last_data_time: 0.0069   lr: 5e-05  max_mem: 4724M
[03/05 11:20:54] d2.utils.events INFO:  eta: 4:37:18  iter: 1879  total_loss: 5.662  loss_ce: 0.9459  loss_giou: 0.7043  loss_bbox: 0.6384  loss_ce_0: 0.919  loss_giou_0: 0.7324  loss_bbox_0: 0.6534  loss_rpn_cls: 0.4493  loss_rpn_reg: 0.6615  time: 0.3417  last_time: 0.2850  data_time: 0.0114  last_data_time: 0.0095   lr: 5e-05  max_mem: 4724M
[03/05 11:21:01] d2.utils.events INFO:  eta: 4:37:12  iter: 1899  total_loss: 5.464  loss_ce: 0.961  loss_giou: 0.6031  loss_bbox: 0.6455  loss_ce_0: 0.9098  loss_giou_0: 0.6063  loss_bbox_0: 0.6418  loss_rpn_cls: 0.3954  loss_rpn_reg: 0.6509  time: 0.3417  last_time: 0.3308  data_time: 0.0113  last_data_time: 0.0065   lr: 5e-05  max_mem: 4724M
[03/05 11:21:08] d2.utils.events INFO:  eta: 4:37:02  iter: 1919  total_loss: 5.675  loss_ce: 0.978  loss_giou: 0.7299  loss_bbox: 0.6593  loss_ce_0: 0.9255  loss_giou_0: 0.699  loss_bbox_0: 0.6372  loss_rpn_cls: 0.4198  loss_rpn_reg: 0.6713  time: 0.3416  last_time: 0.2869  data_time: 0.0122  last_data_time: 0.0074   lr: 5e-05  max_mem: 4724M
[03/05 11:21:15] d2.utils.events INFO:  eta: 4:36:50  iter: 1939  total_loss: 5.484  loss_ce: 0.9224  loss_giou: 0.6662  loss_bbox: 0.6245  loss_ce_0: 0.8881  loss_giou_0: 0.643  loss_bbox_0: 0.6357  loss_rpn_cls: 0.4028  loss_rpn_reg: 0.6535  time: 0.3416  last_time: 0.3793  data_time: 0.0106  last_data_time: 0.0085   lr: 5e-05  max_mem: 4724M
[03/05 11:21:22] d2.utils.events INFO:  eta: 4:36:37  iter: 1959  total_loss: 5.517  loss_ce: 0.9611  loss_giou: 0.6556  loss_bbox: 0.5747  loss_ce_0: 0.9096  loss_giou_0: 0.6557  loss_bbox_0: 0.6563  loss_rpn_cls: 0.4286  loss_rpn_reg: 0.676  time: 0.3415  last_time: 0.3196  data_time: 0.0112  last_data_time: 0.0092   lr: 5e-05  max_mem: 4724M
[03/05 11:21:29] d2.utils.events INFO:  eta: 4:36:41  iter: 1979  total_loss: 5.712  loss_ce: 0.9526  loss_giou: 0.5939  loss_bbox: 0.6174  loss_ce_0: 0.9329  loss_giou_0: 0.5957  loss_bbox_0: 0.6392  loss_rpn_cls: 0.4289  loss_rpn_reg: 0.6566  time: 0.3415  last_time: 0.4451  data_time: 0.0104  last_data_time: 0.0104   lr: 5e-05  max_mem: 4724M
[03/05 11:21:36] d2.utils.events INFO:  eta: 4:36:46  iter: 1999  total_loss: 5.035  loss_ce: 0.9086  loss_giou: 0.5881  loss_bbox: 0.5487  loss_ce_0: 0.875  loss_giou_0: 0.584  loss_bbox_0: 0.5534  loss_rpn_cls: 0.3946  loss_rpn_reg: 0.6263  time: 0.3415  last_time: 0.2737  data_time: 0.0107  last_data_time: 0.0089   lr: 5e-05  max_mem: 4724M
[03/05 11:21:43] d2.utils.events INFO:  eta: 4:36:53  iter: 2019  total_loss: 5.154  loss_ce: 0.8992  loss_giou: 0.5537  loss_bbox: 0.5451  loss_ce_0: 0.8779  loss_giou_0: 0.5651  loss_bbox_0: 0.6055  loss_rpn_cls: 0.3979  loss_rpn_reg: 0.6677  time: 0.3418  last_time: 0.3266  data_time: 0.0118  last_data_time: 0.0117   lr: 5e-05  max_mem: 4724M
[03/05 11:21:50] d2.utils.events INFO:  eta: 4:36:46  iter: 2039  total_loss: 5.641  loss_ce: 0.9483  loss_giou: 0.6472  loss_bbox: 0.6192  loss_ce_0: 0.9055  loss_giou_0: 0.6526  loss_bbox_0: 0.6843  loss_rpn_cls: 0.4196  loss_rpn_reg: 0.7138  time: 0.3418  last_time: 0.4552  data_time: 0.0108  last_data_time: 0.0070   lr: 5e-05  max_mem: 4724M
[03/05 11:21:57] d2.utils.events INFO:  eta: 4:36:40  iter: 2059  total_loss: 5.435  loss_ce: 1.001  loss_giou: 0.6006  loss_bbox: 0.6006  loss_ce_0: 0.9468  loss_giou_0: 0.627  loss_bbox_0: 0.6197  loss_rpn_cls: 0.4178  loss_rpn_reg: 0.6384  time: 0.3417  last_time: 0.2780  data_time: 0.0110  last_data_time: 0.0085   lr: 5e-05  max_mem: 4724M
[03/05 11:22:04] d2.utils.events INFO:  eta: 4:36:37  iter: 2079  total_loss: 5.33  loss_ce: 0.9234  loss_giou: 0.5966  loss_bbox: 0.5734  loss_ce_0: 0.8684  loss_giou_0: 0.6235  loss_bbox_0: 0.6301  loss_rpn_cls: 0.4072  loss_rpn_reg: 0.6065  time: 0.3417  last_time: 0.4394  data_time: 0.0126  last_data_time: 0.0093   lr: 5e-05  max_mem: 4724M
[03/05 11:22:11] d2.utils.events INFO:  eta: 4:36:28  iter: 2099  total_loss: 5.367  loss_ce: 0.9734  loss_giou: 0.602  loss_bbox: 0.5793  loss_ce_0: 0.9271  loss_giou_0: 0.6211  loss_bbox_0: 0.5913  loss_rpn_cls: 0.4234  loss_rpn_reg: 0.635  time: 0.3417  last_time: 0.4599  data_time: 0.0137  last_data_time: 0.0109   lr: 5e-05  max_mem: 4724M
[03/05 11:22:18] d2.utils.events INFO:  eta: 4:36:22  iter: 2119  total_loss: 5.27  loss_ce: 0.9095  loss_giou: 0.6277  loss_bbox: 0.593  loss_ce_0: 0.8543  loss_giou_0: 0.6419  loss_bbox_0: 0.5736  loss_rpn_cls: 0.3951  loss_rpn_reg: 0.6237  time: 0.3418  last_time: 0.3278  data_time: 0.0130  last_data_time: 0.0204   lr: 5e-05  max_mem: 4724M
[03/05 11:22:24] d2.utils.events INFO:  eta: 4:36:53  iter: 2139  total_loss: 5.294  loss_ce: 0.923  loss_giou: 0.5654  loss_bbox: 0.5745  loss_ce_0: 0.895  loss_giou_0: 0.5932  loss_bbox_0: 0.6299  loss_rpn_cls: 0.3998  loss_rpn_reg: 0.6551  time: 0.3418  last_time: 0.3167  data_time: 0.0122  last_data_time: 0.0042   lr: 5e-05  max_mem: 4724M
[03/05 11:22:31] d2.utils.events INFO:  eta: 4:36:21  iter: 2159  total_loss: 5.201  loss_ce: 0.9285  loss_giou: 0.5722  loss_bbox: 0.6047  loss_ce_0: 0.8742  loss_giou_0: 0.6035  loss_bbox_0: 0.616  loss_rpn_cls: 0.4105  loss_rpn_reg: 0.6234  time: 0.3418  last_time: 0.2792  data_time: 0.0134  last_data_time: 0.0061   lr: 5e-05  max_mem: 4724M
[03/05 11:22:38] d2.utils.events INFO:  eta: 4:36:44  iter: 2179  total_loss: 4.98  loss_ce: 0.9189  loss_giou: 0.5292  loss_bbox: 0.5246  loss_ce_0: 0.8768  loss_giou_0: 0.5714  loss_bbox_0: 0.5636  loss_rpn_cls: 0.3859  loss_rpn_reg: 0.6159  time: 0.3418  last_time: 0.3224  data_time: 0.0140  last_data_time: 0.0082   lr: 5e-05  max_mem: 4724M
[03/05 11:22:46] d2.utils.events INFO:  eta: 4:36:45  iter: 2199  total_loss: 4.752  loss_ce: 0.8622  loss_giou: 0.5509  loss_bbox: 0.518  loss_ce_0: 0.8244  loss_giou_0: 0.5736  loss_bbox_0: 0.5381  loss_rpn_cls: 0.3984  loss_rpn_reg: 0.5946  time: 0.3421  last_time: 0.3078  data_time: 0.0129  last_data_time: 0.0103   lr: 5e-05  max_mem: 4724M
[03/05 11:22:53] d2.utils.events INFO:  eta: 4:36:41  iter: 2219  total_loss: 5.022  loss_ce: 0.8273  loss_giou: 0.6102  loss_bbox: 0.5334  loss_ce_0: 0.8087  loss_giou_0: 0.6035  loss_bbox_0: 0.5918  loss_rpn_cls: 0.393  loss_rpn_reg: 0.6004  time: 0.3422  last_time: 0.3227  data_time: 0.0162  last_data_time: 0.0093   lr: 5e-05  max_mem: 4724M
[03/05 11:23:00] d2.utils.events INFO:  eta: 4:36:50  iter: 2239  total_loss: 5.145  loss_ce: 0.8687  loss_giou: 0.6408  loss_bbox: 0.5988  loss_ce_0: 0.8002  loss_giou_0: 0.6336  loss_bbox_0: 0.626  loss_rpn_cls: 0.3986  loss_rpn_reg: 0.6405  time: 0.3423  last_time: 0.3192  data_time: 0.0167  last_data_time: 0.0378   lr: 5e-05  max_mem: 4724M
[03/05 11:23:06] d2.utils.events INFO:  eta: 4:36:28  iter: 2259  total_loss: 4.911  loss_ce: 0.8406  loss_giou: 0.5409  loss_bbox: 0.513  loss_ce_0: 0.8177  loss_giou_0: 0.5649  loss_bbox_0: 0.5577  loss_rpn_cls: 0.3996  loss_rpn_reg: 0.6038  time: 0.3420  last_time: 0.3156  data_time: 0.0105  last_data_time: 0.0126   lr: 5e-05  max_mem: 4724M
[03/05 11:23:13] d2.utils.events INFO:  eta: 4:36:22  iter: 2279  total_loss: 4.908  loss_ce: 0.8635  loss_giou: 0.5721  loss_bbox: 0.566  loss_ce_0: 0.8396  loss_giou_0: 0.585  loss_bbox_0: 0.5988  loss_rpn_cls: 0.3996  loss_rpn_reg: 0.6092  time: 0.3421  last_time: 0.4292  data_time: 0.0141  last_data_time: 0.0169   lr: 5e-05  max_mem: 4724M
[03/05 11:23:20] d2.utils.events INFO:  eta: 4:36:28  iter: 2299  total_loss: 5.137  loss_ce: 0.8502  loss_giou: 0.6114  loss_bbox: 0.5302  loss_ce_0: 0.8359  loss_giou_0: 0.617  loss_bbox_0: 0.538  loss_rpn_cls: 0.4042  loss_rpn_reg: 0.6476  time: 0.3422  last_time: 0.2997  data_time: 0.0126  last_data_time: 0.0065   lr: 5e-05  max_mem: 4724M
[03/05 11:23:27] d2.utils.events INFO:  eta: 4:36:21  iter: 2319  total_loss: 4.83  loss_ce: 0.8476  loss_giou: 0.5687  loss_bbox: 0.4851  loss_ce_0: 0.8074  loss_giou_0: 0.5672  loss_bbox_0: 0.5154  loss_rpn_cls: 0.3846  loss_rpn_reg: 0.6344  time: 0.3420  last_time: 0.3354  data_time: 0.0137  last_data_time: 0.0241   lr: 5e-05  max_mem: 4724M
[03/05 11:23:34] d2.utils.events INFO:  eta: 4:36:15  iter: 2339  total_loss: 5.224  loss_ce: 0.8726  loss_giou: 0.6242  loss_bbox: 0.5689  loss_ce_0: 0.8393  loss_giou_0: 0.6071  loss_bbox_0: 0.5924  loss_rpn_cls: 0.3907  loss_rpn_reg: 0.6284  time: 0.3421  last_time: 0.3188  data_time: 0.0144  last_data_time: 0.0156   lr: 5e-05  max_mem: 4724M
[03/05 11:23:41] d2.utils.events INFO:  eta: 4:36:11  iter: 2359  total_loss: 5.118  loss_ce: 0.857  loss_giou: 0.6242  loss_bbox: 0.5773  loss_ce_0: 0.8471  loss_giou_0: 0.6344  loss_bbox_0: 0.5976  loss_rpn_cls: 0.388  loss_rpn_reg: 0.6014  time: 0.3421  last_time: 0.2925  data_time: 0.0133  last_data_time: 0.0081   lr: 5e-05  max_mem: 4724M
[03/05 11:23:47] d2.utils.events INFO:  eta: 4:35:59  iter: 2379  total_loss: 5.076  loss_ce: 0.8848  loss_giou: 0.5237  loss_bbox: 0.624  loss_ce_0: 0.8483  loss_giou_0: 0.5224  loss_bbox_0: 0.672  loss_rpn_cls: 0.3855  loss_rpn_reg: 0.6261  time: 0.3419  last_time: 0.3383  data_time: 0.0154  last_data_time: 0.0163   lr: 5e-05  max_mem: 4724M
[03/05 11:23:55] d2.utils.events INFO:  eta: 4:36:00  iter: 2399  total_loss: 4.973  loss_ce: 0.8594  loss_giou: 0.5611  loss_bbox: 0.5797  loss_ce_0: 0.8026  loss_giou_0: 0.5638  loss_bbox_0: 0.6016  loss_rpn_cls: 0.395  loss_rpn_reg: 0.6026  time: 0.3421  last_time: 0.3358  data_time: 0.0114  last_data_time: 0.0083   lr: 5e-05  max_mem: 4724M
[03/05 11:24:02] d2.utils.events INFO:  eta: 4:36:00  iter: 2419  total_loss: 4.898  loss_ce: 0.8351  loss_giou: 0.5994  loss_bbox: 0.5338  loss_ce_0: 0.8119  loss_giou_0: 0.5963  loss_bbox_0: 0.5589  loss_rpn_cls: 0.3874  loss_rpn_reg: 0.5906  time: 0.3421  last_time: 0.3394  data_time: 0.0139  last_data_time: 0.0242   lr: 5e-05  max_mem: 4724M
[03/05 11:24:09] d2.utils.events INFO:  eta: 4:35:57  iter: 2439  total_loss: 5.154  loss_ce: 0.884  loss_giou: 0.6134  loss_bbox: 0.5817  loss_ce_0: 0.8472  loss_giou_0: 0.6175  loss_bbox_0: 0.6063  loss_rpn_cls: 0.3955  loss_rpn_reg: 0.5984  time: 0.3421  last_time: 0.3029  data_time: 0.0126  last_data_time: 0.0097   lr: 5e-05  max_mem: 4724M
[03/05 11:24:16] d2.utils.events INFO:  eta: 4:36:02  iter: 2459  total_loss: 5.231  loss_ce: 0.9233  loss_giou: 0.6274  loss_bbox: 0.5817  loss_ce_0: 0.8763  loss_giou_0: 0.6411  loss_bbox_0: 0.609  loss_rpn_cls: 0.3994  loss_rpn_reg: 0.6405  time: 0.3422  last_time: 0.3208  data_time: 0.0126  last_data_time: 0.0084   lr: 5e-05  max_mem: 4724M
[03/05 11:24:23] d2.utils.events INFO:  eta: 4:36:08  iter: 2479  total_loss: 5.249  loss_ce: 0.8339  loss_giou: 0.6012  loss_bbox: 0.555  loss_ce_0: 0.7835  loss_giou_0: 0.6129  loss_bbox_0: 0.5963  loss_rpn_cls: 0.3866  loss_rpn_reg: 0.6568  time: 0.3422  last_time: 0.4866  data_time: 0.0125  last_data_time: 0.0080   lr: 5e-05  max_mem: 4724M
[03/05 11:24:30] d2.utils.events INFO:  eta: 4:35:54  iter: 2499  total_loss: 4.923  loss_ce: 0.8741  loss_giou: 0.5638  loss_bbox: 0.545  loss_ce_0: 0.8126  loss_giou_0: 0.5752  loss_bbox_0: 0.5517  loss_rpn_cls: 0.3795  loss_rpn_reg: 0.6077  time: 0.3423  last_time: 0.2697  data_time: 0.0134  last_data_time: 0.0107   lr: 5e-05  max_mem: 4724M
[03/05 11:24:37] d2.utils.events INFO:  eta: 4:35:51  iter: 2519  total_loss: 4.767  loss_ce: 0.8682  loss_giou: 0.5205  loss_bbox: 0.4989  loss_ce_0: 0.8311  loss_giou_0: 0.5487  loss_bbox_0: 0.5625  loss_rpn_cls: 0.3695  loss_rpn_reg: 0.6343  time: 0.3423  last_time: 0.3400  data_time: 0.0114  last_data_time: 0.0118   lr: 5e-05  max_mem: 4724M
[03/05 11:24:44] d2.utils.events INFO:  eta: 4:36:07  iter: 2539  total_loss: 5.042  loss_ce: 0.8987  loss_giou: 0.5425  loss_bbox: 0.5076  loss_ce_0: 0.8611  loss_giou_0: 0.5467  loss_bbox_0: 0.5409  loss_rpn_cls: 0.4081  loss_rpn_reg: 0.5988  time: 0.3423  last_time: 0.4176  data_time: 0.0154  last_data_time: 0.0108   lr: 5e-05  max_mem: 4724M
[03/05 11:24:51] d2.utils.events INFO:  eta: 4:36:13  iter: 2559  total_loss: 5.156  loss_ce: 0.9307  loss_giou: 0.5399  loss_bbox: 0.5944  loss_ce_0: 0.8557  loss_giou_0: 0.576  loss_bbox_0: 0.646  loss_rpn_cls: 0.3882  loss_rpn_reg: 0.6404  time: 0.3425  last_time: 0.4506  data_time: 0.0134  last_data_time: 0.0060   lr: 5e-05  max_mem: 4724M
[03/05 11:24:58] d2.utils.events INFO:  eta: 4:35:39  iter: 2579  total_loss: 4.818  loss_ce: 0.8228  loss_giou: 0.5525  loss_bbox: 0.5114  loss_ce_0: 0.8285  loss_giou_0: 0.5688  loss_bbox_0: 0.5451  loss_rpn_cls: 0.4089  loss_rpn_reg: 0.6041  time: 0.3423  last_time: 0.4068  data_time: 0.0124  last_data_time: 0.0341   lr: 5e-05  max_mem: 4724M
[03/05 11:25:04] d2.utils.events INFO:  eta: 4:35:47  iter: 2599  total_loss: 5.127  loss_ce: 0.879  loss_giou: 0.5836  loss_bbox: 0.5332  loss_ce_0: 0.8309  loss_giou_0: 0.5721  loss_bbox_0: 0.555  loss_rpn_cls: 0.4124  loss_rpn_reg: 0.6107  time: 0.3424  last_time: 0.3903  data_time: 0.0133  last_data_time: 0.0157   lr: 5e-05  max_mem: 4724M
[03/05 11:25:12] d2.utils.events INFO:  eta: 4:36:03  iter: 2619  total_loss: 4.9  loss_ce: 0.8696  loss_giou: 0.5483  loss_bbox: 0.4722  loss_ce_0: 0.811  loss_giou_0: 0.5558  loss_bbox_0: 0.4837  loss_rpn_cls: 0.3927  loss_rpn_reg: 0.6126  time: 0.3425  last_time: 0.3348  data_time: 0.0127  last_data_time: 0.0149   lr: 5e-05  max_mem: 4724M
[03/05 11:25:19] d2.utils.events INFO:  eta: 4:35:57  iter: 2639  total_loss: 4.906  loss_ce: 0.856  loss_giou: 0.5721  loss_bbox: 0.5384  loss_ce_0: 0.839  loss_giou_0: 0.5937  loss_bbox_0: 0.5698  loss_rpn_cls: 0.3905  loss_rpn_reg: 0.6054  time: 0.3425  last_time: 0.4337  data_time: 0.0116  last_data_time: 0.0091   lr: 5e-05  max_mem: 4724M
[03/05 11:25:25] d2.utils.events INFO:  eta: 4:35:50  iter: 2659  total_loss: 4.931  loss_ce: 0.811  loss_giou: 0.6204  loss_bbox: 0.5699  loss_ce_0: 0.7886  loss_giou_0: 0.6345  loss_bbox_0: 0.5733  loss_rpn_cls: 0.3892  loss_rpn_reg: 0.6376  time: 0.3424  last_time: 0.4134  data_time: 0.0140  last_data_time: 0.0104   lr: 5e-05  max_mem: 4724M
[03/05 11:25:32] d2.utils.events INFO:  eta: 4:35:44  iter: 2679  total_loss: 4.853  loss_ce: 0.8034  loss_giou: 0.6124  loss_bbox: 0.5452  loss_ce_0: 0.7743  loss_giou_0: 0.603  loss_bbox_0: 0.5573  loss_rpn_cls: 0.3559  loss_rpn_reg: 0.6156  time: 0.3424  last_time: 0.3364  data_time: 0.0130  last_data_time: 0.0120   lr: 5e-05  max_mem: 4724M
[03/05 11:25:40] d2.utils.events INFO:  eta: 4:35:55  iter: 2699  total_loss: 4.936  loss_ce: 0.8327  loss_giou: 0.6196  loss_bbox: 0.5494  loss_ce_0: 0.8353  loss_giou_0: 0.6354  loss_bbox_0: 0.5336  loss_rpn_cls: 0.394  loss_rpn_reg: 0.6347  time: 0.3426  last_time: 0.3301  data_time: 0.0134  last_data_time: 0.0156   lr: 5e-05  max_mem: 4724M
[03/05 11:25:46] d2.utils.events INFO:  eta: 4:35:48  iter: 2719  total_loss: 4.514  loss_ce: 0.7951  loss_giou: 0.5231  loss_bbox: 0.4728  loss_ce_0: 0.773  loss_giou_0: 0.5286  loss_bbox_0: 0.5271  loss_rpn_cls: 0.3531  loss_rpn_reg: 0.5866  time: 0.3424  last_time: 0.3301  data_time: 0.0129  last_data_time: 0.0116   lr: 5e-05  max_mem: 4724M
[03/05 11:25:53] d2.utils.events INFO:  eta: 4:35:41  iter: 2739  total_loss: 4.913  loss_ce: 0.8198  loss_giou: 0.5074  loss_bbox: 0.5285  loss_ce_0: 0.8269  loss_giou_0: 0.531  loss_bbox_0: 0.5878  loss_rpn_cls: 0.3736  loss_rpn_reg: 0.6241  time: 0.3424  last_time: 0.4107  data_time: 0.0131  last_data_time: 0.0176   lr: 5e-05  max_mem: 4724M
[03/05 11:25:59] d2.utils.events INFO:  eta: 4:35:20  iter: 2759  total_loss: 4.542  loss_ce: 0.7808  loss_giou: 0.5543  loss_bbox: 0.4714  loss_ce_0: 0.7609  loss_giou_0: 0.5651  loss_bbox_0: 0.4996  loss_rpn_cls: 0.3644  loss_rpn_reg: 0.6177  time: 0.3423  last_time: 0.3026  data_time: 0.0122  last_data_time: 0.0126   lr: 5e-05  max_mem: 4724M
[03/05 11:26:06] d2.utils.events INFO:  eta: 4:35:11  iter: 2779  total_loss: 4.638  loss_ce: 0.85  loss_giou: 0.5184  loss_bbox: 0.4466  loss_ce_0: 0.8225  loss_giou_0: 0.5517  loss_bbox_0: 0.4578  loss_rpn_cls: 0.3642  loss_rpn_reg: 0.606  time: 0.3422  last_time: 0.2982  data_time: 0.0133  last_data_time: 0.0113   lr: 5e-05  max_mem: 4724M
[03/05 11:26:13] d2.utils.events INFO:  eta: 4:35:21  iter: 2799  total_loss: 4.825  loss_ce: 0.874  loss_giou: 0.5194  loss_bbox: 0.5238  loss_ce_0: 0.8533  loss_giou_0: 0.5322  loss_bbox_0: 0.5377  loss_rpn_cls: 0.3917  loss_rpn_reg: 0.6237  time: 0.3423  last_time: 0.3954  data_time: 0.0164  last_data_time: 0.0186   lr: 5e-05  max_mem: 4724M
[03/05 11:26:20] d2.utils.events INFO:  eta: 4:34:52  iter: 2819  total_loss: 4.905  loss_ce: 0.8325  loss_giou: 0.5636  loss_bbox: 0.454  loss_ce_0: 0.846  loss_giou_0: 0.5738  loss_bbox_0: 0.5046  loss_rpn_cls: 0.378  loss_rpn_reg: 0.6072  time: 0.3421  last_time: 0.4257  data_time: 0.0137  last_data_time: 0.0246   lr: 5e-05  max_mem: 4724M
[03/05 11:26:26] d2.utils.events INFO:  eta: 4:34:46  iter: 2839  total_loss: 4.805  loss_ce: 0.7959  loss_giou: 0.5459  loss_bbox: 0.523  loss_ce_0: 0.7818  loss_giou_0: 0.5514  loss_bbox_0: 0.5317  loss_rpn_cls: 0.3847  loss_rpn_reg: 0.6107  time: 0.3420  last_time: 0.3065  data_time: 0.0139  last_data_time: 0.0153   lr: 5e-05  max_mem: 4724M
[03/05 11:26:33] d2.utils.events INFO:  eta: 4:34:36  iter: 2859  total_loss: 4.804  loss_ce: 0.8078  loss_giou: 0.6167  loss_bbox: 0.4617  loss_ce_0: 0.8011  loss_giou_0: 0.6421  loss_bbox_0: 0.5083  loss_rpn_cls: 0.401  loss_rpn_reg: 0.5875  time: 0.3419  last_time: 0.4385  data_time: 0.0130  last_data_time: 0.0155   lr: 5e-05  max_mem: 4724M
[03/05 11:26:40] d2.utils.events INFO:  eta: 4:33:57  iter: 2879  total_loss: 4.852  loss_ce: 0.8304  loss_giou: 0.4859  loss_bbox: 0.5046  loss_ce_0: 0.8301  loss_giou_0: 0.5143  loss_bbox_0: 0.5096  loss_rpn_cls: 0.3664  loss_rpn_reg: 0.612  time: 0.3419  last_time: 0.3111  data_time: 0.0126  last_data_time: 0.0088   lr: 5e-05  max_mem: 4724M
[03/05 11:26:46] d2.utils.events INFO:  eta: 4:33:44  iter: 2899  total_loss: 5.4  loss_ce: 0.8969  loss_giou: 0.5637  loss_bbox: 0.5795  loss_ce_0: 0.9205  loss_giou_0: 0.5838  loss_bbox_0: 0.6615  loss_rpn_cls: 0.4079  loss_rpn_reg: 0.6553  time: 0.3418  last_time: 0.3085  data_time: 0.0143  last_data_time: 0.0048   lr: 5e-05  max_mem: 4724M
[03/05 11:26:54] d2.utils.events INFO:  eta: 4:33:40  iter: 2919  total_loss: 4.767  loss_ce: 0.8486  loss_giou: 0.5398  loss_bbox: 0.5102  loss_ce_0: 0.8226  loss_giou_0: 0.5649  loss_bbox_0: 0.514  loss_rpn_cls: 0.3821  loss_rpn_reg: 0.6248  time: 0.3419  last_time: 0.3064  data_time: 0.0132  last_data_time: 0.0088   lr: 5e-05  max_mem: 4724M
[03/05 11:27:01] d2.utils.events INFO:  eta: 4:33:34  iter: 2939  total_loss: 4.583  loss_ce: 0.7707  loss_giou: 0.5345  loss_bbox: 0.4615  loss_ce_0: 0.7408  loss_giou_0: 0.5463  loss_bbox_0: 0.5152  loss_rpn_cls: 0.3708  loss_rpn_reg: 0.624  time: 0.3419  last_time: 0.3367  data_time: 0.0135  last_data_time: 0.0232   lr: 5e-05  max_mem: 4724M
[03/05 11:27:08] d2.utils.events INFO:  eta: 4:33:53  iter: 2959  total_loss: 4.754  loss_ce: 0.8022  loss_giou: 0.6141  loss_bbox: 0.509  loss_ce_0: 0.735  loss_giou_0: 0.6151  loss_bbox_0: 0.5338  loss_rpn_cls: 0.3837  loss_rpn_reg: 0.624  time: 0.3419  last_time: 0.4363  data_time: 0.0135  last_data_time: 0.0099   lr: 5e-05  max_mem: 4724M
[03/05 11:27:14] d2.utils.events INFO:  eta: 4:33:46  iter: 2979  total_loss: 4.822  loss_ce: 0.8214  loss_giou: 0.5967  loss_bbox: 0.4917  loss_ce_0: 0.8104  loss_giou_0: 0.5866  loss_bbox_0: 0.5337  loss_rpn_cls: 0.3756  loss_rpn_reg: 0.6184  time: 0.3419  last_time: 0.5057  data_time: 0.0146  last_data_time: 0.0157   lr: 5e-05  max_mem: 4724M
[03/05 11:27:21] d2.utils.events INFO:  eta: 4:33:12  iter: 2999  total_loss: 4.84  loss_ce: 0.837  loss_giou: 0.5903  loss_bbox: 0.4872  loss_ce_0: 0.8286  loss_giou_0: 0.6098  loss_bbox_0: 0.5293  loss_rpn_cls: 0.3911  loss_rpn_reg: 0.6048  time: 0.3419  last_time: 0.4647  data_time: 0.0144  last_data_time: 0.0154   lr: 5e-05  max_mem: 4724M
[03/05 11:27:29] d2.utils.events INFO:  eta: 4:32:59  iter: 3019  total_loss: 4.726  loss_ce: 0.763  loss_giou: 0.5669  loss_bbox: 0.4986  loss_ce_0: 0.7852  loss_giou_0: 0.5758  loss_bbox_0: 0.537  loss_rpn_cls: 0.3736  loss_rpn_reg: 0.5841  time: 0.3421  last_time: 0.2957  data_time: 0.0140  last_data_time: 0.0083   lr: 5e-05  max_mem: 4724M
[03/05 11:27:36] d2.utils.events INFO:  eta: 4:33:42  iter: 3039  total_loss: 4.667  loss_ce: 0.8073  loss_giou: 0.5226  loss_bbox: 0.4773  loss_ce_0: 0.7526  loss_giou_0: 0.5444  loss_bbox_0: 0.4695  loss_rpn_cls: 0.3721  loss_rpn_reg: 0.623  time: 0.3422  last_time: 0.3293  data_time: 0.0129  last_data_time: 0.0088   lr: 5e-05  max_mem: 4724M
[03/05 11:27:43] d2.utils.events INFO:  eta: 4:32:59  iter: 3059  total_loss: 4.793  loss_ce: 0.8377  loss_giou: 0.542  loss_bbox: 0.5294  loss_ce_0: 0.805  loss_giou_0: 0.5163  loss_bbox_0: 0.5488  loss_rpn_cls: 0.3486  loss_rpn_reg: 0.582  time: 0.3422  last_time: 0.4633  data_time: 0.0127  last_data_time: 0.0231   lr: 5e-05  max_mem: 4724M
[03/05 11:27:50] d2.utils.events INFO:  eta: 4:32:49  iter: 3079  total_loss: 4.778  loss_ce: 0.8338  loss_giou: 0.556  loss_bbox: 0.4703  loss_ce_0: 0.791  loss_giou_0: 0.5932  loss_bbox_0: 0.5024  loss_rpn_cls: 0.3827  loss_rpn_reg: 0.612  time: 0.3421  last_time: 0.3155  data_time: 0.0116  last_data_time: 0.0079   lr: 5e-05  max_mem: 4724M
[03/05 11:27:56] d2.utils.events INFO:  eta: 4:32:42  iter: 3099  total_loss: 4.549  loss_ce: 0.7943  loss_giou: 0.5085  loss_bbox: 0.5192  loss_ce_0: 0.7525  loss_giou_0: 0.5265  loss_bbox_0: 0.5414  loss_rpn_cls: 0.3719  loss_rpn_reg: 0.5864  time: 0.3421  last_time: 0.3254  data_time: 0.0130  last_data_time: 0.0228   lr: 5e-05  max_mem: 4724M
[03/05 11:28:03] d2.utils.events INFO:  eta: 4:32:18  iter: 3119  total_loss: 4.513  loss_ce: 0.7637  loss_giou: 0.4801  loss_bbox: 0.4648  loss_ce_0: 0.7423  loss_giou_0: 0.5133  loss_bbox_0: 0.5003  loss_rpn_cls: 0.3701  loss_rpn_reg: 0.5566  time: 0.3420  last_time: 0.3226  data_time: 0.0109  last_data_time: 0.0135   lr: 5e-05  max_mem: 4724M
[03/05 11:28:10] d2.utils.events INFO:  eta: 4:32:11  iter: 3139  total_loss: 4.67  loss_ce: 0.7945  loss_giou: 0.5824  loss_bbox: 0.5281  loss_ce_0: 0.7934  loss_giou_0: 0.59  loss_bbox_0: 0.541  loss_rpn_cls: 0.387  loss_rpn_reg: 0.5891  time: 0.3420  last_time: 0.3232  data_time: 0.0137  last_data_time: 0.0211   lr: 5e-05  max_mem: 4724M
[03/05 11:28:17] d2.utils.events INFO:  eta: 4:32:21  iter: 3159  total_loss: 4.342  loss_ce: 0.7198  loss_giou: 0.485  loss_bbox: 0.4291  loss_ce_0: 0.7209  loss_giou_0: 0.512  loss_bbox_0: 0.4627  loss_rpn_cls: 0.3399  loss_rpn_reg: 0.5856  time: 0.3419  last_time: 0.3522  data_time: 0.0149  last_data_time: 0.0176   lr: 5e-05  max_mem: 4724M
[03/05 11:28:24] d2.utils.events INFO:  eta: 4:31:58  iter: 3179  total_loss: 4.492  loss_ce: 0.8033  loss_giou: 0.5033  loss_bbox: 0.4387  loss_ce_0: 0.7792  loss_giou_0: 0.5254  loss_bbox_0: 0.4696  loss_rpn_cls: 0.3557  loss_rpn_reg: 0.5633  time: 0.3419  last_time: 0.2952  data_time: 0.0138  last_data_time: 0.0159   lr: 5e-05  max_mem: 4724M
[03/05 11:28:30] d2.utils.events INFO:  eta: 4:31:37  iter: 3199  total_loss: 4.974  loss_ce: 0.7985  loss_giou: 0.557  loss_bbox: 0.5598  loss_ce_0: 0.8092  loss_giou_0: 0.5612  loss_bbox_0: 0.5886  loss_rpn_cls: 0.3914  loss_rpn_reg: 0.6025  time: 0.3418  last_time: 0.2784  data_time: 0.0110  last_data_time: 0.0064   lr: 5e-05  max_mem: 4724M
[03/05 11:28:37] d2.utils.events INFO:  eta: 4:31:12  iter: 3219  total_loss: 4.464  loss_ce: 0.7639  loss_giou: 0.4829  loss_bbox: 0.4585  loss_ce_0: 0.7507  loss_giou_0: 0.5039  loss_bbox_0: 0.5031  loss_rpn_cls: 0.3584  loss_rpn_reg: 0.5944  time: 0.3419  last_time: 0.3294  data_time: 0.0159  last_data_time: 0.0113   lr: 5e-05  max_mem: 4724M
[03/05 11:28:44] d2.utils.events INFO:  eta: 4:30:57  iter: 3239  total_loss: 4.346  loss_ce: 0.7366  loss_giou: 0.512  loss_bbox: 0.4751  loss_ce_0: 0.7075  loss_giou_0: 0.4977  loss_bbox_0: 0.4812  loss_rpn_cls: 0.3526  loss_rpn_reg: 0.5572  time: 0.3419  last_time: 0.3165  data_time: 0.0146  last_data_time: 0.0137   lr: 5e-05  max_mem: 4724M
[03/05 11:28:51] d2.utils.events INFO:  eta: 4:31:32  iter: 3259  total_loss: 4.509  loss_ce: 0.7751  loss_giou: 0.4937  loss_bbox: 0.5134  loss_ce_0: 0.7468  loss_giou_0: 0.5159  loss_bbox_0: 0.5214  loss_rpn_cls: 0.3677  loss_rpn_reg: 0.5732  time: 0.3420  last_time: 0.2685  data_time: 0.0131  last_data_time: 0.0137   lr: 5e-05  max_mem: 4724M
[03/05 11:28:58] d2.utils.events INFO:  eta: 4:31:13  iter: 3279  total_loss: 4.534  loss_ce: 0.7243  loss_giou: 0.5016  loss_bbox: 0.4952  loss_ce_0: 0.7247  loss_giou_0: 0.5238  loss_bbox_0: 0.4957  loss_rpn_cls: 0.3517  loss_rpn_reg: 0.589  time: 0.3419  last_time: 0.2919  data_time: 0.0120  last_data_time: 0.0065   lr: 5e-05  max_mem: 4724M
[03/05 11:29:05] d2.utils.events INFO:  eta: 4:30:50  iter: 3299  total_loss: 4.475  loss_ce: 0.7635  loss_giou: 0.5027  loss_bbox: 0.4932  loss_ce_0: 0.7337  loss_giou_0: 0.5335  loss_bbox_0: 0.5147  loss_rpn_cls: 0.3517  loss_rpn_reg: 0.5879  time: 0.3419  last_time: 0.3242  data_time: 0.0132  last_data_time: 0.0125   lr: 5e-05  max_mem: 4724M
[03/05 11:29:11] d2.utils.events INFO:  eta: 4:30:42  iter: 3319  total_loss: 4.442  loss_ce: 0.7529  loss_giou: 0.4937  loss_bbox: 0.5219  loss_ce_0: 0.7401  loss_giou_0: 0.4934  loss_bbox_0: 0.5284  loss_rpn_cls: 0.3439  loss_rpn_reg: 0.5838  time: 0.3418  last_time: 0.3142  data_time: 0.0150  last_data_time: 0.0196   lr: 5e-05  max_mem: 4724M
[03/05 11:29:18] d2.utils.events INFO:  eta: 4:30:41  iter: 3339  total_loss: 4.759  loss_ce: 0.7868  loss_giou: 0.6001  loss_bbox: 0.4795  loss_ce_0: 0.7722  loss_giou_0: 0.6175  loss_bbox_0: 0.5152  loss_rpn_cls: 0.3732  loss_rpn_reg: 0.6124  time: 0.3419  last_time: 0.3098  data_time: 0.0150  last_data_time: 0.0130   lr: 5e-05  max_mem: 4724M
[03/05 11:29:25] d2.utils.events INFO:  eta: 4:30:29  iter: 3359  total_loss: 4.582  loss_ce: 0.8098  loss_giou: 0.5377  loss_bbox: 0.5023  loss_ce_0: 0.7919  loss_giou_0: 0.5319  loss_bbox_0: 0.5467  loss_rpn_cls: 0.3614  loss_rpn_reg: 0.5766  time: 0.3419  last_time: 0.3264  data_time: 0.0133  last_data_time: 0.0088   lr: 5e-05  max_mem: 4724M
[03/05 11:29:32] d2.utils.events INFO:  eta: 4:30:17  iter: 3379  total_loss: 4.681  loss_ce: 0.7913  loss_giou: 0.5  loss_bbox: 0.5707  loss_ce_0: 0.7478  loss_giou_0: 0.5067  loss_bbox_0: 0.5484  loss_rpn_cls: 0.3738  loss_rpn_reg: 0.5894  time: 0.3419  last_time: 0.2966  data_time: 0.0148  last_data_time: 0.0067   lr: 5e-05  max_mem: 4724M
[03/05 11:29:40] d2.utils.events INFO:  eta: 4:30:17  iter: 3399  total_loss: 4.702  loss_ce: 0.7702  loss_giou: 0.5838  loss_bbox: 0.5424  loss_ce_0: 0.7485  loss_giou_0: 0.6191  loss_bbox_0: 0.5366  loss_rpn_cls: 0.3568  loss_rpn_reg: 0.6283  time: 0.3420  last_time: 0.3030  data_time: 0.0165  last_data_time: 0.0055   lr: 5e-05  max_mem: 4724M
[03/05 11:29:47] d2.utils.events INFO:  eta: 4:30:00  iter: 3419  total_loss: 4.612  loss_ce: 0.7733  loss_giou: 0.5243  loss_bbox: 0.4815  loss_ce_0: 0.7456  loss_giou_0: 0.5616  loss_bbox_0: 0.5397  loss_rpn_cls: 0.3563  loss_rpn_reg: 0.6132  time: 0.3421  last_time: 0.2892  data_time: 0.0135  last_data_time: 0.0116   lr: 5e-05  max_mem: 4724M
[03/05 11:29:53] d2.utils.events INFO:  eta: 4:29:24  iter: 3439  total_loss: 4.3  loss_ce: 0.7721  loss_giou: 0.449  loss_bbox: 0.4848  loss_ce_0: 0.7542  loss_giou_0: 0.4891  loss_bbox_0: 0.5223  loss_rpn_cls: 0.3742  loss_rpn_reg: 0.5835  time: 0.3419  last_time: 0.2833  data_time: 0.0119  last_data_time: 0.0125   lr: 5e-05  max_mem: 4724M
[03/05 11:30:00] d2.utils.events INFO:  eta: 4:29:17  iter: 3459  total_loss: 4.401  loss_ce: 0.769  loss_giou: 0.4815  loss_bbox: 0.476  loss_ce_0: 0.7533  loss_giou_0: 0.5031  loss_bbox_0: 0.4862  loss_rpn_cls: 0.3539  loss_rpn_reg: 0.5929  time: 0.3420  last_time: 0.2923  data_time: 0.0119  last_data_time: 0.0081   lr: 5e-05  max_mem: 4724M
[03/05 11:30:07] d2.utils.events INFO:  eta: 4:29:01  iter: 3479  total_loss: 4.424  loss_ce: 0.7683  loss_giou: 0.4913  loss_bbox: 0.4303  loss_ce_0: 0.7373  loss_giou_0: 0.5005  loss_bbox_0: 0.4597  loss_rpn_cls: 0.3574  loss_rpn_reg: 0.5958  time: 0.3419  last_time: 0.3047  data_time: 0.0109  last_data_time: 0.0115   lr: 5e-05  max_mem: 4724M
[03/05 11:30:14] d2.utils.events INFO:  eta: 4:28:55  iter: 3499  total_loss: 4.421  loss_ce: 0.7737  loss_giou: 0.4853  loss_bbox: 0.4596  loss_ce_0: 0.7328  loss_giou_0: 0.5062  loss_bbox_0: 0.4938  loss_rpn_cls: 0.3199  loss_rpn_reg: 0.6012  time: 0.3419  last_time: 0.3361  data_time: 0.0128  last_data_time: 0.0283   lr: 5e-05  max_mem: 4724M
[03/05 11:30:21] d2.utils.events INFO:  eta: 4:28:43  iter: 3519  total_loss: 4.635  loss_ce: 0.7692  loss_giou: 0.5546  loss_bbox: 0.4706  loss_ce_0: 0.757  loss_giou_0: 0.5862  loss_bbox_0: 0.4968  loss_rpn_cls: 0.3984  loss_rpn_reg: 0.6394  time: 0.3419  last_time: 0.3445  data_time: 0.0154  last_data_time: 0.0095   lr: 5e-05  max_mem: 4724M
[03/05 11:30:28] d2.utils.events INFO:  eta: 4:29:13  iter: 3539  total_loss: 4.943  loss_ce: 0.7828  loss_giou: 0.5637  loss_bbox: 0.5546  loss_ce_0: 0.7774  loss_giou_0: 0.5807  loss_bbox_0: 0.5565  loss_rpn_cls: 0.3991  loss_rpn_reg: 0.6046  time: 0.3420  last_time: 0.4031  data_time: 0.0151  last_data_time: 0.0190   lr: 5e-05  max_mem: 4724M
[03/05 11:30:34] d2.utils.events INFO:  eta: 4:29:16  iter: 3559  total_loss: 4.81  loss_ce: 0.826  loss_giou: 0.5522  loss_bbox: 0.5111  loss_ce_0: 0.781  loss_giou_0: 0.5391  loss_bbox_0: 0.5467  loss_rpn_cls: 0.3665  loss_rpn_reg: 0.5843  time: 0.3419  last_time: 0.3240  data_time: 0.0131  last_data_time: 0.0122   lr: 5e-05  max_mem: 4724M
[03/05 11:30:41] d2.utils.events INFO:  eta: 4:29:24  iter: 3579  total_loss: 4.42  loss_ce: 0.7684  loss_giou: 0.521  loss_bbox: 0.4389  loss_ce_0: 0.7452  loss_giou_0: 0.5683  loss_bbox_0: 0.4835  loss_rpn_cls: 0.365  loss_rpn_reg: 0.5721  time: 0.3418  last_time: 0.3327  data_time: 0.0125  last_data_time: 0.0077   lr: 5e-05  max_mem: 4724M
[03/05 11:30:48] d2.utils.events INFO:  eta: 4:28:56  iter: 3599  total_loss: 4.366  loss_ce: 0.7454  loss_giou: 0.4844  loss_bbox: 0.4498  loss_ce_0: 0.7244  loss_giou_0: 0.5071  loss_bbox_0: 0.4836  loss_rpn_cls: 0.3593  loss_rpn_reg: 0.6131  time: 0.3418  last_time: 0.3123  data_time: 0.0136  last_data_time: 0.0165   lr: 5e-05  max_mem: 4724M
[03/05 11:30:55] d2.utils.events INFO:  eta: 4:28:11  iter: 3619  total_loss: 4.745  loss_ce: 0.7591  loss_giou: 0.5371  loss_bbox: 0.5327  loss_ce_0: 0.7755  loss_giou_0: 0.5558  loss_bbox_0: 0.5622  loss_rpn_cls: 0.3706  loss_rpn_reg: 0.6022  time: 0.3418  last_time: 0.3764  data_time: 0.0126  last_data_time: 0.0075   lr: 5e-05  max_mem: 4724M
[03/05 11:31:01] d2.utils.events INFO:  eta: 4:28:20  iter: 3639  total_loss: 4.569  loss_ce: 0.7424  loss_giou: 0.5476  loss_bbox: 0.5035  loss_ce_0: 0.7286  loss_giou_0: 0.5742  loss_bbox_0: 0.5278  loss_rpn_cls: 0.3539  loss_rpn_reg: 0.5816  time: 0.3417  last_time: 0.3202  data_time: 0.0115  last_data_time: 0.0134   lr: 5e-05  max_mem: 4724M
[03/05 11:31:08] d2.utils.events INFO:  eta: 4:27:57  iter: 3659  total_loss: 4.418  loss_ce: 0.7724  loss_giou: 0.4511  loss_bbox: 0.4485  loss_ce_0: 0.7877  loss_giou_0: 0.4987  loss_bbox_0: 0.479  loss_rpn_cls: 0.3667  loss_rpn_reg: 0.5654  time: 0.3417  last_time: 0.3155  data_time: 0.0138  last_data_time: 0.0134   lr: 5e-05  max_mem: 4724M
[03/05 11:31:15] d2.utils.events INFO:  eta: 4:27:44  iter: 3679  total_loss: 4.454  loss_ce: 0.8143  loss_giou: 0.487  loss_bbox: 0.4708  loss_ce_0: 0.7747  loss_giou_0: 0.5718  loss_bbox_0: 0.5448  loss_rpn_cls: 0.3646  loss_rpn_reg: 0.5534  time: 0.3417  last_time: 0.3157  data_time: 0.0131  last_data_time: 0.0132   lr: 5e-05  max_mem: 4724M
[03/05 11:31:22] d2.utils.events INFO:  eta: 4:27:41  iter: 3699  total_loss: 4.287  loss_ce: 0.7936  loss_giou: 0.4391  loss_bbox: 0.4491  loss_ce_0: 0.7862  loss_giou_0: 0.4741  loss_bbox_0: 0.5061  loss_rpn_cls: 0.3339  loss_rpn_reg: 0.5404  time: 0.3417  last_time: 0.4397  data_time: 0.0135  last_data_time: 0.0132   lr: 5e-05  max_mem: 4724M
[03/05 11:31:29] d2.utils.events INFO:  eta: 4:27:31  iter: 3719  total_loss: 4.598  loss_ce: 0.7489  loss_giou: 0.5452  loss_bbox: 0.5003  loss_ce_0: 0.7123  loss_giou_0: 0.5315  loss_bbox_0: 0.5445  loss_rpn_cls: 0.3688  loss_rpn_reg: 0.5697  time: 0.3418  last_time: 0.3108  data_time: 0.0141  last_data_time: 0.0103   lr: 5e-05  max_mem: 4724M
[03/05 11:31:36] d2.utils.events INFO:  eta: 4:27:28  iter: 3739  total_loss: 4.462  loss_ce: 0.7693  loss_giou: 0.4798  loss_bbox: 0.4409  loss_ce_0: 0.7529  loss_giou_0: 0.5111  loss_bbox_0: 0.4913  loss_rpn_cls: 0.3319  loss_rpn_reg: 0.6011  time: 0.3418  last_time: 0.4561  data_time: 0.0122  last_data_time: 0.0100   lr: 5e-05  max_mem: 4724M
[03/05 11:31:43] d2.utils.events INFO:  eta: 4:27:57  iter: 3759  total_loss: 4.493  loss_ce: 0.732  loss_giou: 0.5121  loss_bbox: 0.4935  loss_ce_0: 0.7591  loss_giou_0: 0.5313  loss_bbox_0: 0.5265  loss_rpn_cls: 0.3632  loss_rpn_reg: 0.6062  time: 0.3418  last_time: 0.4219  data_time: 0.0131  last_data_time: 0.0096   lr: 5e-05  max_mem: 4724M
[03/05 11:31:50] d2.utils.events INFO:  eta: 4:27:57  iter: 3779  total_loss: 4.448  loss_ce: 0.7623  loss_giou: 0.4909  loss_bbox: 0.4519  loss_ce_0: 0.7526  loss_giou_0: 0.5089  loss_bbox_0: 0.4806  loss_rpn_cls: 0.3472  loss_rpn_reg: 0.5714  time: 0.3418  last_time: 0.3202  data_time: 0.0142  last_data_time: 0.0156   lr: 5e-05  max_mem: 4724M
[03/05 11:31:56] d2.utils.events INFO:  eta: 4:27:37  iter: 3799  total_loss: 4.627  loss_ce: 0.764  loss_giou: 0.5398  loss_bbox: 0.503  loss_ce_0: 0.7531  loss_giou_0: 0.5862  loss_bbox_0: 0.5417  loss_rpn_cls: 0.364  loss_rpn_reg: 0.5667  time: 0.3417  last_time: 0.3135  data_time: 0.0133  last_data_time: 0.0185   lr: 5e-05  max_mem: 4724M
[03/05 11:32:04] d2.utils.events INFO:  eta: 4:27:51  iter: 3819  total_loss: 4.645  loss_ce: 0.7668  loss_giou: 0.5424  loss_bbox: 0.493  loss_ce_0: 0.7446  loss_giou_0: 0.5736  loss_bbox_0: 0.5352  loss_rpn_cls: 0.3526  loss_rpn_reg: 0.5973  time: 0.3417  last_time: 0.3291  data_time: 0.0148  last_data_time: 0.0060   lr: 5e-05  max_mem: 4724M
[03/05 11:32:10] d2.utils.events INFO:  eta: 4:27:50  iter: 3839  total_loss: 4.947  loss_ce: 0.7881  loss_giou: 0.5643  loss_bbox: 0.5443  loss_ce_0: 0.7716  loss_giou_0: 0.5712  loss_bbox_0: 0.5704  loss_rpn_cls: 0.3839  loss_rpn_reg: 0.6011  time: 0.3417  last_time: 0.3224  data_time: 0.0128  last_data_time: 0.0087   lr: 5e-05  max_mem: 4724M
[03/05 11:32:17] d2.utils.events INFO:  eta: 4:27:38  iter: 3859  total_loss: 4.44  loss_ce: 0.7426  loss_giou: 0.5004  loss_bbox: 0.4829  loss_ce_0: 0.7538  loss_giou_0: 0.494  loss_bbox_0: 0.511  loss_rpn_cls: 0.3613  loss_rpn_reg: 0.5778  time: 0.3416  last_time: 0.3068  data_time: 0.0115  last_data_time: 0.0100   lr: 5e-05  max_mem: 4724M
[03/05 11:32:23] d2.utils.events INFO:  eta: 4:27:32  iter: 3879  total_loss: 4.692  loss_ce: 0.7738  loss_giou: 0.5808  loss_bbox: 0.4756  loss_ce_0: 0.7563  loss_giou_0: 0.6053  loss_bbox_0: 0.5154  loss_rpn_cls: 0.3864  loss_rpn_reg: 0.6262  time: 0.3415  last_time: 0.3302  data_time: 0.0121  last_data_time: 0.0173   lr: 5e-05  max_mem: 4724M
[03/05 11:32:31] d2.utils.events INFO:  eta: 4:27:49  iter: 3899  total_loss: 4.667  loss_ce: 0.8062  loss_giou: 0.5327  loss_bbox: 0.5109  loss_ce_0: 0.7719  loss_giou_0: 0.5474  loss_bbox_0: 0.5803  loss_rpn_cls: 0.373  loss_rpn_reg: 0.5803  time: 0.3417  last_time: 0.4161  data_time: 0.0151  last_data_time: 0.0116   lr: 5e-05  max_mem: 4724M
[03/05 11:32:38] d2.utils.events INFO:  eta: 4:27:50  iter: 3919  total_loss: 4.156  loss_ce: 0.7256  loss_giou: 0.4645  loss_bbox: 0.409  loss_ce_0: 0.6998  loss_giou_0: 0.4949  loss_bbox_0: 0.4632  loss_rpn_cls: 0.3415  loss_rpn_reg: 0.5574  time: 0.3417  last_time: 0.3298  data_time: 0.0139  last_data_time: 0.0118   lr: 5e-05  max_mem: 4724M
[03/05 11:32:45] d2.utils.events INFO:  eta: 4:27:49  iter: 3939  total_loss: 4.286  loss_ce: 0.7204  loss_giou: 0.5509  loss_bbox: 0.4464  loss_ce_0: 0.7019  loss_giou_0: 0.5682  loss_bbox_0: 0.4696  loss_rpn_cls: 0.3579  loss_rpn_reg: 0.567  time: 0.3418  last_time: 0.3362  data_time: 0.0145  last_data_time: 0.0217   lr: 5e-05  max_mem: 4724M
[03/05 11:32:52] d2.utils.events INFO:  eta: 4:27:45  iter: 3959  total_loss: 4.681  loss_ce: 0.7459  loss_giou: 0.5161  loss_bbox: 0.4528  loss_ce_0: 0.7784  loss_giou_0: 0.5483  loss_bbox_0: 0.5038  loss_rpn_cls: 0.3634  loss_rpn_reg: 0.5734  time: 0.3418  last_time: 0.3277  data_time: 0.0113  last_data_time: 0.0111   lr: 5e-05  max_mem: 4724M
[03/05 11:32:59] d2.utils.events INFO:  eta: 4:27:56  iter: 3979  total_loss: 4.445  loss_ce: 0.7797  loss_giou: 0.5161  loss_bbox: 0.4859  loss_ce_0: 0.7649  loss_giou_0: 0.5334  loss_bbox_0: 0.519  loss_rpn_cls: 0.3668  loss_rpn_reg: 0.5923  time: 0.3418  last_time: 0.4179  data_time: 0.0139  last_data_time: 0.0167   lr: 5e-05  max_mem: 4724M
[03/05 11:33:06] d2.utils.events INFO:  eta: 4:27:56  iter: 3999  total_loss: 4.258  loss_ce: 0.7245  loss_giou: 0.48  loss_bbox: 0.411  loss_ce_0: 0.7146  loss_giou_0: 0.5451  loss_bbox_0: 0.4523  loss_rpn_cls: 0.3418  loss_rpn_reg: 0.5521  time: 0.3418  last_time: 0.3180  data_time: 0.0140  last_data_time: 0.0270   lr: 5e-05  max_mem: 4724M
[03/05 11:33:13] d2.utils.events INFO:  eta: 4:27:32  iter: 4019  total_loss: 4.331  loss_ce: 0.7602  loss_giou: 0.5013  loss_bbox: 0.4229  loss_ce_0: 0.7296  loss_giou_0: 0.5186  loss_bbox_0: 0.4678  loss_rpn_cls: 0.3589  loss_rpn_reg: 0.5844  time: 0.3418  last_time: 0.3209  data_time: 0.0136  last_data_time: 0.0254   lr: 5e-05  max_mem: 4724M
[03/05 11:33:20] d2.utils.events INFO:  eta: 4:27:07  iter: 4039  total_loss: 4.502  loss_ce: 0.7834  loss_giou: 0.477  loss_bbox: 0.5087  loss_ce_0: 0.8037  loss_giou_0: 0.5072  loss_bbox_0: 0.5113  loss_rpn_cls: 0.3611  loss_rpn_reg: 0.5433  time: 0.3418  last_time: 0.3243  data_time: 0.0130  last_data_time: 0.0118   lr: 5e-05  max_mem: 4724M
[03/05 11:33:27] d2.utils.events INFO:  eta: 4:27:08  iter: 4059  total_loss: 4.778  loss_ce: 0.7905  loss_giou: 0.5693  loss_bbox: 0.4598  loss_ce_0: 0.7729  loss_giou_0: 0.5761  loss_bbox_0: 0.486  loss_rpn_cls: 0.3826  loss_rpn_reg: 0.6177  time: 0.3418  last_time: 0.3055  data_time: 0.0139  last_data_time: 0.0138   lr: 5e-05  max_mem: 4724M
[03/05 11:33:34] d2.utils.events INFO:  eta: 4:27:32  iter: 4079  total_loss: 4.538  loss_ce: 0.7478  loss_giou: 0.4862  loss_bbox: 0.4624  loss_ce_0: 0.7265  loss_giou_0: 0.5254  loss_bbox_0: 0.5226  loss_rpn_cls: 0.3737  loss_rpn_reg: 0.5955  time: 0.3419  last_time: 0.2964  data_time: 0.0147  last_data_time: 0.0116   lr: 5e-05  max_mem: 4724M
[03/05 11:33:41] d2.utils.events INFO:  eta: 4:27:20  iter: 4099  total_loss: 4.437  loss_ce: 0.753  loss_giou: 0.556  loss_bbox: 0.4477  loss_ce_0: 0.7244  loss_giou_0: 0.5889  loss_bbox_0: 0.4975  loss_rpn_cls: 0.3583  loss_rpn_reg: 0.5756  time: 0.3419  last_time: 0.3094  data_time: 0.0153  last_data_time: 0.0148   lr: 5e-05  max_mem: 4724M
[03/05 11:33:47] d2.utils.events INFO:  eta: 4:27:19  iter: 4119  total_loss: 4.121  loss_ce: 0.7231  loss_giou: 0.4587  loss_bbox: 0.4552  loss_ce_0: 0.6647  loss_giou_0: 0.4734  loss_bbox_0: 0.4769  loss_rpn_cls: 0.3249  loss_rpn_reg: 0.5513  time: 0.3418  last_time: 0.3261  data_time: 0.0141  last_data_time: 0.0151   lr: 5e-05  max_mem: 4724M
[03/05 11:33:54] d2.utils.events INFO:  eta: 4:27:12  iter: 4139  total_loss: 4.211  loss_ce: 0.7359  loss_giou: 0.4985  loss_bbox: 0.4426  loss_ce_0: 0.7089  loss_giou_0: 0.5252  loss_bbox_0: 0.475  loss_rpn_cls: 0.3564  loss_rpn_reg: 0.5806  time: 0.3418  last_time: 0.3532  data_time: 0.0129  last_data_time: 0.0285   lr: 5e-05  max_mem: 4724M
[03/05 11:34:01] d2.utils.events INFO:  eta: 4:27:09  iter: 4159  total_loss: 4.304  loss_ce: 0.6882  loss_giou: 0.5425  loss_bbox: 0.4216  loss_ce_0: 0.6803  loss_giou_0: 0.5359  loss_bbox_0: 0.4471  loss_rpn_cls: 0.3445  loss_rpn_reg: 0.5806  time: 0.3418  last_time: 0.3245  data_time: 0.0141  last_data_time: 0.0125   lr: 5e-05  max_mem: 4724M
[03/05 11:34:08] d2.utils.events INFO:  eta: 4:27:13  iter: 4179  total_loss: 4.346  loss_ce: 0.6863  loss_giou: 0.5402  loss_bbox: 0.4694  loss_ce_0: 0.6939  loss_giou_0: 0.5477  loss_bbox_0: 0.4787  loss_rpn_cls: 0.3453  loss_rpn_reg: 0.5779  time: 0.3419  last_time: 0.4151  data_time: 0.0140  last_data_time: 0.0141   lr: 5e-05  max_mem: 4724M
[03/05 11:34:15] d2.utils.events INFO:  eta: 4:27:07  iter: 4199  total_loss: 4.069  loss_ce: 0.6768  loss_giou: 0.5094  loss_bbox: 0.411  loss_ce_0: 0.6782  loss_giou_0: 0.5054  loss_bbox_0: 0.4471  loss_rpn_cls: 0.3402  loss_rpn_reg: 0.5329  time: 0.3419  last_time: 0.4381  data_time: 0.0145  last_data_time: 0.0110   lr: 5e-05  max_mem: 4724M
[03/05 11:38:00] detectron2 INFO: Rank of current process: 0. World size: 2
[03/05 11:38:02] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/05 11:38:02] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['OUTPUT_DIR', './output/t1'], resume=False)
[03/05 11:38:02] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/05 11:38:02] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/05 11:38:02] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/05 11:38:03] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/05 11:38:05] d2.data.build INFO: Valid classes: range(0, 20)
[03/05 11:38:05] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/05 11:38:05] d2.data.build INFO: Distribution of instances among all 81 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |
[03/05 11:38:05] d2.data.build INFO: Number of datapoints: 16551
[03/05 11:38:05] d2.data.build INFO: Using training sampler TrainingSampler
[03/05 11:38:05] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/05 11:38:05] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/05 11:38:05] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/05 11:38:06] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[03/05 11:38:06] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/wxf/.torch/iopath_cache/detectron2/ImageNetPretrained/torchvision/R-50.pkl ...
[03/05 11:38:06] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[03/05 11:38:06] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[03/05 11:38:06] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.fpn_lateral2.{bias, weight}
backbone.fpn_lateral3.{bias, weight}
backbone.fpn_lateral4.{bias, weight}
backbone.fpn_lateral5.{bias, weight}
backbone.fpn_output2.{bias, weight}
backbone.fpn_output3.{bias, weight}
backbone.fpn_output4.{bias, weight}
backbone.fpn_output5.{bias, weight}
backbone.top_block.p6.{bias, weight}
backbone.top_block.p7.{bias, weight}
head.head_series.0.bboxes_delta.{bias, weight}
head.head_series.0.class_logits.{bias, weight}
head.head_series.0.cls_module.0.weight
head.head_series.0.cls_module.1.{bias, weight}
head.head_series.0.inst_interact.dynamic_layer.{bias, weight}
head.head_series.0.inst_interact.norm1.{bias, weight}
head.head_series.0.inst_interact.norm2.{bias, weight}
head.head_series.0.inst_interact.norm3.{bias, weight}
head.head_series.0.inst_interact.out_layer.{bias, weight}
head.head_series.0.linear1.{bias, weight}
head.head_series.0.linear2.{bias, weight}
head.head_series.0.norm1.{bias, weight}
head.head_series.0.norm2.{bias, weight}
head.head_series.0.norm3.{bias, weight}
head.head_series.0.reg_module.0.weight
head.head_series.0.reg_module.1.{bias, weight}
head.head_series.0.reg_module.3.weight
head.head_series.0.reg_module.4.{bias, weight}
head.head_series.0.reg_module.6.weight
head.head_series.0.reg_module.7.{bias, weight}
head.head_series.0.self_attn.out_proj.{bias, weight}
head.head_series.0.self_attn.{in_proj_bias, in_proj_weight}
head.head_series.1.bboxes_delta.{bias, weight}
head.head_series.1.class_logits.{bias, weight}
head.head_series.1.cls_module.0.weight
head.head_series.1.cls_module.1.{bias, weight}
head.head_series.1.inst_interact.dynamic_layer.{bias, weight}
head.head_series.1.inst_interact.norm1.{bias, weight}
head.head_series.1.inst_interact.norm2.{bias, weight}
head.head_series.1.inst_interact.norm3.{bias, weight}
head.head_series.1.inst_interact.out_layer.{bias, weight}
head.head_series.1.linear1.{bias, weight}
head.head_series.1.linear2.{bias, weight}
head.head_series.1.norm1.{bias, weight}
head.head_series.1.norm2.{bias, weight}
head.head_series.1.norm3.{bias, weight}
head.head_series.1.norm4.{bias, weight}
head.head_series.1.reg_module.0.weight
head.head_series.1.reg_module.1.{bias, weight}
head.head_series.1.reg_module.3.weight
head.head_series.1.reg_module.4.{bias, weight}
head.head_series.1.reg_module.6.weight
head.head_series.1.reg_module.7.{bias, weight}
head.head_series.1.self_attn.out_proj.{bias, weight}
head.head_series.1.self_attn.{in_proj_bias, in_proj_weight}
head.head_series.1.self_attn_post.out_proj.{bias, weight}
head.head_series.1.self_attn_post.{in_proj_bias, in_proj_weight}
rpn_head.rpn_head.anchor_deltas.{bias, weight}
rpn_head.rpn_head.conv.{bias, weight}
rpn_head.rpn_head.objectness_logits.{bias, weight}
rpn_head.rpn_head.proposal_feats.{bias, weight}
rpn_head.rpn_head.scales.0.scale
rpn_head.rpn_head.scales.1.scale
rpn_head.rpn_head.scales.2.scale
rpn_head.rpn_head.scales.3.scale
rpn_head.rpn_head.scales.4.scale
[03/05 11:38:06] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  stem.fc.{bias, weight}
[03/05 11:38:06] d2.engine.train_loop INFO: Starting training from iteration 0
[03/05 11:38:21] d2.utils.events INFO:  eta: 9:31:02  iter: 19  total_loss: 19.47  loss_ce: 1.816  loss_giou: 2.074  loss_bbox: 4.236  loss_ce_0: 1.836  loss_giou_0: 2.08  loss_bbox_0: 4.233  loss_rpn_cls: 1.133  loss_rpn_reg: 1.999  time: 0.6352  last_time: 0.6295  data_time: 0.1263  last_data_time: 0.0128   lr: 5.2025e-06  max_mem: 4604M
[03/05 11:38:30] d2.utils.events INFO:  eta: 9:17:46  iter: 39  total_loss: 18.54  loss_ce: 1.524  loss_giou: 2.042  loss_bbox: 3.959  loss_ce_0: 1.509  loss_giou_0: 2.046  loss_bbox_0: 4.137  loss_rpn_cls: 1.131  loss_rpn_reg: 1.999  time: 0.5538  last_time: 0.3354  data_time: 0.0133  last_data_time: 0.0089   lr: 1.0152e-05  max_mem: 4724M
[03/05 11:38:37] d2.utils.events INFO:  eta: 6:25:25  iter: 59  total_loss: 17.12  loss_ce: 1.535  loss_giou: 2.182  loss_bbox: 2.67  loss_ce_0: 1.447  loss_giou_0: 2.084  loss_bbox_0: 4.138  loss_rpn_cls: 1.125  loss_rpn_reg: 1.999  time: 0.4794  last_time: 0.2774  data_time: 0.0124  last_data_time: 0.0068   lr: 1.5102e-05  max_mem: 4724M
[03/05 11:38:44] d2.utils.events INFO:  eta: 5:02:05  iter: 79  total_loss: 14.61  loss_ce: 1.554  loss_giou: 1.703  loss_bbox: 2.149  loss_ce_0: 1.442  loss_giou_0: 2.028  loss_bbox_0: 2.589  loss_rpn_cls: 1.108  loss_rpn_reg: 1.999  time: 0.4427  last_time: 0.3317  data_time: 0.0169  last_data_time: 0.0320   lr: 2.0053e-05  max_mem: 4724M
[03/05 11:38:51] d2.utils.events INFO:  eta: 4:59:03  iter: 99  total_loss: 12.31  loss_ce: 1.576  loss_giou: 1.433  loss_bbox: 1.683  loss_ce_0: 1.604  loss_giou_0: 1.337  loss_bbox_0: 1.632  loss_rpn_cls: 1.07  loss_rpn_reg: 1.996  time: 0.4209  last_time: 0.3121  data_time: 0.0144  last_data_time: 0.0109   lr: 2.5002e-05  max_mem: 4724M
[03/05 11:38:58] d2.utils.events INFO:  eta: 4:58:18  iter: 119  total_loss: 12.29  loss_ce: 1.499  loss_giou: 1.44  loss_bbox: 1.755  loss_ce_0: 1.471  loss_giou_0: 1.357  loss_bbox_0: 1.65  loss_rpn_cls: 1.025  loss_rpn_reg: 1.993  time: 0.4081  last_time: 0.3160  data_time: 0.0147  last_data_time: 0.0116   lr: 2.9953e-05  max_mem: 4724M
[03/05 11:39:05] d2.utils.events INFO:  eta: 4:58:05  iter: 139  total_loss: 11.61  loss_ce: 1.514  loss_giou: 1.254  loss_bbox: 1.743  loss_ce_0: 1.521  loss_giou_0: 1.153  loss_bbox_0: 1.481  loss_rpn_cls: 0.8962  loss_rpn_reg: 1.966  time: 0.3992  last_time: 0.4463  data_time: 0.0135  last_data_time: 0.0145   lr: 3.4902e-05  max_mem: 4724M
[03/05 11:39:12] d2.utils.events INFO:  eta: 4:56:32  iter: 159  total_loss: 10.89  loss_ce: 1.543  loss_giou: 1.346  loss_bbox: 1.609  loss_ce_0: 1.609  loss_giou_0: 1.302  loss_bbox_0: 1.735  loss_rpn_cls: 0.4769  loss_rpn_reg: 1.547  time: 0.3917  last_time: 0.3030  data_time: 0.0137  last_data_time: 0.0076   lr: 3.9852e-05  max_mem: 4724M
[03/05 11:39:19] d2.utils.events INFO:  eta: 4:56:25  iter: 179  total_loss: 10.17  loss_ce: 1.51  loss_giou: 1.173  loss_bbox: 1.529  loss_ce_0: 1.515  loss_giou_0: 1.14  loss_bbox_0: 1.542  loss_rpn_cls: 0.5046  loss_rpn_reg: 1.228  time: 0.3873  last_time: 0.4316  data_time: 0.0126  last_data_time: 0.0097   lr: 4.4802e-05  max_mem: 4724M
[03/05 11:39:26] d2.utils.events INFO:  eta: 4:55:36  iter: 199  total_loss: 9.874  loss_ce: 1.428  loss_giou: 1.294  loss_bbox: 1.474  loss_ce_0: 1.48  loss_giou_0: 1.241  loss_bbox_0: 1.392  loss_rpn_cls: 0.543  loss_rpn_reg: 1.086  time: 0.3825  last_time: 0.4172  data_time: 0.0139  last_data_time: 0.0025   lr: 4.9752e-05  max_mem: 4724M
[03/05 11:39:33] d2.utils.events INFO:  eta: 4:55:42  iter: 219  total_loss: 9.714  loss_ce: 1.446  loss_giou: 1.159  loss_bbox: 1.461  loss_ce_0: 1.49  loss_giou_0: 1.06  loss_bbox_0: 1.342  loss_rpn_cls: 0.5622  loss_rpn_reg: 0.9616  time: 0.3799  last_time: 0.4640  data_time: 0.0120  last_data_time: 0.0179   lr: 5e-05  max_mem: 4724M
[03/05 11:39:39] d2.utils.events INFO:  eta: 4:55:22  iter: 239  total_loss: 9.361  loss_ce: 1.405  loss_giou: 1.165  loss_bbox: 1.521  loss_ce_0: 1.397  loss_giou_0: 1.134  loss_bbox_0: 1.379  loss_rpn_cls: 0.5477  loss_rpn_reg: 0.9601  time: 0.3749  last_time: 0.3014  data_time: 0.0137  last_data_time: 0.0118   lr: 5e-05  max_mem: 4724M
[03/05 11:39:46] d2.utils.events INFO:  eta: 4:53:47  iter: 259  total_loss: 9.337  loss_ce: 1.365  loss_giou: 1.25  loss_bbox: 1.548  loss_ce_0: 1.359  loss_giou_0: 1.143  loss_bbox_0: 1.333  loss_rpn_cls: 0.5474  loss_rpn_reg: 0.9522  time: 0.3724  last_time: 0.3259  data_time: 0.0115  last_data_time: 0.0146   lr: 5e-05  max_mem: 4724M
[03/05 11:39:53] d2.utils.events INFO:  eta: 4:54:02  iter: 279  total_loss: 8.898  loss_ce: 1.338  loss_giou: 1.146  loss_bbox: 1.348  loss_ce_0: 1.286  loss_giou_0: 1.055  loss_bbox_0: 1.219  loss_rpn_cls: 0.576  loss_rpn_reg: 0.9106  time: 0.3713  last_time: 0.4466  data_time: 0.0114  last_data_time: 0.0104   lr: 5e-05  max_mem: 4724M
[03/05 11:40:00] d2.utils.events INFO:  eta: 4:53:00  iter: 299  total_loss: 8.983  loss_ce: 1.407  loss_giou: 1.04  loss_bbox: 1.225  loss_ce_0: 1.394  loss_giou_0: 0.977  loss_bbox_0: 1.143  loss_rpn_cls: 0.5613  loss_rpn_reg: 0.8474  time: 0.3685  last_time: 0.3192  data_time: 0.0110  last_data_time: 0.0269   lr: 5e-05  max_mem: 4724M
[03/05 11:40:07] d2.utils.events INFO:  eta: 4:52:53  iter: 319  total_loss: 8.156  loss_ce: 1.362  loss_giou: 1.024  loss_bbox: 1.105  loss_ce_0: 1.317  loss_giou_0: 0.9187  loss_bbox_0: 1.023  loss_rpn_cls: 0.5186  loss_rpn_reg: 0.8296  time: 0.3672  last_time: 0.3611  data_time: 0.0130  last_data_time: 0.0133   lr: 5e-05  max_mem: 4724M
[03/05 11:40:14] d2.utils.events INFO:  eta: 4:53:01  iter: 339  total_loss: 7.985  loss_ce: 1.401  loss_giou: 0.9782  loss_bbox: 1.136  loss_ce_0: 1.355  loss_giou_0: 0.8922  loss_bbox_0: 1.002  loss_rpn_cls: 0.4925  loss_rpn_reg: 0.7927  time: 0.3659  last_time: 0.3228  data_time: 0.0118  last_data_time: 0.0091   lr: 5e-05  max_mem: 4724M
[03/05 11:40:21] d2.utils.events INFO:  eta: 4:53:11  iter: 359  total_loss: 8.077  loss_ce: 1.331  loss_giou: 1.006  loss_bbox: 1.091  loss_ce_0: 1.272  loss_giou_0: 0.9365  loss_bbox_0: 1.071  loss_rpn_cls: 0.5549  loss_rpn_reg: 0.7903  time: 0.3645  last_time: 0.3368  data_time: 0.0124  last_data_time: 0.0094   lr: 5e-05  max_mem: 4724M
[03/05 11:40:28] d2.utils.events INFO:  eta: 4:53:20  iter: 379  total_loss: 7.844  loss_ce: 1.383  loss_giou: 0.907  loss_bbox: 1.121  loss_ce_0: 1.336  loss_giou_0: 0.842  loss_bbox_0: 1.006  loss_rpn_cls: 0.508  loss_rpn_reg: 0.7625  time: 0.3642  last_time: 0.3527  data_time: 0.0136  last_data_time: 0.0234   lr: 5e-05  max_mem: 4724M
[03/05 11:40:35] d2.utils.events INFO:  eta: 4:52:58  iter: 399  total_loss: 7.56  loss_ce: 1.38  loss_giou: 0.904  loss_bbox: 0.9733  loss_ce_0: 1.313  loss_giou_0: 0.8489  loss_bbox_0: 0.8729  loss_rpn_cls: 0.5047  loss_rpn_reg: 0.7519  time: 0.3634  last_time: 0.4582  data_time: 0.0107  last_data_time: 0.0115   lr: 5e-05  max_mem: 4724M
[03/05 11:40:42] d2.utils.events INFO:  eta: 4:52:35  iter: 419  total_loss: 7.706  loss_ce: 1.355  loss_giou: 0.8804  loss_bbox: 1.038  loss_ce_0: 1.301  loss_giou_0: 0.8568  loss_bbox_0: 0.9975  loss_rpn_cls: 0.4829  loss_rpn_reg: 0.7511  time: 0.3628  last_time: 0.2979  data_time: 0.0140  last_data_time: 0.0088   lr: 5e-05  max_mem: 4724M
[03/05 11:40:49] d2.utils.events INFO:  eta: 4:52:04  iter: 439  total_loss: 7.72  loss_ce: 1.348  loss_giou: 0.9311  loss_bbox: 1.125  loss_ce_0: 1.284  loss_giou_0: 0.8312  loss_bbox_0: 0.969  loss_rpn_cls: 0.4954  loss_rpn_reg: 0.7742  time: 0.3613  last_time: 0.3227  data_time: 0.0114  last_data_time: 0.0113   lr: 5e-05  max_mem: 4724M
[03/05 11:40:55] d2.utils.events INFO:  eta: 4:51:30  iter: 459  total_loss: 7.964  loss_ce: 1.33  loss_giou: 1.004  loss_bbox: 1.126  loss_ce_0: 1.274  loss_giou_0: 0.9147  loss_bbox_0: 0.9279  loss_rpn_cls: 0.5059  loss_rpn_reg: 0.7731  time: 0.3597  last_time: 0.3196  data_time: 0.0139  last_data_time: 0.0282   lr: 5e-05  max_mem: 4724M
[03/05 11:41:02] d2.utils.events INFO:  eta: 4:50:42  iter: 479  total_loss: 7.67  loss_ce: 1.283  loss_giou: 0.9411  loss_bbox: 0.9944  loss_ce_0: 1.236  loss_giou_0: 0.9002  loss_bbox_0: 0.9242  loss_rpn_cls: 0.4819  loss_rpn_reg: 0.7886  time: 0.3587  last_time: 0.4420  data_time: 0.0116  last_data_time: 0.0104   lr: 5e-05  max_mem: 4724M
[03/05 11:41:09] d2.utils.events INFO:  eta: 4:49:40  iter: 499  total_loss: 7.393  loss_ce: 1.281  loss_giou: 0.8623  loss_bbox: 0.9956  loss_ce_0: 1.222  loss_giou_0: 0.8578  loss_bbox_0: 0.9657  loss_rpn_cls: 0.4961  loss_rpn_reg: 0.7485  time: 0.3581  last_time: 0.3458  data_time: 0.0143  last_data_time: 0.0213   lr: 5e-05  max_mem: 4724M
[03/05 11:41:16] d2.utils.events INFO:  eta: 4:50:29  iter: 519  total_loss: 7.724  loss_ce: 1.287  loss_giou: 1.011  loss_bbox: 1.137  loss_ce_0: 1.252  loss_giou_0: 0.8608  loss_bbox_0: 0.9366  loss_rpn_cls: 0.493  loss_rpn_reg: 0.7468  time: 0.3584  last_time: 0.3370  data_time: 0.0112  last_data_time: 0.0076   lr: 5e-05  max_mem: 4724M
[03/05 11:41:23] d2.utils.events INFO:  eta: 4:50:23  iter: 539  total_loss: 7.688  loss_ce: 1.326  loss_giou: 0.8694  loss_bbox: 1.003  loss_ce_0: 1.268  loss_giou_0: 0.8268  loss_bbox_0: 0.9941  loss_rpn_cls: 0.5134  loss_rpn_reg: 0.7735  time: 0.3579  last_time: 0.3667  data_time: 0.0123  last_data_time: 0.0047   lr: 5e-05  max_mem: 4724M
[03/05 11:41:31] d2.utils.events INFO:  eta: 4:50:57  iter: 559  total_loss: 7.755  loss_ce: 1.324  loss_giou: 0.9098  loss_bbox: 1.039  loss_ce_0: 1.251  loss_giou_0: 0.8651  loss_bbox_0: 1.006  loss_rpn_cls: 0.4786  loss_rpn_reg: 0.7549  time: 0.3582  last_time: 0.3324  data_time: 0.0117  last_data_time: 0.0084   lr: 5e-05  max_mem: 4724M
[03/05 11:41:38] d2.utils.events INFO:  eta: 4:50:28  iter: 579  total_loss: 7.342  loss_ce: 1.267  loss_giou: 0.8881  loss_bbox: 0.9564  loss_ce_0: 1.206  loss_giou_0: 0.8517  loss_bbox_0: 0.8851  loss_rpn_cls: 0.4948  loss_rpn_reg: 0.7281  time: 0.3575  last_time: 0.3180  data_time: 0.0113  last_data_time: 0.0087   lr: 5e-05  max_mem: 4724M
[03/05 11:41:44] d2.utils.events INFO:  eta: 4:49:22  iter: 599  total_loss: 7.25  loss_ce: 1.243  loss_giou: 0.9562  loss_bbox: 1.011  loss_ce_0: 1.187  loss_giou_0: 0.8837  loss_bbox_0: 0.9163  loss_rpn_cls: 0.484  loss_rpn_reg: 0.7128  time: 0.3566  last_time: 0.3247  data_time: 0.0110  last_data_time: 0.0112   lr: 5e-05  max_mem: 4724M
[03/05 11:41:51] d2.utils.events INFO:  eta: 4:49:10  iter: 619  total_loss: 7.592  loss_ce: 1.224  loss_giou: 0.9098  loss_bbox: 1.053  loss_ce_0: 1.183  loss_giou_0: 0.8733  loss_bbox_0: 1.004  loss_rpn_cls: 0.5251  loss_rpn_reg: 0.7285  time: 0.3564  last_time: 0.3109  data_time: 0.0107  last_data_time: 0.0070   lr: 5e-05  max_mem: 4724M
[03/05 11:41:58] d2.utils.events INFO:  eta: 4:48:48  iter: 639  total_loss: 7.883  loss_ce: 1.225  loss_giou: 0.9601  loss_bbox: 1.049  loss_ce_0: 1.141  loss_giou_0: 0.9856  loss_bbox_0: 0.9428  loss_rpn_cls: 0.492  loss_rpn_reg: 0.783  time: 0.3556  last_time: 0.3021  data_time: 0.0103  last_data_time: 0.0136   lr: 5e-05  max_mem: 4724M
[03/05 11:42:05] d2.utils.events INFO:  eta: 4:48:44  iter: 659  total_loss: 7.284  loss_ce: 1.278  loss_giou: 0.9186  loss_bbox: 0.9688  loss_ce_0: 1.215  loss_giou_0: 0.8684  loss_bbox_0: 0.8786  loss_rpn_cls: 0.4942  loss_rpn_reg: 0.705  time: 0.3553  last_time: 0.3601  data_time: 0.0131  last_data_time: 0.0146   lr: 5e-05  max_mem: 4724M
[03/05 11:42:12] d2.utils.events INFO:  eta: 4:48:36  iter: 679  total_loss: 7.108  loss_ce: 1.247  loss_giou: 0.8629  loss_bbox: 0.902  loss_ce_0: 1.173  loss_giou_0: 0.8267  loss_bbox_0: 0.8786  loss_rpn_cls: 0.5063  loss_rpn_reg: 0.7541  time: 0.3544  last_time: 0.3306  data_time: 0.0119  last_data_time: 0.0290   lr: 5e-05  max_mem: 4724M
[03/05 11:42:19] d2.utils.events INFO:  eta: 4:48:33  iter: 699  total_loss: 6.85  loss_ce: 1.216  loss_giou: 0.8691  loss_bbox: 0.8863  loss_ce_0: 1.15  loss_giou_0: 0.8405  loss_bbox_0: 0.8557  loss_rpn_cls: 0.4928  loss_rpn_reg: 0.7334  time: 0.3542  last_time: 0.3396  data_time: 0.0128  last_data_time: 0.0209   lr: 5e-05  max_mem: 4724M
[03/05 11:42:26] d2.utils.events INFO:  eta: 4:48:30  iter: 719  total_loss: 6.661  loss_ce: 1.181  loss_giou: 0.7755  loss_bbox: 0.8839  loss_ce_0: 1.13  loss_giou_0: 0.7517  loss_bbox_0: 0.8522  loss_rpn_cls: 0.4847  loss_rpn_reg: 0.7177  time: 0.3540  last_time: 0.3325  data_time: 0.0137  last_data_time: 0.0074   lr: 5e-05  max_mem: 4724M
[03/05 11:42:33] d2.utils.events INFO:  eta: 4:49:12  iter: 739  total_loss: 6.979  loss_ce: 1.181  loss_giou: 0.8195  loss_bbox: 0.934  loss_ce_0: 1.152  loss_giou_0: 0.8253  loss_bbox_0: 0.8838  loss_rpn_cls: 0.4907  loss_rpn_reg: 0.7448  time: 0.3546  last_time: 0.2972  data_time: 0.0155  last_data_time: 0.0111   lr: 5e-05  max_mem: 4724M
[03/05 11:42:40] d2.utils.events INFO:  eta: 4:49:01  iter: 759  total_loss: 6.928  loss_ce: 1.27  loss_giou: 0.7958  loss_bbox: 0.8529  loss_ce_0: 1.207  loss_giou_0: 0.7884  loss_bbox_0: 0.8388  loss_rpn_cls: 0.5009  loss_rpn_reg: 0.7261  time: 0.3544  last_time: 0.2783  data_time: 0.0129  last_data_time: 0.0106   lr: 5e-05  max_mem: 4724M
[03/05 11:43:22] detectron2 INFO: Rank of current process: 0. World size: 2
[03/05 11:43:23] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/05 11:43:23] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'OUTPUT_DIR', './output/t1'], resume=False)
[03/05 11:43:23] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/05 11:43:23] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/05 11:43:23] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/05 11:43:24] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/05 11:43:26] d2.data.build INFO: Valid classes: range(0, 20)
[03/05 11:43:26] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/05 11:43:27] d2.data.build INFO: Distribution of instances among all 81 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |
[03/05 11:43:27] d2.data.build INFO: Number of datapoints: 16551
[03/05 11:43:27] d2.data.build INFO: Using training sampler TrainingSampler
[03/05 11:43:27] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/05 11:43:27] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/05 11:43:27] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/05 11:43:27] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[03/05 11:43:27] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/wxf/.torch/iopath_cache/detectron2/ImageNetPretrained/torchvision/R-50.pkl ...
[03/05 11:43:27] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[03/05 11:43:27] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[03/05 11:43:27] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.fpn_lateral2.{bias, weight}
backbone.fpn_lateral3.{bias, weight}
backbone.fpn_lateral4.{bias, weight}
backbone.fpn_lateral5.{bias, weight}
backbone.fpn_output2.{bias, weight}
backbone.fpn_output3.{bias, weight}
backbone.fpn_output4.{bias, weight}
backbone.fpn_output5.{bias, weight}
backbone.top_block.p6.{bias, weight}
backbone.top_block.p7.{bias, weight}
head.head_series.0.bboxes_delta.{bias, weight}
head.head_series.0.class_logits.{bias, weight}
head.head_series.0.cls_module.0.weight
head.head_series.0.cls_module.1.{bias, weight}
head.head_series.0.inst_interact.dynamic_layer.{bias, weight}
head.head_series.0.inst_interact.norm1.{bias, weight}
head.head_series.0.inst_interact.norm2.{bias, weight}
head.head_series.0.inst_interact.norm3.{bias, weight}
head.head_series.0.inst_interact.out_layer.{bias, weight}
head.head_series.0.linear1.{bias, weight}
head.head_series.0.linear2.{bias, weight}
head.head_series.0.norm1.{bias, weight}
head.head_series.0.norm2.{bias, weight}
head.head_series.0.norm3.{bias, weight}
head.head_series.0.reg_module.0.weight
head.head_series.0.reg_module.1.{bias, weight}
head.head_series.0.reg_module.3.weight
head.head_series.0.reg_module.4.{bias, weight}
head.head_series.0.reg_module.6.weight
head.head_series.0.reg_module.7.{bias, weight}
head.head_series.0.self_attn.out_proj.{bias, weight}
head.head_series.0.self_attn.{in_proj_bias, in_proj_weight}
head.head_series.1.bboxes_delta.{bias, weight}
head.head_series.1.class_logits.{bias, weight}
head.head_series.1.cls_module.0.weight
head.head_series.1.cls_module.1.{bias, weight}
head.head_series.1.inst_interact.dynamic_layer.{bias, weight}
head.head_series.1.inst_interact.norm1.{bias, weight}
head.head_series.1.inst_interact.norm2.{bias, weight}
head.head_series.1.inst_interact.norm3.{bias, weight}
head.head_series.1.inst_interact.out_layer.{bias, weight}
head.head_series.1.linear1.{bias, weight}
head.head_series.1.linear2.{bias, weight}
head.head_series.1.norm1.{bias, weight}
head.head_series.1.norm2.{bias, weight}
head.head_series.1.norm3.{bias, weight}
head.head_series.1.norm4.{bias, weight}
head.head_series.1.reg_module.0.weight
head.head_series.1.reg_module.1.{bias, weight}
head.head_series.1.reg_module.3.weight
head.head_series.1.reg_module.4.{bias, weight}
head.head_series.1.reg_module.6.weight
head.head_series.1.reg_module.7.{bias, weight}
head.head_series.1.self_attn.out_proj.{bias, weight}
head.head_series.1.self_attn.{in_proj_bias, in_proj_weight}
head.head_series.1.self_attn_post.out_proj.{bias, weight}
head.head_series.1.self_attn_post.{in_proj_bias, in_proj_weight}
rpn_head.rpn_head.anchor_deltas.{bias, weight}
rpn_head.rpn_head.conv.{bias, weight}
rpn_head.rpn_head.objectness_logits.{bias, weight}
rpn_head.rpn_head.proposal_feats.{bias, weight}
rpn_head.rpn_head.scales.0.scale
rpn_head.rpn_head.scales.1.scale
rpn_head.rpn_head.scales.2.scale
rpn_head.rpn_head.scales.3.scale
rpn_head.rpn_head.scales.4.scale
[03/05 11:43:27] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  stem.fc.{bias, weight}
[03/05 11:43:27] d2.engine.train_loop INFO: Starting training from iteration 0
[03/05 11:43:40] d2.utils.events INFO:  eta: 7:59:34  iter: 19  total_loss: 18.91  loss_ce: 1.96  loss_giou: 2.015  loss_bbox: 4.121  loss_ce_0: 1.758  loss_giou_0: 2.016  loss_bbox_0: 4.123  loss_rpn_cls: 1.132  loss_rpn_reg: 1.999  time: 0.5390  last_time: 0.5089  data_time: 0.1149  last_data_time: 0.0075   lr: 5.2025e-06  max_mem: 2906M
[03/05 11:43:46] d2.utils.events INFO:  eta: 7:28:41  iter: 39  total_loss: 18.67  loss_ce: 1.445  loss_giou: 2.019  loss_bbox: 4.098  loss_ce_0: 1.492  loss_giou_0: 2.025  loss_bbox_0: 4.132  loss_rpn_cls: 1.13  loss_rpn_reg: 1.999  time: 0.4239  last_time: 0.1936  data_time: 0.0046  last_data_time: 0.0049   lr: 1.0152e-05  max_mem: 2906M
[03/05 11:43:51] d2.utils.events INFO:  eta: 5:12:31  iter: 59  total_loss: 18.16  loss_ce: 1.739  loss_giou: 2.117  loss_bbox: 2.991  loss_ce_0: 1.649  loss_giou_0: 2.021  loss_bbox_0: 4.408  loss_rpn_cls: 1.129  loss_rpn_reg: 1.999  time: 0.3604  last_time: 0.2245  data_time: 0.0050  last_data_time: 0.0078   lr: 1.5102e-05  max_mem: 2906M
[03/05 11:43:55] d2.utils.events INFO:  eta: 3:02:08  iter: 79  total_loss: 16.25  loss_ce: 1.543  loss_giou: 2.093  loss_bbox: 2.469  loss_ce_0: 1.455  loss_giou_0: 2.076  loss_bbox_0: 3.381  loss_rpn_cls: 1.123  loss_rpn_reg: 1.999  time: 0.3188  last_time: 0.1843  data_time: 0.0061  last_data_time: 0.0103   lr: 2.0053e-05  max_mem: 2930M
[03/05 11:43:59] d2.utils.events INFO:  eta: 3:00:21  iter: 99  total_loss: 13.7  loss_ce: 1.495  loss_giou: 1.296  loss_bbox: 1.936  loss_ce_0: 1.525  loss_giou_0: 1.973  loss_bbox_0: 2.461  loss_rpn_cls: 1.116  loss_rpn_reg: 1.998  time: 0.2929  last_time: 0.1937  data_time: 0.0058  last_data_time: 0.0028   lr: 2.5002e-05  max_mem: 3029M
[03/05 11:44:03] d2.utils.events INFO:  eta: 2:57:00  iter: 119  total_loss: 13.03  loss_ce: 1.723  loss_giou: 1.375  loss_bbox: 1.973  loss_ce_0: 1.592  loss_giou_0: 1.341  loss_bbox_0: 1.922  loss_rpn_cls: 1.095  loss_rpn_reg: 1.996  time: 0.2754  last_time: 0.1897  data_time: 0.0056  last_data_time: 0.0083   lr: 2.9953e-05  max_mem: 3029M
[03/05 11:44:07] d2.utils.events INFO:  eta: 2:55:05  iter: 139  total_loss: 13.03  loss_ce: 1.6  loss_giou: 1.424  loss_bbox: 2.05  loss_ce_0: 1.578  loss_giou_0: 1.402  loss_bbox_0: 1.875  loss_rpn_cls: 1.041  loss_rpn_reg: 1.983  time: 0.2633  last_time: 0.2030  data_time: 0.0056  last_data_time: 0.0054   lr: 3.4902e-05  max_mem: 3029M
[03/05 11:44:11] d2.utils.events INFO:  eta: 2:54:53  iter: 159  total_loss: 13.16  loss_ce: 1.514  loss_giou: 1.468  loss_bbox: 2.033  loss_ce_0: 1.551  loss_giou_0: 1.434  loss_bbox_0: 2.202  loss_rpn_cls: 0.8166  loss_rpn_reg: 1.756  time: 0.2546  last_time: 0.1986  data_time: 0.0059  last_data_time: 0.0045   lr: 3.9852e-05  max_mem: 3029M
[03/05 11:44:15] d2.utils.events INFO:  eta: 2:54:29  iter: 179  total_loss: 11.22  loss_ce: 1.541  loss_giou: 1.374  loss_bbox: 1.865  loss_ce_0: 1.557  loss_giou_0: 1.316  loss_bbox_0: 1.567  loss_rpn_cls: 0.5793  loss_rpn_reg: 1.272  time: 0.2476  last_time: 0.1849  data_time: 0.0051  last_data_time: 0.0054   lr: 4.4802e-05  max_mem: 3029M
[03/05 11:44:19] d2.utils.events INFO:  eta: 2:54:12  iter: 199  total_loss: 11.23  loss_ce: 1.574  loss_giou: 1.345  loss_bbox: 1.938  loss_ce_0: 1.58  loss_giou_0: 1.331  loss_bbox_0: 1.8  loss_rpn_cls: 0.6404  loss_rpn_reg: 1.143  time: 0.2419  last_time: 0.1955  data_time: 0.0051  last_data_time: 0.0038   lr: 4.9752e-05  max_mem: 3029M
[03/05 11:44:23] d2.utils.events INFO:  eta: 2:53:33  iter: 219  total_loss: 11.33  loss_ce: 1.535  loss_giou: 1.292  loss_bbox: 2.208  loss_ce_0: 1.508  loss_giou_0: 1.18  loss_bbox_0: 1.858  loss_rpn_cls: 0.6059  loss_rpn_reg: 0.9953  time: 0.2369  last_time: 0.2182  data_time: 0.0052  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 11:44:26] d2.utils.events INFO:  eta: 2:53:25  iter: 239  total_loss: 9.913  loss_ce: 1.418  loss_giou: 1.324  loss_bbox: 1.519  loss_ce_0: 1.42  loss_giou_0: 1.272  loss_bbox_0: 1.486  loss_rpn_cls: 0.5912  loss_rpn_reg: 1.044  time: 0.2334  last_time: 0.1910  data_time: 0.0053  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 11:44:30] d2.utils.events INFO:  eta: 2:52:58  iter: 259  total_loss: 10.6  loss_ce: 1.507  loss_giou: 1.417  loss_bbox: 1.736  loss_ce_0: 1.469  loss_giou_0: 1.176  loss_bbox_0: 1.435  loss_rpn_cls: 0.6206  loss_rpn_reg: 0.975  time: 0.2302  last_time: 0.2038  data_time: 0.0055  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 11:44:34] d2.utils.events INFO:  eta: 2:52:54  iter: 279  total_loss: 10.31  loss_ce: 1.483  loss_giou: 1.152  loss_bbox: 1.998  loss_ce_0: 1.471  loss_giou_0: 1.069  loss_bbox_0: 1.648  loss_rpn_cls: 0.5619  loss_rpn_reg: 1.015  time: 0.2274  last_time: 0.1791  data_time: 0.0048  last_data_time: 0.0067   lr: 5e-05  max_mem: 3029M
[03/05 11:44:38] d2.utils.events INFO:  eta: 2:52:35  iter: 299  total_loss: 9.576  loss_ce: 1.518  loss_giou: 1.175  loss_bbox: 1.427  loss_ce_0: 1.453  loss_giou_0: 1.094  loss_bbox_0: 1.346  loss_rpn_cls: 0.5729  loss_rpn_reg: 0.947  time: 0.2247  last_time: 0.1876  data_time: 0.0052  last_data_time: 0.0094   lr: 5e-05  max_mem: 3029M
[03/05 11:44:42] d2.utils.events INFO:  eta: 2:52:28  iter: 319  total_loss: 9.191  loss_ce: 1.513  loss_giou: 1.071  loss_bbox: 1.34  loss_ce_0: 1.501  loss_giou_0: 0.9741  loss_bbox_0: 1.217  loss_rpn_cls: 0.5789  loss_rpn_reg: 0.9309  time: 0.2226  last_time: 0.1963  data_time: 0.0054  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 11:44:46] d2.utils.events INFO:  eta: 2:52:38  iter: 339  total_loss: 9.262  loss_ce: 1.466  loss_giou: 1.075  loss_bbox: 1.474  loss_ce_0: 1.375  loss_giou_0: 1.003  loss_bbox_0: 1.32  loss_rpn_cls: 0.5202  loss_rpn_reg: 0.9464  time: 0.2210  last_time: 0.2097  data_time: 0.0052  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 11:44:50] d2.utils.events INFO:  eta: 2:52:37  iter: 359  total_loss: 10.11  loss_ce: 1.48  loss_giou: 1.182  loss_bbox: 1.824  loss_ce_0: 1.469  loss_giou_0: 1.052  loss_bbox_0: 1.489  loss_rpn_cls: 0.5015  loss_rpn_reg: 0.9758  time: 0.2196  last_time: 0.1809  data_time: 0.0053  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 11:44:54] d2.utils.events INFO:  eta: 2:52:27  iter: 379  total_loss: 9.36  loss_ce: 1.468  loss_giou: 1.134  loss_bbox: 1.327  loss_ce_0: 1.376  loss_giou_0: 1.063  loss_bbox_0: 1.301  loss_rpn_cls: 0.5416  loss_rpn_reg: 0.9559  time: 0.2180  last_time: 0.1874  data_time: 0.0053  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 11:44:58] d2.utils.events INFO:  eta: 2:52:31  iter: 399  total_loss: 8.595  loss_ce: 1.439  loss_giou: 1.022  loss_bbox: 1.249  loss_ce_0: 1.413  loss_giou_0: 1.049  loss_bbox_0: 1.158  loss_rpn_cls: 0.5453  loss_rpn_reg: 0.8583  time: 0.2170  last_time: 0.1966  data_time: 0.0047  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 11:45:02] d2.utils.events INFO:  eta: 2:52:28  iter: 419  total_loss: 8.991  loss_ce: 1.45  loss_giou: 1.06  loss_bbox: 1.392  loss_ce_0: 1.423  loss_giou_0: 1.004  loss_bbox_0: 1.349  loss_rpn_cls: 0.5372  loss_rpn_reg: 0.8632  time: 0.2160  last_time: 0.1907  data_time: 0.0054  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 11:45:06] d2.utils.events INFO:  eta: 2:52:23  iter: 439  total_loss: 8.955  loss_ce: 1.496  loss_giou: 1.088  loss_bbox: 1.41  loss_ce_0: 1.429  loss_giou_0: 0.9505  loss_bbox_0: 1.081  loss_rpn_cls: 0.5134  loss_rpn_reg: 0.8532  time: 0.2147  last_time: 0.1779  data_time: 0.0050  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 11:45:09] d2.utils.events INFO:  eta: 2:52:06  iter: 459  total_loss: 9.235  loss_ce: 1.406  loss_giou: 1.237  loss_bbox: 1.538  loss_ce_0: 1.398  loss_giou_0: 1.047  loss_bbox_0: 1.274  loss_rpn_cls: 0.5309  loss_rpn_reg: 0.8881  time: 0.2133  last_time: 0.1670  data_time: 0.0050  last_data_time: 0.0007   lr: 5e-05  max_mem: 3029M
[03/05 11:45:13] d2.utils.events INFO:  eta: 2:51:57  iter: 479  total_loss: 8.642  loss_ce: 1.356  loss_giou: 1.036  loss_bbox: 1.259  loss_ce_0: 1.327  loss_giou_0: 0.9377  loss_bbox_0: 1.218  loss_rpn_cls: 0.5076  loss_rpn_reg: 0.8473  time: 0.2125  last_time: 0.2169  data_time: 0.0062  last_data_time: 0.0081   lr: 5e-05  max_mem: 3029M
[03/05 11:45:17] d2.utils.events INFO:  eta: 2:51:45  iter: 499  total_loss: 8.498  loss_ce: 1.382  loss_giou: 1.087  loss_bbox: 1.188  loss_ce_0: 1.349  loss_giou_0: 1.025  loss_bbox_0: 1.178  loss_rpn_cls: 0.5712  loss_rpn_reg: 0.8008  time: 0.2117  last_time: 0.1685  data_time: 0.0052  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 11:45:21] d2.utils.events INFO:  eta: 2:51:35  iter: 519  total_loss: 8.194  loss_ce: 1.29  loss_giou: 1.026  loss_bbox: 1.109  loss_ce_0: 1.289  loss_giou_0: 0.9687  loss_bbox_0: 1.088  loss_rpn_cls: 0.5839  loss_rpn_reg: 0.8138  time: 0.2109  last_time: 0.1968  data_time: 0.0053  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 11:45:25] d2.utils.events INFO:  eta: 2:51:26  iter: 539  total_loss: 8.54  loss_ce: 1.417  loss_giou: 1.017  loss_bbox: 1.249  loss_ce_0: 1.373  loss_giou_0: 1  loss_bbox_0: 1.092  loss_rpn_cls: 0.5962  loss_rpn_reg: 0.8052  time: 0.2102  last_time: 0.1967  data_time: 0.0050  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 11:45:29] d2.utils.events INFO:  eta: 2:51:17  iter: 559  total_loss: 8.153  loss_ce: 1.323  loss_giou: 1.041  loss_bbox: 1.161  loss_ce_0: 1.347  loss_giou_0: 0.9833  loss_bbox_0: 1.101  loss_rpn_cls: 0.5441  loss_rpn_reg: 0.7917  time: 0.2095  last_time: 0.1821  data_time: 0.0049  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 11:45:33] d2.utils.events INFO:  eta: 2:51:14  iter: 579  total_loss: 8.396  loss_ce: 1.461  loss_giou: 0.8974  loss_bbox: 1.136  loss_ce_0: 1.394  loss_giou_0: 0.881  loss_bbox_0: 1.135  loss_rpn_cls: 0.5165  loss_rpn_reg: 0.809  time: 0.2090  last_time: 0.2100  data_time: 0.0058  last_data_time: 0.0072   lr: 5e-05  max_mem: 3029M
[03/05 11:45:37] d2.utils.events INFO:  eta: 2:51:06  iter: 599  total_loss: 8.136  loss_ce: 1.416  loss_giou: 0.9055  loss_bbox: 1.211  loss_ce_0: 1.397  loss_giou_0: 0.8359  loss_bbox_0: 1.144  loss_rpn_cls: 0.5463  loss_rpn_reg: 0.7719  time: 0.2083  last_time: 0.1912  data_time: 0.0046  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 11:45:40] d2.utils.events INFO:  eta: 2:51:02  iter: 619  total_loss: 8.486  loss_ce: 1.345  loss_giou: 1.056  loss_bbox: 1.228  loss_ce_0: 1.313  loss_giou_0: 0.9983  loss_bbox_0: 1.165  loss_rpn_cls: 0.5749  loss_rpn_reg: 0.7785  time: 0.2077  last_time: 0.1950  data_time: 0.0049  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 11:45:44] d2.utils.events INFO:  eta: 2:50:58  iter: 639  total_loss: 8.053  loss_ce: 1.408  loss_giou: 0.8849  loss_bbox: 1.084  loss_ce_0: 1.363  loss_giou_0: 0.8144  loss_bbox_0: 0.9268  loss_rpn_cls: 0.5846  loss_rpn_reg: 0.7271  time: 0.2073  last_time: 0.1812  data_time: 0.0058  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 11:45:48] d2.utils.events INFO:  eta: 2:50:54  iter: 659  total_loss: 8.232  loss_ce: 1.432  loss_giou: 0.9556  loss_bbox: 1.105  loss_ce_0: 1.395  loss_giou_0: 0.9231  loss_bbox_0: 0.9776  loss_rpn_cls: 0.5736  loss_rpn_reg: 0.8137  time: 0.2068  last_time: 0.1881  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 11:45:52] d2.utils.events INFO:  eta: 2:50:53  iter: 679  total_loss: 8.071  loss_ce: 1.405  loss_giou: 0.7987  loss_bbox: 1.172  loss_ce_0: 1.34  loss_giou_0: 0.8312  loss_bbox_0: 1.094  loss_rpn_cls: 0.5211  loss_rpn_reg: 0.765  time: 0.2064  last_time: 0.2120  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 11:45:56] d2.utils.events INFO:  eta: 2:51:00  iter: 699  total_loss: 8.208  loss_ce: 1.303  loss_giou: 1.024  loss_bbox: 1.056  loss_ce_0: 1.264  loss_giou_0: 0.9284  loss_bbox_0: 0.9088  loss_rpn_cls: 0.6036  loss_rpn_reg: 0.7575  time: 0.2063  last_time: 0.2021  data_time: 0.0051  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 11:46:00] d2.utils.events INFO:  eta: 2:51:06  iter: 719  total_loss: 8.071  loss_ce: 1.385  loss_giou: 0.9662  loss_bbox: 0.9771  loss_ce_0: 1.351  loss_giou_0: 0.9458  loss_bbox_0: 1.009  loss_rpn_cls: 0.5888  loss_rpn_reg: 0.769  time: 0.2061  last_time: 0.2225  data_time: 0.0050  last_data_time: 0.0069   lr: 5e-05  max_mem: 3029M
[03/05 11:46:04] d2.utils.events INFO:  eta: 2:50:58  iter: 739  total_loss: 7.716  loss_ce: 1.265  loss_giou: 0.9086  loss_bbox: 1.185  loss_ce_0: 1.254  loss_giou_0: 0.8071  loss_bbox_0: 1.02  loss_rpn_cls: 0.517  loss_rpn_reg: 0.7644  time: 0.2057  last_time: 0.1947  data_time: 0.0052  last_data_time: 0.0070   lr: 5e-05  max_mem: 3029M
[03/05 11:46:08] d2.utils.events INFO:  eta: 2:50:39  iter: 759  total_loss: 7.982  loss_ce: 1.397  loss_giou: 0.866  loss_bbox: 1.054  loss_ce_0: 1.316  loss_giou_0: 0.8323  loss_bbox_0: 0.9134  loss_rpn_cls: 0.5235  loss_rpn_reg: 0.7881  time: 0.2050  last_time: 0.2009  data_time: 0.0052  last_data_time: 0.0076   lr: 5e-05  max_mem: 3029M
[03/05 11:46:12] d2.utils.events INFO:  eta: 2:50:34  iter: 779  total_loss: 7.679  loss_ce: 1.401  loss_giou: 0.923  loss_bbox: 0.9894  loss_ce_0: 1.31  loss_giou_0: 0.9057  loss_bbox_0: 0.9082  loss_rpn_cls: 0.4823  loss_rpn_reg: 0.8327  time: 0.2046  last_time: 0.2010  data_time: 0.0061  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 11:46:16] d2.utils.events INFO:  eta: 2:50:39  iter: 799  total_loss: 7.945  loss_ce: 1.358  loss_giou: 0.9654  loss_bbox: 1.121  loss_ce_0: 1.295  loss_giou_0: 0.867  loss_bbox_0: 1.012  loss_rpn_cls: 0.4868  loss_rpn_reg: 0.8191  time: 0.2044  last_time: 0.2054  data_time: 0.0051  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 11:46:20] d2.utils.events INFO:  eta: 2:50:30  iter: 819  total_loss: 8  loss_ce: 1.382  loss_giou: 0.9472  loss_bbox: 1.132  loss_ce_0: 1.391  loss_giou_0: 0.9134  loss_bbox_0: 1.12  loss_rpn_cls: 0.5001  loss_rpn_reg: 0.7823  time: 0.2041  last_time: 0.1826  data_time: 0.0054  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 11:46:23] d2.utils.events INFO:  eta: 2:50:22  iter: 839  total_loss: 7.724  loss_ce: 1.351  loss_giou: 0.8942  loss_bbox: 1.039  loss_ce_0: 1.255  loss_giou_0: 0.7789  loss_bbox_0: 0.9087  loss_rpn_cls: 0.4971  loss_rpn_reg: 0.7591  time: 0.2038  last_time: 0.1917  data_time: 0.0053  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 11:46:27] d2.utils.events INFO:  eta: 2:50:18  iter: 859  total_loss: 7.483  loss_ce: 1.35  loss_giou: 0.7853  loss_bbox: 0.9811  loss_ce_0: 1.324  loss_giou_0: 0.7729  loss_bbox_0: 0.9612  loss_rpn_cls: 0.5521  loss_rpn_reg: 0.7291  time: 0.2035  last_time: 0.1841  data_time: 0.0047  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 11:46:31] d2.utils.events INFO:  eta: 2:50:15  iter: 879  total_loss: 7.497  loss_ce: 1.318  loss_giou: 0.8546  loss_bbox: 1.11  loss_ce_0: 1.29  loss_giou_0: 0.8451  loss_bbox_0: 0.9371  loss_rpn_cls: 0.5166  loss_rpn_reg: 0.758  time: 0.2033  last_time: 0.1783  data_time: 0.0054  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 11:46:35] d2.utils.events INFO:  eta: 2:50:08  iter: 899  total_loss: 7.187  loss_ce: 1.301  loss_giou: 0.8403  loss_bbox: 0.9756  loss_ce_0: 1.245  loss_giou_0: 0.7559  loss_bbox_0: 0.852  loss_rpn_cls: 0.467  loss_rpn_reg: 0.7653  time: 0.2030  last_time: 0.2056  data_time: 0.0062  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 11:46:39] d2.utils.events INFO:  eta: 2:50:00  iter: 919  total_loss: 7.582  loss_ce: 1.265  loss_giou: 0.9491  loss_bbox: 0.9743  loss_ce_0: 1.24  loss_giou_0: 0.8973  loss_bbox_0: 0.9344  loss_rpn_cls: 0.5215  loss_rpn_reg: 0.7947  time: 0.2027  last_time: 0.1837  data_time: 0.0056  last_data_time: 0.0070   lr: 5e-05  max_mem: 3029M
[03/05 11:46:43] d2.utils.events INFO:  eta: 2:49:49  iter: 939  total_loss: 7.696  loss_ce: 1.287  loss_giou: 0.9807  loss_bbox: 1.049  loss_ce_0: 1.257  loss_giou_0: 0.9289  loss_bbox_0: 0.9847  loss_rpn_cls: 0.5096  loss_rpn_reg: 0.7227  time: 0.2023  last_time: 0.2004  data_time: 0.0050  last_data_time: 0.0070   lr: 5e-05  max_mem: 3029M
[03/05 11:46:47] d2.utils.events INFO:  eta: 2:49:47  iter: 959  total_loss: 7.179  loss_ce: 1.31  loss_giou: 0.8223  loss_bbox: 0.9085  loss_ce_0: 1.214  loss_giou_0: 0.7445  loss_bbox_0: 0.8287  loss_rpn_cls: 0.524  loss_rpn_reg: 0.7367  time: 0.2020  last_time: 0.2058  data_time: 0.0056  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 11:46:51] d2.utils.events INFO:  eta: 2:49:40  iter: 979  total_loss: 7.028  loss_ce: 1.251  loss_giou: 0.8565  loss_bbox: 0.8946  loss_ce_0: 1.208  loss_giou_0: 0.7958  loss_bbox_0: 0.7975  loss_rpn_cls: 0.525  loss_rpn_reg: 0.7238  time: 0.2019  last_time: 0.1754  data_time: 0.0046  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 11:46:54] d2.utils.events INFO:  eta: 2:49:29  iter: 999  total_loss: 7.439  loss_ce: 1.285  loss_giou: 0.9556  loss_bbox: 0.9559  loss_ce_0: 1.242  loss_giou_0: 0.8306  loss_bbox_0: 0.8572  loss_rpn_cls: 0.5482  loss_rpn_reg: 0.7605  time: 0.2015  last_time: 0.2040  data_time: 0.0047  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 11:46:58] d2.utils.events INFO:  eta: 2:48:52  iter: 1019  total_loss: 7.111  loss_ce: 1.238  loss_giou: 0.7939  loss_bbox: 0.9641  loss_ce_0: 1.177  loss_giou_0: 0.7868  loss_bbox_0: 0.895  loss_rpn_cls: 0.5078  loss_rpn_reg: 0.7483  time: 0.2012  last_time: 0.1945  data_time: 0.0045  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 11:47:02] d2.utils.events INFO:  eta: 2:48:33  iter: 1039  total_loss: 7.499  loss_ce: 1.293  loss_giou: 0.839  loss_bbox: 1.037  loss_ce_0: 1.241  loss_giou_0: 0.8055  loss_bbox_0: 0.9526  loss_rpn_cls: 0.5181  loss_rpn_reg: 0.7539  time: 0.2007  last_time: 0.1889  data_time: 0.0040  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 11:47:06] d2.utils.events INFO:  eta: 2:48:29  iter: 1059  total_loss: 7.329  loss_ce: 1.325  loss_giou: 0.7447  loss_bbox: 1  loss_ce_0: 1.266  loss_giou_0: 0.7304  loss_bbox_0: 0.9836  loss_rpn_cls: 0.4979  loss_rpn_reg: 0.7714  time: 0.2006  last_time: 0.1678  data_time: 0.0046  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 11:47:09] d2.utils.events INFO:  eta: 2:48:21  iter: 1079  total_loss: 7.149  loss_ce: 1.225  loss_giou: 0.881  loss_bbox: 0.9493  loss_ce_0: 1.218  loss_giou_0: 0.8162  loss_bbox_0: 0.7899  loss_rpn_cls: 0.4937  loss_rpn_reg: 0.7311  time: 0.2004  last_time: 0.2006  data_time: 0.0050  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 11:47:13] d2.utils.events INFO:  eta: 2:48:06  iter: 1099  total_loss: 6.835  loss_ce: 1.281  loss_giou: 0.7667  loss_bbox: 0.8899  loss_ce_0: 1.225  loss_giou_0: 0.7488  loss_bbox_0: 0.8004  loss_rpn_cls: 0.4925  loss_rpn_reg: 0.7189  time: 0.2002  last_time: 0.1846  data_time: 0.0045  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 11:47:17] d2.utils.events INFO:  eta: 2:48:08  iter: 1119  total_loss: 7.857  loss_ce: 1.296  loss_giou: 0.8956  loss_bbox: 1.063  loss_ce_0: 1.228  loss_giou_0: 0.868  loss_bbox_0: 0.9965  loss_rpn_cls: 0.5104  loss_rpn_reg: 0.8015  time: 0.2000  last_time: 0.1985  data_time: 0.0050  last_data_time: 0.0077   lr: 5e-05  max_mem: 3029M
[03/05 11:47:21] d2.utils.events INFO:  eta: 2:48:04  iter: 1139  total_loss: 7.82  loss_ce: 1.303  loss_giou: 0.9218  loss_bbox: 1.161  loss_ce_0: 1.253  loss_giou_0: 0.8868  loss_bbox_0: 1.028  loss_rpn_cls: 0.5064  loss_rpn_reg: 0.7384  time: 0.1998  last_time: 0.1974  data_time: 0.0043  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 11:47:25] d2.utils.events INFO:  eta: 2:47:45  iter: 1159  total_loss: 7.043  loss_ce: 1.286  loss_giou: 0.8262  loss_bbox: 0.8381  loss_ce_0: 1.237  loss_giou_0: 0.8102  loss_bbox_0: 0.8253  loss_rpn_cls: 0.5089  loss_rpn_reg: 0.727  time: 0.1995  last_time: 0.1791  data_time: 0.0052  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 11:47:28] d2.utils.events INFO:  eta: 2:47:24  iter: 1179  total_loss: 7.327  loss_ce: 1.232  loss_giou: 0.8345  loss_bbox: 1.039  loss_ce_0: 1.189  loss_giou_0: 0.822  loss_bbox_0: 1.004  loss_rpn_cls: 0.4757  loss_rpn_reg: 0.7667  time: 0.1993  last_time: 0.1799  data_time: 0.0049  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 11:47:32] d2.utils.events INFO:  eta: 2:47:11  iter: 1199  total_loss: 7.279  loss_ce: 1.216  loss_giou: 0.9256  loss_bbox: 0.9234  loss_ce_0: 1.186  loss_giou_0: 0.8743  loss_bbox_0: 0.8977  loss_rpn_cls: 0.5209  loss_rpn_reg: 0.7134  time: 0.1991  last_time: 0.2141  data_time: 0.0046  last_data_time: 0.0073   lr: 5e-05  max_mem: 3029M
[03/05 11:47:36] d2.utils.events INFO:  eta: 2:46:56  iter: 1219  total_loss: 7.28  loss_ce: 1.177  loss_giou: 0.9522  loss_bbox: 0.9688  loss_ce_0: 1.139  loss_giou_0: 0.9639  loss_bbox_0: 0.9239  loss_rpn_cls: 0.5049  loss_rpn_reg: 0.7745  time: 0.1989  last_time: 0.1724  data_time: 0.0042  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 11:47:40] d2.utils.events INFO:  eta: 2:46:51  iter: 1239  total_loss: 7.134  loss_ce: 1.255  loss_giou: 0.8057  loss_bbox: 0.9196  loss_ce_0: 1.158  loss_giou_0: 0.7328  loss_bbox_0: 0.8126  loss_rpn_cls: 0.5008  loss_rpn_reg: 0.7266  time: 0.1986  last_time: 0.1752  data_time: 0.0047  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 11:47:43] d2.utils.events INFO:  eta: 2:46:37  iter: 1259  total_loss: 7.215  loss_ce: 1.207  loss_giou: 0.9407  loss_bbox: 0.892  loss_ce_0: 1.098  loss_giou_0: 0.9181  loss_bbox_0: 0.911  loss_rpn_cls: 0.5  loss_rpn_reg: 0.7689  time: 0.1984  last_time: 0.1910  data_time: 0.0043  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 11:47:47] d2.utils.events INFO:  eta: 2:46:32  iter: 1279  total_loss: 7.295  loss_ce: 1.296  loss_giou: 0.8168  loss_bbox: 1.007  loss_ce_0: 1.14  loss_giou_0: 0.8196  loss_bbox_0: 0.945  loss_rpn_cls: 0.5202  loss_rpn_reg: 0.6941  time: 0.1982  last_time: 0.1944  data_time: 0.0047  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 11:47:51] d2.utils.events INFO:  eta: 2:46:32  iter: 1299  total_loss: 7.4  loss_ce: 1.21  loss_giou: 0.8577  loss_bbox: 1.077  loss_ce_0: 1.193  loss_giou_0: 0.8035  loss_bbox_0: 0.8231  loss_rpn_cls: 0.4984  loss_rpn_reg: 0.7186  time: 0.1982  last_time: 0.1915  data_time: 0.0050  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 11:47:55] d2.utils.events INFO:  eta: 2:46:25  iter: 1319  total_loss: 7.268  loss_ce: 1.259  loss_giou: 0.8636  loss_bbox: 0.9363  loss_ce_0: 1.182  loss_giou_0: 0.8288  loss_bbox_0: 0.9293  loss_rpn_cls: 0.4961  loss_rpn_reg: 0.7067  time: 0.1980  last_time: 0.1860  data_time: 0.0051  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 11:47:59] d2.utils.events INFO:  eta: 2:46:09  iter: 1339  total_loss: 7.198  loss_ce: 1.193  loss_giou: 0.83  loss_bbox: 0.9375  loss_ce_0: 1.122  loss_giou_0: 0.8205  loss_bbox_0: 0.9497  loss_rpn_cls: 0.4814  loss_rpn_reg: 0.7985  time: 0.1979  last_time: 0.1717  data_time: 0.0049  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 11:48:03] d2.utils.events INFO:  eta: 2:46:05  iter: 1359  total_loss: 6.835  loss_ce: 1.245  loss_giou: 0.7849  loss_bbox: 0.8876  loss_ce_0: 1.185  loss_giou_0: 0.7657  loss_bbox_0: 0.8049  loss_rpn_cls: 0.5005  loss_rpn_reg: 0.7397  time: 0.1978  last_time: 0.1897  data_time: 0.0049  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 11:48:07] d2.utils.events INFO:  eta: 2:46:09  iter: 1379  total_loss: 6.954  loss_ce: 1.219  loss_giou: 0.8167  loss_bbox: 0.7796  loss_ce_0: 1.148  loss_giou_0: 0.8203  loss_bbox_0: 0.8245  loss_rpn_cls: 0.5268  loss_rpn_reg: 0.6921  time: 0.1977  last_time: 0.1995  data_time: 0.0054  last_data_time: 0.0126   lr: 5e-05  max_mem: 3029M
[03/05 11:48:10] d2.utils.events INFO:  eta: 2:45:45  iter: 1399  total_loss: 6.585  loss_ce: 1.199  loss_giou: 0.7872  loss_bbox: 0.8377  loss_ce_0: 1.126  loss_giou_0: 0.7496  loss_bbox_0: 0.7708  loss_rpn_cls: 0.4834  loss_rpn_reg: 0.6998  time: 0.1976  last_time: 0.2008  data_time: 0.0045  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 11:48:14] d2.utils.events INFO:  eta: 2:45:34  iter: 1419  total_loss: 6.826  loss_ce: 1.251  loss_giou: 0.813  loss_bbox: 0.8843  loss_ce_0: 1.186  loss_giou_0: 0.7603  loss_bbox_0: 0.8377  loss_rpn_cls: 0.4882  loss_rpn_reg: 0.7421  time: 0.1974  last_time: 0.2253  data_time: 0.0045  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 11:48:18] d2.utils.events INFO:  eta: 2:45:40  iter: 1439  total_loss: 6.674  loss_ce: 1.17  loss_giou: 0.7263  loss_bbox: 0.8609  loss_ce_0: 1.158  loss_giou_0: 0.6871  loss_bbox_0: 0.7935  loss_rpn_cls: 0.4913  loss_rpn_reg: 0.6775  time: 0.1975  last_time: 0.2086  data_time: 0.0050  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 11:48:22] d2.utils.events INFO:  eta: 2:45:45  iter: 1459  total_loss: 6.911  loss_ce: 1.153  loss_giou: 0.8523  loss_bbox: 0.9291  loss_ce_0: 1.146  loss_giou_0: 0.8263  loss_bbox_0: 0.8447  loss_rpn_cls: 0.4753  loss_rpn_reg: 0.7699  time: 0.1974  last_time: 0.2024  data_time: 0.0045  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 11:48:26] d2.utils.events INFO:  eta: 2:45:42  iter: 1479  total_loss: 6.95  loss_ce: 1.188  loss_giou: 0.8129  loss_bbox: 0.9892  loss_ce_0: 1.146  loss_giou_0: 0.7635  loss_bbox_0: 0.8659  loss_rpn_cls: 0.4398  loss_rpn_reg: 0.7103  time: 0.1974  last_time: 0.2036  data_time: 0.0046  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 11:48:30] d2.utils.events INFO:  eta: 2:45:52  iter: 1499  total_loss: 7.357  loss_ce: 1.262  loss_giou: 0.8498  loss_bbox: 1.055  loss_ce_0: 1.163  loss_giou_0: 0.796  loss_bbox_0: 0.9347  loss_rpn_cls: 0.4453  loss_rpn_reg: 0.7643  time: 0.1974  last_time: 0.1917  data_time: 0.0047  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 11:48:34] d2.utils.events INFO:  eta: 2:45:46  iter: 1519  total_loss: 7.172  loss_ce: 1.194  loss_giou: 0.8679  loss_bbox: 0.99  loss_ce_0: 1.119  loss_giou_0: 0.822  loss_bbox_0: 0.916  loss_rpn_cls: 0.5  loss_rpn_reg: 0.6944  time: 0.1972  last_time: 0.1944  data_time: 0.0046  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 11:48:38] d2.utils.events INFO:  eta: 2:45:43  iter: 1539  total_loss: 6.543  loss_ce: 1.169  loss_giou: 0.665  loss_bbox: 0.8843  loss_ce_0: 1.121  loss_giou_0: 0.6385  loss_bbox_0: 0.8118  loss_rpn_cls: 0.4727  loss_rpn_reg: 0.6717  time: 0.1972  last_time: 0.1725  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 11:48:42] d2.utils.events INFO:  eta: 2:45:43  iter: 1559  total_loss: 6.764  loss_ce: 1.143  loss_giou: 0.7756  loss_bbox: 0.9052  loss_ce_0: 1.049  loss_giou_0: 0.7786  loss_bbox_0: 0.8665  loss_rpn_cls: 0.458  loss_rpn_reg: 0.7294  time: 0.1971  last_time: 0.2049  data_time: 0.0046  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 11:48:46] d2.utils.events INFO:  eta: 2:45:38  iter: 1579  total_loss: 6.246  loss_ce: 1.091  loss_giou: 0.7678  loss_bbox: 0.7686  loss_ce_0: 1.009  loss_giou_0: 0.7252  loss_bbox_0: 0.7745  loss_rpn_cls: 0.478  loss_rpn_reg: 0.6948  time: 0.1970  last_time: 0.1896  data_time: 0.0044  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 11:48:50] d2.utils.events INFO:  eta: 2:45:41  iter: 1599  total_loss: 7.117  loss_ce: 1.186  loss_giou: 0.8405  loss_bbox: 1.005  loss_ce_0: 1.161  loss_giou_0: 0.8133  loss_bbox_0: 0.8767  loss_rpn_cls: 0.5039  loss_rpn_reg: 0.8297  time: 0.1970  last_time: 0.2103  data_time: 0.0049  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 11:48:53] d2.utils.events INFO:  eta: 2:45:30  iter: 1619  total_loss: 6.504  loss_ce: 1.156  loss_giou: 0.7625  loss_bbox: 0.8526  loss_ce_0: 1.083  loss_giou_0: 0.7353  loss_bbox_0: 0.8474  loss_rpn_cls: 0.4626  loss_rpn_reg: 0.6876  time: 0.1968  last_time: 0.1885  data_time: 0.0050  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 11:48:57] d2.utils.events INFO:  eta: 2:45:36  iter: 1639  total_loss: 6.906  loss_ce: 1.157  loss_giou: 0.8192  loss_bbox: 0.7512  loss_ce_0: 1.135  loss_giou_0: 0.8199  loss_bbox_0: 0.7122  loss_rpn_cls: 0.4978  loss_rpn_reg: 0.8121  time: 0.1969  last_time: 0.1822  data_time: 0.0052  last_data_time: 0.0031   lr: 5e-05  max_mem: 3029M
[03/05 11:49:01] d2.utils.events INFO:  eta: 2:45:32  iter: 1659  total_loss: 7.131  loss_ce: 1.243  loss_giou: 0.7863  loss_bbox: 0.9045  loss_ce_0: 1.202  loss_giou_0: 0.7398  loss_bbox_0: 0.8876  loss_rpn_cls: 0.4957  loss_rpn_reg: 0.7646  time: 0.1968  last_time: 0.1792  data_time: 0.0057  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 11:49:05] d2.utils.events INFO:  eta: 2:45:28  iter: 1679  total_loss: 6.817  loss_ce: 1.165  loss_giou: 0.869  loss_bbox: 0.8302  loss_ce_0: 1.152  loss_giou_0: 0.8355  loss_bbox_0: 0.8157  loss_rpn_cls: 0.5203  loss_rpn_reg: 0.7087  time: 0.1967  last_time: 0.1907  data_time: 0.0055  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 11:49:09] d2.utils.events INFO:  eta: 2:45:03  iter: 1699  total_loss: 6.459  loss_ce: 1.135  loss_giou: 0.711  loss_bbox: 0.8179  loss_ce_0: 1.077  loss_giou_0: 0.69  loss_bbox_0: 0.7156  loss_rpn_cls: 0.4611  loss_rpn_reg: 0.6785  time: 0.1966  last_time: 0.1984  data_time: 0.0046  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 11:49:13] d2.utils.events INFO:  eta: 2:44:43  iter: 1719  total_loss: 6.621  loss_ce: 1.214  loss_giou: 0.7105  loss_bbox: 0.815  loss_ce_0: 1.111  loss_giou_0: 0.708  loss_bbox_0: 0.8126  loss_rpn_cls: 0.4635  loss_rpn_reg: 0.7332  time: 0.1965  last_time: 0.2020  data_time: 0.0050  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 11:49:17] d2.utils.events INFO:  eta: 2:44:38  iter: 1739  total_loss: 7.165  loss_ce: 1.104  loss_giou: 0.9491  loss_bbox: 0.973  loss_ce_0: 1.076  loss_giou_0: 0.9397  loss_bbox_0: 0.9328  loss_rpn_cls: 0.4911  loss_rpn_reg: 0.7247  time: 0.1963  last_time: 0.1687  data_time: 0.0047  last_data_time: 0.0009   lr: 5e-05  max_mem: 3029M
[03/05 11:49:20] d2.utils.events INFO:  eta: 2:44:51  iter: 1759  total_loss: 6.387  loss_ce: 1.138  loss_giou: 0.7214  loss_bbox: 0.7457  loss_ce_0: 1.069  loss_giou_0: 0.7436  loss_bbox_0: 0.7579  loss_rpn_cls: 0.4756  loss_rpn_reg: 0.7335  time: 0.1963  last_time: 0.1910  data_time: 0.0055  last_data_time: 0.0067   lr: 5e-05  max_mem: 3029M
[03/05 11:49:24] d2.utils.events INFO:  eta: 2:44:47  iter: 1779  total_loss: 6.609  loss_ce: 1.162  loss_giou: 0.7738  loss_bbox: 0.809  loss_ce_0: 1.095  loss_giou_0: 0.7423  loss_bbox_0: 0.7689  loss_rpn_cls: 0.4988  loss_rpn_reg: 0.7453  time: 0.1963  last_time: 0.2025  data_time: 0.0047  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 11:49:28] d2.utils.events INFO:  eta: 2:44:33  iter: 1799  total_loss: 6.853  loss_ce: 1.131  loss_giou: 0.8381  loss_bbox: 0.921  loss_ce_0: 1.092  loss_giou_0: 0.834  loss_bbox_0: 0.7595  loss_rpn_cls: 0.5445  loss_rpn_reg: 0.6904  time: 0.1962  last_time: 0.2215  data_time: 0.0047  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 11:49:32] d2.utils.events INFO:  eta: 2:44:37  iter: 1819  total_loss: 6.149  loss_ce: 1.111  loss_giou: 0.7135  loss_bbox: 0.7542  loss_ce_0: 1.066  loss_giou_0: 0.6988  loss_bbox_0: 0.7276  loss_rpn_cls: 0.4662  loss_rpn_reg: 0.6986  time: 0.1962  last_time: 0.2138  data_time: 0.0047  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 11:49:36] d2.utils.events INFO:  eta: 2:44:36  iter: 1839  total_loss: 6.743  loss_ce: 1.155  loss_giou: 0.814  loss_bbox: 0.8957  loss_ce_0: 1.055  loss_giou_0: 0.796  loss_bbox_0: 0.8975  loss_rpn_cls: 0.482  loss_rpn_reg: 0.7551  time: 0.1961  last_time: 0.2063  data_time: 0.0056  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 11:49:40] d2.utils.events INFO:  eta: 2:44:29  iter: 1859  total_loss: 6.541  loss_ce: 1.184  loss_giou: 0.7565  loss_bbox: 0.843  loss_ce_0: 1.064  loss_giou_0: 0.7248  loss_bbox_0: 0.7912  loss_rpn_cls: 0.4872  loss_rpn_reg: 0.6869  time: 0.1960  last_time: 0.1894  data_time: 0.0043  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 11:49:44] d2.utils.events INFO:  eta: 2:44:21  iter: 1879  total_loss: 6.641  loss_ce: 1.13  loss_giou: 0.7169  loss_bbox: 0.8081  loss_ce_0: 1.039  loss_giou_0: 0.7073  loss_bbox_0: 0.8166  loss_rpn_cls: 0.4873  loss_rpn_reg: 0.688  time: 0.1959  last_time: 0.1893  data_time: 0.0048  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 11:49:48] d2.utils.events INFO:  eta: 2:44:18  iter: 1899  total_loss: 6.518  loss_ce: 1.184  loss_giou: 0.7017  loss_bbox: 0.7629  loss_ce_0: 1.134  loss_giou_0: 0.7012  loss_bbox_0: 0.7048  loss_rpn_cls: 0.4638  loss_rpn_reg: 0.6836  time: 0.1959  last_time: 0.1779  data_time: 0.0057  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 11:49:51] d2.utils.events INFO:  eta: 2:44:07  iter: 1919  total_loss: 6.896  loss_ce: 1.154  loss_giou: 0.7768  loss_bbox: 0.861  loss_ce_0: 1.101  loss_giou_0: 0.715  loss_bbox_0: 0.8342  loss_rpn_cls: 0.4725  loss_rpn_reg: 0.7368  time: 0.1957  last_time: 0.1645  data_time: 0.0050  last_data_time: 0.0027   lr: 5e-05  max_mem: 3029M
[03/05 11:49:55] d2.utils.events INFO:  eta: 2:44:05  iter: 1939  total_loss: 6.666  loss_ce: 1.132  loss_giou: 0.663  loss_bbox: 0.845  loss_ce_0: 1.068  loss_giou_0: 0.7011  loss_bbox_0: 0.8449  loss_rpn_cls: 0.491  loss_rpn_reg: 0.6984  time: 0.1956  last_time: 0.1840  data_time: 0.0048  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 11:49:59] d2.utils.events INFO:  eta: 2:44:06  iter: 1959  total_loss: 6.713  loss_ce: 1.048  loss_giou: 0.7817  loss_bbox: 0.8903  loss_ce_0: 1.037  loss_giou_0: 0.7989  loss_bbox_0: 0.8783  loss_rpn_cls: 0.49  loss_rpn_reg: 0.71  time: 0.1957  last_time: 0.2091  data_time: 0.0061  last_data_time: 0.0077   lr: 5e-05  max_mem: 3029M
[03/05 11:50:03] d2.utils.events INFO:  eta: 2:43:51  iter: 1979  total_loss: 6.234  loss_ce: 1.142  loss_giou: 0.7343  loss_bbox: 0.7456  loss_ce_0: 1.044  loss_giou_0: 0.7263  loss_bbox_0: 0.6666  loss_rpn_cls: 0.4709  loss_rpn_reg: 0.6787  time: 0.1956  last_time: 0.1895  data_time: 0.0053  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 11:50:07] d2.utils.events INFO:  eta: 2:43:58  iter: 1999  total_loss: 6.249  loss_ce: 1.127  loss_giou: 0.7768  loss_bbox: 0.7629  loss_ce_0: 1.082  loss_giou_0: 0.7612  loss_bbox_0: 0.7145  loss_rpn_cls: 0.4444  loss_rpn_reg: 0.691  time: 0.1955  last_time: 0.2040  data_time: 0.0047  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 11:50:10] d2.utils.events INFO:  eta: 2:43:57  iter: 2019  total_loss: 5.874  loss_ce: 1.121  loss_giou: 0.6141  loss_bbox: 0.6499  loss_ce_0: 1.06  loss_giou_0: 0.5875  loss_bbox_0: 0.6802  loss_rpn_cls: 0.4245  loss_rpn_reg: 0.6513  time: 0.1954  last_time: 0.1798  data_time: 0.0053  last_data_time: 0.0064   lr: 5e-05  max_mem: 3029M
[03/05 11:50:14] d2.utils.events INFO:  eta: 2:44:07  iter: 2039  total_loss: 6.19  loss_ce: 1.083  loss_giou: 0.6621  loss_bbox: 0.8217  loss_ce_0: 1.045  loss_giou_0: 0.6511  loss_bbox_0: 0.7482  loss_rpn_cls: 0.4471  loss_rpn_reg: 0.6651  time: 0.1954  last_time: 0.1840  data_time: 0.0050  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 11:50:18] d2.utils.events INFO:  eta: 2:43:54  iter: 2059  total_loss: 6.341  loss_ce: 1.098  loss_giou: 0.743  loss_bbox: 0.802  loss_ce_0: 1.071  loss_giou_0: 0.7326  loss_bbox_0: 0.7851  loss_rpn_cls: 0.4404  loss_rpn_reg: 0.7067  time: 0.1953  last_time: 0.1987  data_time: 0.0045  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 11:50:22] d2.utils.events INFO:  eta: 2:43:47  iter: 2079  total_loss: 6.674  loss_ce: 1.162  loss_giou: 0.7093  loss_bbox: 0.7982  loss_ce_0: 1.117  loss_giou_0: 0.69  loss_bbox_0: 0.7552  loss_rpn_cls: 0.462  loss_rpn_reg: 0.7311  time: 0.1952  last_time: 0.2113  data_time: 0.0047  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 11:50:26] d2.utils.events INFO:  eta: 2:43:51  iter: 2099  total_loss: 6.091  loss_ce: 1.135  loss_giou: 0.7011  loss_bbox: 0.7196  loss_ce_0: 1.079  loss_giou_0: 0.6856  loss_bbox_0: 0.6965  loss_rpn_cls: 0.4952  loss_rpn_reg: 0.7019  time: 0.1952  last_time: 0.1778  data_time: 0.0051  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 11:50:30] d2.utils.events INFO:  eta: 2:43:53  iter: 2119  total_loss: 6.21  loss_ce: 1.036  loss_giou: 0.7682  loss_bbox: 0.8686  loss_ce_0: 1.026  loss_giou_0: 0.7487  loss_bbox_0: 0.7994  loss_rpn_cls: 0.4873  loss_rpn_reg: 0.6708  time: 0.1952  last_time: 0.1933  data_time: 0.0046  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 11:50:34] d2.utils.events INFO:  eta: 2:43:55  iter: 2139  total_loss: 6.158  loss_ce: 1.068  loss_giou: 0.6681  loss_bbox: 0.8148  loss_ce_0: 0.9655  loss_giou_0: 0.7051  loss_bbox_0: 0.8388  loss_rpn_cls: 0.4556  loss_rpn_reg: 0.6831  time: 0.1952  last_time: 0.2067  data_time: 0.0052  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 11:50:38] d2.utils.events INFO:  eta: 2:43:53  iter: 2159  total_loss: 6.176  loss_ce: 1.047  loss_giou: 0.68  loss_bbox: 0.7018  loss_ce_0: 1  loss_giou_0: 0.6704  loss_bbox_0: 0.7015  loss_rpn_cls: 0.4616  loss_rpn_reg: 0.6904  time: 0.1951  last_time: 0.1660  data_time: 0.0046  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 11:50:41] d2.utils.events INFO:  eta: 2:43:50  iter: 2179  total_loss: 6.137  loss_ce: 1.053  loss_giou: 0.7175  loss_bbox: 0.8207  loss_ce_0: 0.9878  loss_giou_0: 0.7085  loss_bbox_0: 0.7992  loss_rpn_cls: 0.4737  loss_rpn_reg: 0.6725  time: 0.1950  last_time: 0.2206  data_time: 0.0047  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 11:50:45] d2.utils.events INFO:  eta: 2:43:45  iter: 2199  total_loss: 5.852  loss_ce: 0.9926  loss_giou: 0.6484  loss_bbox: 0.7169  loss_ce_0: 0.9463  loss_giou_0: 0.6568  loss_bbox_0: 0.6959  loss_rpn_cls: 0.4366  loss_rpn_reg: 0.6356  time: 0.1950  last_time: 0.1850  data_time: 0.0047  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 11:50:49] d2.utils.events INFO:  eta: 2:43:43  iter: 2219  total_loss: 5.767  loss_ce: 1.019  loss_giou: 0.6336  loss_bbox: 0.68  loss_ce_0: 0.984  loss_giou_0: 0.6451  loss_bbox_0: 0.6921  loss_rpn_cls: 0.4548  loss_rpn_reg: 0.6754  time: 0.1949  last_time: 0.2034  data_time: 0.0048  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 11:50:53] d2.utils.events INFO:  eta: 2:43:35  iter: 2239  total_loss: 6.002  loss_ce: 1.089  loss_giou: 0.704  loss_bbox: 0.7095  loss_ce_0: 1.02  loss_giou_0: 0.7117  loss_bbox_0: 0.7161  loss_rpn_cls: 0.4527  loss_rpn_reg: 0.678  time: 0.1948  last_time: 0.1669  data_time: 0.0052  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 11:50:57] d2.utils.events INFO:  eta: 2:43:35  iter: 2259  total_loss: 6.174  loss_ce: 1.035  loss_giou: 0.7363  loss_bbox: 0.7533  loss_ce_0: 0.9814  loss_giou_0: 0.7459  loss_bbox_0: 0.7334  loss_rpn_cls: 0.4649  loss_rpn_reg: 0.6658  time: 0.1948  last_time: 0.2077  data_time: 0.0046  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 11:51:01] d2.utils.events INFO:  eta: 2:43:36  iter: 2279  total_loss: 6.375  loss_ce: 1.146  loss_giou: 0.6791  loss_bbox: 0.7938  loss_ce_0: 1.109  loss_giou_0: 0.6997  loss_bbox_0: 0.7167  loss_rpn_cls: 0.4185  loss_rpn_reg: 0.6713  time: 0.1948  last_time: 0.1889  data_time: 0.0052  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 11:51:05] d2.utils.events INFO:  eta: 2:43:32  iter: 2299  total_loss: 5.884  loss_ce: 1.063  loss_giou: 0.7038  loss_bbox: 0.5995  loss_ce_0: 0.9757  loss_giou_0: 0.6981  loss_bbox_0: 0.6132  loss_rpn_cls: 0.4581  loss_rpn_reg: 0.659  time: 0.1948  last_time: 0.1917  data_time: 0.0050  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 11:51:08] d2.utils.events INFO:  eta: 2:43:29  iter: 2319  total_loss: 6.019  loss_ce: 1.053  loss_giou: 0.6412  loss_bbox: 0.7411  loss_ce_0: 0.9689  loss_giou_0: 0.6367  loss_bbox_0: 0.7654  loss_rpn_cls: 0.4464  loss_rpn_reg: 0.6671  time: 0.1948  last_time: 0.1806  data_time: 0.0048  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 11:51:12] d2.utils.events INFO:  eta: 2:43:26  iter: 2339  total_loss: 6.684  loss_ce: 1.161  loss_giou: 0.8456  loss_bbox: 0.8081  loss_ce_0: 1.082  loss_giou_0: 0.8214  loss_bbox_0: 0.8053  loss_rpn_cls: 0.4855  loss_rpn_reg: 0.7197  time: 0.1947  last_time: 0.1825  data_time: 0.0051  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 11:51:16] d2.utils.events INFO:  eta: 2:43:22  iter: 2359  total_loss: 6.277  loss_ce: 1.1  loss_giou: 0.7378  loss_bbox: 0.7571  loss_ce_0: 1.04  loss_giou_0: 0.7418  loss_bbox_0: 0.7129  loss_rpn_cls: 0.4665  loss_rpn_reg: 0.717  time: 0.1947  last_time: 0.1660  data_time: 0.0052  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 11:51:20] d2.utils.events INFO:  eta: 2:43:18  iter: 2379  total_loss: 5.78  loss_ce: 1.054  loss_giou: 0.6134  loss_bbox: 0.6738  loss_ce_0: 0.9632  loss_giou_0: 0.6171  loss_bbox_0: 0.6686  loss_rpn_cls: 0.4326  loss_rpn_reg: 0.6015  time: 0.1947  last_time: 0.1711  data_time: 0.0059  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 11:51:24] d2.utils.events INFO:  eta: 2:43:16  iter: 2399  total_loss: 6.272  loss_ce: 1.053  loss_giou: 0.6967  loss_bbox: 0.7404  loss_ce_0: 1.015  loss_giou_0: 0.7308  loss_bbox_0: 0.735  loss_rpn_cls: 0.442  loss_rpn_reg: 0.7103  time: 0.1947  last_time: 0.2009  data_time: 0.0059  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 11:51:28] d2.utils.events INFO:  eta: 2:43:22  iter: 2419  total_loss: 5.597  loss_ce: 1.039  loss_giou: 0.6269  loss_bbox: 0.7295  loss_ce_0: 1.018  loss_giou_0: 0.5872  loss_bbox_0: 0.7142  loss_rpn_cls: 0.4329  loss_rpn_reg: 0.6425  time: 0.1946  last_time: 0.2032  data_time: 0.0048  last_data_time: 0.0026   lr: 5e-05  max_mem: 3029M
[03/05 11:51:32] d2.utils.events INFO:  eta: 2:43:01  iter: 2439  total_loss: 6.18  loss_ce: 1.063  loss_giou: 0.7381  loss_bbox: 0.7272  loss_ce_0: 1.078  loss_giou_0: 0.7171  loss_bbox_0: 0.7304  loss_rpn_cls: 0.4684  loss_rpn_reg: 0.685  time: 0.1946  last_time: 0.1841  data_time: 0.0052  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 11:51:36] d2.utils.events INFO:  eta: 2:42:50  iter: 2459  total_loss: 6.056  loss_ce: 1.091  loss_giou: 0.6632  loss_bbox: 0.7044  loss_ce_0: 1.074  loss_giou_0: 0.6884  loss_bbox_0: 0.68  loss_rpn_cls: 0.455  loss_rpn_reg: 0.7111  time: 0.1945  last_time: 0.1868  data_time: 0.0050  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 11:51:39] d2.utils.events INFO:  eta: 2:42:39  iter: 2479  total_loss: 6.123  loss_ce: 1.109  loss_giou: 0.6319  loss_bbox: 0.7528  loss_ce_0: 1.052  loss_giou_0: 0.6421  loss_bbox_0: 0.7086  loss_rpn_cls: 0.4476  loss_rpn_reg: 0.663  time: 0.1944  last_time: 0.1598  data_time: 0.0050  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 11:51:43] d2.utils.events INFO:  eta: 2:42:20  iter: 2499  total_loss: 5.902  loss_ce: 1.039  loss_giou: 0.6483  loss_bbox: 0.6976  loss_ce_0: 0.9868  loss_giou_0: 0.6353  loss_bbox_0: 0.7028  loss_rpn_cls: 0.4801  loss_rpn_reg: 0.6823  time: 0.1944  last_time: 0.1873  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 11:51:47] d2.utils.events INFO:  eta: 2:42:23  iter: 2519  total_loss: 6.106  loss_ce: 1.117  loss_giou: 0.7367  loss_bbox: 0.8217  loss_ce_0: 1.055  loss_giou_0: 0.728  loss_bbox_0: 0.6987  loss_rpn_cls: 0.4843  loss_rpn_reg: 0.6778  time: 0.1944  last_time: 0.1900  data_time: 0.0050  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 11:51:51] d2.utils.events INFO:  eta: 2:42:15  iter: 2539  total_loss: 5.763  loss_ce: 0.9855  loss_giou: 0.6253  loss_bbox: 0.6376  loss_ce_0: 0.9492  loss_giou_0: 0.6177  loss_bbox_0: 0.6291  loss_rpn_cls: 0.4585  loss_rpn_reg: 0.6399  time: 0.1943  last_time: 0.1599  data_time: 0.0050  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 11:51:55] d2.utils.events INFO:  eta: 2:42:08  iter: 2559  total_loss: 6.19  loss_ce: 1.02  loss_giou: 0.7487  loss_bbox: 0.7722  loss_ce_0: 0.9778  loss_giou_0: 0.7731  loss_bbox_0: 0.7451  loss_rpn_cls: 0.4731  loss_rpn_reg: 0.655  time: 0.1942  last_time: 0.2016  data_time: 0.0045  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 11:51:58] d2.utils.events INFO:  eta: 2:41:49  iter: 2579  total_loss: 5.682  loss_ce: 0.98  loss_giou: 0.711  loss_bbox: 0.5989  loss_ce_0: 0.916  loss_giou_0: 0.6812  loss_bbox_0: 0.5926  loss_rpn_cls: 0.4585  loss_rpn_reg: 0.6626  time: 0.1941  last_time: 0.1673  data_time: 0.0048  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 11:52:02] d2.utils.events INFO:  eta: 2:41:40  iter: 2599  total_loss: 5.933  loss_ce: 0.9539  loss_giou: 0.7073  loss_bbox: 0.6926  loss_ce_0: 0.9397  loss_giou_0: 0.6997  loss_bbox_0: 0.7179  loss_rpn_cls: 0.4407  loss_rpn_reg: 0.6715  time: 0.1940  last_time: 0.1908  data_time: 0.0045  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 11:52:06] d2.utils.events INFO:  eta: 2:41:40  iter: 2619  total_loss: 6.146  loss_ce: 1.116  loss_giou: 0.7324  loss_bbox: 0.8176  loss_ce_0: 1.026  loss_giou_0: 0.6987  loss_bbox_0: 0.7909  loss_rpn_cls: 0.4412  loss_rpn_reg: 0.6541  time: 0.1941  last_time: 0.1804  data_time: 0.0057  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 11:52:10] d2.utils.events INFO:  eta: 2:41:32  iter: 2639  total_loss: 5.782  loss_ce: 1.05  loss_giou: 0.6903  loss_bbox: 0.6802  loss_ce_0: 0.9573  loss_giou_0: 0.6971  loss_bbox_0: 0.6371  loss_rpn_cls: 0.4735  loss_rpn_reg: 0.6399  time: 0.1941  last_time: 0.1835  data_time: 0.0054  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 11:52:14] d2.utils.events INFO:  eta: 2:41:28  iter: 2659  total_loss: 5.635  loss_ce: 1.076  loss_giou: 0.6176  loss_bbox: 0.6257  loss_ce_0: 0.9752  loss_giou_0: 0.638  loss_bbox_0: 0.6413  loss_rpn_cls: 0.459  loss_rpn_reg: 0.646  time: 0.1940  last_time: 0.1957  data_time: 0.0049  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 11:52:18] d2.utils.events INFO:  eta: 2:41:21  iter: 2679  total_loss: 6.323  loss_ce: 1.053  loss_giou: 0.6427  loss_bbox: 0.8159  loss_ce_0: 0.9714  loss_giou_0: 0.6828  loss_bbox_0: 0.8595  loss_rpn_cls: 0.4312  loss_rpn_reg: 0.6601  time: 0.1940  last_time: 0.1940  data_time: 0.0054  last_data_time: 0.0067   lr: 5e-05  max_mem: 3029M
[03/05 11:52:21] d2.utils.events INFO:  eta: 2:41:11  iter: 2699  total_loss: 5.429  loss_ce: 0.9849  loss_giou: 0.5896  loss_bbox: 0.7155  loss_ce_0: 0.99  loss_giou_0: 0.6082  loss_bbox_0: 0.7036  loss_rpn_cls: 0.397  loss_rpn_reg: 0.6481  time: 0.1939  last_time: 0.1720  data_time: 0.0049  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 11:52:25] d2.utils.events INFO:  eta: 2:41:01  iter: 2719  total_loss: 5.733  loss_ce: 0.959  loss_giou: 0.6545  loss_bbox: 0.6551  loss_ce_0: 0.9445  loss_giou_0: 0.7137  loss_bbox_0: 0.7157  loss_rpn_cls: 0.4461  loss_rpn_reg: 0.6334  time: 0.1938  last_time: 0.1681  data_time: 0.0050  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 11:52:29] d2.utils.events INFO:  eta: 2:40:55  iter: 2739  total_loss: 5.767  loss_ce: 0.9536  loss_giou: 0.6911  loss_bbox: 0.7167  loss_ce_0: 0.9683  loss_giou_0: 0.6921  loss_bbox_0: 0.7163  loss_rpn_cls: 0.4387  loss_rpn_reg: 0.6647  time: 0.1938  last_time: 0.2023  data_time: 0.0051  last_data_time: 0.0028   lr: 5e-05  max_mem: 3029M
[03/05 11:52:33] d2.utils.events INFO:  eta: 2:40:59  iter: 2759  total_loss: 5.958  loss_ce: 1.037  loss_giou: 0.5949  loss_bbox: 0.6857  loss_ce_0: 1.033  loss_giou_0: 0.5847  loss_bbox_0: 0.7274  loss_rpn_cls: 0.4318  loss_rpn_reg: 0.6562  time: 0.1938  last_time: 0.2010  data_time: 0.0056  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 11:52:36] d2.utils.events INFO:  eta: 2:40:41  iter: 2779  total_loss: 5.589  loss_ce: 1.062  loss_giou: 0.5588  loss_bbox: 0.6384  loss_ce_0: 1.048  loss_giou_0: 0.5516  loss_bbox_0: 0.67  loss_rpn_cls: 0.4615  loss_rpn_reg: 0.6265  time: 0.1937  last_time: 0.2000  data_time: 0.0052  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 11:52:40] d2.utils.events INFO:  eta: 2:40:36  iter: 2799  total_loss: 5.827  loss_ce: 0.9966  loss_giou: 0.6154  loss_bbox: 0.69  loss_ce_0: 0.981  loss_giou_0: 0.6011  loss_bbox_0: 0.6923  loss_rpn_cls: 0.4715  loss_rpn_reg: 0.6607  time: 0.1937  last_time: 0.2003  data_time: 0.0050  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 11:52:44] d2.utils.events INFO:  eta: 2:40:19  iter: 2819  total_loss: 5.842  loss_ce: 1.047  loss_giou: 0.5812  loss_bbox: 0.7218  loss_ce_0: 1.004  loss_giou_0: 0.5749  loss_bbox_0: 0.6867  loss_rpn_cls: 0.4034  loss_rpn_reg: 0.7031  time: 0.1936  last_time: 0.1834  data_time: 0.0047  last_data_time: 0.0031   lr: 5e-05  max_mem: 3029M
[03/05 11:52:48] d2.utils.events INFO:  eta: 2:40:16  iter: 2839  total_loss: 6.011  loss_ce: 1.036  loss_giou: 0.6897  loss_bbox: 0.7529  loss_ce_0: 1.042  loss_giou_0: 0.6604  loss_bbox_0: 0.7112  loss_rpn_cls: 0.434  loss_rpn_reg: 0.6857  time: 0.1936  last_time: 0.1725  data_time: 0.0050  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 11:52:52] d2.utils.events INFO:  eta: 2:40:12  iter: 2859  total_loss: 5.696  loss_ce: 0.9808  loss_giou: 0.6466  loss_bbox: 0.6577  loss_ce_0: 0.9725  loss_giou_0: 0.6946  loss_bbox_0: 0.7186  loss_rpn_cls: 0.4485  loss_rpn_reg: 0.6973  time: 0.1935  last_time: 0.1923  data_time: 0.0047  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 11:52:55] d2.utils.events INFO:  eta: 2:40:07  iter: 2879  total_loss: 5.925  loss_ce: 1.034  loss_giou: 0.6766  loss_bbox: 0.722  loss_ce_0: 0.9558  loss_giou_0: 0.6769  loss_bbox_0: 0.6639  loss_rpn_cls: 0.4298  loss_rpn_reg: 0.6583  time: 0.1935  last_time: 0.1899  data_time: 0.0056  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 11:52:59] d2.utils.events INFO:  eta: 2:40:03  iter: 2899  total_loss: 5.676  loss_ce: 1.079  loss_giou: 0.6525  loss_bbox: 0.6846  loss_ce_0: 0.9667  loss_giou_0: 0.6356  loss_bbox_0: 0.628  loss_rpn_cls: 0.4316  loss_rpn_reg: 0.6833  time: 0.1934  last_time: 0.1984  data_time: 0.0051  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 11:53:03] d2.utils.events INFO:  eta: 2:40:02  iter: 2919  total_loss: 5.863  loss_ce: 0.9791  loss_giou: 0.704  loss_bbox: 0.6469  loss_ce_0: 0.9243  loss_giou_0: 0.7239  loss_bbox_0: 0.6536  loss_rpn_cls: 0.4544  loss_rpn_reg: 0.6698  time: 0.1934  last_time: 0.1894  data_time: 0.0046  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 11:53:07] d2.utils.events INFO:  eta: 2:40:17  iter: 2939  total_loss: 5.779  loss_ce: 0.9961  loss_giou: 0.7253  loss_bbox: 0.6752  loss_ce_0: 0.96  loss_giou_0: 0.699  loss_bbox_0: 0.6468  loss_rpn_cls: 0.4548  loss_rpn_reg: 0.6417  time: 0.1935  last_time: 0.1823  data_time: 0.0050  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 11:53:11] d2.utils.events INFO:  eta: 2:40:10  iter: 2959  total_loss: 5.835  loss_ce: 0.9936  loss_giou: 0.7331  loss_bbox: 0.6642  loss_ce_0: 0.9294  loss_giou_0: 0.7355  loss_bbox_0: 0.6861  loss_rpn_cls: 0.454  loss_rpn_reg: 0.6329  time: 0.1935  last_time: 0.1819  data_time: 0.0050  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 11:53:15] d2.utils.events INFO:  eta: 2:40:28  iter: 2979  total_loss: 5.678  loss_ce: 0.917  loss_giou: 0.6272  loss_bbox: 0.6398  loss_ce_0: 0.862  loss_giou_0: 0.6512  loss_bbox_0: 0.7134  loss_rpn_cls: 0.4534  loss_rpn_reg: 0.6821  time: 0.1936  last_time: 0.1865  data_time: 0.0047  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 11:53:19] d2.utils.events INFO:  eta: 2:40:23  iter: 2999  total_loss: 5.834  loss_ce: 1.065  loss_giou: 0.5983  loss_bbox: 0.641  loss_ce_0: 1.005  loss_giou_0: 0.641  loss_bbox_0: 0.7005  loss_rpn_cls: 0.4489  loss_rpn_reg: 0.6683  time: 0.1936  last_time: 0.1905  data_time: 0.0050  last_data_time: 0.0078   lr: 5e-05  max_mem: 3029M
[03/05 11:53:23] d2.utils.events INFO:  eta: 2:40:20  iter: 3019  total_loss: 5.292  loss_ce: 0.9554  loss_giou: 0.5639  loss_bbox: 0.5433  loss_ce_0: 0.9079  loss_giou_0: 0.5971  loss_bbox_0: 0.5777  loss_rpn_cls: 0.4554  loss_rpn_reg: 0.6248  time: 0.1935  last_time: 0.1627  data_time: 0.0048  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 11:53:27] d2.utils.events INFO:  eta: 2:40:09  iter: 3039  total_loss: 5.694  loss_ce: 1.012  loss_giou: 0.6013  loss_bbox: 0.7509  loss_ce_0: 0.9861  loss_giou_0: 0.6056  loss_bbox_0: 0.7568  loss_rpn_cls: 0.447  loss_rpn_reg: 0.6388  time: 0.1935  last_time: 0.1775  data_time: 0.0051  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 11:53:31] d2.utils.events INFO:  eta: 2:40:13  iter: 3059  total_loss: 5.623  loss_ce: 0.9943  loss_giou: 0.5681  loss_bbox: 0.6417  loss_ce_0: 0.9501  loss_giou_0: 0.6271  loss_bbox_0: 0.6991  loss_rpn_cls: 0.4374  loss_rpn_reg: 0.6571  time: 0.1935  last_time: 0.2077  data_time: 0.0053  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 11:53:35] d2.utils.events INFO:  eta: 2:40:09  iter: 3079  total_loss: 5.471  loss_ce: 1.058  loss_giou: 0.5221  loss_bbox: 0.5756  loss_ce_0: 0.9968  loss_giou_0: 0.553  loss_bbox_0: 0.5876  loss_rpn_cls: 0.4196  loss_rpn_reg: 0.6272  time: 0.1935  last_time: 0.2219  data_time: 0.0050  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 11:53:38] d2.utils.events INFO:  eta: 2:39:47  iter: 3099  total_loss: 5.36  loss_ce: 0.9742  loss_giou: 0.5956  loss_bbox: 0.5536  loss_ce_0: 0.924  loss_giou_0: 0.6078  loss_bbox_0: 0.6035  loss_rpn_cls: 0.3879  loss_rpn_reg: 0.6446  time: 0.1934  last_time: 0.1854  data_time: 0.0048  last_data_time: 0.0083   lr: 5e-05  max_mem: 3029M
[03/05 11:53:42] d2.utils.events INFO:  eta: 2:39:38  iter: 3119  total_loss: 5.506  loss_ce: 1.064  loss_giou: 0.6467  loss_bbox: 0.5833  loss_ce_0: 1.018  loss_giou_0: 0.6501  loss_bbox_0: 0.5734  loss_rpn_cls: 0.4483  loss_rpn_reg: 0.6914  time: 0.1934  last_time: 0.1983  data_time: 0.0044  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 11:53:46] d2.utils.events INFO:  eta: 2:39:20  iter: 3139  total_loss: 5.809  loss_ce: 0.9535  loss_giou: 0.5986  loss_bbox: 0.7296  loss_ce_0: 0.9135  loss_giou_0: 0.6509  loss_bbox_0: 0.7248  loss_rpn_cls: 0.4255  loss_rpn_reg: 0.7186  time: 0.1934  last_time: 0.1746  data_time: 0.0051  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 11:53:50] d2.utils.events INFO:  eta: 2:39:21  iter: 3159  total_loss: 5.374  loss_ce: 0.9817  loss_giou: 0.6453  loss_bbox: 0.6208  loss_ce_0: 0.919  loss_giou_0: 0.6441  loss_bbox_0: 0.6049  loss_rpn_cls: 0.4333  loss_rpn_reg: 0.6074  time: 0.1933  last_time: 0.1859  data_time: 0.0048  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 11:53:54] d2.utils.events INFO:  eta: 2:39:24  iter: 3179  total_loss: 5.38  loss_ce: 0.888  loss_giou: 0.692  loss_bbox: 0.626  loss_ce_0: 0.8504  loss_giou_0: 0.716  loss_bbox_0: 0.6274  loss_rpn_cls: 0.4321  loss_rpn_reg: 0.6121  time: 0.1933  last_time: 0.2104  data_time: 0.0050  last_data_time: 0.0087   lr: 5e-05  max_mem: 3029M
[03/05 11:53:58] d2.utils.events INFO:  eta: 2:39:35  iter: 3199  total_loss: 5.127  loss_ce: 0.9776  loss_giou: 0.5634  loss_bbox: 0.5352  loss_ce_0: 0.9383  loss_giou_0: 0.5888  loss_bbox_0: 0.5028  loss_rpn_cls: 0.4042  loss_rpn_reg: 0.58  time: 0.1933  last_time: 0.2041  data_time: 0.0057  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 11:54:02] d2.utils.events INFO:  eta: 2:39:43  iter: 3219  total_loss: 5.692  loss_ce: 0.9683  loss_giou: 0.6838  loss_bbox: 0.756  loss_ce_0: 0.9532  loss_giou_0: 0.7196  loss_bbox_0: 0.7981  loss_rpn_cls: 0.4208  loss_rpn_reg: 0.6265  time: 0.1933  last_time: 0.1857  data_time: 0.0052  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 11:54:06] d2.utils.events INFO:  eta: 2:39:43  iter: 3239  total_loss: 5.388  loss_ce: 0.9189  loss_giou: 0.5568  loss_bbox: 0.6604  loss_ce_0: 0.8926  loss_giou_0: 0.5798  loss_bbox_0: 0.7506  loss_rpn_cls: 0.4005  loss_rpn_reg: 0.6575  time: 0.1933  last_time: 0.1906  data_time: 0.0046  last_data_time: 0.0025   lr: 5e-05  max_mem: 3029M
[03/05 11:54:09] d2.utils.events INFO:  eta: 2:39:39  iter: 3259  total_loss: 4.957  loss_ce: 0.8504  loss_giou: 0.5349  loss_bbox: 0.6723  loss_ce_0: 0.8311  loss_giou_0: 0.5566  loss_bbox_0: 0.6387  loss_rpn_cls: 0.3907  loss_rpn_reg: 0.5899  time: 0.1933  last_time: 0.2107  data_time: 0.0050  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 11:54:14] d2.utils.events INFO:  eta: 2:39:37  iter: 3279  total_loss: 5.422  loss_ce: 0.9789  loss_giou: 0.5313  loss_bbox: 0.6464  loss_ce_0: 0.919  loss_giou_0: 0.5955  loss_bbox_0: 0.6744  loss_rpn_cls: 0.4142  loss_rpn_reg: 0.6193  time: 0.1933  last_time: 0.1777  data_time: 0.0060  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 11:54:18] d2.utils.events INFO:  eta: 2:39:36  iter: 3299  total_loss: 5.936  loss_ce: 1.02  loss_giou: 0.617  loss_bbox: 0.735  loss_ce_0: 1.024  loss_giou_0: 0.6268  loss_bbox_0: 0.7421  loss_rpn_cls: 0.436  loss_rpn_reg: 0.6628  time: 0.1933  last_time: 0.2237  data_time: 0.0048  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 11:54:22] d2.utils.events INFO:  eta: 2:39:36  iter: 3319  total_loss: 5.559  loss_ce: 0.9733  loss_giou: 0.6157  loss_bbox: 0.6462  loss_ce_0: 0.9015  loss_giou_0: 0.6276  loss_bbox_0: 0.6971  loss_rpn_cls: 0.4063  loss_rpn_reg: 0.6447  time: 0.1934  last_time: 0.2065  data_time: 0.0049  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 11:54:25] d2.utils.events INFO:  eta: 2:39:48  iter: 3339  total_loss: 5.691  loss_ce: 0.997  loss_giou: 0.6561  loss_bbox: 0.6961  loss_ce_0: 0.9457  loss_giou_0: 0.6883  loss_bbox_0: 0.738  loss_rpn_cls: 0.4279  loss_rpn_reg: 0.6739  time: 0.1934  last_time: 0.2184  data_time: 0.0052  last_data_time: 0.0089   lr: 5e-05  max_mem: 3029M
[03/05 11:54:29] d2.utils.events INFO:  eta: 2:39:45  iter: 3359  total_loss: 5.711  loss_ce: 0.9628  loss_giou: 0.6752  loss_bbox: 0.6537  loss_ce_0: 0.8791  loss_giou_0: 0.6954  loss_bbox_0: 0.6475  loss_rpn_cls: 0.4492  loss_rpn_reg: 0.6753  time: 0.1934  last_time: 0.1668  data_time: 0.0049  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 11:54:33] d2.utils.events INFO:  eta: 2:39:45  iter: 3379  total_loss: 4.95  loss_ce: 0.8567  loss_giou: 0.5777  loss_bbox: 0.5485  loss_ce_0: 0.8183  loss_giou_0: 0.6228  loss_bbox_0: 0.5626  loss_rpn_cls: 0.385  loss_rpn_reg: 0.6085  time: 0.1934  last_time: 0.2166  data_time: 0.0055  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 11:54:37] d2.utils.events INFO:  eta: 2:39:27  iter: 3399  total_loss: 5.279  loss_ce: 0.9224  loss_giou: 0.6004  loss_bbox: 0.6263  loss_ce_0: 0.9017  loss_giou_0: 0.5909  loss_bbox_0: 0.597  loss_rpn_cls: 0.4288  loss_rpn_reg: 0.6298  time: 0.1933  last_time: 0.1727  data_time: 0.0049  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 11:54:41] d2.utils.events INFO:  eta: 2:39:08  iter: 3419  total_loss: 5.223  loss_ce: 0.8665  loss_giou: 0.5627  loss_bbox: 0.6398  loss_ce_0: 0.8562  loss_giou_0: 0.5677  loss_bbox_0: 0.6537  loss_rpn_cls: 0.3981  loss_rpn_reg: 0.6379  time: 0.1932  last_time: 0.1884  data_time: 0.0042  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 11:54:45] d2.utils.events INFO:  eta: 2:39:27  iter: 3439  total_loss: 5.447  loss_ce: 0.9683  loss_giou: 0.7013  loss_bbox: 0.5629  loss_ce_0: 0.9327  loss_giou_0: 0.7035  loss_bbox_0: 0.5627  loss_rpn_cls: 0.4208  loss_rpn_reg: 0.6737  time: 0.1932  last_time: 0.2092  data_time: 0.0056  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 11:54:49] d2.utils.events INFO:  eta: 2:39:26  iter: 3459  total_loss: 5.573  loss_ce: 0.8975  loss_giou: 0.6208  loss_bbox: 0.6376  loss_ce_0: 0.8651  loss_giou_0: 0.6365  loss_bbox_0: 0.654  loss_rpn_cls: 0.4253  loss_rpn_reg: 0.6981  time: 0.1932  last_time: 0.1616  data_time: 0.0050  last_data_time: 0.0032   lr: 5e-05  max_mem: 3029M
[03/05 11:54:52] d2.utils.events INFO:  eta: 2:39:28  iter: 3479  total_loss: 5.496  loss_ce: 0.9913  loss_giou: 0.5374  loss_bbox: 0.7084  loss_ce_0: 0.9012  loss_giou_0: 0.5483  loss_bbox_0: 0.7633  loss_rpn_cls: 0.4043  loss_rpn_reg: 0.6117  time: 0.1932  last_time: 0.2009  data_time: 0.0049  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 11:54:56] d2.utils.events INFO:  eta: 2:39:33  iter: 3499  total_loss: 5.587  loss_ce: 0.9356  loss_giou: 0.7438  loss_bbox: 0.6981  loss_ce_0: 0.9024  loss_giou_0: 0.7972  loss_bbox_0: 0.6714  loss_rpn_cls: 0.4411  loss_rpn_reg: 0.6444  time: 0.1932  last_time: 0.1901  data_time: 0.0050  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 11:55:00] d2.utils.events INFO:  eta: 2:39:14  iter: 3519  total_loss: 5.246  loss_ce: 0.8952  loss_giou: 0.5263  loss_bbox: 0.6009  loss_ce_0: 0.8593  loss_giou_0: 0.5288  loss_bbox_0: 0.6125  loss_rpn_cls: 0.4019  loss_rpn_reg: 0.6007  time: 0.1931  last_time: 0.2017  data_time: 0.0046  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 11:55:04] d2.utils.events INFO:  eta: 2:39:09  iter: 3539  total_loss: 5.407  loss_ce: 0.9301  loss_giou: 0.5656  loss_bbox: 0.6094  loss_ce_0: 0.8349  loss_giou_0: 0.6029  loss_bbox_0: 0.6439  loss_rpn_cls: 0.3917  loss_rpn_reg: 0.6417  time: 0.1930  last_time: 0.1788  data_time: 0.0047  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 11:55:07] d2.utils.events INFO:  eta: 2:39:07  iter: 3559  total_loss: 5.557  loss_ce: 0.9388  loss_giou: 0.5171  loss_bbox: 0.7146  loss_ce_0: 0.8896  loss_giou_0: 0.5558  loss_bbox_0: 0.7219  loss_rpn_cls: 0.4168  loss_rpn_reg: 0.629  time: 0.1930  last_time: 0.2042  data_time: 0.0051  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 11:55:12] d2.utils.events INFO:  eta: 2:39:20  iter: 3579  total_loss: 5.484  loss_ce: 0.9708  loss_giou: 0.6033  loss_bbox: 0.6233  loss_ce_0: 0.9096  loss_giou_0: 0.6406  loss_bbox_0: 0.624  loss_rpn_cls: 0.423  loss_rpn_reg: 0.6462  time: 0.1931  last_time: 0.1995  data_time: 0.0056  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 11:55:15] d2.utils.events INFO:  eta: 2:39:22  iter: 3599  total_loss: 5.239  loss_ce: 0.9142  loss_giou: 0.5447  loss_bbox: 0.5539  loss_ce_0: 0.9366  loss_giou_0: 0.6074  loss_bbox_0: 0.568  loss_rpn_cls: 0.3881  loss_rpn_reg: 0.6378  time: 0.1931  last_time: 0.1777  data_time: 0.0047  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 11:55:19] d2.utils.events INFO:  eta: 2:39:33  iter: 3619  total_loss: 5.446  loss_ce: 0.9958  loss_giou: 0.671  loss_bbox: 0.5576  loss_ce_0: 0.8934  loss_giou_0: 0.6858  loss_bbox_0: 0.5813  loss_rpn_cls: 0.4205  loss_rpn_reg: 0.6625  time: 0.1931  last_time: 0.1959  data_time: 0.0048  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 11:55:23] d2.utils.events INFO:  eta: 2:39:32  iter: 3639  total_loss: 5.32  loss_ce: 0.9253  loss_giou: 0.5347  loss_bbox: 0.5779  loss_ce_0: 0.8896  loss_giou_0: 0.5581  loss_bbox_0: 0.635  loss_rpn_cls: 0.4127  loss_rpn_reg: 0.6434  time: 0.1931  last_time: 0.1762  data_time: 0.0046  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 11:55:27] d2.utils.events INFO:  eta: 2:39:30  iter: 3659  total_loss: 5.266  loss_ce: 0.9196  loss_giou: 0.6259  loss_bbox: 0.6158  loss_ce_0: 0.8963  loss_giou_0: 0.6596  loss_bbox_0: 0.629  loss_rpn_cls: 0.3923  loss_rpn_reg: 0.6444  time: 0.1931  last_time: 0.2035  data_time: 0.0048  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 11:55:31] d2.utils.events INFO:  eta: 2:39:36  iter: 3679  total_loss: 5.305  loss_ce: 0.9276  loss_giou: 0.546  loss_bbox: 0.6326  loss_ce_0: 0.9229  loss_giou_0: 0.5667  loss_bbox_0: 0.6439  loss_rpn_cls: 0.4139  loss_rpn_reg: 0.6523  time: 0.1931  last_time: 0.1974  data_time: 0.0048  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 11:55:35] d2.utils.events INFO:  eta: 2:39:32  iter: 3699  total_loss: 5.096  loss_ce: 0.9503  loss_giou: 0.5385  loss_bbox: 0.5562  loss_ce_0: 0.9113  loss_giou_0: 0.5409  loss_bbox_0: 0.6112  loss_rpn_cls: 0.37  loss_rpn_reg: 0.6325  time: 0.1930  last_time: 0.1895  data_time: 0.0050  last_data_time: 0.0074   lr: 5e-05  max_mem: 3029M
[03/05 11:55:39] d2.utils.events INFO:  eta: 2:39:41  iter: 3719  total_loss: 5.242  loss_ce: 0.9472  loss_giou: 0.5715  loss_bbox: 0.5834  loss_ce_0: 0.8997  loss_giou_0: 0.613  loss_bbox_0: 0.6828  loss_rpn_cls: 0.3925  loss_rpn_reg: 0.6522  time: 0.1930  last_time: 0.1929  data_time: 0.0050  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 11:55:43] d2.utils.events INFO:  eta: 2:39:49  iter: 3739  total_loss: 5.4  loss_ce: 0.9282  loss_giou: 0.5969  loss_bbox: 0.6468  loss_ce_0: 0.8538  loss_giou_0: 0.6113  loss_bbox_0: 0.6414  loss_rpn_cls: 0.3988  loss_rpn_reg: 0.6305  time: 0.1930  last_time: 0.1822  data_time: 0.0049  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 11:55:46] d2.utils.events INFO:  eta: 2:39:26  iter: 3759  total_loss: 5.136  loss_ce: 0.9316  loss_giou: 0.5482  loss_bbox: 0.5302  loss_ce_0: 0.8948  loss_giou_0: 0.5619  loss_bbox_0: 0.5599  loss_rpn_cls: 0.3846  loss_rpn_reg: 0.6304  time: 0.1930  last_time: 0.1739  data_time: 0.0048  last_data_time: 0.0082   lr: 5e-05  max_mem: 3029M
[03/05 11:55:50] d2.utils.events INFO:  eta: 2:39:42  iter: 3779  total_loss: 4.917  loss_ce: 0.8582  loss_giou: 0.5402  loss_bbox: 0.5899  loss_ce_0: 0.8466  loss_giou_0: 0.5436  loss_bbox_0: 0.5764  loss_rpn_cls: 0.3815  loss_rpn_reg: 0.5963  time: 0.1930  last_time: 0.1786  data_time: 0.0046  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 11:55:54] d2.utils.events INFO:  eta: 2:39:41  iter: 3799  total_loss: 5.126  loss_ce: 0.8573  loss_giou: 0.5674  loss_bbox: 0.5838  loss_ce_0: 0.8228  loss_giou_0: 0.5869  loss_bbox_0: 0.6503  loss_rpn_cls: 0.3782  loss_rpn_reg: 0.6226  time: 0.1930  last_time: 0.2138  data_time: 0.0047  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 11:55:58] d2.utils.events INFO:  eta: 2:40:01  iter: 3819  total_loss: 5.314  loss_ce: 0.8839  loss_giou: 0.6691  loss_bbox: 0.6661  loss_ce_0: 0.8366  loss_giou_0: 0.7022  loss_bbox_0: 0.6249  loss_rpn_cls: 0.3949  loss_rpn_reg: 0.6194  time: 0.1930  last_time: 0.2016  data_time: 0.0048  last_data_time: 0.0076   lr: 5e-05  max_mem: 3029M
[03/05 11:56:02] d2.utils.events INFO:  eta: 2:39:49  iter: 3839  total_loss: 5.25  loss_ce: 0.9566  loss_giou: 0.5644  loss_bbox: 0.5596  loss_ce_0: 0.914  loss_giou_0: 0.5611  loss_bbox_0: 0.5098  loss_rpn_cls: 0.3867  loss_rpn_reg: 0.6578  time: 0.1930  last_time: 0.1804  data_time: 0.0050  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 11:56:06] d2.utils.events INFO:  eta: 2:39:42  iter: 3859  total_loss: 5.128  loss_ce: 0.9109  loss_giou: 0.5539  loss_bbox: 0.5962  loss_ce_0: 0.8765  loss_giou_0: 0.5711  loss_bbox_0: 0.5852  loss_rpn_cls: 0.4176  loss_rpn_reg: 0.6129  time: 0.1930  last_time: 0.1875  data_time: 0.0046  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 11:56:10] d2.utils.events INFO:  eta: 2:39:39  iter: 3879  total_loss: 5.279  loss_ce: 0.9586  loss_giou: 0.6124  loss_bbox: 0.5266  loss_ce_0: 0.8841  loss_giou_0: 0.6111  loss_bbox_0: 0.5368  loss_rpn_cls: 0.4363  loss_rpn_reg: 0.6224  time: 0.1929  last_time: 0.1875  data_time: 0.0047  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 11:56:14] d2.utils.events INFO:  eta: 2:39:35  iter: 3899  total_loss: 5.299  loss_ce: 0.9336  loss_giou: 0.572  loss_bbox: 0.6453  loss_ce_0: 0.9236  loss_giou_0: 0.6006  loss_bbox_0: 0.6184  loss_rpn_cls: 0.4173  loss_rpn_reg: 0.6305  time: 0.1929  last_time: 0.2143  data_time: 0.0052  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 11:56:17] d2.utils.events INFO:  eta: 2:39:19  iter: 3919  total_loss: 5.311  loss_ce: 0.9513  loss_giou: 0.5684  loss_bbox: 0.5617  loss_ce_0: 0.9294  loss_giou_0: 0.5732  loss_bbox_0: 0.6216  loss_rpn_cls: 0.404  loss_rpn_reg: 0.59  time: 0.1929  last_time: 0.1794  data_time: 0.0048  last_data_time: 0.0021   lr: 5e-05  max_mem: 3029M
[03/05 11:56:21] d2.utils.events INFO:  eta: 2:38:59  iter: 3939  total_loss: 5.204  loss_ce: 0.9867  loss_giou: 0.5193  loss_bbox: 0.6309  loss_ce_0: 0.9103  loss_giou_0: 0.5409  loss_bbox_0: 0.664  loss_rpn_cls: 0.3915  loss_rpn_reg: 0.618  time: 0.1929  last_time: 0.2069  data_time: 0.0054  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 11:56:25] d2.utils.events INFO:  eta: 2:38:48  iter: 3959  total_loss: 5.337  loss_ce: 0.8934  loss_giou: 0.5392  loss_bbox: 0.6327  loss_ce_0: 0.8675  loss_giou_0: 0.5585  loss_bbox_0: 0.6418  loss_rpn_cls: 0.4045  loss_rpn_reg: 0.6465  time: 0.1929  last_time: 0.1867  data_time: 0.0048  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 11:56:29] d2.utils.events INFO:  eta: 2:38:32  iter: 3979  total_loss: 5.143  loss_ce: 0.8921  loss_giou: 0.5234  loss_bbox: 0.6107  loss_ce_0: 0.8344  loss_giou_0: 0.5696  loss_bbox_0: 0.6195  loss_rpn_cls: 0.3885  loss_rpn_reg: 0.6211  time: 0.1929  last_time: 0.1925  data_time: 0.0047  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 11:56:33] d2.utils.events INFO:  eta: 2:38:22  iter: 3999  total_loss: 4.888  loss_ce: 0.9026  loss_giou: 0.5322  loss_bbox: 0.5257  loss_ce_0: 0.8194  loss_giou_0: 0.5391  loss_bbox_0: 0.5467  loss_rpn_cls: 0.3612  loss_rpn_reg: 0.6041  time: 0.1928  last_time: 0.1990  data_time: 0.0042  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 11:56:37] d2.utils.events INFO:  eta: 2:38:16  iter: 4019  total_loss: 5.383  loss_ce: 0.8513  loss_giou: 0.5534  loss_bbox: 0.5997  loss_ce_0: 0.8355  loss_giou_0: 0.5961  loss_bbox_0: 0.6149  loss_rpn_cls: 0.3796  loss_rpn_reg: 0.6342  time: 0.1928  last_time: 0.2170  data_time: 0.0048  last_data_time: 0.0031   lr: 5e-05  max_mem: 3029M
[03/05 11:56:40] d2.utils.events INFO:  eta: 2:38:12  iter: 4039  total_loss: 4.744  loss_ce: 0.8447  loss_giou: 0.5255  loss_bbox: 0.5281  loss_ce_0: 0.8313  loss_giou_0: 0.5005  loss_bbox_0: 0.5101  loss_rpn_cls: 0.3832  loss_rpn_reg: 0.6157  time: 0.1928  last_time: 0.2040  data_time: 0.0054  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 11:56:44] d2.utils.events INFO:  eta: 2:38:08  iter: 4059  total_loss: 5.205  loss_ce: 0.9138  loss_giou: 0.574  loss_bbox: 0.616  loss_ce_0: 0.8721  loss_giou_0: 0.5833  loss_bbox_0: 0.6382  loss_rpn_cls: 0.4109  loss_rpn_reg: 0.6861  time: 0.1928  last_time: 0.1648  data_time: 0.0047  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 11:56:48] d2.utils.events INFO:  eta: 2:38:07  iter: 4079  total_loss: 5.148  loss_ce: 0.918  loss_giou: 0.5005  loss_bbox: 0.6023  loss_ce_0: 0.8764  loss_giou_0: 0.5058  loss_bbox_0: 0.624  loss_rpn_cls: 0.3862  loss_rpn_reg: 0.595  time: 0.1928  last_time: 0.1562  data_time: 0.0048  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 11:56:52] d2.utils.events INFO:  eta: 2:38:18  iter: 4099  total_loss: 5.661  loss_ce: 1.033  loss_giou: 0.5703  loss_bbox: 0.5852  loss_ce_0: 0.988  loss_giou_0: 0.5849  loss_bbox_0: 0.6674  loss_rpn_cls: 0.4134  loss_rpn_reg: 0.6265  time: 0.1928  last_time: 0.2034  data_time: 0.0051  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 11:56:56] d2.utils.events INFO:  eta: 2:38:06  iter: 4119  total_loss: 5.149  loss_ce: 0.8811  loss_giou: 0.5805  loss_bbox: 0.563  loss_ce_0: 0.8664  loss_giou_0: 0.5867  loss_bbox_0: 0.5685  loss_rpn_cls: 0.4097  loss_rpn_reg: 0.6183  time: 0.1928  last_time: 0.1822  data_time: 0.0050  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 11:57:00] d2.utils.events INFO:  eta: 2:38:02  iter: 4139  total_loss: 5.087  loss_ce: 0.8552  loss_giou: 0.5573  loss_bbox: 0.621  loss_ce_0: 0.8787  loss_giou_0: 0.6011  loss_bbox_0: 0.5973  loss_rpn_cls: 0.3833  loss_rpn_reg: 0.6385  time: 0.1927  last_time: 0.1765  data_time: 0.0045  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 11:57:04] d2.utils.events INFO:  eta: 2:38:06  iter: 4159  total_loss: 5.172  loss_ce: 0.9108  loss_giou: 0.5281  loss_bbox: 0.625  loss_ce_0: 0.8982  loss_giou_0: 0.5507  loss_bbox_0: 0.6639  loss_rpn_cls: 0.3957  loss_rpn_reg: 0.631  time: 0.1927  last_time: 0.1721  data_time: 0.0052  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 11:57:07] d2.utils.events INFO:  eta: 2:37:53  iter: 4179  total_loss: 4.626  loss_ce: 0.8294  loss_giou: 0.4523  loss_bbox: 0.5065  loss_ce_0: 0.7876  loss_giou_0: 0.4994  loss_bbox_0: 0.5652  loss_rpn_cls: 0.4262  loss_rpn_reg: 0.5938  time: 0.1927  last_time: 0.1906  data_time: 0.0046  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 11:57:11] d2.utils.events INFO:  eta: 2:37:42  iter: 4199  total_loss: 5.284  loss_ce: 0.9299  loss_giou: 0.5606  loss_bbox: 0.6032  loss_ce_0: 0.8879  loss_giou_0: 0.5818  loss_bbox_0: 0.7136  loss_rpn_cls: 0.4122  loss_rpn_reg: 0.6297  time: 0.1926  last_time: 0.1825  data_time: 0.0051  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 11:57:15] d2.utils.events INFO:  eta: 2:37:25  iter: 4219  total_loss: 4.593  loss_ce: 0.8662  loss_giou: 0.53  loss_bbox: 0.4881  loss_ce_0: 0.8254  loss_giou_0: 0.559  loss_bbox_0: 0.4953  loss_rpn_cls: 0.3927  loss_rpn_reg: 0.5693  time: 0.1926  last_time: 0.1931  data_time: 0.0048  last_data_time: 0.0081   lr: 5e-05  max_mem: 3029M
[03/05 11:57:19] d2.utils.events INFO:  eta: 2:37:24  iter: 4239  total_loss: 4.868  loss_ce: 0.8508  loss_giou: 0.5993  loss_bbox: 0.5444  loss_ce_0: 0.805  loss_giou_0: 0.5968  loss_bbox_0: 0.5216  loss_rpn_cls: 0.3804  loss_rpn_reg: 0.6164  time: 0.1926  last_time: 0.1602  data_time: 0.0061  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 11:57:22] d2.utils.events INFO:  eta: 2:37:14  iter: 4259  total_loss: 5.136  loss_ce: 0.8605  loss_giou: 0.5352  loss_bbox: 0.5226  loss_ce_0: 0.8615  loss_giou_0: 0.5617  loss_bbox_0: 0.568  loss_rpn_cls: 0.3853  loss_rpn_reg: 0.611  time: 0.1925  last_time: 0.1648  data_time: 0.0045  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 11:57:26] d2.utils.events INFO:  eta: 2:37:06  iter: 4279  total_loss: 5.157  loss_ce: 0.8614  loss_giou: 0.5677  loss_bbox: 0.555  loss_ce_0: 0.7937  loss_giou_0: 0.5781  loss_bbox_0: 0.5905  loss_rpn_cls: 0.4141  loss_rpn_reg: 0.6203  time: 0.1925  last_time: 0.1909  data_time: 0.0048  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 11:57:30] d2.utils.events INFO:  eta: 2:36:58  iter: 4299  total_loss: 4.829  loss_ce: 0.81  loss_giou: 0.5962  loss_bbox: 0.5625  loss_ce_0: 0.7763  loss_giou_0: 0.6246  loss_bbox_0: 0.5458  loss_rpn_cls: 0.4221  loss_rpn_reg: 0.6246  time: 0.1925  last_time: 0.1816  data_time: 0.0050  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 11:57:34] d2.utils.events INFO:  eta: 2:36:43  iter: 4319  total_loss: 4.751  loss_ce: 0.8797  loss_giou: 0.489  loss_bbox: 0.5528  loss_ce_0: 0.8246  loss_giou_0: 0.4965  loss_bbox_0: 0.5534  loss_rpn_cls: 0.3656  loss_rpn_reg: 0.5511  time: 0.1925  last_time: 0.1856  data_time: 0.0049  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 11:57:38] d2.utils.events INFO:  eta: 2:36:28  iter: 4339  total_loss: 4.666  loss_ce: 0.8985  loss_giou: 0.4892  loss_bbox: 0.47  loss_ce_0: 0.8738  loss_giou_0: 0.5259  loss_bbox_0: 0.5013  loss_rpn_cls: 0.3752  loss_rpn_reg: 0.6036  time: 0.1924  last_time: 0.1864  data_time: 0.0043  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 11:57:41] d2.utils.events INFO:  eta: 2:36:18  iter: 4359  total_loss: 4.846  loss_ce: 0.8845  loss_giou: 0.5848  loss_bbox: 0.5656  loss_ce_0: 0.828  loss_giou_0: 0.59  loss_bbox_0: 0.5403  loss_rpn_cls: 0.348  loss_rpn_reg: 0.6445  time: 0.1924  last_time: 0.1913  data_time: 0.0046  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 11:57:45] d2.utils.events INFO:  eta: 2:36:02  iter: 4379  total_loss: 4.71  loss_ce: 0.8242  loss_giou: 0.5312  loss_bbox: 0.5275  loss_ce_0: 0.7893  loss_giou_0: 0.5491  loss_bbox_0: 0.5329  loss_rpn_cls: 0.3774  loss_rpn_reg: 0.5798  time: 0.1923  last_time: 0.1939  data_time: 0.0049  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 11:57:49] d2.utils.events INFO:  eta: 2:36:06  iter: 4399  total_loss: 4.549  loss_ce: 0.7964  loss_giou: 0.462  loss_bbox: 0.448  loss_ce_0: 0.7975  loss_giou_0: 0.4962  loss_bbox_0: 0.4703  loss_rpn_cls: 0.3463  loss_rpn_reg: 0.5755  time: 0.1923  last_time: 0.1826  data_time: 0.0045  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 11:57:53] d2.utils.events INFO:  eta: 2:36:13  iter: 4419  total_loss: 4.818  loss_ce: 0.8228  loss_giou: 0.5425  loss_bbox: 0.4648  loss_ce_0: 0.8308  loss_giou_0: 0.5776  loss_bbox_0: 0.5035  loss_rpn_cls: 0.3614  loss_rpn_reg: 0.588  time: 0.1923  last_time: 0.1923  data_time: 0.0045  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 11:57:56] d2.utils.events INFO:  eta: 2:35:59  iter: 4439  total_loss: 5.037  loss_ce: 0.9686  loss_giou: 0.4181  loss_bbox: 0.5484  loss_ce_0: 0.9283  loss_giou_0: 0.4792  loss_bbox_0: 0.5178  loss_rpn_cls: 0.4007  loss_rpn_reg: 0.5433  time: 0.1923  last_time: 0.1993  data_time: 0.0049  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 11:58:00] d2.utils.events INFO:  eta: 2:35:51  iter: 4459  total_loss: 4.883  loss_ce: 0.8202  loss_giou: 0.5921  loss_bbox: 0.5562  loss_ce_0: 0.7842  loss_giou_0: 0.6157  loss_bbox_0: 0.5632  loss_rpn_cls: 0.4008  loss_rpn_reg: 0.6332  time: 0.1922  last_time: 0.1959  data_time: 0.0045  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 11:58:04] d2.utils.events INFO:  eta: 2:35:47  iter: 4479  total_loss: 4.812  loss_ce: 0.8986  loss_giou: 0.5313  loss_bbox: 0.5015  loss_ce_0: 0.8155  loss_giou_0: 0.5303  loss_bbox_0: 0.5066  loss_rpn_cls: 0.4047  loss_rpn_reg: 0.6044  time: 0.1922  last_time: 0.1886  data_time: 0.0048  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 11:58:08] d2.utils.events INFO:  eta: 2:35:36  iter: 4499  total_loss: 4.738  loss_ce: 0.7994  loss_giou: 0.53  loss_bbox: 0.4789  loss_ce_0: 0.7726  loss_giou_0: 0.5362  loss_bbox_0: 0.4698  loss_rpn_cls: 0.4152  loss_rpn_reg: 0.5684  time: 0.1922  last_time: 0.1874  data_time: 0.0044  last_data_time: 0.0024   lr: 5e-05  max_mem: 3029M
[03/05 11:58:12] d2.utils.events INFO:  eta: 2:35:37  iter: 4519  total_loss: 4.771  loss_ce: 0.8981  loss_giou: 0.4976  loss_bbox: 0.4497  loss_ce_0: 0.8328  loss_giou_0: 0.4968  loss_bbox_0: 0.4692  loss_rpn_cls: 0.3935  loss_rpn_reg: 0.5869  time: 0.1922  last_time: 0.2124  data_time: 0.0047  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 11:58:15] d2.utils.events INFO:  eta: 2:35:34  iter: 4539  total_loss: 4.543  loss_ce: 0.8091  loss_giou: 0.4619  loss_bbox: 0.4745  loss_ce_0: 0.7386  loss_giou_0: 0.475  loss_bbox_0: 0.5011  loss_rpn_cls: 0.3744  loss_rpn_reg: 0.5486  time: 0.1921  last_time: 0.1922  data_time: 0.0043  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 11:58:19] d2.utils.events INFO:  eta: 2:35:25  iter: 4559  total_loss: 4.76  loss_ce: 0.8557  loss_giou: 0.5033  loss_bbox: 0.4522  loss_ce_0: 0.8445  loss_giou_0: 0.547  loss_bbox_0: 0.5037  loss_rpn_cls: 0.3766  loss_rpn_reg: 0.586  time: 0.1921  last_time: 0.1971  data_time: 0.0047  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 11:58:23] d2.utils.events INFO:  eta: 2:35:14  iter: 4579  total_loss: 4.708  loss_ce: 0.7889  loss_giou: 0.5568  loss_bbox: 0.4368  loss_ce_0: 0.7231  loss_giou_0: 0.5844  loss_bbox_0: 0.4544  loss_rpn_cls: 0.3667  loss_rpn_reg: 0.5968  time: 0.1921  last_time: 0.1851  data_time: 0.0054  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 11:58:27] d2.utils.events INFO:  eta: 2:35:08  iter: 4599  total_loss: 4.977  loss_ce: 0.8616  loss_giou: 0.5317  loss_bbox: 0.5261  loss_ce_0: 0.8163  loss_giou_0: 0.5606  loss_bbox_0: 0.6068  loss_rpn_cls: 0.4054  loss_rpn_reg: 0.6207  time: 0.1921  last_time: 0.1852  data_time: 0.0049  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 11:58:31] d2.utils.events INFO:  eta: 2:34:58  iter: 4619  total_loss: 4.822  loss_ce: 0.8445  loss_giou: 0.5185  loss_bbox: 0.5279  loss_ce_0: 0.8429  loss_giou_0: 0.556  loss_bbox_0: 0.554  loss_rpn_cls: 0.37  loss_rpn_reg: 0.6005  time: 0.1921  last_time: 0.1894  data_time: 0.0046  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 11:58:35] d2.utils.events INFO:  eta: 2:34:49  iter: 4639  total_loss: 4.707  loss_ce: 0.7945  loss_giou: 0.4955  loss_bbox: 0.5234  loss_ce_0: 0.8188  loss_giou_0: 0.4649  loss_bbox_0: 0.547  loss_rpn_cls: 0.3766  loss_rpn_reg: 0.5418  time: 0.1921  last_time: 0.2095  data_time: 0.0048  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 11:58:38] d2.utils.events INFO:  eta: 2:34:39  iter: 4659  total_loss: 4.961  loss_ce: 0.8993  loss_giou: 0.5366  loss_bbox: 0.4903  loss_ce_0: 0.8329  loss_giou_0: 0.5452  loss_bbox_0: 0.5508  loss_rpn_cls: 0.4271  loss_rpn_reg: 0.582  time: 0.1920  last_time: 0.1721  data_time: 0.0051  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 11:58:42] d2.utils.events INFO:  eta: 2:34:33  iter: 4679  total_loss: 5.068  loss_ce: 0.8493  loss_giou: 0.5128  loss_bbox: 0.5512  loss_ce_0: 0.7882  loss_giou_0: 0.5668  loss_bbox_0: 0.5726  loss_rpn_cls: 0.4136  loss_rpn_reg: 0.6112  time: 0.1920  last_time: 0.2025  data_time: 0.0047  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 11:58:46] d2.utils.events INFO:  eta: 2:34:29  iter: 4699  total_loss: 4.895  loss_ce: 0.8473  loss_giou: 0.5672  loss_bbox: 0.5741  loss_ce_0: 0.8174  loss_giou_0: 0.5906  loss_bbox_0: 0.583  loss_rpn_cls: 0.3784  loss_rpn_reg: 0.6068  time: 0.1920  last_time: 0.1876  data_time: 0.0052  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 11:58:50] d2.utils.events INFO:  eta: 2:34:20  iter: 4719  total_loss: 4.817  loss_ce: 0.8792  loss_giou: 0.5177  loss_bbox: 0.5161  loss_ce_0: 0.8358  loss_giou_0: 0.5127  loss_bbox_0: 0.5714  loss_rpn_cls: 0.3741  loss_rpn_reg: 0.5909  time: 0.1920  last_time: 0.1902  data_time: 0.0054  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 11:58:54] d2.utils.events INFO:  eta: 2:34:07  iter: 4739  total_loss: 4.786  loss_ce: 0.8662  loss_giou: 0.4489  loss_bbox: 0.525  loss_ce_0: 0.8355  loss_giou_0: 0.4622  loss_bbox_0: 0.5654  loss_rpn_cls: 0.3625  loss_rpn_reg: 0.5679  time: 0.1919  last_time: 0.2007  data_time: 0.0053  last_data_time: 0.0123   lr: 5e-05  max_mem: 3029M
[03/05 11:58:57] d2.utils.events INFO:  eta: 2:33:59  iter: 4759  total_loss: 4.839  loss_ce: 0.8962  loss_giou: 0.4816  loss_bbox: 0.5723  loss_ce_0: 0.8304  loss_giou_0: 0.5104  loss_bbox_0: 0.6337  loss_rpn_cls: 0.3393  loss_rpn_reg: 0.6149  time: 0.1919  last_time: 0.1886  data_time: 0.0049  last_data_time: 0.0084   lr: 5e-05  max_mem: 3029M
[03/05 11:59:01] d2.utils.events INFO:  eta: 2:33:52  iter: 4779  total_loss: 4.641  loss_ce: 0.8422  loss_giou: 0.4457  loss_bbox: 0.5422  loss_ce_0: 0.8181  loss_giou_0: 0.5031  loss_bbox_0: 0.5402  loss_rpn_cls: 0.3841  loss_rpn_reg: 0.569  time: 0.1919  last_time: 0.2054  data_time: 0.0049  last_data_time: 0.0072   lr: 5e-05  max_mem: 3029M
[03/05 11:59:05] d2.utils.events INFO:  eta: 2:33:52  iter: 4799  total_loss: 4.63  loss_ce: 0.8169  loss_giou: 0.4543  loss_bbox: 0.4999  loss_ce_0: 0.8171  loss_giou_0: 0.4872  loss_bbox_0: 0.5493  loss_rpn_cls: 0.3648  loss_rpn_reg: 0.5959  time: 0.1919  last_time: 0.1889  data_time: 0.0047  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 11:59:09] d2.utils.events INFO:  eta: 2:33:43  iter: 4819  total_loss: 4.826  loss_ce: 0.7914  loss_giou: 0.5907  loss_bbox: 0.5068  loss_ce_0: 0.7759  loss_giou_0: 0.5633  loss_bbox_0: 0.5138  loss_rpn_cls: 0.4126  loss_rpn_reg: 0.5965  time: 0.1919  last_time: 0.1809  data_time: 0.0051  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 11:59:13] d2.utils.events INFO:  eta: 2:33:37  iter: 4839  total_loss: 4.575  loss_ce: 0.882  loss_giou: 0.461  loss_bbox: 0.4874  loss_ce_0: 0.8633  loss_giou_0: 0.4799  loss_bbox_0: 0.5153  loss_rpn_cls: 0.3601  loss_rpn_reg: 0.5953  time: 0.1919  last_time: 0.1873  data_time: 0.0049  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 11:59:17] d2.utils.events INFO:  eta: 2:33:35  iter: 4859  total_loss: 5.105  loss_ce: 0.9379  loss_giou: 0.4935  loss_bbox: 0.5608  loss_ce_0: 0.9408  loss_giou_0: 0.5006  loss_bbox_0: 0.5513  loss_rpn_cls: 0.4024  loss_rpn_reg: 0.6176  time: 0.1919  last_time: 0.1817  data_time: 0.0057  last_data_time: 0.0121   lr: 5e-05  max_mem: 3029M
[03/05 11:59:20] d2.utils.events INFO:  eta: 2:33:19  iter: 4879  total_loss: 4.962  loss_ce: 0.8553  loss_giou: 0.5442  loss_bbox: 0.5647  loss_ce_0: 0.8236  loss_giou_0: 0.552  loss_bbox_0: 0.558  loss_rpn_cls: 0.3647  loss_rpn_reg: 0.6334  time: 0.1918  last_time: 0.1779  data_time: 0.0045  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 11:59:24] d2.utils.events INFO:  eta: 2:33:14  iter: 4899  total_loss: 4.73  loss_ce: 0.9212  loss_giou: 0.4554  loss_bbox: 0.4554  loss_ce_0: 0.8882  loss_giou_0: 0.459  loss_bbox_0: 0.491  loss_rpn_cls: 0.4016  loss_rpn_reg: 0.5712  time: 0.1918  last_time: 0.1958  data_time: 0.0052  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 11:59:28] d2.utils.events INFO:  eta: 2:33:17  iter: 4919  total_loss: 4.91  loss_ce: 0.8492  loss_giou: 0.5445  loss_bbox: 0.4747  loss_ce_0: 0.819  loss_giou_0: 0.5671  loss_bbox_0: 0.5379  loss_rpn_cls: 0.3964  loss_rpn_reg: 0.5971  time: 0.1918  last_time: 0.1932  data_time: 0.0052  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 11:59:32] d2.utils.events INFO:  eta: 2:33:13  iter: 4939  total_loss: 4.64  loss_ce: 0.8433  loss_giou: 0.4899  loss_bbox: 0.5065  loss_ce_0: 0.8503  loss_giou_0: 0.5243  loss_bbox_0: 0.5371  loss_rpn_cls: 0.3913  loss_rpn_reg: 0.5822  time: 0.1918  last_time: 0.1716  data_time: 0.0048  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 11:59:36] d2.utils.events INFO:  eta: 2:33:09  iter: 4959  total_loss: 4.671  loss_ce: 0.7828  loss_giou: 0.5578  loss_bbox: 0.5241  loss_ce_0: 0.7525  loss_giou_0: 0.5582  loss_bbox_0: 0.496  loss_rpn_cls: 0.384  loss_rpn_reg: 0.604  time: 0.1918  last_time: 0.1760  data_time: 0.0054  last_data_time: 0.0064   lr: 5e-05  max_mem: 3029M
[03/05 11:59:39] d2.utils.events INFO:  eta: 2:33:02  iter: 4979  total_loss: 4.518  loss_ce: 0.7541  loss_giou: 0.4936  loss_bbox: 0.5127  loss_ce_0: 0.733  loss_giou_0: 0.4957  loss_bbox_0: 0.5029  loss_rpn_cls: 0.3707  loss_rpn_reg: 0.5899  time: 0.1917  last_time: 0.1706  data_time: 0.0051  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 11:59:43] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/t1/model_0004999.pth
[03/05 11:59:44] d2.utils.events INFO:  eta: 2:32:56  iter: 4999  total_loss: 5.245  loss_ce: 0.8234  loss_giou: 0.5328  loss_bbox: 0.5703  loss_ce_0: 0.761  loss_giou_0: 0.5924  loss_bbox_0: 0.5958  loss_rpn_cls: 0.3695  loss_rpn_reg: 0.6491  time: 0.1917  last_time: 0.1755  data_time: 0.0049  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 11:59:48] d2.utils.events INFO:  eta: 2:32:52  iter: 5019  total_loss: 4.326  loss_ce: 0.8077  loss_giou: 0.4508  loss_bbox: 0.4618  loss_ce_0: 0.8161  loss_giou_0: 0.4533  loss_bbox_0: 0.4827  loss_rpn_cls: 0.3765  loss_rpn_reg: 0.5914  time: 0.1917  last_time: 0.1988  data_time: 0.0049  last_data_time: 0.0087   lr: 5e-05  max_mem: 3029M
[03/05 11:59:52] d2.utils.events INFO:  eta: 2:32:54  iter: 5039  total_loss: 4.957  loss_ce: 0.8541  loss_giou: 0.561  loss_bbox: 0.4978  loss_ce_0: 0.8109  loss_giou_0: 0.6031  loss_bbox_0: 0.5938  loss_rpn_cls: 0.3891  loss_rpn_reg: 0.6088  time: 0.1917  last_time: 0.1912  data_time: 0.0051  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 11:59:56] d2.utils.events INFO:  eta: 2:32:44  iter: 5059  total_loss: 4.698  loss_ce: 0.8062  loss_giou: 0.4712  loss_bbox: 0.493  loss_ce_0: 0.8244  loss_giou_0: 0.4883  loss_bbox_0: 0.5116  loss_rpn_cls: 0.3758  loss_rpn_reg: 0.5959  time: 0.1917  last_time: 0.1718  data_time: 0.0050  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:00:00] d2.utils.events INFO:  eta: 2:32:30  iter: 5079  total_loss: 4.454  loss_ce: 0.8667  loss_giou: 0.4231  loss_bbox: 0.4663  loss_ce_0: 0.8131  loss_giou_0: 0.4552  loss_bbox_0: 0.5279  loss_rpn_cls: 0.3793  loss_rpn_reg: 0.5727  time: 0.1916  last_time: 0.1818  data_time: 0.0051  last_data_time: 0.0025   lr: 5e-05  max_mem: 3029M
[03/05 12:00:03] d2.utils.events INFO:  eta: 2:32:23  iter: 5099  total_loss: 4.454  loss_ce: 0.8425  loss_giou: 0.4466  loss_bbox: 0.5086  loss_ce_0: 0.8186  loss_giou_0: 0.4903  loss_bbox_0: 0.5424  loss_rpn_cls: 0.3689  loss_rpn_reg: 0.5881  time: 0.1916  last_time: 0.1798  data_time: 0.0050  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:00:07] d2.utils.events INFO:  eta: 2:32:11  iter: 5119  total_loss: 4.566  loss_ce: 0.872  loss_giou: 0.4449  loss_bbox: 0.4593  loss_ce_0: 0.8438  loss_giou_0: 0.4861  loss_bbox_0: 0.5263  loss_rpn_cls: 0.3747  loss_rpn_reg: 0.6123  time: 0.1916  last_time: 0.1633  data_time: 0.0048  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:00:11] d2.utils.events INFO:  eta: 2:32:08  iter: 5139  total_loss: 4.783  loss_ce: 0.8275  loss_giou: 0.5273  loss_bbox: 0.5092  loss_ce_0: 0.8126  loss_giou_0: 0.5381  loss_bbox_0: 0.5337  loss_rpn_cls: 0.347  loss_rpn_reg: 0.6192  time: 0.1916  last_time: 0.1789  data_time: 0.0046  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:00:15] d2.utils.events INFO:  eta: 2:32:02  iter: 5159  total_loss: 4.73  loss_ce: 0.7699  loss_giou: 0.5547  loss_bbox: 0.4946  loss_ce_0: 0.7057  loss_giou_0: 0.5747  loss_bbox_0: 0.5157  loss_rpn_cls: 0.3872  loss_rpn_reg: 0.596  time: 0.1916  last_time: 0.1760  data_time: 0.0048  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:00:19] d2.utils.events INFO:  eta: 2:31:59  iter: 5179  total_loss: 4.827  loss_ce: 0.8447  loss_giou: 0.5606  loss_bbox: 0.4764  loss_ce_0: 0.7782  loss_giou_0: 0.5331  loss_bbox_0: 0.5469  loss_rpn_cls: 0.3604  loss_rpn_reg: 0.6687  time: 0.1915  last_time: 0.1764  data_time: 0.0049  last_data_time: 0.0076   lr: 5e-05  max_mem: 3029M
[03/05 12:00:23] d2.utils.events INFO:  eta: 2:31:55  iter: 5199  total_loss: 4.779  loss_ce: 0.8434  loss_giou: 0.5343  loss_bbox: 0.5217  loss_ce_0: 0.8083  loss_giou_0: 0.5584  loss_bbox_0: 0.6078  loss_rpn_cls: 0.3612  loss_rpn_reg: 0.6167  time: 0.1915  last_time: 0.2060  data_time: 0.0058  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 12:00:26] d2.utils.events INFO:  eta: 2:31:53  iter: 5219  total_loss: 4.802  loss_ce: 0.7876  loss_giou: 0.5566  loss_bbox: 0.4618  loss_ce_0: 0.7099  loss_giou_0: 0.6271  loss_bbox_0: 0.4868  loss_rpn_cls: 0.3945  loss_rpn_reg: 0.6376  time: 0.1915  last_time: 0.1928  data_time: 0.0055  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:00:30] d2.utils.events INFO:  eta: 2:31:50  iter: 5239  total_loss: 4.589  loss_ce: 0.8288  loss_giou: 0.5117  loss_bbox: 0.4317  loss_ce_0: 0.8445  loss_giou_0: 0.5435  loss_bbox_0: 0.4779  loss_rpn_cls: 0.393  loss_rpn_reg: 0.5536  time: 0.1915  last_time: 0.1892  data_time: 0.0050  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:00:34] d2.utils.events INFO:  eta: 2:31:56  iter: 5259  total_loss: 4.782  loss_ce: 0.8714  loss_giou: 0.5035  loss_bbox: 0.5164  loss_ce_0: 0.864  loss_giou_0: 0.5254  loss_bbox_0: 0.5359  loss_rpn_cls: 0.387  loss_rpn_reg: 0.6047  time: 0.1915  last_time: 0.1816  data_time: 0.0051  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:00:38] d2.utils.events INFO:  eta: 2:31:52  iter: 5279  total_loss: 4.988  loss_ce: 0.9019  loss_giou: 0.5183  loss_bbox: 0.534  loss_ce_0: 0.85  loss_giou_0: 0.525  loss_bbox_0: 0.5731  loss_rpn_cls: 0.3948  loss_rpn_reg: 0.5962  time: 0.1915  last_time: 0.1690  data_time: 0.0052  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:00:42] d2.utils.events INFO:  eta: 2:31:48  iter: 5299  total_loss: 4.396  loss_ce: 0.7725  loss_giou: 0.5441  loss_bbox: 0.5086  loss_ce_0: 0.7487  loss_giou_0: 0.5511  loss_bbox_0: 0.4936  loss_rpn_cls: 0.3608  loss_rpn_reg: 0.5892  time: 0.1915  last_time: 0.1794  data_time: 0.0045  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:00:46] d2.utils.events INFO:  eta: 2:31:49  iter: 5319  total_loss: 4.853  loss_ce: 0.8259  loss_giou: 0.5028  loss_bbox: 0.5526  loss_ce_0: 0.7929  loss_giou_0: 0.5472  loss_bbox_0: 0.5204  loss_rpn_cls: 0.3642  loss_rpn_reg: 0.6056  time: 0.1915  last_time: 0.1805  data_time: 0.0048  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 12:00:50] d2.utils.events INFO:  eta: 2:31:46  iter: 5339  total_loss: 4.892  loss_ce: 0.8288  loss_giou: 0.5208  loss_bbox: 0.4711  loss_ce_0: 0.7825  loss_giou_0: 0.5311  loss_bbox_0: 0.5397  loss_rpn_cls: 0.3901  loss_rpn_reg: 0.5816  time: 0.1915  last_time: 0.1819  data_time: 0.0049  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:00:53] d2.utils.events INFO:  eta: 2:31:48  iter: 5359  total_loss: 4.691  loss_ce: 0.7566  loss_giou: 0.491  loss_bbox: 0.5333  loss_ce_0: 0.7797  loss_giou_0: 0.5465  loss_bbox_0: 0.5614  loss_rpn_cls: 0.3805  loss_rpn_reg: 0.5569  time: 0.1915  last_time: 0.1689  data_time: 0.0047  last_data_time: 0.0026   lr: 5e-05  max_mem: 3029M
[03/05 12:00:57] d2.utils.events INFO:  eta: 2:31:50  iter: 5379  total_loss: 4.968  loss_ce: 0.8441  loss_giou: 0.6196  loss_bbox: 0.5318  loss_ce_0: 0.8045  loss_giou_0: 0.6321  loss_bbox_0: 0.5323  loss_rpn_cls: 0.3985  loss_rpn_reg: 0.6258  time: 0.1915  last_time: 0.1745  data_time: 0.0055  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:01:01] d2.utils.events INFO:  eta: 2:31:50  iter: 5399  total_loss: 4.9  loss_ce: 0.9129  loss_giou: 0.5186  loss_bbox: 0.5086  loss_ce_0: 0.9163  loss_giou_0: 0.5288  loss_bbox_0: 0.4978  loss_rpn_cls: 0.3707  loss_rpn_reg: 0.6222  time: 0.1915  last_time: 0.2022  data_time: 0.0046  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:01:05] d2.utils.events INFO:  eta: 2:31:43  iter: 5419  total_loss: 4.12  loss_ce: 0.7363  loss_giou: 0.4228  loss_bbox: 0.3805  loss_ce_0: 0.7567  loss_giou_0: 0.4604  loss_bbox_0: 0.4255  loss_rpn_cls: 0.3411  loss_rpn_reg: 0.5332  time: 0.1915  last_time: 0.1891  data_time: 0.0056  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:01:09] d2.utils.events INFO:  eta: 2:31:41  iter: 5439  total_loss: 4.834  loss_ce: 0.811  loss_giou: 0.4751  loss_bbox: 0.5472  loss_ce_0: 0.7662  loss_giou_0: 0.5135  loss_bbox_0: 0.6425  loss_rpn_cls: 0.3841  loss_rpn_reg: 0.6186  time: 0.1915  last_time: 0.1797  data_time: 0.0050  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:01:13] d2.utils.events INFO:  eta: 2:31:49  iter: 5459  total_loss: 4.625  loss_ce: 0.819  loss_giou: 0.4433  loss_bbox: 0.4886  loss_ce_0: 0.8199  loss_giou_0: 0.4828  loss_bbox_0: 0.5282  loss_rpn_cls: 0.3811  loss_rpn_reg: 0.625  time: 0.1915  last_time: 0.2201  data_time: 0.0051  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 12:01:17] d2.utils.events INFO:  eta: 2:31:44  iter: 5479  total_loss: 5.018  loss_ce: 0.8571  loss_giou: 0.5608  loss_bbox: 0.5084  loss_ce_0: 0.8547  loss_giou_0: 0.5693  loss_bbox_0: 0.5587  loss_rpn_cls: 0.3708  loss_rpn_reg: 0.633  time: 0.1915  last_time: 0.1602  data_time: 0.0046  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:01:21] d2.utils.events INFO:  eta: 2:31:42  iter: 5499  total_loss: 4.557  loss_ce: 0.7407  loss_giou: 0.5587  loss_bbox: 0.4508  loss_ce_0: 0.7685  loss_giou_0: 0.5647  loss_bbox_0: 0.5031  loss_rpn_cls: 0.3716  loss_rpn_reg: 0.603  time: 0.1915  last_time: 0.1793  data_time: 0.0048  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:01:25] d2.utils.events INFO:  eta: 2:31:36  iter: 5519  total_loss: 4.51  loss_ce: 0.7733  loss_giou: 0.5065  loss_bbox: 0.4941  loss_ce_0: 0.7765  loss_giou_0: 0.5266  loss_bbox_0: 0.5213  loss_rpn_cls: 0.3605  loss_rpn_reg: 0.5653  time: 0.1915  last_time: 0.1912  data_time: 0.0050  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:01:28] d2.utils.events INFO:  eta: 2:31:24  iter: 5539  total_loss: 4.407  loss_ce: 0.8187  loss_giou: 0.4616  loss_bbox: 0.398  loss_ce_0: 0.7539  loss_giou_0: 0.466  loss_bbox_0: 0.4881  loss_rpn_cls: 0.3496  loss_rpn_reg: 0.5879  time: 0.1915  last_time: 0.1851  data_time: 0.0045  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:01:32] d2.utils.events INFO:  eta: 2:31:17  iter: 5559  total_loss: 4.584  loss_ce: 0.8259  loss_giou: 0.5288  loss_bbox: 0.4681  loss_ce_0: 0.7948  loss_giou_0: 0.5372  loss_bbox_0: 0.4982  loss_rpn_cls: 0.3718  loss_rpn_reg: 0.58  time: 0.1914  last_time: 0.1880  data_time: 0.0051  last_data_time: 0.0031   lr: 5e-05  max_mem: 3029M
[03/05 12:01:36] d2.utils.events INFO:  eta: 2:31:15  iter: 5579  total_loss: 4.335  loss_ce: 0.7399  loss_giou: 0.4324  loss_bbox: 0.4786  loss_ce_0: 0.7634  loss_giou_0: 0.5084  loss_bbox_0: 0.5024  loss_rpn_cls: 0.3672  loss_rpn_reg: 0.573  time: 0.1914  last_time: 0.1867  data_time: 0.0046  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:01:40] d2.utils.events INFO:  eta: 2:31:10  iter: 5599  total_loss: 4.473  loss_ce: 0.8348  loss_giou: 0.489  loss_bbox: 0.467  loss_ce_0: 0.8026  loss_giou_0: 0.525  loss_bbox_0: 0.5066  loss_rpn_cls: 0.3711  loss_rpn_reg: 0.5863  time: 0.1914  last_time: 0.1892  data_time: 0.0046  last_data_time: 0.0031   lr: 5e-05  max_mem: 3029M
[03/05 12:01:44] d2.utils.events INFO:  eta: 2:31:13  iter: 5619  total_loss: 4.795  loss_ce: 0.8069  loss_giou: 0.4657  loss_bbox: 0.4954  loss_ce_0: 0.7877  loss_giou_0: 0.4806  loss_bbox_0: 0.4925  loss_rpn_cls: 0.3606  loss_rpn_reg: 0.5871  time: 0.1914  last_time: 0.1886  data_time: 0.0047  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 12:01:47] d2.utils.events INFO:  eta: 2:31:02  iter: 5639  total_loss: 4.393  loss_ce: 0.8359  loss_giou: 0.4049  loss_bbox: 0.4322  loss_ce_0: 0.7679  loss_giou_0: 0.4259  loss_bbox_0: 0.4652  loss_rpn_cls: 0.3559  loss_rpn_reg: 0.566  time: 0.1914  last_time: 0.1838  data_time: 0.0051  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:01:51] d2.utils.events INFO:  eta: 2:31:01  iter: 5659  total_loss: 4.537  loss_ce: 0.7462  loss_giou: 0.487  loss_bbox: 0.4059  loss_ce_0: 0.7327  loss_giou_0: 0.5341  loss_bbox_0: 0.4241  loss_rpn_cls: 0.3824  loss_rpn_reg: 0.6219  time: 0.1914  last_time: 0.1909  data_time: 0.0048  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:01:55] d2.utils.events INFO:  eta: 2:30:58  iter: 5679  total_loss: 4.754  loss_ce: 0.7738  loss_giou: 0.5781  loss_bbox: 0.47  loss_ce_0: 0.7791  loss_giou_0: 0.6036  loss_bbox_0: 0.4655  loss_rpn_cls: 0.3715  loss_rpn_reg: 0.653  time: 0.1914  last_time: 0.1977  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:01:59] d2.utils.events INFO:  eta: 2:31:06  iter: 5699  total_loss: 4.883  loss_ce: 0.7991  loss_giou: 0.51  loss_bbox: 0.4848  loss_ce_0: 0.7938  loss_giou_0: 0.5456  loss_bbox_0: 0.5067  loss_rpn_cls: 0.3717  loss_rpn_reg: 0.6087  time: 0.1914  last_time: 0.2167  data_time: 0.0047  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:02:03] d2.utils.events INFO:  eta: 2:30:54  iter: 5719  total_loss: 4.583  loss_ce: 0.7557  loss_giou: 0.5393  loss_bbox: 0.462  loss_ce_0: 0.7581  loss_giou_0: 0.5295  loss_bbox_0: 0.4788  loss_rpn_cls: 0.3548  loss_rpn_reg: 0.611  time: 0.1914  last_time: 0.1764  data_time: 0.0047  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:02:06] d2.utils.events INFO:  eta: 2:30:50  iter: 5739  total_loss: 4.46  loss_ce: 0.7941  loss_giou: 0.4394  loss_bbox: 0.4109  loss_ce_0: 0.7525  loss_giou_0: 0.4715  loss_bbox_0: 0.4818  loss_rpn_cls: 0.3246  loss_rpn_reg: 0.5789  time: 0.1913  last_time: 0.1705  data_time: 0.0048  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:02:10] d2.utils.events INFO:  eta: 2:30:55  iter: 5759  total_loss: 4.583  loss_ce: 0.7744  loss_giou: 0.4205  loss_bbox: 0.5055  loss_ce_0: 0.7521  loss_giou_0: 0.4621  loss_bbox_0: 0.5283  loss_rpn_cls: 0.374  loss_rpn_reg: 0.5553  time: 0.1913  last_time: 0.1705  data_time: 0.0047  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:02:14] d2.utils.events INFO:  eta: 2:30:53  iter: 5779  total_loss: 4.698  loss_ce: 0.8732  loss_giou: 0.4708  loss_bbox: 0.4746  loss_ce_0: 0.8964  loss_giou_0: 0.5377  loss_bbox_0: 0.4669  loss_rpn_cls: 0.394  loss_rpn_reg: 0.5938  time: 0.1913  last_time: 0.2108  data_time: 0.0049  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:02:18] d2.utils.events INFO:  eta: 2:30:47  iter: 5799  total_loss: 4.673  loss_ce: 0.764  loss_giou: 0.4443  loss_bbox: 0.5828  loss_ce_0: 0.7482  loss_giou_0: 0.4939  loss_bbox_0: 0.6477  loss_rpn_cls: 0.3538  loss_rpn_reg: 0.609  time: 0.1913  last_time: 0.1832  data_time: 0.0050  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 12:02:22] d2.utils.events INFO:  eta: 2:30:40  iter: 5819  total_loss: 4.236  loss_ce: 0.7965  loss_giou: 0.4484  loss_bbox: 0.3898  loss_ce_0: 0.7601  loss_giou_0: 0.4857  loss_bbox_0: 0.4376  loss_rpn_cls: 0.3562  loss_rpn_reg: 0.5882  time: 0.1913  last_time: 0.1738  data_time: 0.0047  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:02:26] d2.utils.events INFO:  eta: 2:30:26  iter: 5839  total_loss: 4.351  loss_ce: 0.7262  loss_giou: 0.4782  loss_bbox: 0.42  loss_ce_0: 0.7439  loss_giou_0: 0.5063  loss_bbox_0: 0.4821  loss_rpn_cls: 0.3421  loss_rpn_reg: 0.5933  time: 0.1913  last_time: 0.1992  data_time: 0.0047  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:02:29] d2.utils.events INFO:  eta: 2:30:33  iter: 5859  total_loss: 4.51  loss_ce: 0.7181  loss_giou: 0.5505  loss_bbox: 0.5059  loss_ce_0: 0.7212  loss_giou_0: 0.5839  loss_bbox_0: 0.5148  loss_rpn_cls: 0.3499  loss_rpn_reg: 0.6105  time: 0.1913  last_time: 0.1701  data_time: 0.0051  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:02:33] d2.utils.events INFO:  eta: 2:30:34  iter: 5879  total_loss: 4.324  loss_ce: 0.7441  loss_giou: 0.4755  loss_bbox: 0.4043  loss_ce_0: 0.715  loss_giou_0: 0.516  loss_bbox_0: 0.4562  loss_rpn_cls: 0.3554  loss_rpn_reg: 0.5726  time: 0.1913  last_time: 0.2349  data_time: 0.0045  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 12:02:37] d2.utils.events INFO:  eta: 2:30:35  iter: 5899  total_loss: 4.618  loss_ce: 0.7805  loss_giou: 0.5325  loss_bbox: 0.5178  loss_ce_0: 0.7533  loss_giou_0: 0.5431  loss_bbox_0: 0.4932  loss_rpn_cls: 0.3563  loss_rpn_reg: 0.5904  time: 0.1913  last_time: 0.2131  data_time: 0.0053  last_data_time: 0.0030   lr: 5e-05  max_mem: 3029M
[03/05 12:02:41] d2.utils.events INFO:  eta: 2:30:28  iter: 5919  total_loss: 4.782  loss_ce: 0.8184  loss_giou: 0.5163  loss_bbox: 0.5116  loss_ce_0: 0.7472  loss_giou_0: 0.5265  loss_bbox_0: 0.534  loss_rpn_cls: 0.3834  loss_rpn_reg: 0.6179  time: 0.1913  last_time: 0.1716  data_time: 0.0048  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:02:45] d2.utils.events INFO:  eta: 2:30:24  iter: 5939  total_loss: 4.61  loss_ce: 0.8008  loss_giou: 0.5374  loss_bbox: 0.4632  loss_ce_0: 0.8021  loss_giou_0: 0.5548  loss_bbox_0: 0.5149  loss_rpn_cls: 0.3725  loss_rpn_reg: 0.6032  time: 0.1913  last_time: 0.1687  data_time: 0.0053  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:02:49] d2.utils.events INFO:  eta: 2:30:24  iter: 5959  total_loss: 4.536  loss_ce: 0.7553  loss_giou: 0.5534  loss_bbox: 0.5082  loss_ce_0: 0.7989  loss_giou_0: 0.5617  loss_bbox_0: 0.5453  loss_rpn_cls: 0.3665  loss_rpn_reg: 0.5817  time: 0.1913  last_time: 0.1921  data_time: 0.0048  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:02:53] d2.utils.events INFO:  eta: 2:30:20  iter: 5979  total_loss: 4.886  loss_ce: 0.8104  loss_giou: 0.5273  loss_bbox: 0.5579  loss_ce_0: 0.8239  loss_giou_0: 0.5398  loss_bbox_0: 0.5692  loss_rpn_cls: 0.3867  loss_rpn_reg: 0.6151  time: 0.1912  last_time: 0.1902  data_time: 0.0061  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:02:56] d2.utils.events INFO:  eta: 2:30:19  iter: 5999  total_loss: 4.665  loss_ce: 0.807  loss_giou: 0.5488  loss_bbox: 0.4422  loss_ce_0: 0.7994  loss_giou_0: 0.5913  loss_bbox_0: 0.4746  loss_rpn_cls: 0.3485  loss_rpn_reg: 0.5826  time: 0.1912  last_time: 0.1821  data_time: 0.0053  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 12:03:00] d2.utils.events INFO:  eta: 2:30:11  iter: 6019  total_loss: 4.602  loss_ce: 0.7815  loss_giou: 0.6074  loss_bbox: 0.4326  loss_ce_0: 0.7632  loss_giou_0: 0.6274  loss_bbox_0: 0.4744  loss_rpn_cls: 0.3814  loss_rpn_reg: 0.5448  time: 0.1912  last_time: 0.1873  data_time: 0.0047  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:03:04] d2.utils.events INFO:  eta: 2:30:03  iter: 6039  total_loss: 4.251  loss_ce: 0.7286  loss_giou: 0.4903  loss_bbox: 0.4747  loss_ce_0: 0.699  loss_giou_0: 0.5306  loss_bbox_0: 0.4949  loss_rpn_cls: 0.352  loss_rpn_reg: 0.538  time: 0.1912  last_time: 0.1859  data_time: 0.0049  last_data_time: 0.0071   lr: 5e-05  max_mem: 3029M
[03/05 12:03:08] d2.utils.events INFO:  eta: 2:30:03  iter: 6059  total_loss: 4.635  loss_ce: 0.8154  loss_giou: 0.4808  loss_bbox: 0.488  loss_ce_0: 0.7342  loss_giou_0: 0.5202  loss_bbox_0: 0.4958  loss_rpn_cls: 0.3446  loss_rpn_reg: 0.5995  time: 0.1912  last_time: 0.1998  data_time: 0.0050  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 12:03:12] d2.utils.events INFO:  eta: 2:30:04  iter: 6079  total_loss: 4.514  loss_ce: 0.791  loss_giou: 0.5298  loss_bbox: 0.4543  loss_ce_0: 0.7559  loss_giou_0: 0.5684  loss_bbox_0: 0.541  loss_rpn_cls: 0.3706  loss_rpn_reg: 0.6392  time: 0.1912  last_time: 0.1993  data_time: 0.0049  last_data_time: 0.0079   lr: 5e-05  max_mem: 3029M
[03/05 12:03:15] d2.utils.events INFO:  eta: 2:29:59  iter: 6099  total_loss: 4.287  loss_ce: 0.7439  loss_giou: 0.4535  loss_bbox: 0.4952  loss_ce_0: 0.74  loss_giou_0: 0.4705  loss_bbox_0: 0.5131  loss_rpn_cls: 0.3466  loss_rpn_reg: 0.5861  time: 0.1912  last_time: 0.1878  data_time: 0.0044  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:03:19] d2.utils.events INFO:  eta: 2:30:01  iter: 6119  total_loss: 4.849  loss_ce: 0.8116  loss_giou: 0.4665  loss_bbox: 0.5174  loss_ce_0: 0.8012  loss_giou_0: 0.5117  loss_bbox_0: 0.5673  loss_rpn_cls: 0.3964  loss_rpn_reg: 0.6233  time: 0.1912  last_time: 0.1707  data_time: 0.0057  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 12:03:23] d2.utils.events INFO:  eta: 2:29:54  iter: 6139  total_loss: 4.793  loss_ce: 0.7764  loss_giou: 0.5473  loss_bbox: 0.4474  loss_ce_0: 0.7824  loss_giou_0: 0.5459  loss_bbox_0: 0.4949  loss_rpn_cls: 0.3812  loss_rpn_reg: 0.6165  time: 0.1911  last_time: 0.1714  data_time: 0.0047  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:03:27] d2.utils.events INFO:  eta: 2:29:53  iter: 6159  total_loss: 4.377  loss_ce: 0.8503  loss_giou: 0.4656  loss_bbox: 0.4384  loss_ce_0: 0.8021  loss_giou_0: 0.4718  loss_bbox_0: 0.4951  loss_rpn_cls: 0.3406  loss_rpn_reg: 0.577  time: 0.1911  last_time: 0.2015  data_time: 0.0051  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:03:31] d2.utils.events INFO:  eta: 2:29:50  iter: 6179  total_loss: 4.519  loss_ce: 0.7982  loss_giou: 0.4245  loss_bbox: 0.4434  loss_ce_0: 0.7436  loss_giou_0: 0.4835  loss_bbox_0: 0.5437  loss_rpn_cls: 0.3383  loss_rpn_reg: 0.5873  time: 0.1911  last_time: 0.1942  data_time: 0.0049  last_data_time: 0.0083   lr: 5e-05  max_mem: 3029M
[03/05 12:03:34] d2.utils.events INFO:  eta: 2:29:42  iter: 6199  total_loss: 4.472  loss_ce: 0.7678  loss_giou: 0.5245  loss_bbox: 0.4447  loss_ce_0: 0.8233  loss_giou_0: 0.5711  loss_bbox_0: 0.4998  loss_rpn_cls: 0.3732  loss_rpn_reg: 0.5954  time: 0.1911  last_time: 0.2068  data_time: 0.0050  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 12:03:38] d2.utils.events INFO:  eta: 2:29:40  iter: 6219  total_loss: 4.603  loss_ce: 0.6876  loss_giou: 0.5063  loss_bbox: 0.549  loss_ce_0: 0.7471  loss_giou_0: 0.5175  loss_bbox_0: 0.6112  loss_rpn_cls: 0.3882  loss_rpn_reg: 0.5929  time: 0.1911  last_time: 0.1641  data_time: 0.0052  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:03:42] d2.utils.events INFO:  eta: 2:29:38  iter: 6239  total_loss: 4.046  loss_ce: 0.7443  loss_giou: 0.3904  loss_bbox: 0.4262  loss_ce_0: 0.7232  loss_giou_0: 0.4028  loss_bbox_0: 0.4556  loss_rpn_cls: 0.3216  loss_rpn_reg: 0.5684  time: 0.1911  last_time: 0.1934  data_time: 0.0054  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 12:03:46] d2.utils.events INFO:  eta: 2:29:27  iter: 6259  total_loss: 4.588  loss_ce: 0.7924  loss_giou: 0.5965  loss_bbox: 0.5114  loss_ce_0: 0.7673  loss_giou_0: 0.6342  loss_bbox_0: 0.5491  loss_rpn_cls: 0.3547  loss_rpn_reg: 0.6231  time: 0.1911  last_time: 0.1691  data_time: 0.0049  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 12:03:50] d2.utils.events INFO:  eta: 2:29:27  iter: 6279  total_loss: 4.722  loss_ce: 0.8023  loss_giou: 0.4742  loss_bbox: 0.5437  loss_ce_0: 0.7829  loss_giou_0: 0.5061  loss_bbox_0: 0.5611  loss_rpn_cls: 0.3652  loss_rpn_reg: 0.5768  time: 0.1911  last_time: 0.1791  data_time: 0.0047  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:03:54] d2.utils.events INFO:  eta: 2:29:25  iter: 6299  total_loss: 4.544  loss_ce: 0.7374  loss_giou: 0.4853  loss_bbox: 0.4758  loss_ce_0: 0.7162  loss_giou_0: 0.5003  loss_bbox_0: 0.5492  loss_rpn_cls: 0.3353  loss_rpn_reg: 0.5555  time: 0.1911  last_time: 0.1722  data_time: 0.0048  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:03:58] d2.utils.events INFO:  eta: 2:29:21  iter: 6319  total_loss: 4.116  loss_ce: 0.7627  loss_giou: 0.4227  loss_bbox: 0.3835  loss_ce_0: 0.7163  loss_giou_0: 0.4344  loss_bbox_0: 0.4154  loss_rpn_cls: 0.3307  loss_rpn_reg: 0.5614  time: 0.1911  last_time: 0.1741  data_time: 0.0049  last_data_time: 0.0029   lr: 5e-05  max_mem: 3029M
[03/05 12:04:01] d2.utils.events INFO:  eta: 2:29:16  iter: 6339  total_loss: 4.515  loss_ce: 0.7396  loss_giou: 0.5557  loss_bbox: 0.5068  loss_ce_0: 0.7325  loss_giou_0: 0.5494  loss_bbox_0: 0.506  loss_rpn_cls: 0.3709  loss_rpn_reg: 0.5934  time: 0.1911  last_time: 0.1998  data_time: 0.0050  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:04:05] d2.utils.events INFO:  eta: 2:29:11  iter: 6359  total_loss: 4.264  loss_ce: 0.7311  loss_giou: 0.4273  loss_bbox: 0.3982  loss_ce_0: 0.6741  loss_giou_0: 0.4832  loss_bbox_0: 0.4714  loss_rpn_cls: 0.337  loss_rpn_reg: 0.573  time: 0.1911  last_time: 0.1900  data_time: 0.0050  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 12:04:09] d2.utils.events INFO:  eta: 2:29:05  iter: 6379  total_loss: 4.748  loss_ce: 0.7124  loss_giou: 0.5257  loss_bbox: 0.5104  loss_ce_0: 0.7366  loss_giou_0: 0.5196  loss_bbox_0: 0.5467  loss_rpn_cls: 0.3662  loss_rpn_reg: 0.5843  time: 0.1910  last_time: 0.1823  data_time: 0.0047  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:04:13] d2.utils.events INFO:  eta: 2:29:03  iter: 6399  total_loss: 4.57  loss_ce: 0.8075  loss_giou: 0.4856  loss_bbox: 0.5137  loss_ce_0: 0.8  loss_giou_0: 0.5054  loss_bbox_0: 0.5268  loss_rpn_cls: 0.3781  loss_rpn_reg: 0.5514  time: 0.1910  last_time: 0.1710  data_time: 0.0055  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:04:17] d2.utils.events INFO:  eta: 2:29:00  iter: 6419  total_loss: 4.308  loss_ce: 0.7471  loss_giou: 0.4637  loss_bbox: 0.4368  loss_ce_0: 0.7191  loss_giou_0: 0.461  loss_bbox_0: 0.4647  loss_rpn_cls: 0.3454  loss_rpn_reg: 0.5867  time: 0.1910  last_time: 0.1847  data_time: 0.0044  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 12:04:20] d2.utils.events INFO:  eta: 2:28:56  iter: 6439  total_loss: 3.989  loss_ce: 0.69  loss_giou: 0.3868  loss_bbox: 0.4034  loss_ce_0: 0.6472  loss_giou_0: 0.4023  loss_bbox_0: 0.4254  loss_rpn_cls: 0.3252  loss_rpn_reg: 0.5612  time: 0.1910  last_time: 0.1986  data_time: 0.0050  last_data_time: 0.0074   lr: 5e-05  max_mem: 3029M
[03/05 12:04:24] d2.utils.events INFO:  eta: 2:28:48  iter: 6459  total_loss: 4.095  loss_ce: 0.6769  loss_giou: 0.4561  loss_bbox: 0.441  loss_ce_0: 0.67  loss_giou_0: 0.4885  loss_bbox_0: 0.4407  loss_rpn_cls: 0.3381  loss_rpn_reg: 0.5515  time: 0.1910  last_time: 0.2039  data_time: 0.0053  last_data_time: 0.0078   lr: 5e-05  max_mem: 3029M
[03/05 12:04:28] d2.utils.events INFO:  eta: 2:28:42  iter: 6479  total_loss: 4.282  loss_ce: 0.7571  loss_giou: 0.4741  loss_bbox: 0.4309  loss_ce_0: 0.6859  loss_giou_0: 0.5173  loss_bbox_0: 0.4871  loss_rpn_cls: 0.3367  loss_rpn_reg: 0.5714  time: 0.1910  last_time: 0.1822  data_time: 0.0046  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:04:32] d2.utils.events INFO:  eta: 2:28:43  iter: 6499  total_loss: 4.672  loss_ce: 0.8012  loss_giou: 0.469  loss_bbox: 0.4413  loss_ce_0: 0.7995  loss_giou_0: 0.4885  loss_bbox_0: 0.4572  loss_rpn_cls: 0.3736  loss_rpn_reg: 0.573  time: 0.1910  last_time: 0.1869  data_time: 0.0054  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:04:36] d2.utils.events INFO:  eta: 2:28:39  iter: 6519  total_loss: 4.227  loss_ce: 0.7574  loss_giou: 0.4358  loss_bbox: 0.4744  loss_ce_0: 0.7309  loss_giou_0: 0.4614  loss_bbox_0: 0.489  loss_rpn_cls: 0.3001  loss_rpn_reg: 0.5977  time: 0.1910  last_time: 0.1686  data_time: 0.0049  last_data_time: 0.0024   lr: 5e-05  max_mem: 3029M
[03/05 12:04:40] d2.utils.events INFO:  eta: 2:28:38  iter: 6539  total_loss: 4.305  loss_ce: 0.7311  loss_giou: 0.4763  loss_bbox: 0.4144  loss_ce_0: 0.7239  loss_giou_0: 0.482  loss_bbox_0: 0.4377  loss_rpn_cls: 0.3057  loss_rpn_reg: 0.5805  time: 0.1910  last_time: 0.1699  data_time: 0.0049  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:04:43] d2.utils.events INFO:  eta: 2:28:34  iter: 6559  total_loss: 4.564  loss_ce: 0.7081  loss_giou: 0.4645  loss_bbox: 0.4694  loss_ce_0: 0.697  loss_giou_0: 0.4897  loss_bbox_0: 0.5013  loss_rpn_cls: 0.3363  loss_rpn_reg: 0.5798  time: 0.1910  last_time: 0.1842  data_time: 0.0052  last_data_time: 0.0095   lr: 5e-05  max_mem: 3029M
[03/05 12:04:47] d2.utils.events INFO:  eta: 2:28:31  iter: 6579  total_loss: 4.316  loss_ce: 0.759  loss_giou: 0.4565  loss_bbox: 0.4629  loss_ce_0: 0.7362  loss_giou_0: 0.4631  loss_bbox_0: 0.5208  loss_rpn_cls: 0.325  loss_rpn_reg: 0.5781  time: 0.1910  last_time: 0.1727  data_time: 0.0053  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 12:04:51] d2.utils.events INFO:  eta: 2:28:29  iter: 6599  total_loss: 4.356  loss_ce: 0.7775  loss_giou: 0.4514  loss_bbox: 0.4298  loss_ce_0: 0.7564  loss_giou_0: 0.4734  loss_bbox_0: 0.5141  loss_rpn_cls: 0.3523  loss_rpn_reg: 0.5848  time: 0.1910  last_time: 0.1839  data_time: 0.0046  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:04:55] d2.utils.events INFO:  eta: 2:28:23  iter: 6619  total_loss: 4.177  loss_ce: 0.7315  loss_giou: 0.3908  loss_bbox: 0.4634  loss_ce_0: 0.7578  loss_giou_0: 0.444  loss_bbox_0: 0.4656  loss_rpn_cls: 0.3405  loss_rpn_reg: 0.5456  time: 0.1910  last_time: 0.2081  data_time: 0.0053  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:04:59] d2.utils.events INFO:  eta: 2:28:27  iter: 6639  total_loss: 4.422  loss_ce: 0.7772  loss_giou: 0.5049  loss_bbox: 0.4692  loss_ce_0: 0.7166  loss_giou_0: 0.5149  loss_bbox_0: 0.4607  loss_rpn_cls: 0.3702  loss_rpn_reg: 0.5663  time: 0.1910  last_time: 0.1795  data_time: 0.0049  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:05:03] d2.utils.events INFO:  eta: 2:28:18  iter: 6659  total_loss: 4.542  loss_ce: 0.7582  loss_giou: 0.506  loss_bbox: 0.4248  loss_ce_0: 0.7397  loss_giou_0: 0.5198  loss_bbox_0: 0.4791  loss_rpn_cls: 0.3625  loss_rpn_reg: 0.5911  time: 0.1909  last_time: 0.1785  data_time: 0.0044  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:05:06] d2.utils.events INFO:  eta: 2:28:13  iter: 6679  total_loss: 4.462  loss_ce: 0.7871  loss_giou: 0.5643  loss_bbox: 0.4461  loss_ce_0: 0.7495  loss_giou_0: 0.5583  loss_bbox_0: 0.492  loss_rpn_cls: 0.3885  loss_rpn_reg: 0.5851  time: 0.1909  last_time: 0.1879  data_time: 0.0061  last_data_time: 0.0104   lr: 5e-05  max_mem: 3029M
[03/05 12:05:10] d2.utils.events INFO:  eta: 2:28:07  iter: 6699  total_loss: 4.231  loss_ce: 0.641  loss_giou: 0.4193  loss_bbox: 0.4647  loss_ce_0: 0.6327  loss_giou_0: 0.4492  loss_bbox_0: 0.5199  loss_rpn_cls: 0.3165  loss_rpn_reg: 0.5623  time: 0.1909  last_time: 0.2097  data_time: 0.0045  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:05:14] d2.utils.events INFO:  eta: 2:28:05  iter: 6719  total_loss: 4.356  loss_ce: 0.7457  loss_giou: 0.4351  loss_bbox: 0.5154  loss_ce_0: 0.706  loss_giou_0: 0.4476  loss_bbox_0: 0.5307  loss_rpn_cls: 0.3334  loss_rpn_reg: 0.5502  time: 0.1909  last_time: 0.2012  data_time: 0.0051  last_data_time: 0.0103   lr: 5e-05  max_mem: 3029M
[03/05 12:05:18] d2.utils.events INFO:  eta: 2:28:06  iter: 6739  total_loss: 4.89  loss_ce: 0.7444  loss_giou: 0.5205  loss_bbox: 0.6098  loss_ce_0: 0.7305  loss_giou_0: 0.5282  loss_bbox_0: 0.6674  loss_rpn_cls: 0.3418  loss_rpn_reg: 0.6471  time: 0.1909  last_time: 0.2195  data_time: 0.0045  last_data_time: 0.0080   lr: 5e-05  max_mem: 3029M
[03/05 12:05:22] d2.utils.events INFO:  eta: 2:28:02  iter: 6759  total_loss: 4.227  loss_ce: 0.7366  loss_giou: 0.4741  loss_bbox: 0.4255  loss_ce_0: 0.7509  loss_giou_0: 0.4853  loss_bbox_0: 0.4694  loss_rpn_cls: 0.3279  loss_rpn_reg: 0.5614  time: 0.1909  last_time: 0.1769  data_time: 0.0050  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:05:25] d2.utils.events INFO:  eta: 2:27:53  iter: 6779  total_loss: 4.199  loss_ce: 0.6392  loss_giou: 0.4668  loss_bbox: 0.4798  loss_ce_0: 0.66  loss_giou_0: 0.5321  loss_bbox_0: 0.498  loss_rpn_cls: 0.3345  loss_rpn_reg: 0.6041  time: 0.1909  last_time: 0.1744  data_time: 0.0057  last_data_time: 0.0070   lr: 5e-05  max_mem: 3029M
[03/05 12:05:29] d2.utils.events INFO:  eta: 2:27:47  iter: 6799  total_loss: 4.505  loss_ce: 0.7833  loss_giou: 0.5129  loss_bbox: 0.5007  loss_ce_0: 0.7671  loss_giou_0: 0.4987  loss_bbox_0: 0.5025  loss_rpn_cls: 0.3529  loss_rpn_reg: 0.5747  time: 0.1909  last_time: 0.1760  data_time: 0.0052  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:05:33] d2.utils.events INFO:  eta: 2:27:42  iter: 6819  total_loss: 4.381  loss_ce: 0.7577  loss_giou: 0.4944  loss_bbox: 0.4607  loss_ce_0: 0.7427  loss_giou_0: 0.4981  loss_bbox_0: 0.4967  loss_rpn_cls: 0.3639  loss_rpn_reg: 0.5843  time: 0.1909  last_time: 0.1699  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:05:37] d2.utils.events INFO:  eta: 2:27:44  iter: 6839  total_loss: 4.677  loss_ce: 0.7546  loss_giou: 0.5716  loss_bbox: 0.4544  loss_ce_0: 0.7489  loss_giou_0: 0.5462  loss_bbox_0: 0.4982  loss_rpn_cls: 0.3937  loss_rpn_reg: 0.5832  time: 0.1908  last_time: 0.1906  data_time: 0.0051  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 12:05:41] d2.utils.events INFO:  eta: 2:27:38  iter: 6859  total_loss: 4.562  loss_ce: 0.7968  loss_giou: 0.428  loss_bbox: 0.4827  loss_ce_0: 0.7557  loss_giou_0: 0.4596  loss_bbox_0: 0.519  loss_rpn_cls: 0.3396  loss_rpn_reg: 0.5658  time: 0.1908  last_time: 0.2146  data_time: 0.0051  last_data_time: 0.0075   lr: 5e-05  max_mem: 3029M
[03/05 12:05:44] d2.utils.events INFO:  eta: 2:27:31  iter: 6879  total_loss: 4.88  loss_ce: 0.8409  loss_giou: 0.4904  loss_bbox: 0.5137  loss_ce_0: 0.7809  loss_giou_0: 0.5075  loss_bbox_0: 0.5337  loss_rpn_cls: 0.3584  loss_rpn_reg: 0.6014  time: 0.1908  last_time: 0.1609  data_time: 0.0045  last_data_time: 0.0032   lr: 5e-05  max_mem: 3029M
[03/05 12:05:48] d2.utils.events INFO:  eta: 2:27:25  iter: 6899  total_loss: 4.291  loss_ce: 0.7961  loss_giou: 0.4834  loss_bbox: 0.4453  loss_ce_0: 0.7501  loss_giou_0: 0.5245  loss_bbox_0: 0.4743  loss_rpn_cls: 0.353  loss_rpn_reg: 0.5433  time: 0.1908  last_time: 0.1596  data_time: 0.0052  last_data_time: 0.0025   lr: 5e-05  max_mem: 3029M
[03/05 12:05:52] d2.utils.events INFO:  eta: 2:27:20  iter: 6919  total_loss: 4.107  loss_ce: 0.6643  loss_giou: 0.3909  loss_bbox: 0.4983  loss_ce_0: 0.6376  loss_giou_0: 0.4498  loss_bbox_0: 0.5262  loss_rpn_cls: 0.3101  loss_rpn_reg: 0.5431  time: 0.1908  last_time: 0.1878  data_time: 0.0048  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:05:56] d2.utils.events INFO:  eta: 2:27:25  iter: 6939  total_loss: 4.327  loss_ce: 0.7295  loss_giou: 0.4486  loss_bbox: 0.4256  loss_ce_0: 0.7434  loss_giou_0: 0.4797  loss_bbox_0: 0.4997  loss_rpn_cls: 0.3447  loss_rpn_reg: 0.5426  time: 0.1908  last_time: 0.1989  data_time: 0.0047  last_data_time: 0.0064   lr: 5e-05  max_mem: 3029M
[03/05 12:06:00] d2.utils.events INFO:  eta: 2:27:14  iter: 6959  total_loss: 4.043  loss_ce: 0.6866  loss_giou: 0.4338  loss_bbox: 0.3833  loss_ce_0: 0.6762  loss_giou_0: 0.463  loss_bbox_0: 0.4353  loss_rpn_cls: 0.3442  loss_rpn_reg: 0.5653  time: 0.1908  last_time: 0.1835  data_time: 0.0050  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:06:04] d2.utils.events INFO:  eta: 2:27:12  iter: 6979  total_loss: 4.424  loss_ce: 0.7148  loss_giou: 0.4506  loss_bbox: 0.4812  loss_ce_0: 0.7189  loss_giou_0: 0.4854  loss_bbox_0: 0.549  loss_rpn_cls: 0.3475  loss_rpn_reg: 0.5478  time: 0.1908  last_time: 0.1872  data_time: 0.0048  last_data_time: 0.0073   lr: 5e-05  max_mem: 3029M
[03/05 12:06:08] d2.utils.events INFO:  eta: 2:27:17  iter: 6999  total_loss: 4.486  loss_ce: 0.7072  loss_giou: 0.4889  loss_bbox: 0.5097  loss_ce_0: 0.7111  loss_giou_0: 0.5077  loss_bbox_0: 0.518  loss_rpn_cls: 0.3687  loss_rpn_reg: 0.5896  time: 0.1908  last_time: 0.2091  data_time: 0.0051  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:06:12] d2.utils.events INFO:  eta: 2:27:18  iter: 7019  total_loss: 4.324  loss_ce: 0.745  loss_giou: 0.4323  loss_bbox: 0.4072  loss_ce_0: 0.7684  loss_giou_0: 0.4648  loss_bbox_0: 0.4786  loss_rpn_cls: 0.3653  loss_rpn_reg: 0.5609  time: 0.1908  last_time: 0.1804  data_time: 0.0051  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:06:15] d2.utils.events INFO:  eta: 2:27:17  iter: 7039  total_loss: 4.618  loss_ce: 0.7065  loss_giou: 0.5469  loss_bbox: 0.4593  loss_ce_0: 0.7624  loss_giou_0: 0.5488  loss_bbox_0: 0.4765  loss_rpn_cls: 0.3827  loss_rpn_reg: 0.5688  time: 0.1908  last_time: 0.2296  data_time: 0.0056  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:06:19] d2.utils.events INFO:  eta: 2:27:08  iter: 7059  total_loss: 4.233  loss_ce: 0.7353  loss_giou: 0.4917  loss_bbox: 0.4361  loss_ce_0: 0.7402  loss_giou_0: 0.4777  loss_bbox_0: 0.4402  loss_rpn_cls: 0.3273  loss_rpn_reg: 0.5612  time: 0.1908  last_time: 0.1904  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:06:23] d2.utils.events INFO:  eta: 2:27:14  iter: 7079  total_loss: 4.709  loss_ce: 0.742  loss_giou: 0.5493  loss_bbox: 0.4669  loss_ce_0: 0.7175  loss_giou_0: 0.568  loss_bbox_0: 0.476  loss_rpn_cls: 0.3952  loss_rpn_reg: 0.6244  time: 0.1908  last_time: 0.1906  data_time: 0.0054  last_data_time: 0.0026   lr: 5e-05  max_mem: 3029M
[03/05 12:06:27] d2.utils.events INFO:  eta: 2:27:29  iter: 7099  total_loss: 4.569  loss_ce: 0.7995  loss_giou: 0.5115  loss_bbox: 0.4799  loss_ce_0: 0.7712  loss_giou_0: 0.5457  loss_bbox_0: 0.5141  loss_rpn_cls: 0.3583  loss_rpn_reg: 0.6321  time: 0.1908  last_time: 0.1891  data_time: 0.0045  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 12:06:31] d2.utils.events INFO:  eta: 2:27:24  iter: 7119  total_loss: 4.579  loss_ce: 0.7682  loss_giou: 0.5624  loss_bbox: 0.4742  loss_ce_0: 0.7632  loss_giou_0: 0.5607  loss_bbox_0: 0.509  loss_rpn_cls: 0.3546  loss_rpn_reg: 0.6027  time: 0.1909  last_time: 0.2122  data_time: 0.0047  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:06:35] d2.utils.events INFO:  eta: 2:27:31  iter: 7139  total_loss: 4.181  loss_ce: 0.6774  loss_giou: 0.437  loss_bbox: 0.4651  loss_ce_0: 0.6846  loss_giou_0: 0.4483  loss_bbox_0: 0.4992  loss_rpn_cls: 0.3029  loss_rpn_reg: 0.5601  time: 0.1909  last_time: 0.1825  data_time: 0.0045  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:06:39] d2.utils.events INFO:  eta: 2:27:32  iter: 7159  total_loss: 4.398  loss_ce: 0.7197  loss_giou: 0.5313  loss_bbox: 0.4314  loss_ce_0: 0.6777  loss_giou_0: 0.5502  loss_bbox_0: 0.4748  loss_rpn_cls: 0.358  loss_rpn_reg: 0.5656  time: 0.1909  last_time: 0.2145  data_time: 0.0055  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:06:43] d2.utils.events INFO:  eta: 2:27:29  iter: 7179  total_loss: 4.137  loss_ce: 0.6533  loss_giou: 0.4525  loss_bbox: 0.415  loss_ce_0: 0.6381  loss_giou_0: 0.5075  loss_bbox_0: 0.4835  loss_rpn_cls: 0.3335  loss_rpn_reg: 0.5562  time: 0.1909  last_time: 0.1788  data_time: 0.0047  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:06:47] d2.utils.events INFO:  eta: 2:27:40  iter: 7199  total_loss: 4.233  loss_ce: 0.7227  loss_giou: 0.4756  loss_bbox: 0.3859  loss_ce_0: 0.7306  loss_giou_0: 0.4883  loss_bbox_0: 0.4391  loss_rpn_cls: 0.3442  loss_rpn_reg: 0.5448  time: 0.1909  last_time: 0.2126  data_time: 0.0050  last_data_time: 0.0073   lr: 5e-05  max_mem: 3029M
[03/05 12:06:51] d2.utils.events INFO:  eta: 2:27:37  iter: 7219  total_loss: 3.971  loss_ce: 0.732  loss_giou: 0.4477  loss_bbox: 0.4176  loss_ce_0: 0.7616  loss_giou_0: 0.4828  loss_bbox_0: 0.4247  loss_rpn_cls: 0.3342  loss_rpn_reg: 0.5689  time: 0.1909  last_time: 0.1946  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:06:54] d2.utils.events INFO:  eta: 2:27:17  iter: 7239  total_loss: 4.346  loss_ce: 0.7227  loss_giou: 0.5228  loss_bbox: 0.4721  loss_ce_0: 0.7062  loss_giou_0: 0.5497  loss_bbox_0: 0.4939  loss_rpn_cls: 0.3571  loss_rpn_reg: 0.5802  time: 0.1909  last_time: 0.1793  data_time: 0.0051  last_data_time: 0.0075   lr: 5e-05  max_mem: 3029M
[03/05 12:06:58] d2.utils.events INFO:  eta: 2:27:18  iter: 7259  total_loss: 4.256  loss_ce: 0.7335  loss_giou: 0.4515  loss_bbox: 0.4121  loss_ce_0: 0.7379  loss_giou_0: 0.4647  loss_bbox_0: 0.4428  loss_rpn_cls: 0.3257  loss_rpn_reg: 0.5372  time: 0.1909  last_time: 0.1789  data_time: 0.0050  last_data_time: 0.0070   lr: 5e-05  max_mem: 3029M
[03/05 12:07:02] d2.utils.events INFO:  eta: 2:27:08  iter: 7279  total_loss: 4.151  loss_ce: 0.7039  loss_giou: 0.4548  loss_bbox: 0.5073  loss_ce_0: 0.7086  loss_giou_0: 0.4555  loss_bbox_0: 0.5376  loss_rpn_cls: 0.3246  loss_rpn_reg: 0.5643  time: 0.1908  last_time: 0.1825  data_time: 0.0057  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 12:07:06] d2.utils.events INFO:  eta: 2:26:56  iter: 7299  total_loss: 4.484  loss_ce: 0.7524  loss_giou: 0.4662  loss_bbox: 0.473  loss_ce_0: 0.748  loss_giou_0: 0.4801  loss_bbox_0: 0.4845  loss_rpn_cls: 0.3803  loss_rpn_reg: 0.5681  time: 0.1908  last_time: 0.1730  data_time: 0.0050  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:07:10] d2.utils.events INFO:  eta: 2:26:57  iter: 7319  total_loss: 4.347  loss_ce: 0.7492  loss_giou: 0.4177  loss_bbox: 0.4075  loss_ce_0: 0.7867  loss_giou_0: 0.428  loss_bbox_0: 0.4445  loss_rpn_cls: 0.3567  loss_rpn_reg: 0.5877  time: 0.1908  last_time: 0.2165  data_time: 0.0050  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:07:14] d2.utils.events INFO:  eta: 2:26:49  iter: 7339  total_loss: 4.505  loss_ce: 0.7643  loss_giou: 0.5115  loss_bbox: 0.5127  loss_ce_0: 0.7548  loss_giou_0: 0.5135  loss_bbox_0: 0.5858  loss_rpn_cls: 0.3222  loss_rpn_reg: 0.6253  time: 0.1908  last_time: 0.1763  data_time: 0.0051  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:07:17] d2.utils.events INFO:  eta: 2:26:37  iter: 7359  total_loss: 4.489  loss_ce: 0.797  loss_giou: 0.5142  loss_bbox: 0.4217  loss_ce_0: 0.8049  loss_giou_0: 0.5188  loss_bbox_0: 0.4249  loss_rpn_cls: 0.344  loss_rpn_reg: 0.5699  time: 0.1908  last_time: 0.1728  data_time: 0.0044  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:07:21] d2.utils.events INFO:  eta: 2:26:37  iter: 7379  total_loss: 3.864  loss_ce: 0.6616  loss_giou: 0.4415  loss_bbox: 0.3884  loss_ce_0: 0.6823  loss_giou_0: 0.4524  loss_bbox_0: 0.3704  loss_rpn_cls: 0.3212  loss_rpn_reg: 0.5761  time: 0.1908  last_time: 0.1810  data_time: 0.0050  last_data_time: 0.0064   lr: 5e-05  max_mem: 3029M
[03/05 12:07:25] d2.utils.events INFO:  eta: 2:26:20  iter: 7399  total_loss: 4.113  loss_ce: 0.7426  loss_giou: 0.4312  loss_bbox: 0.4444  loss_ce_0: 0.7553  loss_giou_0: 0.4598  loss_bbox_0: 0.473  loss_rpn_cls: 0.3044  loss_rpn_reg: 0.5553  time: 0.1908  last_time: 0.1910  data_time: 0.0052  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:07:29] d2.utils.events INFO:  eta: 2:26:20  iter: 7419  total_loss: 4.251  loss_ce: 0.6905  loss_giou: 0.4673  loss_bbox: 0.4763  loss_ce_0: 0.6884  loss_giou_0: 0.4801  loss_bbox_0: 0.4954  loss_rpn_cls: 0.337  loss_rpn_reg: 0.5928  time: 0.1908  last_time: 0.1778  data_time: 0.0053  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:07:33] d2.utils.events INFO:  eta: 2:26:16  iter: 7439  total_loss: 3.967  loss_ce: 0.653  loss_giou: 0.4645  loss_bbox: 0.3503  loss_ce_0: 0.6878  loss_giou_0: 0.4723  loss_bbox_0: 0.3648  loss_rpn_cls: 0.3352  loss_rpn_reg: 0.5334  time: 0.1908  last_time: 0.2064  data_time: 0.0054  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:07:36] d2.utils.events INFO:  eta: 2:26:16  iter: 7459  total_loss: 3.924  loss_ce: 0.6692  loss_giou: 0.421  loss_bbox: 0.4158  loss_ce_0: 0.6531  loss_giou_0: 0.4484  loss_bbox_0: 0.4579  loss_rpn_cls: 0.3366  loss_rpn_reg: 0.5427  time: 0.1908  last_time: 0.1777  data_time: 0.0053  last_data_time: 0.0032   lr: 5e-05  max_mem: 3029M
[03/05 12:07:40] d2.utils.events INFO:  eta: 2:26:12  iter: 7479  total_loss: 4.31  loss_ce: 0.7336  loss_giou: 0.4557  loss_bbox: 0.4499  loss_ce_0: 0.7596  loss_giou_0: 0.4637  loss_bbox_0: 0.4932  loss_rpn_cls: 0.3375  loss_rpn_reg: 0.5773  time: 0.1908  last_time: 0.1662  data_time: 0.0045  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:07:44] d2.utils.events INFO:  eta: 2:26:01  iter: 7499  total_loss: 4.016  loss_ce: 0.6803  loss_giou: 0.4741  loss_bbox: 0.361  loss_ce_0: 0.6919  loss_giou_0: 0.5012  loss_bbox_0: 0.4142  loss_rpn_cls: 0.3335  loss_rpn_reg: 0.5865  time: 0.1908  last_time: 0.1774  data_time: 0.0053  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:07:48] d2.utils.events INFO:  eta: 2:25:54  iter: 7519  total_loss: 4.113  loss_ce: 0.7579  loss_giou: 0.4141  loss_bbox: 0.4008  loss_ce_0: 0.6767  loss_giou_0: 0.4374  loss_bbox_0: 0.4339  loss_rpn_cls: 0.3311  loss_rpn_reg: 0.5817  time: 0.1908  last_time: 0.1961  data_time: 0.0045  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:07:52] d2.utils.events INFO:  eta: 2:26:01  iter: 7539  total_loss: 4.435  loss_ce: 0.7562  loss_giou: 0.4811  loss_bbox: 0.518  loss_ce_0: 0.69  loss_giou_0: 0.519  loss_bbox_0: 0.5368  loss_rpn_cls: 0.3568  loss_rpn_reg: 0.5805  time: 0.1908  last_time: 0.2078  data_time: 0.0049  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:07:56] d2.utils.events INFO:  eta: 2:26:03  iter: 7559  total_loss: 4.118  loss_ce: 0.7524  loss_giou: 0.4905  loss_bbox: 0.4067  loss_ce_0: 0.7503  loss_giou_0: 0.4826  loss_bbox_0: 0.4432  loss_rpn_cls: 0.3553  loss_rpn_reg: 0.5472  time: 0.1908  last_time: 0.1898  data_time: 0.0046  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:07:59] d2.utils.events INFO:  eta: 2:25:59  iter: 7579  total_loss: 4.32  loss_ce: 0.6815  loss_giou: 0.4557  loss_bbox: 0.4334  loss_ce_0: 0.6947  loss_giou_0: 0.4797  loss_bbox_0: 0.4895  loss_rpn_cls: 0.3306  loss_rpn_reg: 0.5556  time: 0.1908  last_time: 0.1887  data_time: 0.0046  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:08:03] d2.utils.events INFO:  eta: 2:25:54  iter: 7599  total_loss: 4.4  loss_ce: 0.7149  loss_giou: 0.5758  loss_bbox: 0.4535  loss_ce_0: 0.7445  loss_giou_0: 0.5442  loss_bbox_0: 0.5068  loss_rpn_cls: 0.3618  loss_rpn_reg: 0.589  time: 0.1907  last_time: 0.1854  data_time: 0.0047  last_data_time: 0.0080   lr: 5e-05  max_mem: 3029M
[03/05 12:08:07] d2.utils.events INFO:  eta: 2:25:43  iter: 7619  total_loss: 4.208  loss_ce: 0.7704  loss_giou: 0.4495  loss_bbox: 0.4291  loss_ce_0: 0.7216  loss_giou_0: 0.5115  loss_bbox_0: 0.5006  loss_rpn_cls: 0.3406  loss_rpn_reg: 0.6024  time: 0.1907  last_time: 0.1775  data_time: 0.0046  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 12:08:11] d2.utils.events INFO:  eta: 2:25:23  iter: 7639  total_loss: 4.43  loss_ce: 0.7528  loss_giou: 0.5223  loss_bbox: 0.4304  loss_ce_0: 0.7273  loss_giou_0: 0.4824  loss_bbox_0: 0.4315  loss_rpn_cls: 0.3613  loss_rpn_reg: 0.5842  time: 0.1907  last_time: 0.1856  data_time: 0.0051  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:08:14] d2.utils.events INFO:  eta: 2:25:22  iter: 7659  total_loss: 4.357  loss_ce: 0.7536  loss_giou: 0.4922  loss_bbox: 0.5046  loss_ce_0: 0.7018  loss_giou_0: 0.4855  loss_bbox_0: 0.511  loss_rpn_cls: 0.3634  loss_rpn_reg: 0.5341  time: 0.1907  last_time: 0.1921  data_time: 0.0052  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:08:18] d2.utils.events INFO:  eta: 2:25:18  iter: 7679  total_loss: 4.479  loss_ce: 0.7414  loss_giou: 0.4877  loss_bbox: 0.4729  loss_ce_0: 0.7483  loss_giou_0: 0.5001  loss_bbox_0: 0.5086  loss_rpn_cls: 0.373  loss_rpn_reg: 0.5733  time: 0.1907  last_time: 0.1705  data_time: 0.0045  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:08:22] d2.utils.events INFO:  eta: 2:25:11  iter: 7699  total_loss: 4.357  loss_ce: 0.7957  loss_giou: 0.4226  loss_bbox: 0.4849  loss_ce_0: 0.7771  loss_giou_0: 0.4502  loss_bbox_0: 0.5214  loss_rpn_cls: 0.3368  loss_rpn_reg: 0.5373  time: 0.1907  last_time: 0.1886  data_time: 0.0047  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 12:08:26] d2.utils.events INFO:  eta: 2:25:07  iter: 7719  total_loss: 4.331  loss_ce: 0.7273  loss_giou: 0.5351  loss_bbox: 0.423  loss_ce_0: 0.7399  loss_giou_0: 0.5713  loss_bbox_0: 0.4321  loss_rpn_cls: 0.3758  loss_rpn_reg: 0.5723  time: 0.1907  last_time: 0.1960  data_time: 0.0045  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:08:30] d2.utils.events INFO:  eta: 2:25:03  iter: 7739  total_loss: 4.495  loss_ce: 0.72  loss_giou: 0.4983  loss_bbox: 0.4688  loss_ce_0: 0.7318  loss_giou_0: 0.5156  loss_bbox_0: 0.5159  loss_rpn_cls: 0.3747  loss_rpn_reg: 0.5891  time: 0.1907  last_time: 0.1965  data_time: 0.0048  last_data_time: 0.0025   lr: 5e-05  max_mem: 3029M
[03/05 12:08:34] d2.utils.events INFO:  eta: 2:25:16  iter: 7759  total_loss: 4.41  loss_ce: 0.7143  loss_giou: 0.4858  loss_bbox: 0.4292  loss_ce_0: 0.7371  loss_giou_0: 0.5288  loss_bbox_0: 0.4683  loss_rpn_cls: 0.3521  loss_rpn_reg: 0.5811  time: 0.1907  last_time: 0.2171  data_time: 0.0049  last_data_time: 0.0020   lr: 5e-05  max_mem: 3029M
[03/05 12:08:38] d2.utils.events INFO:  eta: 2:25:18  iter: 7779  total_loss: 4.648  loss_ce: 0.7562  loss_giou: 0.5136  loss_bbox: 0.4736  loss_ce_0: 0.7915  loss_giou_0: 0.5021  loss_bbox_0: 0.5239  loss_rpn_cls: 0.3372  loss_rpn_reg: 0.6108  time: 0.1907  last_time: 0.1850  data_time: 0.0051  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:08:42] d2.utils.events INFO:  eta: 2:25:16  iter: 7799  total_loss: 4.12  loss_ce: 0.7697  loss_giou: 0.4442  loss_bbox: 0.4215  loss_ce_0: 0.7339  loss_giou_0: 0.4814  loss_bbox_0: 0.47  loss_rpn_cls: 0.3314  loss_rpn_reg: 0.545  time: 0.1907  last_time: 0.1717  data_time: 0.0047  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 12:08:45] d2.utils.events INFO:  eta: 2:25:10  iter: 7819  total_loss: 4.178  loss_ce: 0.6808  loss_giou: 0.4457  loss_bbox: 0.4147  loss_ce_0: 0.6699  loss_giou_0: 0.4355  loss_bbox_0: 0.4301  loss_rpn_cls: 0.3233  loss_rpn_reg: 0.5676  time: 0.1907  last_time: 0.1646  data_time: 0.0051  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:08:49] d2.utils.events INFO:  eta: 2:25:00  iter: 7839  total_loss: 3.895  loss_ce: 0.6733  loss_giou: 0.4337  loss_bbox: 0.3751  loss_ce_0: 0.6493  loss_giou_0: 0.4634  loss_bbox_0: 0.4291  loss_rpn_cls: 0.3329  loss_rpn_reg: 0.5636  time: 0.1907  last_time: 0.1832  data_time: 0.0051  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 12:08:53] d2.utils.events INFO:  eta: 2:24:41  iter: 7859  total_loss: 3.835  loss_ce: 0.6707  loss_giou: 0.4945  loss_bbox: 0.3464  loss_ce_0: 0.6723  loss_giou_0: 0.5102  loss_bbox_0: 0.4151  loss_rpn_cls: 0.3372  loss_rpn_reg: 0.5003  time: 0.1906  last_time: 0.1616  data_time: 0.0045  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:08:57] d2.utils.events INFO:  eta: 2:24:40  iter: 7879  total_loss: 4.651  loss_ce: 0.7277  loss_giou: 0.512  loss_bbox: 0.4767  loss_ce_0: 0.6995  loss_giou_0: 0.5424  loss_bbox_0: 0.5444  loss_rpn_cls: 0.3329  loss_rpn_reg: 0.5941  time: 0.1906  last_time: 0.1967  data_time: 0.0062  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:09:00] d2.utils.events INFO:  eta: 2:24:37  iter: 7899  total_loss: 4.308  loss_ce: 0.7243  loss_giou: 0.4878  loss_bbox: 0.3483  loss_ce_0: 0.7344  loss_giou_0: 0.4842  loss_bbox_0: 0.3942  loss_rpn_cls: 0.3524  loss_rpn_reg: 0.5887  time: 0.1906  last_time: 0.1711  data_time: 0.0047  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 12:09:04] d2.utils.events INFO:  eta: 2:24:48  iter: 7919  total_loss: 4.115  loss_ce: 0.7652  loss_giou: 0.415  loss_bbox: 0.4379  loss_ce_0: 0.845  loss_giou_0: 0.4315  loss_bbox_0: 0.428  loss_rpn_cls: 0.3253  loss_rpn_reg: 0.5205  time: 0.1906  last_time: 0.1874  data_time: 0.0047  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 12:09:08] d2.utils.events INFO:  eta: 2:24:44  iter: 7939  total_loss: 4.167  loss_ce: 0.7282  loss_giou: 0.443  loss_bbox: 0.4477  loss_ce_0: 0.74  loss_giou_0: 0.4755  loss_bbox_0: 0.5085  loss_rpn_cls: 0.3525  loss_rpn_reg: 0.5782  time: 0.1906  last_time: 0.1586  data_time: 0.0051  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:09:12] d2.utils.events INFO:  eta: 2:24:44  iter: 7959  total_loss: 4.363  loss_ce: 0.7335  loss_giou: 0.4595  loss_bbox: 0.4884  loss_ce_0: 0.7135  loss_giou_0: 0.4636  loss_bbox_0: 0.5666  loss_rpn_cls: 0.3579  loss_rpn_reg: 0.5791  time: 0.1906  last_time: 0.1747  data_time: 0.0044  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:09:16] d2.utils.events INFO:  eta: 2:24:51  iter: 7979  total_loss: 4.075  loss_ce: 0.7128  loss_giou: 0.3877  loss_bbox: 0.4019  loss_ce_0: 0.7423  loss_giou_0: 0.4197  loss_bbox_0: 0.4321  loss_rpn_cls: 0.3297  loss_rpn_reg: 0.5546  time: 0.1907  last_time: 0.2235  data_time: 0.0051  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:09:20] d2.utils.events INFO:  eta: 2:24:40  iter: 7999  total_loss: 4.138  loss_ce: 0.7427  loss_giou: 0.455  loss_bbox: 0.4325  loss_ce_0: 0.7241  loss_giou_0: 0.4338  loss_bbox_0: 0.4581  loss_rpn_cls: 0.3232  loss_rpn_reg: 0.5117  time: 0.1907  last_time: 0.1678  data_time: 0.0048  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:09:24] d2.utils.events INFO:  eta: 2:24:36  iter: 8019  total_loss: 3.964  loss_ce: 0.7114  loss_giou: 0.3983  loss_bbox: 0.4203  loss_ce_0: 0.7712  loss_giou_0: 0.4274  loss_bbox_0: 0.4314  loss_rpn_cls: 0.3178  loss_rpn_reg: 0.532  time: 0.1907  last_time: 0.1890  data_time: 0.0050  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:09:28] d2.utils.events INFO:  eta: 2:24:38  iter: 8039  total_loss: 4.074  loss_ce: 0.682  loss_giou: 0.4724  loss_bbox: 0.4176  loss_ce_0: 0.6801  loss_giou_0: 0.4603  loss_bbox_0: 0.4594  loss_rpn_cls: 0.3468  loss_rpn_reg: 0.5253  time: 0.1907  last_time: 0.1759  data_time: 0.0050  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:09:31] d2.utils.events INFO:  eta: 2:24:35  iter: 8059  total_loss: 4.663  loss_ce: 0.7297  loss_giou: 0.4895  loss_bbox: 0.4685  loss_ce_0: 0.7291  loss_giou_0: 0.4749  loss_bbox_0: 0.4976  loss_rpn_cls: 0.3599  loss_rpn_reg: 0.5796  time: 0.1906  last_time: 0.1945  data_time: 0.0045  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:09:35] d2.utils.events INFO:  eta: 2:24:22  iter: 8079  total_loss: 4.264  loss_ce: 0.6706  loss_giou: 0.4078  loss_bbox: 0.4804  loss_ce_0: 0.6843  loss_giou_0: 0.4409  loss_bbox_0: 0.5141  loss_rpn_cls: 0.3301  loss_rpn_reg: 0.5728  time: 0.1906  last_time: 0.2161  data_time: 0.0054  last_data_time: 0.0091   lr: 5e-05  max_mem: 3029M
[03/05 12:09:39] d2.utils.events INFO:  eta: 2:24:19  iter: 8099  total_loss: 4.43  loss_ce: 0.8046  loss_giou: 0.5037  loss_bbox: 0.4322  loss_ce_0: 0.7631  loss_giou_0: 0.532  loss_bbox_0: 0.5172  loss_rpn_cls: 0.3476  loss_rpn_reg: 0.5745  time: 0.1906  last_time: 0.1719  data_time: 0.0062  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:09:43] d2.utils.events INFO:  eta: 2:23:59  iter: 8119  total_loss: 4.196  loss_ce: 0.7242  loss_giou: 0.53  loss_bbox: 0.4098  loss_ce_0: 0.7076  loss_giou_0: 0.5006  loss_bbox_0: 0.4655  loss_rpn_cls: 0.3452  loss_rpn_reg: 0.572  time: 0.1906  last_time: 0.1751  data_time: 0.0050  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:09:47] d2.utils.events INFO:  eta: 2:23:48  iter: 8139  total_loss: 4.352  loss_ce: 0.6833  loss_giou: 0.5117  loss_bbox: 0.4459  loss_ce_0: 0.6843  loss_giou_0: 0.5488  loss_bbox_0: 0.4826  loss_rpn_cls: 0.3531  loss_rpn_reg: 0.5625  time: 0.1906  last_time: 0.2024  data_time: 0.0047  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 12:09:51] d2.utils.events INFO:  eta: 2:23:44  iter: 8159  total_loss: 4.3  loss_ce: 0.8677  loss_giou: 0.3851  loss_bbox: 0.451  loss_ce_0: 0.7491  loss_giou_0: 0.4486  loss_bbox_0: 0.5031  loss_rpn_cls: 0.3522  loss_rpn_reg: 0.5506  time: 0.1906  last_time: 0.1664  data_time: 0.0050  last_data_time: 0.0023   lr: 5e-05  max_mem: 3029M
[03/05 12:09:55] d2.utils.events INFO:  eta: 2:23:48  iter: 8179  total_loss: 4.018  loss_ce: 0.7368  loss_giou: 0.4544  loss_bbox: 0.3719  loss_ce_0: 0.7342  loss_giou_0: 0.4819  loss_bbox_0: 0.4289  loss_rpn_cls: 0.333  loss_rpn_reg: 0.5441  time: 0.1906  last_time: 0.2111  data_time: 0.0050  last_data_time: 0.0030   lr: 5e-05  max_mem: 3029M
[03/05 12:09:58] d2.utils.events INFO:  eta: 2:23:36  iter: 8199  total_loss: 4.072  loss_ce: 0.689  loss_giou: 0.4406  loss_bbox: 0.4369  loss_ce_0: 0.6794  loss_giou_0: 0.4555  loss_bbox_0: 0.4758  loss_rpn_cls: 0.3432  loss_rpn_reg: 0.5379  time: 0.1906  last_time: 0.1745  data_time: 0.0050  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:10:02] d2.utils.events INFO:  eta: 2:23:24  iter: 8219  total_loss: 3.97  loss_ce: 0.6936  loss_giou: 0.4175  loss_bbox: 0.3823  loss_ce_0: 0.7158  loss_giou_0: 0.403  loss_bbox_0: 0.3953  loss_rpn_cls: 0.3469  loss_rpn_reg: 0.5328  time: 0.1906  last_time: 0.1686  data_time: 0.0048  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:10:06] d2.utils.events INFO:  eta: 2:23:24  iter: 8239  total_loss: 4.124  loss_ce: 0.7729  loss_giou: 0.3724  loss_bbox: 0.4689  loss_ce_0: 0.7605  loss_giou_0: 0.3725  loss_bbox_0: 0.5084  loss_rpn_cls: 0.3495  loss_rpn_reg: 0.5153  time: 0.1906  last_time: 0.1912  data_time: 0.0052  last_data_time: 0.0092   lr: 5e-05  max_mem: 3029M
[03/05 12:10:10] d2.utils.events INFO:  eta: 2:23:39  iter: 8259  total_loss: 4.195  loss_ce: 0.697  loss_giou: 0.4707  loss_bbox: 0.4455  loss_ce_0: 0.7077  loss_giou_0: 0.4946  loss_bbox_0: 0.4463  loss_rpn_cls: 0.3426  loss_rpn_reg: 0.5439  time: 0.1906  last_time: 0.2139  data_time: 0.0048  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:10:14] d2.utils.events INFO:  eta: 2:23:48  iter: 8279  total_loss: 4.423  loss_ce: 0.7359  loss_giou: 0.444  loss_bbox: 0.4532  loss_ce_0: 0.706  loss_giou_0: 0.461  loss_bbox_0: 0.5194  loss_rpn_cls: 0.3357  loss_rpn_reg: 0.5453  time: 0.1906  last_time: 0.2192  data_time: 0.0054  last_data_time: 0.0026   lr: 5e-05  max_mem: 3029M
[03/05 12:10:18] d2.utils.events INFO:  eta: 2:23:44  iter: 8299  total_loss: 3.844  loss_ce: 0.6649  loss_giou: 0.4813  loss_bbox: 0.3271  loss_ce_0: 0.6411  loss_giou_0: 0.5053  loss_bbox_0: 0.347  loss_rpn_cls: 0.3435  loss_rpn_reg: 0.5381  time: 0.1906  last_time: 0.1739  data_time: 0.0047  last_data_time: 0.0028   lr: 5e-05  max_mem: 3029M
[03/05 12:10:22] d2.utils.events INFO:  eta: 2:23:44  iter: 8319  total_loss: 4.292  loss_ce: 0.6237  loss_giou: 0.4092  loss_bbox: 0.4261  loss_ce_0: 0.6491  loss_giou_0: 0.4209  loss_bbox_0: 0.4202  loss_rpn_cls: 0.3457  loss_rpn_reg: 0.5467  time: 0.1906  last_time: 0.2236  data_time: 0.0055  last_data_time: 0.0098   lr: 5e-05  max_mem: 3029M
[03/05 12:10:26] d2.utils.events INFO:  eta: 2:23:39  iter: 8339  total_loss: 4.174  loss_ce: 0.6406  loss_giou: 0.5135  loss_bbox: 0.4825  loss_ce_0: 0.623  loss_giou_0: 0.5438  loss_bbox_0: 0.5017  loss_rpn_cls: 0.3371  loss_rpn_reg: 0.5701  time: 0.1906  last_time: 0.1949  data_time: 0.0049  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:10:29] d2.utils.events INFO:  eta: 2:23:37  iter: 8359  total_loss: 4.423  loss_ce: 0.6878  loss_giou: 0.5221  loss_bbox: 0.5568  loss_ce_0: 0.7078  loss_giou_0: 0.5366  loss_bbox_0: 0.6223  loss_rpn_cls: 0.3323  loss_rpn_reg: 0.5386  time: 0.1906  last_time: 0.1885  data_time: 0.0049  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:10:33] d2.utils.events INFO:  eta: 2:23:28  iter: 8379  total_loss: 4.117  loss_ce: 0.6812  loss_giou: 0.4264  loss_bbox: 0.421  loss_ce_0: 0.6581  loss_giou_0: 0.4719  loss_bbox_0: 0.4689  loss_rpn_cls: 0.3514  loss_rpn_reg: 0.5214  time: 0.1906  last_time: 0.1830  data_time: 0.0049  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:10:37] d2.utils.events INFO:  eta: 2:23:24  iter: 8399  total_loss: 3.903  loss_ce: 0.6864  loss_giou: 0.4508  loss_bbox: 0.4143  loss_ce_0: 0.7337  loss_giou_0: 0.4588  loss_bbox_0: 0.458  loss_rpn_cls: 0.3062  loss_rpn_reg: 0.5218  time: 0.1906  last_time: 0.1873  data_time: 0.0047  last_data_time: 0.0064   lr: 5e-05  max_mem: 3029M
[03/05 12:10:41] d2.utils.events INFO:  eta: 2:23:20  iter: 8419  total_loss: 4.097  loss_ce: 0.6616  loss_giou: 0.5279  loss_bbox: 0.468  loss_ce_0: 0.6322  loss_giou_0: 0.5316  loss_bbox_0: 0.478  loss_rpn_cls: 0.3269  loss_rpn_reg: 0.5928  time: 0.1906  last_time: 0.1919  data_time: 0.0056  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:10:45] d2.utils.events INFO:  eta: 2:23:19  iter: 8439  total_loss: 4.292  loss_ce: 0.6928  loss_giou: 0.5084  loss_bbox: 0.4485  loss_ce_0: 0.7182  loss_giou_0: 0.5124  loss_bbox_0: 0.4747  loss_rpn_cls: 0.343  loss_rpn_reg: 0.5798  time: 0.1906  last_time: 0.1727  data_time: 0.0044  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:10:48] d2.utils.events INFO:  eta: 2:23:15  iter: 8459  total_loss: 4.233  loss_ce: 0.7482  loss_giou: 0.4451  loss_bbox: 0.4488  loss_ce_0: 0.7266  loss_giou_0: 0.4678  loss_bbox_0: 0.4741  loss_rpn_cls: 0.3192  loss_rpn_reg: 0.5567  time: 0.1906  last_time: 0.1664  data_time: 0.0051  last_data_time: 0.0032   lr: 5e-05  max_mem: 3029M
[03/05 12:10:52] d2.utils.events INFO:  eta: 2:23:11  iter: 8479  total_loss: 4.212  loss_ce: 0.6829  loss_giou: 0.4477  loss_bbox: 0.406  loss_ce_0: 0.7049  loss_giou_0: 0.4882  loss_bbox_0: 0.4009  loss_rpn_cls: 0.3354  loss_rpn_reg: 0.5206  time: 0.1906  last_time: 0.1798  data_time: 0.0051  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 12:10:56] d2.utils.events INFO:  eta: 2:23:03  iter: 8499  total_loss: 3.948  loss_ce: 0.7225  loss_giou: 0.429  loss_bbox: 0.3937  loss_ce_0: 0.704  loss_giou_0: 0.4811  loss_bbox_0: 0.4303  loss_rpn_cls: 0.3394  loss_rpn_reg: 0.5722  time: 0.1905  last_time: 0.1890  data_time: 0.0048  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:11:00] d2.utils.events INFO:  eta: 2:22:58  iter: 8519  total_loss: 4.263  loss_ce: 0.7276  loss_giou: 0.4463  loss_bbox: 0.418  loss_ce_0: 0.7297  loss_giou_0: 0.4777  loss_bbox_0: 0.476  loss_rpn_cls: 0.3407  loss_rpn_reg: 0.557  time: 0.1905  last_time: 0.1894  data_time: 0.0042  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:11:03] d2.utils.events INFO:  eta: 2:22:48  iter: 8539  total_loss: 4.161  loss_ce: 0.7437  loss_giou: 0.4497  loss_bbox: 0.4203  loss_ce_0: 0.7099  loss_giou_0: 0.4799  loss_bbox_0: 0.4125  loss_rpn_cls: 0.343  loss_rpn_reg: 0.5901  time: 0.1905  last_time: 0.1811  data_time: 0.0051  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:11:07] d2.utils.events INFO:  eta: 2:22:48  iter: 8559  total_loss: 4.276  loss_ce: 0.7206  loss_giou: 0.5031  loss_bbox: 0.395  loss_ce_0: 0.721  loss_giou_0: 0.5011  loss_bbox_0: 0.4317  loss_rpn_cls: 0.3401  loss_rpn_reg: 0.5548  time: 0.1905  last_time: 0.1965  data_time: 0.0049  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:11:11] d2.utils.events INFO:  eta: 2:22:44  iter: 8579  total_loss: 4.135  loss_ce: 0.6858  loss_giou: 0.4496  loss_bbox: 0.3752  loss_ce_0: 0.6958  loss_giou_0: 0.4264  loss_bbox_0: 0.412  loss_rpn_cls: 0.337  loss_rpn_reg: 0.5609  time: 0.1905  last_time: 0.1910  data_time: 0.0049  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 12:11:15] d2.utils.events INFO:  eta: 2:22:41  iter: 8599  total_loss: 4.272  loss_ce: 0.7405  loss_giou: 0.4588  loss_bbox: 0.4434  loss_ce_0: 0.7594  loss_giou_0: 0.4788  loss_bbox_0: 0.4683  loss_rpn_cls: 0.3521  loss_rpn_reg: 0.5655  time: 0.1905  last_time: 0.1870  data_time: 0.0046  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:11:19] d2.utils.events INFO:  eta: 2:22:48  iter: 8619  total_loss: 3.914  loss_ce: 0.7284  loss_giou: 0.3733  loss_bbox: 0.383  loss_ce_0: 0.6747  loss_giou_0: 0.4098  loss_bbox_0: 0.3875  loss_rpn_cls: 0.3373  loss_rpn_reg: 0.5318  time: 0.1905  last_time: 0.2092  data_time: 0.0049  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:11:23] d2.utils.events INFO:  eta: 2:22:41  iter: 8639  total_loss: 4.106  loss_ce: 0.7151  loss_giou: 0.5014  loss_bbox: 0.4325  loss_ce_0: 0.6877  loss_giou_0: 0.4784  loss_bbox_0: 0.4462  loss_rpn_cls: 0.3193  loss_rpn_reg: 0.5841  time: 0.1905  last_time: 0.2010  data_time: 0.0048  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:11:27] d2.utils.events INFO:  eta: 2:22:35  iter: 8659  total_loss: 4.043  loss_ce: 0.689  loss_giou: 0.3948  loss_bbox: 0.3926  loss_ce_0: 0.7064  loss_giou_0: 0.3993  loss_bbox_0: 0.443  loss_rpn_cls: 0.3195  loss_rpn_reg: 0.5616  time: 0.1905  last_time: 0.2078  data_time: 0.0049  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:11:31] d2.utils.events INFO:  eta: 2:22:32  iter: 8679  total_loss: 3.511  loss_ce: 0.6093  loss_giou: 0.3347  loss_bbox: 0.3506  loss_ce_0: 0.6052  loss_giou_0: 0.381  loss_bbox_0: 0.3664  loss_rpn_cls: 0.3097  loss_rpn_reg: 0.5226  time: 0.1905  last_time: 0.1862  data_time: 0.0050  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 12:11:34] d2.utils.events INFO:  eta: 2:22:34  iter: 8699  total_loss: 3.849  loss_ce: 0.6142  loss_giou: 0.4137  loss_bbox: 0.3868  loss_ce_0: 0.6553  loss_giou_0: 0.4288  loss_bbox_0: 0.383  loss_rpn_cls: 0.3014  loss_rpn_reg: 0.5461  time: 0.1905  last_time: 0.2044  data_time: 0.0046  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:11:38] d2.utils.events INFO:  eta: 2:22:32  iter: 8719  total_loss: 3.92  loss_ce: 0.6919  loss_giou: 0.4226  loss_bbox: 0.344  loss_ce_0: 0.6828  loss_giou_0: 0.4675  loss_bbox_0: 0.4432  loss_rpn_cls: 0.3291  loss_rpn_reg: 0.5543  time: 0.1905  last_time: 0.1796  data_time: 0.0051  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:11:42] d2.utils.events INFO:  eta: 2:22:22  iter: 8739  total_loss: 4.369  loss_ce: 0.7228  loss_giou: 0.4257  loss_bbox: 0.3691  loss_ce_0: 0.7263  loss_giou_0: 0.4558  loss_bbox_0: 0.4455  loss_rpn_cls: 0.3227  loss_rpn_reg: 0.5248  time: 0.1905  last_time: 0.1755  data_time: 0.0055  last_data_time: 0.0028   lr: 5e-05  max_mem: 3029M
[03/05 12:11:46] d2.utils.events INFO:  eta: 2:22:22  iter: 8759  total_loss: 4.207  loss_ce: 0.7276  loss_giou: 0.4847  loss_bbox: 0.4359  loss_ce_0: 0.6865  loss_giou_0: 0.4634  loss_bbox_0: 0.433  loss_rpn_cls: 0.3476  loss_rpn_reg: 0.5398  time: 0.1905  last_time: 0.2132  data_time: 0.0052  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:11:50] d2.utils.events INFO:  eta: 2:22:24  iter: 8779  total_loss: 3.922  loss_ce: 0.6825  loss_giou: 0.4047  loss_bbox: 0.4114  loss_ce_0: 0.673  loss_giou_0: 0.468  loss_bbox_0: 0.4372  loss_rpn_cls: 0.3294  loss_rpn_reg: 0.562  time: 0.1905  last_time: 0.1983  data_time: 0.0049  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:11:54] d2.utils.events INFO:  eta: 2:22:23  iter: 8799  total_loss: 3.875  loss_ce: 0.6327  loss_giou: 0.4654  loss_bbox: 0.4122  loss_ce_0: 0.6308  loss_giou_0: 0.4792  loss_bbox_0: 0.4603  loss_rpn_cls: 0.3246  loss_rpn_reg: 0.5969  time: 0.1905  last_time: 0.2065  data_time: 0.0055  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 12:11:58] d2.utils.events INFO:  eta: 2:22:23  iter: 8819  total_loss: 3.882  loss_ce: 0.6247  loss_giou: 0.434  loss_bbox: 0.3954  loss_ce_0: 0.6569  loss_giou_0: 0.427  loss_bbox_0: 0.44  loss_rpn_cls: 0.3131  loss_rpn_reg: 0.5395  time: 0.1905  last_time: 0.2002  data_time: 0.0053  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:12:02] d2.utils.events INFO:  eta: 2:22:23  iter: 8839  total_loss: 4.133  loss_ce: 0.6758  loss_giou: 0.4337  loss_bbox: 0.3825  loss_ce_0: 0.6809  loss_giou_0: 0.4977  loss_bbox_0: 0.4064  loss_rpn_cls: 0.3479  loss_rpn_reg: 0.5462  time: 0.1905  last_time: 0.1948  data_time: 0.0053  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 12:12:06] d2.utils.events INFO:  eta: 2:22:21  iter: 8859  total_loss: 3.804  loss_ce: 0.6384  loss_giou: 0.4549  loss_bbox: 0.398  loss_ce_0: 0.6493  loss_giou_0: 0.4815  loss_bbox_0: 0.4207  loss_rpn_cls: 0.3133  loss_rpn_reg: 0.5493  time: 0.1905  last_time: 0.2034  data_time: 0.0056  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:12:09] d2.utils.events INFO:  eta: 2:22:21  iter: 8879  total_loss: 4.296  loss_ce: 0.7159  loss_giou: 0.4692  loss_bbox: 0.4051  loss_ce_0: 0.7344  loss_giou_0: 0.4796  loss_bbox_0: 0.4747  loss_rpn_cls: 0.3198  loss_rpn_reg: 0.5473  time: 0.1905  last_time: 0.1894  data_time: 0.0044  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:12:13] d2.utils.events INFO:  eta: 2:22:25  iter: 8899  total_loss: 4.163  loss_ce: 0.694  loss_giou: 0.4514  loss_bbox: 0.4278  loss_ce_0: 0.7161  loss_giou_0: 0.496  loss_bbox_0: 0.4484  loss_rpn_cls: 0.3158  loss_rpn_reg: 0.5369  time: 0.1905  last_time: 0.1626  data_time: 0.0062  last_data_time: 0.0073   lr: 5e-05  max_mem: 3029M
[03/05 12:12:17] d2.utils.events INFO:  eta: 2:22:09  iter: 8919  total_loss: 3.772  loss_ce: 0.6722  loss_giou: 0.4367  loss_bbox: 0.4206  loss_ce_0: 0.6623  loss_giou_0: 0.4455  loss_bbox_0: 0.4408  loss_rpn_cls: 0.2807  loss_rpn_reg: 0.5286  time: 0.1905  last_time: 0.1890  data_time: 0.0048  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:12:21] d2.utils.events INFO:  eta: 2:22:03  iter: 8939  total_loss: 4.063  loss_ce: 0.6595  loss_giou: 0.423  loss_bbox: 0.3879  loss_ce_0: 0.6916  loss_giou_0: 0.4376  loss_bbox_0: 0.4453  loss_rpn_cls: 0.3209  loss_rpn_reg: 0.5611  time: 0.1905  last_time: 0.1806  data_time: 0.0045  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:12:25] d2.utils.events INFO:  eta: 2:22:00  iter: 8959  total_loss: 3.547  loss_ce: 0.625  loss_giou: 0.4207  loss_bbox: 0.3088  loss_ce_0: 0.5891  loss_giou_0: 0.4352  loss_bbox_0: 0.3832  loss_rpn_cls: 0.2743  loss_rpn_reg: 0.5094  time: 0.1905  last_time: 0.1877  data_time: 0.0052  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:12:29] d2.utils.events INFO:  eta: 2:21:51  iter: 8979  total_loss: 3.829  loss_ce: 0.6318  loss_giou: 0.4257  loss_bbox: 0.409  loss_ce_0: 0.6795  loss_giou_0: 0.4573  loss_bbox_0: 0.4448  loss_rpn_cls: 0.2926  loss_rpn_reg: 0.5577  time: 0.1905  last_time: 0.1933  data_time: 0.0053  last_data_time: 0.0162   lr: 5e-05  max_mem: 3029M
[03/05 12:12:33] d2.utils.events INFO:  eta: 2:21:45  iter: 8999  total_loss: 3.91  loss_ce: 0.663  loss_giou: 0.4393  loss_bbox: 0.3551  loss_ce_0: 0.669  loss_giou_0: 0.4822  loss_bbox_0: 0.403  loss_rpn_cls: 0.3014  loss_rpn_reg: 0.5538  time: 0.1905  last_time: 0.2077  data_time: 0.0046  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:12:36] d2.utils.events INFO:  eta: 2:21:42  iter: 9019  total_loss: 4.314  loss_ce: 0.6986  loss_giou: 0.5011  loss_bbox: 0.483  loss_ce_0: 0.7096  loss_giou_0: 0.4997  loss_bbox_0: 0.5065  loss_rpn_cls: 0.3127  loss_rpn_reg: 0.5879  time: 0.1905  last_time: 0.1814  data_time: 0.0046  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:12:40] d2.utils.events INFO:  eta: 2:21:39  iter: 9039  total_loss: 4.036  loss_ce: 0.6421  loss_giou: 0.3701  loss_bbox: 0.4159  loss_ce_0: 0.6539  loss_giou_0: 0.4193  loss_bbox_0: 0.4979  loss_rpn_cls: 0.3144  loss_rpn_reg: 0.5129  time: 0.1905  last_time: 0.1663  data_time: 0.0046  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:12:44] d2.utils.events INFO:  eta: 2:21:34  iter: 9059  total_loss: 4.069  loss_ce: 0.6922  loss_giou: 0.4278  loss_bbox: 0.4125  loss_ce_0: 0.7581  loss_giou_0: 0.4445  loss_bbox_0: 0.4238  loss_rpn_cls: 0.3566  loss_rpn_reg: 0.6043  time: 0.1905  last_time: 0.2030  data_time: 0.0046  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:12:48] d2.utils.events INFO:  eta: 2:21:34  iter: 9079  total_loss: 3.9  loss_ce: 0.6515  loss_giou: 0.4972  loss_bbox: 0.3693  loss_ce_0: 0.6984  loss_giou_0: 0.5167  loss_bbox_0: 0.4075  loss_rpn_cls: 0.3154  loss_rpn_reg: 0.555  time: 0.1905  last_time: 0.1710  data_time: 0.0048  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:12:52] d2.utils.events INFO:  eta: 2:21:25  iter: 9099  total_loss: 4.409  loss_ce: 0.725  loss_giou: 0.4632  loss_bbox: 0.4469  loss_ce_0: 0.7717  loss_giou_0: 0.4968  loss_bbox_0: 0.5015  loss_rpn_cls: 0.3438  loss_rpn_reg: 0.5708  time: 0.1905  last_time: 0.1864  data_time: 0.0054  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:12:55] d2.utils.events INFO:  eta: 2:21:21  iter: 9119  total_loss: 4.118  loss_ce: 0.7324  loss_giou: 0.4373  loss_bbox: 0.4714  loss_ce_0: 0.7216  loss_giou_0: 0.4698  loss_bbox_0: 0.4957  loss_rpn_cls: 0.3358  loss_rpn_reg: 0.5704  time: 0.1905  last_time: 0.1984  data_time: 0.0048  last_data_time: 0.0032   lr: 5e-05  max_mem: 3029M
[03/05 12:12:59] d2.utils.events INFO:  eta: 2:21:10  iter: 9139  total_loss: 4.134  loss_ce: 0.641  loss_giou: 0.4482  loss_bbox: 0.5041  loss_ce_0: 0.6715  loss_giou_0: 0.4575  loss_bbox_0: 0.4937  loss_rpn_cls: 0.3097  loss_rpn_reg: 0.5433  time: 0.1905  last_time: 0.2001  data_time: 0.0044  last_data_time: 0.0032   lr: 5e-05  max_mem: 3029M
[03/05 12:13:03] d2.utils.events INFO:  eta: 2:21:05  iter: 9159  total_loss: 4.123  loss_ce: 0.7105  loss_giou: 0.4741  loss_bbox: 0.4949  loss_ce_0: 0.7356  loss_giou_0: 0.4977  loss_bbox_0: 0.4846  loss_rpn_cls: 0.3105  loss_rpn_reg: 0.5555  time: 0.1905  last_time: 0.1931  data_time: 0.0052  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:13:07] d2.utils.events INFO:  eta: 2:21:00  iter: 9179  total_loss: 3.941  loss_ce: 0.6572  loss_giou: 0.405  loss_bbox: 0.3741  loss_ce_0: 0.6981  loss_giou_0: 0.4666  loss_bbox_0: 0.4127  loss_rpn_cls: 0.317  loss_rpn_reg: 0.537  time: 0.1905  last_time: 0.1638  data_time: 0.0057  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:13:11] d2.utils.events INFO:  eta: 2:20:55  iter: 9199  total_loss: 3.971  loss_ce: 0.689  loss_giou: 0.4475  loss_bbox: 0.3795  loss_ce_0: 0.7001  loss_giou_0: 0.4571  loss_bbox_0: 0.4248  loss_rpn_cls: 0.3184  loss_rpn_reg: 0.5626  time: 0.1905  last_time: 0.1802  data_time: 0.0047  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:13:14] d2.utils.events INFO:  eta: 2:20:53  iter: 9219  total_loss: 4.196  loss_ce: 0.7052  loss_giou: 0.406  loss_bbox: 0.4222  loss_ce_0: 0.73  loss_giou_0: 0.4655  loss_bbox_0: 0.4739  loss_rpn_cls: 0.3261  loss_rpn_reg: 0.5525  time: 0.1904  last_time: 0.2002  data_time: 0.0049  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:13:18] d2.utils.events INFO:  eta: 2:20:49  iter: 9239  total_loss: 4.123  loss_ce: 0.6806  loss_giou: 0.4295  loss_bbox: 0.471  loss_ce_0: 0.7015  loss_giou_0: 0.4393  loss_bbox_0: 0.491  loss_rpn_cls: 0.3148  loss_rpn_reg: 0.5285  time: 0.1904  last_time: 0.1783  data_time: 0.0048  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 12:13:22] d2.utils.events INFO:  eta: 2:20:32  iter: 9259  total_loss: 4.17  loss_ce: 0.7126  loss_giou: 0.4219  loss_bbox: 0.4568  loss_ce_0: 0.72  loss_giou_0: 0.4497  loss_bbox_0: 0.5044  loss_rpn_cls: 0.3053  loss_rpn_reg: 0.5626  time: 0.1904  last_time: 0.2018  data_time: 0.0046  last_data_time: 0.0069   lr: 5e-05  max_mem: 3029M
[03/05 12:13:25] d2.utils.events INFO:  eta: 2:20:23  iter: 9279  total_loss: 4.149  loss_ce: 0.682  loss_giou: 0.4509  loss_bbox: 0.4178  loss_ce_0: 0.6774  loss_giou_0: 0.4672  loss_bbox_0: 0.4479  loss_rpn_cls: 0.3317  loss_rpn_reg: 0.5542  time: 0.1904  last_time: 0.1838  data_time: 0.0048  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 12:13:29] d2.utils.events INFO:  eta: 2:20:22  iter: 9299  total_loss: 4.266  loss_ce: 0.7513  loss_giou: 0.4926  loss_bbox: 0.466  loss_ce_0: 0.7311  loss_giou_0: 0.5136  loss_bbox_0: 0.4408  loss_rpn_cls: 0.3425  loss_rpn_reg: 0.5626  time: 0.1904  last_time: 0.2038  data_time: 0.0053  last_data_time: 0.0025   lr: 5e-05  max_mem: 3029M
[03/05 12:13:33] d2.utils.events INFO:  eta: 2:20:13  iter: 9319  total_loss: 4.252  loss_ce: 0.7025  loss_giou: 0.4294  loss_bbox: 0.4472  loss_ce_0: 0.6907  loss_giou_0: 0.455  loss_bbox_0: 0.461  loss_rpn_cls: 0.3251  loss_rpn_reg: 0.5803  time: 0.1904  last_time: 0.1991  data_time: 0.0050  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:13:37] d2.utils.events INFO:  eta: 2:20:12  iter: 9339  total_loss: 4.138  loss_ce: 0.7063  loss_giou: 0.4441  loss_bbox: 0.4036  loss_ce_0: 0.749  loss_giou_0: 0.47  loss_bbox_0: 0.4224  loss_rpn_cls: 0.3439  loss_rpn_reg: 0.5573  time: 0.1904  last_time: 0.2030  data_time: 0.0047  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:13:41] d2.utils.events INFO:  eta: 2:20:10  iter: 9359  total_loss: 4.086  loss_ce: 0.6861  loss_giou: 0.4582  loss_bbox: 0.3649  loss_ce_0: 0.6979  loss_giou_0: 0.5103  loss_bbox_0: 0.4082  loss_rpn_cls: 0.3267  loss_rpn_reg: 0.5833  time: 0.1904  last_time: 0.2083  data_time: 0.0051  last_data_time: 0.0029   lr: 5e-05  max_mem: 3029M
[03/05 12:13:44] d2.utils.events INFO:  eta: 2:20:08  iter: 9379  total_loss: 4.072  loss_ce: 0.66  loss_giou: 0.4536  loss_bbox: 0.3822  loss_ce_0: 0.6991  loss_giou_0: 0.4558  loss_bbox_0: 0.445  loss_rpn_cls: 0.3444  loss_rpn_reg: 0.5196  time: 0.1904  last_time: 0.2002  data_time: 0.0042  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:13:48] d2.utils.events INFO:  eta: 2:20:03  iter: 9399  total_loss: 3.833  loss_ce: 0.6952  loss_giou: 0.3941  loss_bbox: 0.4067  loss_ce_0: 0.6781  loss_giou_0: 0.4338  loss_bbox_0: 0.4429  loss_rpn_cls: 0.3107  loss_rpn_reg: 0.515  time: 0.1904  last_time: 0.1867  data_time: 0.0047  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:13:52] d2.utils.events INFO:  eta: 2:19:57  iter: 9419  total_loss: 4.379  loss_ce: 0.763  loss_giou: 0.4766  loss_bbox: 0.5249  loss_ce_0: 0.7425  loss_giou_0: 0.4655  loss_bbox_0: 0.5571  loss_rpn_cls: 0.3199  loss_rpn_reg: 0.5563  time: 0.1904  last_time: 0.1778  data_time: 0.0046  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:13:56] d2.utils.events INFO:  eta: 2:19:53  iter: 9439  total_loss: 3.867  loss_ce: 0.7074  loss_giou: 0.4011  loss_bbox: 0.4442  loss_ce_0: 0.6837  loss_giou_0: 0.4162  loss_bbox_0: 0.4551  loss_rpn_cls: 0.3076  loss_rpn_reg: 0.5374  time: 0.1904  last_time: 0.1946  data_time: 0.0042  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:14:00] d2.utils.events INFO:  eta: 2:19:47  iter: 9459  total_loss: 3.806  loss_ce: 0.5994  loss_giou: 0.4221  loss_bbox: 0.3598  loss_ce_0: 0.6149  loss_giou_0: 0.4537  loss_bbox_0: 0.3802  loss_rpn_cls: 0.321  loss_rpn_reg: 0.4991  time: 0.1903  last_time: 0.1951  data_time: 0.0048  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:14:03] d2.utils.events INFO:  eta: 2:19:44  iter: 9479  total_loss: 4.061  loss_ce: 0.6811  loss_giou: 0.4288  loss_bbox: 0.3265  loss_ce_0: 0.7  loss_giou_0: 0.429  loss_bbox_0: 0.37  loss_rpn_cls: 0.3217  loss_rpn_reg: 0.5471  time: 0.1903  last_time: 0.1946  data_time: 0.0046  last_data_time: 0.0027   lr: 5e-05  max_mem: 3029M
[03/05 12:14:07] d2.utils.events INFO:  eta: 2:19:45  iter: 9499  total_loss: 3.996  loss_ce: 0.7097  loss_giou: 0.3862  loss_bbox: 0.4003  loss_ce_0: 0.7065  loss_giou_0: 0.4088  loss_bbox_0: 0.4555  loss_rpn_cls: 0.3528  loss_rpn_reg: 0.5493  time: 0.1903  last_time: 0.1943  data_time: 0.0047  last_data_time: 0.0022   lr: 5e-05  max_mem: 3029M
[03/05 12:14:11] d2.utils.events INFO:  eta: 2:19:54  iter: 9519  total_loss: 3.914  loss_ce: 0.6478  loss_giou: 0.4754  loss_bbox: 0.3811  loss_ce_0: 0.6582  loss_giou_0: 0.4611  loss_bbox_0: 0.4252  loss_rpn_cls: 0.3393  loss_rpn_reg: 0.5447  time: 0.1904  last_time: 0.1691  data_time: 0.0045  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:14:15] d2.utils.events INFO:  eta: 2:19:47  iter: 9539  total_loss: 4.041  loss_ce: 0.6692  loss_giou: 0.5204  loss_bbox: 0.4176  loss_ce_0: 0.6469  loss_giou_0: 0.5559  loss_bbox_0: 0.4338  loss_rpn_cls: 0.3591  loss_rpn_reg: 0.6092  time: 0.1903  last_time: 0.1797  data_time: 0.0047  last_data_time: 0.0024   lr: 5e-05  max_mem: 3029M
[03/05 12:14:19] d2.utils.events INFO:  eta: 2:19:34  iter: 9559  total_loss: 4.015  loss_ce: 0.6559  loss_giou: 0.4447  loss_bbox: 0.4261  loss_ce_0: 0.6529  loss_giou_0: 0.4656  loss_bbox_0: 0.465  loss_rpn_cls: 0.3247  loss_rpn_reg: 0.5735  time: 0.1903  last_time: 0.1732  data_time: 0.0044  last_data_time: 0.0030   lr: 5e-05  max_mem: 3029M
[03/05 12:14:22] d2.utils.events INFO:  eta: 2:19:25  iter: 9579  total_loss: 3.76  loss_ce: 0.6979  loss_giou: 0.4341  loss_bbox: 0.3683  loss_ce_0: 0.7171  loss_giou_0: 0.4527  loss_bbox_0: 0.3781  loss_rpn_cls: 0.3288  loss_rpn_reg: 0.548  time: 0.1903  last_time: 0.1830  data_time: 0.0049  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:14:26] d2.utils.events INFO:  eta: 2:19:21  iter: 9599  total_loss: 4.144  loss_ce: 0.6628  loss_giou: 0.4589  loss_bbox: 0.3813  loss_ce_0: 0.6926  loss_giou_0: 0.5116  loss_bbox_0: 0.4277  loss_rpn_cls: 0.3225  loss_rpn_reg: 0.5582  time: 0.1903  last_time: 0.1937  data_time: 0.0046  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 12:14:30] d2.utils.events INFO:  eta: 2:19:18  iter: 9619  total_loss: 4.283  loss_ce: 0.6895  loss_giou: 0.4799  loss_bbox: 0.4734  loss_ce_0: 0.666  loss_giou_0: 0.5058  loss_bbox_0: 0.4994  loss_rpn_cls: 0.3338  loss_rpn_reg: 0.5636  time: 0.1903  last_time: 0.1844  data_time: 0.0044  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:14:34] d2.utils.events INFO:  eta: 2:19:15  iter: 9639  total_loss: 3.915  loss_ce: 0.6736  loss_giou: 0.4431  loss_bbox: 0.365  loss_ce_0: 0.6272  loss_giou_0: 0.4465  loss_bbox_0: 0.3916  loss_rpn_cls: 0.3351  loss_rpn_reg: 0.5329  time: 0.1903  last_time: 0.1954  data_time: 0.0046  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:14:38] d2.utils.events INFO:  eta: 2:19:19  iter: 9659  total_loss: 3.793  loss_ce: 0.6408  loss_giou: 0.403  loss_bbox: 0.3684  loss_ce_0: 0.6372  loss_giou_0: 0.447  loss_bbox_0: 0.4514  loss_rpn_cls: 0.2996  loss_rpn_reg: 0.5285  time: 0.1903  last_time: 0.1702  data_time: 0.0051  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:14:42] d2.utils.events INFO:  eta: 2:19:06  iter: 9679  total_loss: 3.993  loss_ce: 0.6449  loss_giou: 0.444  loss_bbox: 0.4642  loss_ce_0: 0.6405  loss_giou_0: 0.475  loss_bbox_0: 0.4976  loss_rpn_cls: 0.3208  loss_rpn_reg: 0.5314  time: 0.1903  last_time: 0.1876  data_time: 0.0045  last_data_time: 0.0028   lr: 5e-05  max_mem: 3029M
[03/05 12:14:45] d2.utils.events INFO:  eta: 2:19:02  iter: 9699  total_loss: 3.856  loss_ce: 0.6639  loss_giou: 0.3982  loss_bbox: 0.404  loss_ce_0: 0.6652  loss_giou_0: 0.4246  loss_bbox_0: 0.4444  loss_rpn_cls: 0.3052  loss_rpn_reg: 0.5145  time: 0.1903  last_time: 0.1627  data_time: 0.0046  last_data_time: 0.0072   lr: 5e-05  max_mem: 3029M
[03/05 12:14:49] d2.utils.events INFO:  eta: 2:18:58  iter: 9719  total_loss: 4.134  loss_ce: 0.7382  loss_giou: 0.4328  loss_bbox: 0.4577  loss_ce_0: 0.7092  loss_giou_0: 0.4993  loss_bbox_0: 0.4889  loss_rpn_cls: 0.3655  loss_rpn_reg: 0.5673  time: 0.1903  last_time: 0.1826  data_time: 0.0044  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:14:53] d2.utils.events INFO:  eta: 2:18:52  iter: 9739  total_loss: 4.04  loss_ce: 0.648  loss_giou: 0.4657  loss_bbox: 0.3848  loss_ce_0: 0.6927  loss_giou_0: 0.4542  loss_bbox_0: 0.4026  loss_rpn_cls: 0.3379  loss_rpn_reg: 0.5665  time: 0.1903  last_time: 0.1938  data_time: 0.0045  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:14:57] d2.utils.events INFO:  eta: 2:18:37  iter: 9759  total_loss: 4.034  loss_ce: 0.7002  loss_giou: 0.3885  loss_bbox: 0.3826  loss_ce_0: 0.6581  loss_giou_0: 0.4186  loss_bbox_0: 0.424  loss_rpn_cls: 0.3071  loss_rpn_reg: 0.5463  time: 0.1903  last_time: 0.1588  data_time: 0.0050  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:15:00] d2.utils.events INFO:  eta: 2:18:19  iter: 9779  total_loss: 3.87  loss_ce: 0.6447  loss_giou: 0.4206  loss_bbox: 0.3945  loss_ce_0: 0.6319  loss_giou_0: 0.4389  loss_bbox_0: 0.4254  loss_rpn_cls: 0.3164  loss_rpn_reg: 0.5552  time: 0.1902  last_time: 0.1599  data_time: 0.0050  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 12:15:04] d2.utils.events INFO:  eta: 2:17:52  iter: 9799  total_loss: 4.358  loss_ce: 0.7237  loss_giou: 0.4924  loss_bbox: 0.3887  loss_ce_0: 0.7115  loss_giou_0: 0.4902  loss_bbox_0: 0.4078  loss_rpn_cls: 0.3471  loss_rpn_reg: 0.5894  time: 0.1902  last_time: 0.1607  data_time: 0.0047  last_data_time: 0.0027   lr: 5e-05  max_mem: 3029M
[03/05 12:15:08] d2.utils.events INFO:  eta: 2:17:41  iter: 9819  total_loss: 4.035  loss_ce: 0.6018  loss_giou: 0.4698  loss_bbox: 0.4366  loss_ce_0: 0.6253  loss_giou_0: 0.4844  loss_bbox_0: 0.447  loss_rpn_cls: 0.2947  loss_rpn_reg: 0.5646  time: 0.1902  last_time: 0.1860  data_time: 0.0049  last_data_time: 0.0099   lr: 5e-05  max_mem: 3029M
[03/05 12:15:11] d2.utils.events INFO:  eta: 2:17:33  iter: 9839  total_loss: 3.981  loss_ce: 0.6159  loss_giou: 0.4505  loss_bbox: 0.3727  loss_ce_0: 0.6299  loss_giou_0: 0.5072  loss_bbox_0: 0.4452  loss_rpn_cls: 0.3328  loss_rpn_reg: 0.5631  time: 0.1902  last_time: 0.1934  data_time: 0.0047  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:15:15] d2.utils.events INFO:  eta: 2:17:30  iter: 9859  total_loss: 4.149  loss_ce: 0.7025  loss_giou: 0.4229  loss_bbox: 0.4565  loss_ce_0: 0.6993  loss_giou_0: 0.4457  loss_bbox_0: 0.5003  loss_rpn_cls: 0.3204  loss_rpn_reg: 0.557  time: 0.1902  last_time: 0.1768  data_time: 0.0048  last_data_time: 0.0028   lr: 5e-05  max_mem: 3029M
[03/05 12:15:19] d2.utils.events INFO:  eta: 2:17:26  iter: 9879  total_loss: 4.244  loss_ce: 0.6464  loss_giou: 0.553  loss_bbox: 0.4229  loss_ce_0: 0.6636  loss_giou_0: 0.5608  loss_bbox_0: 0.4427  loss_rpn_cls: 0.3275  loss_rpn_reg: 0.5778  time: 0.1902  last_time: 0.2158  data_time: 0.0051  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:15:23] d2.utils.events INFO:  eta: 2:17:20  iter: 9899  total_loss: 3.769  loss_ce: 0.7041  loss_giou: 0.4199  loss_bbox: 0.397  loss_ce_0: 0.6823  loss_giou_0: 0.435  loss_bbox_0: 0.4337  loss_rpn_cls: 0.3034  loss_rpn_reg: 0.5192  time: 0.1902  last_time: 0.1913  data_time: 0.0052  last_data_time: 0.0116   lr: 5e-05  max_mem: 3029M
[03/05 12:15:27] d2.utils.events INFO:  eta: 2:17:20  iter: 9919  total_loss: 4.23  loss_ce: 0.6179  loss_giou: 0.4317  loss_bbox: 0.4297  loss_ce_0: 0.6415  loss_giou_0: 0.4402  loss_bbox_0: 0.46  loss_rpn_cls: 0.2858  loss_rpn_reg: 0.5557  time: 0.1902  last_time: 0.1808  data_time: 0.0043  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:15:31] d2.utils.events INFO:  eta: 2:17:20  iter: 9939  total_loss: 3.841  loss_ce: 0.664  loss_giou: 0.4033  loss_bbox: 0.3661  loss_ce_0: 0.6682  loss_giou_0: 0.4275  loss_bbox_0: 0.3781  loss_rpn_cls: 0.336  loss_rpn_reg: 0.5256  time: 0.1902  last_time: 0.2072  data_time: 0.0055  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 12:15:34] d2.utils.events INFO:  eta: 2:17:19  iter: 9959  total_loss: 3.969  loss_ce: 0.6682  loss_giou: 0.435  loss_bbox: 0.4332  loss_ce_0: 0.6666  loss_giou_0: 0.4588  loss_bbox_0: 0.4495  loss_rpn_cls: 0.3377  loss_rpn_reg: 0.5359  time: 0.1902  last_time: 0.1946  data_time: 0.0055  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:15:38] d2.utils.events INFO:  eta: 2:17:11  iter: 9979  total_loss: 4.046  loss_ce: 0.6118  loss_giou: 0.4379  loss_bbox: 0.4161  loss_ce_0: 0.6601  loss_giou_0: 0.4508  loss_bbox_0: 0.4501  loss_rpn_cls: 0.3216  loss_rpn_reg: 0.5569  time: 0.1902  last_time: 0.2003  data_time: 0.0045  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 12:15:42] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/t1/model_0009999.pth
[03/05 12:15:43] d2.utils.events INFO:  eta: 2:17:08  iter: 9999  total_loss: 4.037  loss_ce: 0.7024  loss_giou: 0.3948  loss_bbox: 0.3891  loss_ce_0: 0.6929  loss_giou_0: 0.4407  loss_bbox_0: 0.4333  loss_rpn_cls: 0.3394  loss_rpn_reg: 0.5687  time: 0.1902  last_time: 0.1980  data_time: 0.0054  last_data_time: 0.0101   lr: 5e-05  max_mem: 3029M
[03/05 12:15:47] d2.utils.events INFO:  eta: 2:17:08  iter: 10019  total_loss: 4.199  loss_ce: 0.7256  loss_giou: 0.4393  loss_bbox: 0.4168  loss_ce_0: 0.7461  loss_giou_0: 0.4629  loss_bbox_0: 0.4733  loss_rpn_cls: 0.315  loss_rpn_reg: 0.5591  time: 0.1902  last_time: 0.1910  data_time: 0.0053  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:15:51] d2.utils.events INFO:  eta: 2:16:58  iter: 10039  total_loss: 4.217  loss_ce: 0.621  loss_giou: 0.4611  loss_bbox: 0.3772  loss_ce_0: 0.6529  loss_giou_0: 0.4668  loss_bbox_0: 0.3921  loss_rpn_cls: 0.3191  loss_rpn_reg: 0.5839  time: 0.1902  last_time: 0.1898  data_time: 0.0045  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:15:55] d2.utils.events INFO:  eta: 2:16:57  iter: 10059  total_loss: 4.136  loss_ce: 0.7054  loss_giou: 0.4341  loss_bbox: 0.4236  loss_ce_0: 0.7042  loss_giou_0: 0.5212  loss_bbox_0: 0.5239  loss_rpn_cls: 0.3221  loss_rpn_reg: 0.5598  time: 0.1901  last_time: 0.1960  data_time: 0.0044  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:15:59] d2.utils.events INFO:  eta: 2:16:50  iter: 10079  total_loss: 3.947  loss_ce: 0.7574  loss_giou: 0.401  loss_bbox: 0.3966  loss_ce_0: 0.7166  loss_giou_0: 0.4561  loss_bbox_0: 0.4852  loss_rpn_cls: 0.3473  loss_rpn_reg: 0.5312  time: 0.1902  last_time: 0.1899  data_time: 0.0058  last_data_time: 0.0105   lr: 5e-05  max_mem: 3029M
[03/05 12:16:03] d2.utils.events INFO:  eta: 2:16:54  iter: 10099  total_loss: 3.858  loss_ce: 0.6679  loss_giou: 0.3876  loss_bbox: 0.3705  loss_ce_0: 0.6801  loss_giou_0: 0.4172  loss_bbox_0: 0.3921  loss_rpn_cls: 0.3238  loss_rpn_reg: 0.5236  time: 0.1902  last_time: 0.2065  data_time: 0.0059  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:16:06] d2.utils.events INFO:  eta: 2:16:55  iter: 10119  total_loss: 3.686  loss_ce: 0.5843  loss_giou: 0.4025  loss_bbox: 0.3504  loss_ce_0: 0.5742  loss_giou_0: 0.4078  loss_bbox_0: 0.3395  loss_rpn_cls: 0.2844  loss_rpn_reg: 0.5193  time: 0.1902  last_time: 0.1951  data_time: 0.0047  last_data_time: 0.0077   lr: 5e-05  max_mem: 3029M
[03/05 12:16:10] d2.utils.events INFO:  eta: 2:16:56  iter: 10139  total_loss: 3.885  loss_ce: 0.6012  loss_giou: 0.4812  loss_bbox: 0.4329  loss_ce_0: 0.6183  loss_giou_0: 0.4841  loss_bbox_0: 0.4385  loss_rpn_cls: 0.3074  loss_rpn_reg: 0.5098  time: 0.1902  last_time: 0.2015  data_time: 0.0047  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:16:14] d2.utils.events INFO:  eta: 2:16:44  iter: 10159  total_loss: 3.83  loss_ce: 0.5775  loss_giou: 0.4323  loss_bbox: 0.3516  loss_ce_0: 0.6132  loss_giou_0: 0.4738  loss_bbox_0: 0.3593  loss_rpn_cls: 0.3397  loss_rpn_reg: 0.5166  time: 0.1901  last_time: 0.1861  data_time: 0.0043  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:16:18] d2.utils.events INFO:  eta: 2:16:37  iter: 10179  total_loss: 3.925  loss_ce: 0.669  loss_giou: 0.4065  loss_bbox: 0.4573  loss_ce_0: 0.7321  loss_giou_0: 0.411  loss_bbox_0: 0.4487  loss_rpn_cls: 0.3149  loss_rpn_reg: 0.5567  time: 0.1901  last_time: 0.1978  data_time: 0.0055  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:16:22] d2.utils.events INFO:  eta: 2:16:36  iter: 10199  total_loss: 3.812  loss_ce: 0.6661  loss_giou: 0.3707  loss_bbox: 0.415  loss_ce_0: 0.6584  loss_giou_0: 0.3749  loss_bbox_0: 0.4364  loss_rpn_cls: 0.2985  loss_rpn_reg: 0.5188  time: 0.1901  last_time: 0.1742  data_time: 0.0042  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:16:26] d2.utils.events INFO:  eta: 2:16:42  iter: 10219  total_loss: 3.756  loss_ce: 0.5644  loss_giou: 0.4284  loss_bbox: 0.402  loss_ce_0: 0.5679  loss_giou_0: 0.4346  loss_bbox_0: 0.3965  loss_rpn_cls: 0.3075  loss_rpn_reg: 0.5214  time: 0.1901  last_time: 0.1950  data_time: 0.0048  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:16:29] d2.utils.events INFO:  eta: 2:16:33  iter: 10239  total_loss: 4.122  loss_ce: 0.6827  loss_giou: 0.443  loss_bbox: 0.4188  loss_ce_0: 0.6965  loss_giou_0: 0.4514  loss_bbox_0: 0.4687  loss_rpn_cls: 0.345  loss_rpn_reg: 0.5601  time: 0.1901  last_time: 0.1884  data_time: 0.0046  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 12:16:33] d2.utils.events INFO:  eta: 2:16:36  iter: 10259  total_loss: 3.667  loss_ce: 0.6071  loss_giou: 0.4025  loss_bbox: 0.3576  loss_ce_0: 0.576  loss_giou_0: 0.4208  loss_bbox_0: 0.3827  loss_rpn_cls: 0.3031  loss_rpn_reg: 0.5168  time: 0.1901  last_time: 0.1983  data_time: 0.0048  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:16:37] d2.utils.events INFO:  eta: 2:16:31  iter: 10279  total_loss: 3.934  loss_ce: 0.6211  loss_giou: 0.4298  loss_bbox: 0.3873  loss_ce_0: 0.6435  loss_giou_0: 0.4691  loss_bbox_0: 0.4102  loss_rpn_cls: 0.3009  loss_rpn_reg: 0.5209  time: 0.1901  last_time: 0.1833  data_time: 0.0047  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:16:41] d2.utils.events INFO:  eta: 2:16:20  iter: 10299  total_loss: 3.974  loss_ce: 0.6604  loss_giou: 0.4327  loss_bbox: 0.4346  loss_ce_0: 0.639  loss_giou_0: 0.4703  loss_bbox_0: 0.437  loss_rpn_cls: 0.3052  loss_rpn_reg: 0.5218  time: 0.1901  last_time: 0.1999  data_time: 0.0047  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:16:44] d2.utils.events INFO:  eta: 2:16:23  iter: 10319  total_loss: 3.971  loss_ce: 0.74  loss_giou: 0.3929  loss_bbox: 0.3912  loss_ce_0: 0.738  loss_giou_0: 0.423  loss_bbox_0: 0.4303  loss_rpn_cls: 0.3034  loss_rpn_reg: 0.5112  time: 0.1901  last_time: 0.2008  data_time: 0.0051  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:16:48] d2.utils.events INFO:  eta: 2:16:19  iter: 10339  total_loss: 3.957  loss_ce: 0.6821  loss_giou: 0.3646  loss_bbox: 0.3913  loss_ce_0: 0.7023  loss_giou_0: 0.4067  loss_bbox_0: 0.4159  loss_rpn_cls: 0.3111  loss_rpn_reg: 0.5021  time: 0.1901  last_time: 0.1887  data_time: 0.0046  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:16:52] d2.utils.events INFO:  eta: 2:16:16  iter: 10359  total_loss: 3.944  loss_ce: 0.6901  loss_giou: 0.3685  loss_bbox: 0.3813  loss_ce_0: 0.6694  loss_giou_0: 0.3973  loss_bbox_0: 0.4053  loss_rpn_cls: 0.3381  loss_rpn_reg: 0.5247  time: 0.1901  last_time: 0.1818  data_time: 0.0053  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:16:56] d2.utils.events INFO:  eta: 2:16:06  iter: 10379  total_loss: 3.807  loss_ce: 0.6026  loss_giou: 0.4301  loss_bbox: 0.3332  loss_ce_0: 0.5922  loss_giou_0: 0.465  loss_bbox_0: 0.3772  loss_rpn_cls: 0.3049  loss_rpn_reg: 0.5442  time: 0.1901  last_time: 0.1962  data_time: 0.0047  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:17:00] d2.utils.events INFO:  eta: 2:16:03  iter: 10399  total_loss: 4  loss_ce: 0.6828  loss_giou: 0.4469  loss_bbox: 0.3642  loss_ce_0: 0.6838  loss_giou_0: 0.4753  loss_bbox_0: 0.4203  loss_rpn_cls: 0.3251  loss_rpn_reg: 0.5278  time: 0.1901  last_time: 0.1769  data_time: 0.0059  last_data_time: 0.0032   lr: 5e-05  max_mem: 3029M
[03/05 12:17:03] d2.utils.events INFO:  eta: 2:15:57  iter: 10419  total_loss: 4.334  loss_ce: 0.6891  loss_giou: 0.4501  loss_bbox: 0.4724  loss_ce_0: 0.6694  loss_giou_0: 0.5024  loss_bbox_0: 0.5421  loss_rpn_cls: 0.3517  loss_rpn_reg: 0.5649  time: 0.1901  last_time: 0.1766  data_time: 0.0049  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:17:07] d2.utils.events INFO:  eta: 2:15:54  iter: 10439  total_loss: 4.001  loss_ce: 0.6117  loss_giou: 0.4309  loss_bbox: 0.4089  loss_ce_0: 0.6141  loss_giou_0: 0.4704  loss_bbox_0: 0.4381  loss_rpn_cls: 0.3368  loss_rpn_reg: 0.5464  time: 0.1901  last_time: 0.2006  data_time: 0.0052  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 12:17:11] d2.utils.events INFO:  eta: 2:15:51  iter: 10459  total_loss: 3.823  loss_ce: 0.6471  loss_giou: 0.427  loss_bbox: 0.3608  loss_ce_0: 0.6378  loss_giou_0: 0.458  loss_bbox_0: 0.4206  loss_rpn_cls: 0.3113  loss_rpn_reg: 0.5406  time: 0.1900  last_time: 0.1641  data_time: 0.0045  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:17:15] d2.utils.events INFO:  eta: 2:15:48  iter: 10479  total_loss: 3.837  loss_ce: 0.6208  loss_giou: 0.4063  loss_bbox: 0.4226  loss_ce_0: 0.6987  loss_giou_0: 0.4036  loss_bbox_0: 0.4339  loss_rpn_cls: 0.2922  loss_rpn_reg: 0.5178  time: 0.1901  last_time: 0.1912  data_time: 0.0053  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:17:19] d2.utils.events INFO:  eta: 2:15:35  iter: 10499  total_loss: 3.828  loss_ce: 0.5619  loss_giou: 0.4599  loss_bbox: 0.368  loss_ce_0: 0.5892  loss_giou_0: 0.4736  loss_bbox_0: 0.377  loss_rpn_cls: 0.312  loss_rpn_reg: 0.5285  time: 0.1901  last_time: 0.1794  data_time: 0.0044  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:17:23] d2.utils.events INFO:  eta: 2:15:27  iter: 10519  total_loss: 3.758  loss_ce: 0.6123  loss_giou: 0.4322  loss_bbox: 0.4107  loss_ce_0: 0.6351  loss_giou_0: 0.4395  loss_bbox_0: 0.4094  loss_rpn_cls: 0.3132  loss_rpn_reg: 0.5311  time: 0.1900  last_time: 0.1977  data_time: 0.0052  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:17:26] d2.utils.events INFO:  eta: 2:15:22  iter: 10539  total_loss: 4.144  loss_ce: 0.6531  loss_giou: 0.4567  loss_bbox: 0.413  loss_ce_0: 0.6554  loss_giou_0: 0.4846  loss_bbox_0: 0.4515  loss_rpn_cls: 0.3272  loss_rpn_reg: 0.5812  time: 0.1900  last_time: 0.1577  data_time: 0.0047  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:17:30] d2.utils.events INFO:  eta: 2:15:22  iter: 10559  total_loss: 4.338  loss_ce: 0.6259  loss_giou: 0.5005  loss_bbox: 0.5089  loss_ce_0: 0.6562  loss_giou_0: 0.5079  loss_bbox_0: 0.5273  loss_rpn_cls: 0.3223  loss_rpn_reg: 0.6056  time: 0.1900  last_time: 0.1785  data_time: 0.0049  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:17:34] d2.utils.events INFO:  eta: 2:15:20  iter: 10579  total_loss: 3.743  loss_ce: 0.6495  loss_giou: 0.4016  loss_bbox: 0.4351  loss_ce_0: 0.6822  loss_giou_0: 0.4159  loss_bbox_0: 0.4472  loss_rpn_cls: 0.2828  loss_rpn_reg: 0.4967  time: 0.1900  last_time: 0.1966  data_time: 0.0047  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:17:38] d2.utils.events INFO:  eta: 2:15:24  iter: 10599  total_loss: 3.731  loss_ce: 0.592  loss_giou: 0.4676  loss_bbox: 0.3752  loss_ce_0: 0.5776  loss_giou_0: 0.4876  loss_bbox_0: 0.3817  loss_rpn_cls: 0.3148  loss_rpn_reg: 0.5262  time: 0.1900  last_time: 0.2046  data_time: 0.0061  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:17:41] d2.utils.events INFO:  eta: 2:15:11  iter: 10619  total_loss: 3.699  loss_ce: 0.6017  loss_giou: 0.4423  loss_bbox: 0.4302  loss_ce_0: 0.6204  loss_giou_0: 0.4339  loss_bbox_0: 0.3664  loss_rpn_cls: 0.2967  loss_rpn_reg: 0.5051  time: 0.1900  last_time: 0.1858  data_time: 0.0048  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:17:45] d2.utils.events INFO:  eta: 2:15:01  iter: 10639  total_loss: 4.005  loss_ce: 0.6308  loss_giou: 0.4728  loss_bbox: 0.4216  loss_ce_0: 0.651  loss_giou_0: 0.4899  loss_bbox_0: 0.4376  loss_rpn_cls: 0.3348  loss_rpn_reg: 0.5165  time: 0.1900  last_time: 0.1825  data_time: 0.0048  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:17:49] d2.utils.events INFO:  eta: 2:14:50  iter: 10659  total_loss: 3.852  loss_ce: 0.6861  loss_giou: 0.4046  loss_bbox: 0.3708  loss_ce_0: 0.7048  loss_giou_0: 0.4441  loss_bbox_0: 0.4038  loss_rpn_cls: 0.3079  loss_rpn_reg: 0.5177  time: 0.1900  last_time: 0.1942  data_time: 0.0046  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:17:52] d2.utils.events INFO:  eta: 2:14:46  iter: 10679  total_loss: 3.894  loss_ce: 0.6434  loss_giou: 0.3966  loss_bbox: 0.4263  loss_ce_0: 0.6749  loss_giou_0: 0.4389  loss_bbox_0: 0.445  loss_rpn_cls: 0.2966  loss_rpn_reg: 0.5712  time: 0.1900  last_time: 0.1739  data_time: 0.0043  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:17:56] d2.utils.events INFO:  eta: 2:14:37  iter: 10699  total_loss: 3.819  loss_ce: 0.5938  loss_giou: 0.3897  loss_bbox: 0.4085  loss_ce_0: 0.5943  loss_giou_0: 0.4143  loss_bbox_0: 0.4042  loss_rpn_cls: 0.2897  loss_rpn_reg: 0.5367  time: 0.1899  last_time: 0.1849  data_time: 0.0049  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:18:00] d2.utils.events INFO:  eta: 2:14:33  iter: 10719  total_loss: 3.622  loss_ce: 0.6406  loss_giou: 0.406  loss_bbox: 0.3514  loss_ce_0: 0.686  loss_giou_0: 0.4022  loss_bbox_0: 0.3817  loss_rpn_cls: 0.3014  loss_rpn_reg: 0.5178  time: 0.1899  last_time: 0.2565  data_time: 0.0051  last_data_time: 0.0077   lr: 5e-05  max_mem: 3029M
[03/05 12:18:04] d2.utils.events INFO:  eta: 2:14:35  iter: 10739  total_loss: 3.852  loss_ce: 0.68  loss_giou: 0.3949  loss_bbox: 0.3622  loss_ce_0: 0.6679  loss_giou_0: 0.4262  loss_bbox_0: 0.4312  loss_rpn_cls: 0.3267  loss_rpn_reg: 0.5108  time: 0.1899  last_time: 0.1765  data_time: 0.0052  last_data_time: 0.0126   lr: 5e-05  max_mem: 3029M
[03/05 12:18:08] d2.utils.events INFO:  eta: 2:14:26  iter: 10759  total_loss: 3.737  loss_ce: 0.5796  loss_giou: 0.4534  loss_bbox: 0.3159  loss_ce_0: 0.593  loss_giou_0: 0.4844  loss_bbox_0: 0.3798  loss_rpn_cls: 0.2948  loss_rpn_reg: 0.549  time: 0.1899  last_time: 0.1992  data_time: 0.0044  last_data_time: 0.0032   lr: 5e-05  max_mem: 3029M
[03/05 12:18:11] d2.utils.events INFO:  eta: 2:14:26  iter: 10779  total_loss: 3.851  loss_ce: 0.576  loss_giou: 0.4624  loss_bbox: 0.3792  loss_ce_0: 0.5855  loss_giou_0: 0.4806  loss_bbox_0: 0.4179  loss_rpn_cls: 0.3092  loss_rpn_reg: 0.5557  time: 0.1899  last_time: 0.1873  data_time: 0.0053  last_data_time: 0.0073   lr: 5e-05  max_mem: 3029M
[03/05 12:18:15] d2.utils.events INFO:  eta: 2:14:26  iter: 10799  total_loss: 4.027  loss_ce: 0.6031  loss_giou: 0.4589  loss_bbox: 0.3984  loss_ce_0: 0.6537  loss_giou_0: 0.4727  loss_bbox_0: 0.4148  loss_rpn_cls: 0.3191  loss_rpn_reg: 0.5593  time: 0.1899  last_time: 0.1981  data_time: 0.0045  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:18:19] d2.utils.events INFO:  eta: 2:14:36  iter: 10819  total_loss: 4.19  loss_ce: 0.6521  loss_giou: 0.4636  loss_bbox: 0.3426  loss_ce_0: 0.674  loss_giou_0: 0.4832  loss_bbox_0: 0.3844  loss_rpn_cls: 0.3318  loss_rpn_reg: 0.5681  time: 0.1899  last_time: 0.2208  data_time: 0.0054  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:18:23] d2.utils.events INFO:  eta: 2:14:34  iter: 10839  total_loss: 3.58  loss_ce: 0.6839  loss_giou: 0.3989  loss_bbox: 0.3872  loss_ce_0: 0.7268  loss_giou_0: 0.4294  loss_bbox_0: 0.404  loss_rpn_cls: 0.2955  loss_rpn_reg: 0.5402  time: 0.1899  last_time: 0.1898  data_time: 0.0049  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:18:27] d2.utils.events INFO:  eta: 2:14:32  iter: 10859  total_loss: 4.202  loss_ce: 0.7426  loss_giou: 0.4788  loss_bbox: 0.401  loss_ce_0: 0.7345  loss_giou_0: 0.4949  loss_bbox_0: 0.463  loss_rpn_cls: 0.3386  loss_rpn_reg: 0.5562  time: 0.1899  last_time: 0.2006  data_time: 0.0050  last_data_time: 0.0074   lr: 5e-05  max_mem: 3029M
[03/05 12:18:31] d2.utils.events INFO:  eta: 2:14:27  iter: 10879  total_loss: 4.033  loss_ce: 0.6502  loss_giou: 0.4868  loss_bbox: 0.401  loss_ce_0: 0.6613  loss_giou_0: 0.5078  loss_bbox_0: 0.4442  loss_rpn_cls: 0.3413  loss_rpn_reg: 0.5562  time: 0.1899  last_time: 0.2010  data_time: 0.0044  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 12:18:34] d2.utils.events INFO:  eta: 2:14:22  iter: 10899  total_loss: 3.574  loss_ce: 0.6395  loss_giou: 0.3891  loss_bbox: 0.3383  loss_ce_0: 0.5962  loss_giou_0: 0.4179  loss_bbox_0: 0.3644  loss_rpn_cls: 0.3109  loss_rpn_reg: 0.539  time: 0.1899  last_time: 0.1847  data_time: 0.0042  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:18:38] d2.utils.events INFO:  eta: 2:14:18  iter: 10919  total_loss: 4.01  loss_ce: 0.7067  loss_giou: 0.4237  loss_bbox: 0.3841  loss_ce_0: 0.6976  loss_giou_0: 0.4439  loss_bbox_0: 0.4342  loss_rpn_cls: 0.318  loss_rpn_reg: 0.5376  time: 0.1899  last_time: 0.1950  data_time: 0.0049  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:18:42] d2.utils.events INFO:  eta: 2:14:06  iter: 10939  total_loss: 3.851  loss_ce: 0.6403  loss_giou: 0.419  loss_bbox: 0.3674  loss_ce_0: 0.6755  loss_giou_0: 0.4553  loss_bbox_0: 0.4321  loss_rpn_cls: 0.3165  loss_rpn_reg: 0.5292  time: 0.1899  last_time: 0.1937  data_time: 0.0045  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:18:46] d2.utils.events INFO:  eta: 2:13:54  iter: 10959  total_loss: 3.656  loss_ce: 0.5926  loss_giou: 0.3881  loss_bbox: 0.3423  loss_ce_0: 0.6117  loss_giou_0: 0.4295  loss_bbox_0: 0.3818  loss_rpn_cls: 0.3  loss_rpn_reg: 0.5321  time: 0.1899  last_time: 0.1960  data_time: 0.0049  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 12:18:49] d2.utils.events INFO:  eta: 2:13:46  iter: 10979  total_loss: 3.806  loss_ce: 0.5511  loss_giou: 0.4294  loss_bbox: 0.3717  loss_ce_0: 0.5849  loss_giou_0: 0.4348  loss_bbox_0: 0.3755  loss_rpn_cls: 0.3223  loss_rpn_reg: 0.5263  time: 0.1899  last_time: 0.1811  data_time: 0.0046  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:18:53] d2.utils.events INFO:  eta: 2:13:38  iter: 10999  total_loss: 3.501  loss_ce: 0.5933  loss_giou: 0.3726  loss_bbox: 0.3671  loss_ce_0: 0.585  loss_giou_0: 0.3945  loss_bbox_0: 0.4175  loss_rpn_cls: 0.268  loss_rpn_reg: 0.5458  time: 0.1898  last_time: 0.1921  data_time: 0.0055  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:18:57] d2.utils.events INFO:  eta: 2:13:33  iter: 11019  total_loss: 4.212  loss_ce: 0.7362  loss_giou: 0.4433  loss_bbox: 0.4833  loss_ce_0: 0.734  loss_giou_0: 0.4971  loss_bbox_0: 0.4795  loss_rpn_cls: 0.3365  loss_rpn_reg: 0.5764  time: 0.1898  last_time: 0.2010  data_time: 0.0058  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:19:01] d2.utils.events INFO:  eta: 2:13:34  iter: 11039  total_loss: 4.293  loss_ce: 0.7475  loss_giou: 0.4492  loss_bbox: 0.457  loss_ce_0: 0.7257  loss_giou_0: 0.4971  loss_bbox_0: 0.4774  loss_rpn_cls: 0.3374  loss_rpn_reg: 0.5527  time: 0.1898  last_time: 0.1896  data_time: 0.0053  last_data_time: 0.0078   lr: 5e-05  max_mem: 3029M
[03/05 12:19:05] d2.utils.events INFO:  eta: 2:13:33  iter: 11059  total_loss: 3.999  loss_ce: 0.6746  loss_giou: 0.4602  loss_bbox: 0.3947  loss_ce_0: 0.6768  loss_giou_0: 0.4457  loss_bbox_0: 0.3871  loss_rpn_cls: 0.3269  loss_rpn_reg: 0.508  time: 0.1898  last_time: 0.1932  data_time: 0.0045  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:19:08] d2.utils.events INFO:  eta: 2:13:29  iter: 11079  total_loss: 3.747  loss_ce: 0.6753  loss_giou: 0.3757  loss_bbox: 0.3624  loss_ce_0: 0.627  loss_giou_0: 0.3746  loss_bbox_0: 0.3744  loss_rpn_cls: 0.2985  loss_rpn_reg: 0.4881  time: 0.1898  last_time: 0.2002  data_time: 0.0048  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:19:12] d2.utils.events INFO:  eta: 2:13:25  iter: 11099  total_loss: 3.793  loss_ce: 0.6763  loss_giou: 0.4257  loss_bbox: 0.3925  loss_ce_0: 0.6862  loss_giou_0: 0.4544  loss_bbox_0: 0.4157  loss_rpn_cls: 0.3109  loss_rpn_reg: 0.5567  time: 0.1899  last_time: 0.1919  data_time: 0.0050  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:19:16] d2.utils.events INFO:  eta: 2:13:17  iter: 11119  total_loss: 3.877  loss_ce: 0.6619  loss_giou: 0.4488  loss_bbox: 0.3938  loss_ce_0: 0.6354  loss_giou_0: 0.4775  loss_bbox_0: 0.4344  loss_rpn_cls: 0.3168  loss_rpn_reg: 0.5371  time: 0.1899  last_time: 0.2177  data_time: 0.0048  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:19:20] d2.utils.events INFO:  eta: 2:13:08  iter: 11139  total_loss: 4.105  loss_ce: 0.6931  loss_giou: 0.4301  loss_bbox: 0.3929  loss_ce_0: 0.6798  loss_giou_0: 0.4497  loss_bbox_0: 0.4428  loss_rpn_cls: 0.3013  loss_rpn_reg: 0.5537  time: 0.1898  last_time: 0.2016  data_time: 0.0052  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:19:24] d2.utils.events INFO:  eta: 2:13:06  iter: 11159  total_loss: 3.829  loss_ce: 0.6618  loss_giou: 0.444  loss_bbox: 0.3806  loss_ce_0: 0.6639  loss_giou_0: 0.4663  loss_bbox_0: 0.3755  loss_rpn_cls: 0.3078  loss_rpn_reg: 0.5538  time: 0.1898  last_time: 0.1666  data_time: 0.0047  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:19:28] d2.utils.events INFO:  eta: 2:13:03  iter: 11179  total_loss: 3.353  loss_ce: 0.5451  loss_giou: 0.3702  loss_bbox: 0.3654  loss_ce_0: 0.585  loss_giou_0: 0.3744  loss_bbox_0: 0.3798  loss_rpn_cls: 0.2544  loss_rpn_reg: 0.5137  time: 0.1898  last_time: 0.1886  data_time: 0.0049  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:19:31] d2.utils.events INFO:  eta: 2:12:57  iter: 11199  total_loss: 3.668  loss_ce: 0.6521  loss_giou: 0.3999  loss_bbox: 0.3643  loss_ce_0: 0.6477  loss_giou_0: 0.4036  loss_bbox_0: 0.3831  loss_rpn_cls: 0.3115  loss_rpn_reg: 0.5129  time: 0.1898  last_time: 0.2010  data_time: 0.0045  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 12:19:35] d2.utils.events INFO:  eta: 2:12:43  iter: 11219  total_loss: 4.118  loss_ce: 0.6366  loss_giou: 0.4456  loss_bbox: 0.421  loss_ce_0: 0.6451  loss_giou_0: 0.4557  loss_bbox_0: 0.4228  loss_rpn_cls: 0.322  loss_rpn_reg: 0.5499  time: 0.1898  last_time: 0.1989  data_time: 0.0045  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:19:39] d2.utils.events INFO:  eta: 2:12:49  iter: 11239  total_loss: 4.214  loss_ce: 0.7156  loss_giou: 0.4239  loss_bbox: 0.39  loss_ce_0: 0.6734  loss_giou_0: 0.4306  loss_bbox_0: 0.4392  loss_rpn_cls: 0.3151  loss_rpn_reg: 0.5494  time: 0.1898  last_time: 0.1857  data_time: 0.0051  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:19:43] d2.utils.events INFO:  eta: 2:12:37  iter: 11259  total_loss: 3.962  loss_ce: 0.6898  loss_giou: 0.3774  loss_bbox: 0.4329  loss_ce_0: 0.7052  loss_giou_0: 0.3825  loss_bbox_0: 0.4535  loss_rpn_cls: 0.3379  loss_rpn_reg: 0.4944  time: 0.1898  last_time: 0.1890  data_time: 0.0045  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:19:47] d2.utils.events INFO:  eta: 2:12:46  iter: 11279  total_loss: 3.968  loss_ce: 0.6201  loss_giou: 0.4464  loss_bbox: 0.3866  loss_ce_0: 0.6098  loss_giou_0: 0.451  loss_bbox_0: 0.444  loss_rpn_cls: 0.2824  loss_rpn_reg: 0.5801  time: 0.1898  last_time: 0.1871  data_time: 0.0052  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:19:50] d2.utils.events INFO:  eta: 2:12:48  iter: 11299  total_loss: 3.908  loss_ce: 0.6726  loss_giou: 0.4595  loss_bbox: 0.4083  loss_ce_0: 0.6618  loss_giou_0: 0.4845  loss_bbox_0: 0.4836  loss_rpn_cls: 0.3211  loss_rpn_reg: 0.5512  time: 0.1898  last_time: 0.1801  data_time: 0.0046  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:19:54] d2.utils.events INFO:  eta: 2:12:37  iter: 11319  total_loss: 3.944  loss_ce: 0.7326  loss_giou: 0.3818  loss_bbox: 0.4035  loss_ce_0: 0.7498  loss_giou_0: 0.4013  loss_bbox_0: 0.4413  loss_rpn_cls: 0.3185  loss_rpn_reg: 0.5396  time: 0.1898  last_time: 0.1683  data_time: 0.0046  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:19:58] d2.utils.events INFO:  eta: 2:12:31  iter: 11339  total_loss: 4.018  loss_ce: 0.7149  loss_giou: 0.3991  loss_bbox: 0.4071  loss_ce_0: 0.7693  loss_giou_0: 0.423  loss_bbox_0: 0.5018  loss_rpn_cls: 0.3157  loss_rpn_reg: 0.5808  time: 0.1898  last_time: 0.1694  data_time: 0.0052  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:20:02] d2.utils.events INFO:  eta: 2:12:26  iter: 11359  total_loss: 3.899  loss_ce: 0.648  loss_giou: 0.428  loss_bbox: 0.4196  loss_ce_0: 0.7116  loss_giou_0: 0.4406  loss_bbox_0: 0.4007  loss_rpn_cls: 0.327  loss_rpn_reg: 0.5128  time: 0.1898  last_time: 0.1913  data_time: 0.0049  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:20:05] d2.utils.events INFO:  eta: 2:12:23  iter: 11379  total_loss: 3.757  loss_ce: 0.6789  loss_giou: 0.3721  loss_bbox: 0.3666  loss_ce_0: 0.6606  loss_giou_0: 0.3913  loss_bbox_0: 0.4081  loss_rpn_cls: 0.2927  loss_rpn_reg: 0.5061  time: 0.1898  last_time: 0.2010  data_time: 0.0045  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:20:09] d2.utils.events INFO:  eta: 2:12:19  iter: 11399  total_loss: 4.518  loss_ce: 0.7099  loss_giou: 0.47  loss_bbox: 0.4508  loss_ce_0: 0.703  loss_giou_0: 0.4828  loss_bbox_0: 0.5077  loss_rpn_cls: 0.3441  loss_rpn_reg: 0.5421  time: 0.1898  last_time: 0.1778  data_time: 0.0054  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:20:13] d2.utils.events INFO:  eta: 2:12:19  iter: 11419  total_loss: 4.082  loss_ce: 0.7318  loss_giou: 0.4184  loss_bbox: 0.3467  loss_ce_0: 0.7347  loss_giou_0: 0.4551  loss_bbox_0: 0.3929  loss_rpn_cls: 0.3369  loss_rpn_reg: 0.5534  time: 0.1898  last_time: 0.2040  data_time: 0.0049  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:20:17] d2.utils.events INFO:  eta: 2:12:03  iter: 11439  total_loss: 3.966  loss_ce: 0.6659  loss_giou: 0.4281  loss_bbox: 0.357  loss_ce_0: 0.7235  loss_giou_0: 0.4483  loss_bbox_0: 0.3781  loss_rpn_cls: 0.3449  loss_rpn_reg: 0.5417  time: 0.1898  last_time: 0.1854  data_time: 0.0049  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:20:21] d2.utils.events INFO:  eta: 2:12:01  iter: 11459  total_loss: 3.727  loss_ce: 0.6171  loss_giou: 0.4134  loss_bbox: 0.3607  loss_ce_0: 0.6434  loss_giou_0: 0.4148  loss_bbox_0: 0.357  loss_rpn_cls: 0.2968  loss_rpn_reg: 0.5165  time: 0.1898  last_time: 0.1896  data_time: 0.0050  last_data_time: 0.0069   lr: 5e-05  max_mem: 3029M
[03/05 12:20:25] d2.utils.events INFO:  eta: 2:11:57  iter: 11479  total_loss: 3.871  loss_ce: 0.6285  loss_giou: 0.3534  loss_bbox: 0.3778  loss_ce_0: 0.634  loss_giou_0: 0.4117  loss_bbox_0: 0.3966  loss_rpn_cls: 0.3368  loss_rpn_reg: 0.5173  time: 0.1898  last_time: 0.1703  data_time: 0.0054  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:20:29] d2.utils.events INFO:  eta: 2:12:01  iter: 11499  total_loss: 3.859  loss_ce: 0.6179  loss_giou: 0.4185  loss_bbox: 0.3966  loss_ce_0: 0.6001  loss_giou_0: 0.4277  loss_bbox_0: 0.4347  loss_rpn_cls: 0.3091  loss_rpn_reg: 0.5424  time: 0.1898  last_time: 0.1681  data_time: 0.0047  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:20:33] d2.utils.events INFO:  eta: 2:12:00  iter: 11519  total_loss: 3.803  loss_ce: 0.6788  loss_giou: 0.4387  loss_bbox: 0.3681  loss_ce_0: 0.7135  loss_giou_0: 0.4635  loss_bbox_0: 0.3817  loss_rpn_cls: 0.2974  loss_rpn_reg: 0.5843  time: 0.1898  last_time: 0.2200  data_time: 0.0048  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:20:36] d2.utils.events INFO:  eta: 2:11:58  iter: 11539  total_loss: 3.326  loss_ce: 0.5693  loss_giou: 0.3436  loss_bbox: 0.3281  loss_ce_0: 0.5982  loss_giou_0: 0.3912  loss_bbox_0: 0.3748  loss_rpn_cls: 0.3007  loss_rpn_reg: 0.496  time: 0.1898  last_time: 0.1842  data_time: 0.0049  last_data_time: 0.0090   lr: 5e-05  max_mem: 3029M
[03/05 12:20:40] d2.utils.events INFO:  eta: 2:11:55  iter: 11559  total_loss: 3.856  loss_ce: 0.6303  loss_giou: 0.4525  loss_bbox: 0.3855  loss_ce_0: 0.6317  loss_giou_0: 0.4524  loss_bbox_0: 0.3993  loss_rpn_cls: 0.3142  loss_rpn_reg: 0.5534  time: 0.1897  last_time: 0.2022  data_time: 0.0052  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:20:44] d2.utils.events INFO:  eta: 2:12:03  iter: 11579  total_loss: 3.979  loss_ce: 0.6497  loss_giou: 0.4312  loss_bbox: 0.4242  loss_ce_0: 0.6987  loss_giou_0: 0.4702  loss_bbox_0: 0.4905  loss_rpn_cls: 0.3162  loss_rpn_reg: 0.5438  time: 0.1897  last_time: 0.1843  data_time: 0.0044  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:20:48] d2.utils.events INFO:  eta: 2:11:52  iter: 11599  total_loss: 3.667  loss_ce: 0.6311  loss_giou: 0.4086  loss_bbox: 0.3758  loss_ce_0: 0.6031  loss_giou_0: 0.4414  loss_bbox_0: 0.3646  loss_rpn_cls: 0.3031  loss_rpn_reg: 0.5526  time: 0.1898  last_time: 0.1769  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:20:51] d2.utils.events INFO:  eta: 2:11:52  iter: 11619  total_loss: 3.861  loss_ce: 0.6493  loss_giou: 0.4438  loss_bbox: 0.3666  loss_ce_0: 0.6255  loss_giou_0: 0.4686  loss_bbox_0: 0.3692  loss_rpn_cls: 0.3068  loss_rpn_reg: 0.5686  time: 0.1897  last_time: 0.1912  data_time: 0.0050  last_data_time: 0.0074   lr: 5e-05  max_mem: 3029M
[03/05 12:20:55] d2.utils.events INFO:  eta: 2:11:51  iter: 11639  total_loss: 3.374  loss_ce: 0.5698  loss_giou: 0.333  loss_bbox: 0.3502  loss_ce_0: 0.5736  loss_giou_0: 0.3701  loss_bbox_0: 0.3711  loss_rpn_cls: 0.2734  loss_rpn_reg: 0.4945  time: 0.1897  last_time: 0.1810  data_time: 0.0052  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:20:59] d2.utils.events INFO:  eta: 2:11:52  iter: 11659  total_loss: 3.632  loss_ce: 0.6356  loss_giou: 0.417  loss_bbox: 0.3522  loss_ce_0: 0.6599  loss_giou_0: 0.4209  loss_bbox_0: 0.3809  loss_rpn_cls: 0.2904  loss_rpn_reg: 0.5194  time: 0.1897  last_time: 0.2007  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:21:03] d2.utils.events INFO:  eta: 2:11:50  iter: 11679  total_loss: 3.752  loss_ce: 0.5583  loss_giou: 0.4645  loss_bbox: 0.4011  loss_ce_0: 0.6066  loss_giou_0: 0.4629  loss_bbox_0: 0.4112  loss_rpn_cls: 0.3115  loss_rpn_reg: 0.5623  time: 0.1897  last_time: 0.1778  data_time: 0.0045  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:21:07] d2.utils.events INFO:  eta: 2:11:57  iter: 11699  total_loss: 3.792  loss_ce: 0.6308  loss_giou: 0.4369  loss_bbox: 0.445  loss_ce_0: 0.6694  loss_giou_0: 0.4321  loss_bbox_0: 0.4123  loss_rpn_cls: 0.3068  loss_rpn_reg: 0.5454  time: 0.1897  last_time: 0.1725  data_time: 0.0045  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 12:21:10] d2.utils.events INFO:  eta: 2:11:56  iter: 11719  total_loss: 3.512  loss_ce: 0.5687  loss_giou: 0.3804  loss_bbox: 0.3549  loss_ce_0: 0.6279  loss_giou_0: 0.4186  loss_bbox_0: 0.411  loss_rpn_cls: 0.2781  loss_rpn_reg: 0.5261  time: 0.1897  last_time: 0.1807  data_time: 0.0046  last_data_time: 0.0077   lr: 5e-05  max_mem: 3029M
[03/05 12:21:14] d2.utils.events INFO:  eta: 2:11:53  iter: 11739  total_loss: 3.896  loss_ce: 0.6704  loss_giou: 0.4165  loss_bbox: 0.379  loss_ce_0: 0.6901  loss_giou_0: 0.4399  loss_bbox_0: 0.4087  loss_rpn_cls: 0.3234  loss_rpn_reg: 0.5241  time: 0.1897  last_time: 0.1816  data_time: 0.0048  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:21:18] d2.utils.events INFO:  eta: 2:11:56  iter: 11759  total_loss: 4.055  loss_ce: 0.7159  loss_giou: 0.4147  loss_bbox: 0.4284  loss_ce_0: 0.6557  loss_giou_0: 0.4189  loss_bbox_0: 0.4845  loss_rpn_cls: 0.3182  loss_rpn_reg: 0.5823  time: 0.1897  last_time: 0.1830  data_time: 0.0048  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:21:22] d2.utils.events INFO:  eta: 2:11:56  iter: 11779  total_loss: 3.438  loss_ce: 0.5564  loss_giou: 0.3782  loss_bbox: 0.2974  loss_ce_0: 0.5848  loss_giou_0: 0.42  loss_bbox_0: 0.3268  loss_rpn_cls: 0.282  loss_rpn_reg: 0.4952  time: 0.1897  last_time: 0.1826  data_time: 0.0045  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:21:26] d2.utils.events INFO:  eta: 2:11:52  iter: 11799  total_loss: 3.427  loss_ce: 0.5867  loss_giou: 0.3315  loss_bbox: 0.3384  loss_ce_0: 0.579  loss_giou_0: 0.3727  loss_bbox_0: 0.3737  loss_rpn_cls: 0.3128  loss_rpn_reg: 0.4757  time: 0.1897  last_time: 0.1594  data_time: 0.0048  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:21:30] d2.utils.events INFO:  eta: 2:11:38  iter: 11819  total_loss: 4.252  loss_ce: 0.7057  loss_giou: 0.4245  loss_bbox: 0.4063  loss_ce_0: 0.6713  loss_giou_0: 0.4562  loss_bbox_0: 0.4575  loss_rpn_cls: 0.326  loss_rpn_reg: 0.5314  time: 0.1897  last_time: 0.2139  data_time: 0.0051  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:21:33] d2.utils.events INFO:  eta: 2:11:41  iter: 11839  total_loss: 3.51  loss_ce: 0.6049  loss_giou: 0.4186  loss_bbox: 0.3644  loss_ce_0: 0.6322  loss_giou_0: 0.4385  loss_bbox_0: 0.3735  loss_rpn_cls: 0.302  loss_rpn_reg: 0.5342  time: 0.1897  last_time: 0.2071  data_time: 0.0050  last_data_time: 0.0070   lr: 5e-05  max_mem: 3029M
[03/05 12:21:37] d2.utils.events INFO:  eta: 2:11:27  iter: 11859  total_loss: 4.122  loss_ce: 0.6893  loss_giou: 0.4944  loss_bbox: 0.3797  loss_ce_0: 0.704  loss_giou_0: 0.5227  loss_bbox_0: 0.4286  loss_rpn_cls: 0.3331  loss_rpn_reg: 0.5634  time: 0.1897  last_time: 0.1723  data_time: 0.0044  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:21:41] d2.utils.events INFO:  eta: 2:11:19  iter: 11879  total_loss: 3.849  loss_ce: 0.6426  loss_giou: 0.4346  loss_bbox: 0.3706  loss_ce_0: 0.6359  loss_giou_0: 0.48  loss_bbox_0: 0.4168  loss_rpn_cls: 0.3152  loss_rpn_reg: 0.5596  time: 0.1897  last_time: 0.1601  data_time: 0.0045  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:21:45] d2.utils.events INFO:  eta: 2:11:23  iter: 11899  total_loss: 3.551  loss_ce: 0.6014  loss_giou: 0.4362  loss_bbox: 0.334  loss_ce_0: 0.6216  loss_giou_0: 0.4533  loss_bbox_0: 0.3185  loss_rpn_cls: 0.3049  loss_rpn_reg: 0.5296  time: 0.1897  last_time: 0.1891  data_time: 0.0048  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:21:49] d2.utils.events INFO:  eta: 2:11:30  iter: 11919  total_loss: 3.668  loss_ce: 0.6201  loss_giou: 0.3828  loss_bbox: 0.381  loss_ce_0: 0.6128  loss_giou_0: 0.3827  loss_bbox_0: 0.4102  loss_rpn_cls: 0.275  loss_rpn_reg: 0.534  time: 0.1897  last_time: 0.1895  data_time: 0.0046  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:21:52] d2.utils.events INFO:  eta: 2:11:26  iter: 11939  total_loss: 3.465  loss_ce: 0.5886  loss_giou: 0.378  loss_bbox: 0.3368  loss_ce_0: 0.6167  loss_giou_0: 0.3929  loss_bbox_0: 0.3414  loss_rpn_cls: 0.2667  loss_rpn_reg: 0.5321  time: 0.1897  last_time: 0.1899  data_time: 0.0051  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:21:56] d2.utils.events INFO:  eta: 2:11:26  iter: 11959  total_loss: 3.663  loss_ce: 0.5839  loss_giou: 0.4134  loss_bbox: 0.3736  loss_ce_0: 0.5437  loss_giou_0: 0.418  loss_bbox_0: 0.4168  loss_rpn_cls: 0.2848  loss_rpn_reg: 0.5148  time: 0.1897  last_time: 0.2002  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:22:00] d2.utils.events INFO:  eta: 2:11:36  iter: 11979  total_loss: 3.791  loss_ce: 0.5399  loss_giou: 0.4529  loss_bbox: 0.4379  loss_ce_0: 0.5429  loss_giou_0: 0.4468  loss_bbox_0: 0.4317  loss_rpn_cls: 0.3095  loss_rpn_reg: 0.5307  time: 0.1897  last_time: 0.1936  data_time: 0.0044  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:22:04] d2.utils.events INFO:  eta: 2:11:33  iter: 11999  total_loss: 3.917  loss_ce: 0.665  loss_giou: 0.4116  loss_bbox: 0.3555  loss_ce_0: 0.6458  loss_giou_0: 0.4425  loss_bbox_0: 0.3854  loss_rpn_cls: 0.3178  loss_rpn_reg: 0.496  time: 0.1897  last_time: 0.1830  data_time: 0.0050  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:22:08] d2.utils.events INFO:  eta: 2:11:24  iter: 12019  total_loss: 3.817  loss_ce: 0.5856  loss_giou: 0.4019  loss_bbox: 0.3729  loss_ce_0: 0.5755  loss_giou_0: 0.4434  loss_bbox_0: 0.4148  loss_rpn_cls: 0.3356  loss_rpn_reg: 0.552  time: 0.1897  last_time: 0.1801  data_time: 0.0051  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:22:11] d2.utils.events INFO:  eta: 2:11:07  iter: 12039  total_loss: 3.97  loss_ce: 0.6355  loss_giou: 0.3866  loss_bbox: 0.3781  loss_ce_0: 0.6812  loss_giou_0: 0.4572  loss_bbox_0: 0.4112  loss_rpn_cls: 0.2988  loss_rpn_reg: 0.5425  time: 0.1897  last_time: 0.1797  data_time: 0.0046  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:22:15] d2.utils.events INFO:  eta: 2:10:58  iter: 12059  total_loss: 3.8  loss_ce: 0.6817  loss_giou: 0.4331  loss_bbox: 0.3673  loss_ce_0: 0.7372  loss_giou_0: 0.4357  loss_bbox_0: 0.363  loss_rpn_cls: 0.3152  loss_rpn_reg: 0.5494  time: 0.1897  last_time: 0.1839  data_time: 0.0046  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:22:19] d2.utils.events INFO:  eta: 2:11:00  iter: 12079  total_loss: 3.695  loss_ce: 0.6135  loss_giou: 0.3616  loss_bbox: 0.3816  loss_ce_0: 0.5971  loss_giou_0: 0.3968  loss_bbox_0: 0.3873  loss_rpn_cls: 0.3153  loss_rpn_reg: 0.4987  time: 0.1897  last_time: 0.1876  data_time: 0.0052  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:22:23] d2.utils.events INFO:  eta: 2:10:50  iter: 12099  total_loss: 3.563  loss_ce: 0.5976  loss_giou: 0.4152  loss_bbox: 0.2803  loss_ce_0: 0.6027  loss_giou_0: 0.4299  loss_bbox_0: 0.3264  loss_rpn_cls: 0.2933  loss_rpn_reg: 0.5297  time: 0.1897  last_time: 0.1892  data_time: 0.0049  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 12:22:27] d2.utils.events INFO:  eta: 2:10:40  iter: 12119  total_loss: 3.827  loss_ce: 0.623  loss_giou: 0.4096  loss_bbox: 0.4226  loss_ce_0: 0.6664  loss_giou_0: 0.4075  loss_bbox_0: 0.4047  loss_rpn_cls: 0.2782  loss_rpn_reg: 0.5499  time: 0.1897  last_time: 0.1744  data_time: 0.0046  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 12:22:30] d2.utils.events INFO:  eta: 2:10:40  iter: 12139  total_loss: 3.664  loss_ce: 0.5718  loss_giou: 0.3892  loss_bbox: 0.3827  loss_ce_0: 0.6022  loss_giou_0: 0.4122  loss_bbox_0: 0.4416  loss_rpn_cls: 0.3055  loss_rpn_reg: 0.5091  time: 0.1897  last_time: 0.1895  data_time: 0.0046  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 12:22:34] d2.utils.events INFO:  eta: 2:10:40  iter: 12159  total_loss: 3.694  loss_ce: 0.6286  loss_giou: 0.4265  loss_bbox: 0.3307  loss_ce_0: 0.6319  loss_giou_0: 0.4744  loss_bbox_0: 0.3846  loss_rpn_cls: 0.3173  loss_rpn_reg: 0.4994  time: 0.1896  last_time: 0.2115  data_time: 0.0051  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 12:22:38] d2.utils.events INFO:  eta: 2:10:39  iter: 12179  total_loss: 4.082  loss_ce: 0.6511  loss_giou: 0.4107  loss_bbox: 0.3395  loss_ce_0: 0.6348  loss_giou_0: 0.4409  loss_bbox_0: 0.371  loss_rpn_cls: 0.2967  loss_rpn_reg: 0.5261  time: 0.1896  last_time: 0.1731  data_time: 0.0048  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:22:42] d2.utils.events INFO:  eta: 2:10:42  iter: 12199  total_loss: 4.139  loss_ce: 0.5761  loss_giou: 0.4458  loss_bbox: 0.474  loss_ce_0: 0.623  loss_giou_0: 0.4952  loss_bbox_0: 0.4675  loss_rpn_cls: 0.2781  loss_rpn_reg: 0.5735  time: 0.1896  last_time: 0.1922  data_time: 0.0052  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:22:46] d2.utils.events INFO:  eta: 2:10:37  iter: 12219  total_loss: 3.699  loss_ce: 0.5832  loss_giou: 0.4755  loss_bbox: 0.3996  loss_ce_0: 0.595  loss_giou_0: 0.4634  loss_bbox_0: 0.4027  loss_rpn_cls: 0.2846  loss_rpn_reg: 0.5255  time: 0.1896  last_time: 0.1678  data_time: 0.0054  last_data_time: 0.0031   lr: 5e-05  max_mem: 3029M
[03/05 12:22:49] d2.utils.events INFO:  eta: 2:10:28  iter: 12239  total_loss: 3.75  loss_ce: 0.5935  loss_giou: 0.4497  loss_bbox: 0.3957  loss_ce_0: 0.6364  loss_giou_0: 0.4452  loss_bbox_0: 0.4043  loss_rpn_cls: 0.2983  loss_rpn_reg: 0.5392  time: 0.1896  last_time: 0.1891  data_time: 0.0051  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:22:53] d2.utils.events INFO:  eta: 2:10:24  iter: 12259  total_loss: 3.538  loss_ce: 0.5882  loss_giou: 0.3721  loss_bbox: 0.4363  loss_ce_0: 0.5627  loss_giou_0: 0.3834  loss_bbox_0: 0.4492  loss_rpn_cls: 0.2804  loss_rpn_reg: 0.473  time: 0.1896  last_time: 0.1803  data_time: 0.0050  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:22:57] d2.utils.events INFO:  eta: 2:10:18  iter: 12279  total_loss: 3.795  loss_ce: 0.6276  loss_giou: 0.3935  loss_bbox: 0.3822  loss_ce_0: 0.6399  loss_giou_0: 0.399  loss_bbox_0: 0.3702  loss_rpn_cls: 0.308  loss_rpn_reg: 0.5432  time: 0.1896  last_time: 0.1768  data_time: 0.0048  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:23:01] d2.utils.events INFO:  eta: 2:10:16  iter: 12299  total_loss: 3.672  loss_ce: 0.611  loss_giou: 0.3908  loss_bbox: 0.3931  loss_ce_0: 0.5787  loss_giou_0: 0.4305  loss_bbox_0: 0.471  loss_rpn_cls: 0.2967  loss_rpn_reg: 0.524  time: 0.1896  last_time: 0.1820  data_time: 0.0051  last_data_time: 0.0027   lr: 5e-05  max_mem: 3029M
[03/05 12:23:05] d2.utils.events INFO:  eta: 2:10:15  iter: 12319  total_loss: 3.968  loss_ce: 0.6663  loss_giou: 0.4557  loss_bbox: 0.4274  loss_ce_0: 0.6895  loss_giou_0: 0.4786  loss_bbox_0: 0.4663  loss_rpn_cls: 0.3058  loss_rpn_reg: 0.5416  time: 0.1896  last_time: 0.1626  data_time: 0.0052  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:23:09] d2.utils.events INFO:  eta: 2:10:15  iter: 12339  total_loss: 3.759  loss_ce: 0.6512  loss_giou: 0.4473  loss_bbox: 0.415  loss_ce_0: 0.6539  loss_giou_0: 0.462  loss_bbox_0: 0.3974  loss_rpn_cls: 0.3146  loss_rpn_reg: 0.5578  time: 0.1896  last_time: 0.1642  data_time: 0.0045  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:23:13] d2.utils.events INFO:  eta: 2:10:07  iter: 12359  total_loss: 3.703  loss_ce: 0.5862  loss_giou: 0.4992  loss_bbox: 0.3403  loss_ce_0: 0.5719  loss_giou_0: 0.5098  loss_bbox_0: 0.3902  loss_rpn_cls: 0.3033  loss_rpn_reg: 0.5824  time: 0.1896  last_time: 0.2011  data_time: 0.0054  last_data_time: 0.0080   lr: 5e-05  max_mem: 3029M
[03/05 12:23:16] d2.utils.events INFO:  eta: 2:10:13  iter: 12379  total_loss: 3.763  loss_ce: 0.5892  loss_giou: 0.4426  loss_bbox: 0.4313  loss_ce_0: 0.6369  loss_giou_0: 0.4546  loss_bbox_0: 0.4383  loss_rpn_cls: 0.2887  loss_rpn_reg: 0.5552  time: 0.1896  last_time: 0.1905  data_time: 0.0052  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:23:20] d2.utils.events INFO:  eta: 2:10:15  iter: 12399  total_loss: 3.565  loss_ce: 0.5835  loss_giou: 0.3733  loss_bbox: 0.4042  loss_ce_0: 0.5872  loss_giou_0: 0.3948  loss_bbox_0: 0.4386  loss_rpn_cls: 0.2537  loss_rpn_reg: 0.5019  time: 0.1896  last_time: 0.1961  data_time: 0.0047  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:23:24] d2.utils.events INFO:  eta: 2:10:18  iter: 12419  total_loss: 3.722  loss_ce: 0.6102  loss_giou: 0.4667  loss_bbox: 0.3201  loss_ce_0: 0.6048  loss_giou_0: 0.5005  loss_bbox_0: 0.3481  loss_rpn_cls: 0.3019  loss_rpn_reg: 0.5536  time: 0.1896  last_time: 0.2062  data_time: 0.0049  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:23:28] d2.utils.events INFO:  eta: 2:10:15  iter: 12439  total_loss: 3.722  loss_ce: 0.566  loss_giou: 0.3884  loss_bbox: 0.3829  loss_ce_0: 0.5909  loss_giou_0: 0.4224  loss_bbox_0: 0.4142  loss_rpn_cls: 0.2703  loss_rpn_reg: 0.5437  time: 0.1896  last_time: 0.1863  data_time: 0.0044  last_data_time: 0.0025   lr: 5e-05  max_mem: 3029M
[03/05 12:23:32] d2.utils.events INFO:  eta: 2:10:17  iter: 12459  total_loss: 3.381  loss_ce: 0.5631  loss_giou: 0.3674  loss_bbox: 0.3587  loss_ce_0: 0.5676  loss_giou_0: 0.4026  loss_bbox_0: 0.4162  loss_rpn_cls: 0.2798  loss_rpn_reg: 0.5133  time: 0.1896  last_time: 0.2043  data_time: 0.0048  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:23:36] d2.utils.events INFO:  eta: 2:10:07  iter: 12479  total_loss: 3.159  loss_ce: 0.5294  loss_giou: 0.3308  loss_bbox: 0.321  loss_ce_0: 0.5392  loss_giou_0: 0.3489  loss_bbox_0: 0.3485  loss_rpn_cls: 0.2767  loss_rpn_reg: 0.4815  time: 0.1896  last_time: 0.1795  data_time: 0.0051  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:23:40] d2.utils.events INFO:  eta: 2:10:03  iter: 12499  total_loss: 3.577  loss_ce: 0.5802  loss_giou: 0.4046  loss_bbox: 0.3637  loss_ce_0: 0.5685  loss_giou_0: 0.4182  loss_bbox_0: 0.3848  loss_rpn_cls: 0.3029  loss_rpn_reg: 0.5382  time: 0.1896  last_time: 0.2053  data_time: 0.0049  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:23:44] d2.utils.events INFO:  eta: 2:10:03  iter: 12519  total_loss: 3.679  loss_ce: 0.5784  loss_giou: 0.3871  loss_bbox: 0.3743  loss_ce_0: 0.6019  loss_giou_0: 0.3989  loss_bbox_0: 0.3627  loss_rpn_cls: 0.3069  loss_rpn_reg: 0.4911  time: 0.1896  last_time: 0.1970  data_time: 0.0048  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 12:23:47] d2.utils.events INFO:  eta: 2:10:08  iter: 12539  total_loss: 3.496  loss_ce: 0.5889  loss_giou: 0.4086  loss_bbox: 0.3405  loss_ce_0: 0.5741  loss_giou_0: 0.3943  loss_bbox_0: 0.3622  loss_rpn_cls: 0.3005  loss_rpn_reg: 0.5181  time: 0.1896  last_time: 0.1842  data_time: 0.0047  last_data_time: 0.0028   lr: 5e-05  max_mem: 3029M
[03/05 12:23:51] d2.utils.events INFO:  eta: 2:10:05  iter: 12559  total_loss: 3.728  loss_ce: 0.5224  loss_giou: 0.4179  loss_bbox: 0.3782  loss_ce_0: 0.5458  loss_giou_0: 0.4325  loss_bbox_0: 0.4046  loss_rpn_cls: 0.265  loss_rpn_reg: 0.5469  time: 0.1896  last_time: 0.1784  data_time: 0.0048  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:23:55] d2.utils.events INFO:  eta: 2:10:05  iter: 12579  total_loss: 3.689  loss_ce: 0.6055  loss_giou: 0.4196  loss_bbox: 0.3416  loss_ce_0: 0.6099  loss_giou_0: 0.4523  loss_bbox_0: 0.3746  loss_rpn_cls: 0.2927  loss_rpn_reg: 0.5312  time: 0.1896  last_time: 0.1756  data_time: 0.0048  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:23:59] d2.utils.events INFO:  eta: 2:10:03  iter: 12599  total_loss: 3.251  loss_ce: 0.4914  loss_giou: 0.355  loss_bbox: 0.3446  loss_ce_0: 0.5198  loss_giou_0: 0.3711  loss_bbox_0: 0.3604  loss_rpn_cls: 0.2558  loss_rpn_reg: 0.5048  time: 0.1897  last_time: 0.1984  data_time: 0.0049  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:24:03] d2.utils.events INFO:  eta: 2:10:04  iter: 12619  total_loss: 3.525  loss_ce: 0.5814  loss_giou: 0.3752  loss_bbox: 0.3645  loss_ce_0: 0.5649  loss_giou_0: 0.3769  loss_bbox_0: 0.3902  loss_rpn_cls: 0.2707  loss_rpn_reg: 0.5232  time: 0.1897  last_time: 0.1966  data_time: 0.0045  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:24:07] d2.utils.events INFO:  eta: 2:10:04  iter: 12639  total_loss: 3.559  loss_ce: 0.554  loss_giou: 0.388  loss_bbox: 0.3416  loss_ce_0: 0.5916  loss_giou_0: 0.4001  loss_bbox_0: 0.3514  loss_rpn_cls: 0.3001  loss_rpn_reg: 0.5167  time: 0.1897  last_time: 0.2147  data_time: 0.0057  last_data_time: 0.0130   lr: 5e-05  max_mem: 3029M
[03/05 12:24:11] d2.utils.events INFO:  eta: 2:10:00  iter: 12659  total_loss: 3.535  loss_ce: 0.5892  loss_giou: 0.3693  loss_bbox: 0.3881  loss_ce_0: 0.6179  loss_giou_0: 0.3975  loss_bbox_0: 0.3968  loss_rpn_cls: 0.2916  loss_rpn_reg: 0.5124  time: 0.1897  last_time: 0.1620  data_time: 0.0044  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:24:15] d2.utils.events INFO:  eta: 2:09:58  iter: 12679  total_loss: 3.73  loss_ce: 0.6115  loss_giou: 0.4136  loss_bbox: 0.4694  loss_ce_0: 0.6143  loss_giou_0: 0.4247  loss_bbox_0: 0.4163  loss_rpn_cls: 0.3058  loss_rpn_reg: 0.5278  time: 0.1897  last_time: 0.1937  data_time: 0.0052  last_data_time: 0.0080   lr: 5e-05  max_mem: 3029M
[03/05 12:24:18] d2.utils.events INFO:  eta: 2:09:52  iter: 12699  total_loss: 3.167  loss_ce: 0.5149  loss_giou: 0.3661  loss_bbox: 0.3343  loss_ce_0: 0.5634  loss_giou_0: 0.3887  loss_bbox_0: 0.3527  loss_rpn_cls: 0.2721  loss_rpn_reg: 0.515  time: 0.1897  last_time: 0.1878  data_time: 0.0044  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 12:24:22] d2.utils.events INFO:  eta: 2:09:49  iter: 12719  total_loss: 3.696  loss_ce: 0.6159  loss_giou: 0.4273  loss_bbox: 0.4399  loss_ce_0: 0.6134  loss_giou_0: 0.467  loss_bbox_0: 0.4531  loss_rpn_cls: 0.307  loss_rpn_reg: 0.5102  time: 0.1897  last_time: 0.1924  data_time: 0.0049  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:24:26] d2.utils.events INFO:  eta: 2:09:39  iter: 12739  total_loss: 3.484  loss_ce: 0.6038  loss_giou: 0.3925  loss_bbox: 0.3766  loss_ce_0: 0.5909  loss_giou_0: 0.3948  loss_bbox_0: 0.3682  loss_rpn_cls: 0.2804  loss_rpn_reg: 0.5162  time: 0.1897  last_time: 0.1819  data_time: 0.0053  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:24:30] d2.utils.events INFO:  eta: 2:09:41  iter: 12759  total_loss: 3.576  loss_ce: 0.5996  loss_giou: 0.4129  loss_bbox: 0.3585  loss_ce_0: 0.5578  loss_giou_0: 0.4019  loss_bbox_0: 0.4037  loss_rpn_cls: 0.2617  loss_rpn_reg: 0.508  time: 0.1897  last_time: 0.1951  data_time: 0.0047  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:24:34] d2.utils.events INFO:  eta: 2:09:37  iter: 12779  total_loss: 3.795  loss_ce: 0.6074  loss_giou: 0.4474  loss_bbox: 0.3821  loss_ce_0: 0.6286  loss_giou_0: 0.4708  loss_bbox_0: 0.4321  loss_rpn_cls: 0.3159  loss_rpn_reg: 0.5016  time: 0.1897  last_time: 0.1730  data_time: 0.0049  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:24:38] d2.utils.events INFO:  eta: 2:09:38  iter: 12799  total_loss: 3.795  loss_ce: 0.5659  loss_giou: 0.4174  loss_bbox: 0.4115  loss_ce_0: 0.6133  loss_giou_0: 0.4468  loss_bbox_0: 0.4287  loss_rpn_cls: 0.3012  loss_rpn_reg: 0.5403  time: 0.1896  last_time: 0.2044  data_time: 0.0053  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:24:42] d2.utils.events INFO:  eta: 2:09:37  iter: 12819  total_loss: 3.638  loss_ce: 0.6537  loss_giou: 0.3541  loss_bbox: 0.3427  loss_ce_0: 0.6476  loss_giou_0: 0.3948  loss_bbox_0: 0.3844  loss_rpn_cls: 0.2934  loss_rpn_reg: 0.5225  time: 0.1897  last_time: 0.1889  data_time: 0.0047  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:24:45] d2.utils.events INFO:  eta: 2:09:32  iter: 12839  total_loss: 3.927  loss_ce: 0.6477  loss_giou: 0.4502  loss_bbox: 0.4056  loss_ce_0: 0.6716  loss_giou_0: 0.4832  loss_bbox_0: 0.4609  loss_rpn_cls: 0.3042  loss_rpn_reg: 0.554  time: 0.1897  last_time: 0.1941  data_time: 0.0050  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:24:49] d2.utils.events INFO:  eta: 2:09:35  iter: 12859  total_loss: 4.184  loss_ce: 0.6567  loss_giou: 0.4731  loss_bbox: 0.3942  loss_ce_0: 0.6644  loss_giou_0: 0.4993  loss_bbox_0: 0.4423  loss_rpn_cls: 0.3413  loss_rpn_reg: 0.606  time: 0.1897  last_time: 0.1976  data_time: 0.0047  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:24:53] d2.utils.events INFO:  eta: 2:09:34  iter: 12879  total_loss: 3.624  loss_ce: 0.6199  loss_giou: 0.4265  loss_bbox: 0.3578  loss_ce_0: 0.6339  loss_giou_0: 0.4544  loss_bbox_0: 0.3778  loss_rpn_cls: 0.3155  loss_rpn_reg: 0.5151  time: 0.1896  last_time: 0.1662  data_time: 0.0045  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:24:57] d2.utils.events INFO:  eta: 2:09:27  iter: 12899  total_loss: 3.828  loss_ce: 0.6897  loss_giou: 0.4142  loss_bbox: 0.3561  loss_ce_0: 0.6866  loss_giou_0: 0.4569  loss_bbox_0: 0.3987  loss_rpn_cls: 0.3268  loss_rpn_reg: 0.5207  time: 0.1896  last_time: 0.1593  data_time: 0.0047  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:25:01] d2.utils.events INFO:  eta: 2:09:22  iter: 12919  total_loss: 3.097  loss_ce: 0.4948  loss_giou: 0.3223  loss_bbox: 0.3238  loss_ce_0: 0.5051  loss_giou_0: 0.3359  loss_bbox_0: 0.326  loss_rpn_cls: 0.2492  loss_rpn_reg: 0.4862  time: 0.1896  last_time: 0.1876  data_time: 0.0043  last_data_time: 0.0070   lr: 5e-05  max_mem: 3029M
[03/05 12:25:05] d2.utils.events INFO:  eta: 2:09:25  iter: 12939  total_loss: 3.775  loss_ce: 0.6237  loss_giou: 0.3546  loss_bbox: 0.354  loss_ce_0: 0.6135  loss_giou_0: 0.4301  loss_bbox_0: 0.4419  loss_rpn_cls: 0.2743  loss_rpn_reg: 0.5227  time: 0.1897  last_time: 0.1809  data_time: 0.0052  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:25:09] d2.utils.events INFO:  eta: 2:09:21  iter: 12959  total_loss: 3.71  loss_ce: 0.668  loss_giou: 0.4564  loss_bbox: 0.3552  loss_ce_0: 0.6655  loss_giou_0: 0.4882  loss_bbox_0: 0.3831  loss_rpn_cls: 0.2982  loss_rpn_reg: 0.5188  time: 0.1897  last_time: 0.1850  data_time: 0.0046  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:25:12] d2.utils.events INFO:  eta: 2:09:17  iter: 12979  total_loss: 3.725  loss_ce: 0.6738  loss_giou: 0.4211  loss_bbox: 0.3405  loss_ce_0: 0.6564  loss_giou_0: 0.4423  loss_bbox_0: 0.4109  loss_rpn_cls: 0.2988  loss_rpn_reg: 0.5367  time: 0.1897  last_time: 0.2162  data_time: 0.0052  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:25:16] d2.utils.events INFO:  eta: 2:09:17  iter: 12999  total_loss: 3.701  loss_ce: 0.5795  loss_giou: 0.44  loss_bbox: 0.3723  loss_ce_0: 0.526  loss_giou_0: 0.4526  loss_bbox_0: 0.3813  loss_rpn_cls: 0.3122  loss_rpn_reg: 0.5214  time: 0.1897  last_time: 0.1702  data_time: 0.0047  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:25:20] d2.utils.events INFO:  eta: 2:09:15  iter: 13019  total_loss: 3.676  loss_ce: 0.6567  loss_giou: 0.4097  loss_bbox: 0.3814  loss_ce_0: 0.6537  loss_giou_0: 0.4227  loss_bbox_0: 0.3766  loss_rpn_cls: 0.3098  loss_rpn_reg: 0.5449  time: 0.1897  last_time: 0.1905  data_time: 0.0049  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:25:24] d2.utils.events INFO:  eta: 2:09:15  iter: 13039  total_loss: 3.641  loss_ce: 0.6031  loss_giou: 0.3599  loss_bbox: 0.391  loss_ce_0: 0.5841  loss_giou_0: 0.3786  loss_bbox_0: 0.43  loss_rpn_cls: 0.276  loss_rpn_reg: 0.5171  time: 0.1896  last_time: 0.1786  data_time: 0.0045  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:25:28] d2.utils.events INFO:  eta: 2:09:11  iter: 13059  total_loss: 3.886  loss_ce: 0.6128  loss_giou: 0.3534  loss_bbox: 0.4103  loss_ce_0: 0.6105  loss_giou_0: 0.3862  loss_bbox_0: 0.4785  loss_rpn_cls: 0.2859  loss_rpn_reg: 0.5292  time: 0.1896  last_time: 0.2109  data_time: 0.0048  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:25:32] d2.utils.events INFO:  eta: 2:09:06  iter: 13079  total_loss: 3.618  loss_ce: 0.6117  loss_giou: 0.4258  loss_bbox: 0.3163  loss_ce_0: 0.6323  loss_giou_0: 0.459  loss_bbox_0: 0.3645  loss_rpn_cls: 0.3194  loss_rpn_reg: 0.559  time: 0.1896  last_time: 0.1976  data_time: 0.0056  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:25:35] d2.utils.events INFO:  eta: 2:09:03  iter: 13099  total_loss: 3.46  loss_ce: 0.6168  loss_giou: 0.3356  loss_bbox: 0.3664  loss_ce_0: 0.6169  loss_giou_0: 0.382  loss_bbox_0: 0.3706  loss_rpn_cls: 0.2917  loss_rpn_reg: 0.4763  time: 0.1896  last_time: 0.2080  data_time: 0.0047  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:25:39] d2.utils.events INFO:  eta: 2:09:00  iter: 13119  total_loss: 3.555  loss_ce: 0.5968  loss_giou: 0.4246  loss_bbox: 0.2997  loss_ce_0: 0.6337  loss_giou_0: 0.4163  loss_bbox_0: 0.3225  loss_rpn_cls: 0.2979  loss_rpn_reg: 0.538  time: 0.1896  last_time: 0.1774  data_time: 0.0052  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:25:43] d2.utils.events INFO:  eta: 2:08:56  iter: 13139  total_loss: 3.48  loss_ce: 0.5967  loss_giou: 0.3375  loss_bbox: 0.3807  loss_ce_0: 0.543  loss_giou_0: 0.391  loss_bbox_0: 0.3879  loss_rpn_cls: 0.2634  loss_rpn_reg: 0.5196  time: 0.1896  last_time: 0.1617  data_time: 0.0048  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:25:47] d2.utils.events INFO:  eta: 2:08:53  iter: 13159  total_loss: 3.467  loss_ce: 0.5295  loss_giou: 0.4155  loss_bbox: 0.3377  loss_ce_0: 0.5379  loss_giou_0: 0.43  loss_bbox_0: 0.3385  loss_rpn_cls: 0.2849  loss_rpn_reg: 0.5262  time: 0.1896  last_time: 0.1938  data_time: 0.0051  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:25:51] d2.utils.events INFO:  eta: 2:08:49  iter: 13179  total_loss: 3.516  loss_ce: 0.5766  loss_giou: 0.3758  loss_bbox: 0.3473  loss_ce_0: 0.6029  loss_giou_0: 0.4024  loss_bbox_0: 0.3574  loss_rpn_cls: 0.2612  loss_rpn_reg: 0.494  time: 0.1896  last_time: 0.2189  data_time: 0.0048  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:25:55] d2.utils.events INFO:  eta: 2:08:44  iter: 13199  total_loss: 3.697  loss_ce: 0.6131  loss_giou: 0.4544  loss_bbox: 0.3352  loss_ce_0: 0.5911  loss_giou_0: 0.4813  loss_bbox_0: 0.3456  loss_rpn_cls: 0.289  loss_rpn_reg: 0.5202  time: 0.1896  last_time: 0.2011  data_time: 0.0046  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:25:58] d2.utils.events INFO:  eta: 2:08:44  iter: 13219  total_loss: 3.826  loss_ce: 0.5841  loss_giou: 0.4209  loss_bbox: 0.3687  loss_ce_0: 0.5908  loss_giou_0: 0.4627  loss_bbox_0: 0.4183  loss_rpn_cls: 0.2818  loss_rpn_reg: 0.5332  time: 0.1896  last_time: 0.1683  data_time: 0.0047  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:26:02] d2.utils.events INFO:  eta: 2:08:49  iter: 13239  total_loss: 3.662  loss_ce: 0.6352  loss_giou: 0.4286  loss_bbox: 0.3629  loss_ce_0: 0.5992  loss_giou_0: 0.4551  loss_bbox_0: 0.3693  loss_rpn_cls: 0.3124  loss_rpn_reg: 0.5029  time: 0.1897  last_time: 0.1772  data_time: 0.0052  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:26:06] d2.utils.events INFO:  eta: 2:08:46  iter: 13259  total_loss: 3.57  loss_ce: 0.5807  loss_giou: 0.3835  loss_bbox: 0.3401  loss_ce_0: 0.6033  loss_giou_0: 0.4193  loss_bbox_0: 0.374  loss_rpn_cls: 0.2303  loss_rpn_reg: 0.5423  time: 0.1896  last_time: 0.1867  data_time: 0.0046  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:26:10] d2.utils.events INFO:  eta: 2:08:38  iter: 13279  total_loss: 3.772  loss_ce: 0.5482  loss_giou: 0.4142  loss_bbox: 0.4011  loss_ce_0: 0.5908  loss_giou_0: 0.4208  loss_bbox_0: 0.3928  loss_rpn_cls: 0.2924  loss_rpn_reg: 0.5602  time: 0.1896  last_time: 0.1698  data_time: 0.0043  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:26:14] d2.utils.events INFO:  eta: 2:08:38  iter: 13299  total_loss: 3.815  loss_ce: 0.6812  loss_giou: 0.4078  loss_bbox: 0.4022  loss_ce_0: 0.6535  loss_giou_0: 0.4415  loss_bbox_0: 0.4213  loss_rpn_cls: 0.3228  loss_rpn_reg: 0.513  time: 0.1896  last_time: 0.1969  data_time: 0.0057  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 12:26:18] d2.utils.events INFO:  eta: 2:08:34  iter: 13319  total_loss: 3.373  loss_ce: 0.5925  loss_giou: 0.3523  loss_bbox: 0.3433  loss_ce_0: 0.5774  loss_giou_0: 0.3736  loss_bbox_0: 0.3563  loss_rpn_cls: 0.2786  loss_rpn_reg: 0.4917  time: 0.1896  last_time: 0.1695  data_time: 0.0045  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:26:22] d2.utils.events INFO:  eta: 2:08:32  iter: 13339  total_loss: 3.983  loss_ce: 0.6215  loss_giou: 0.4116  loss_bbox: 0.3941  loss_ce_0: 0.6265  loss_giou_0: 0.4575  loss_bbox_0: 0.4447  loss_rpn_cls: 0.2947  loss_rpn_reg: 0.5393  time: 0.1896  last_time: 0.1866  data_time: 0.0052  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 12:26:25] d2.utils.events INFO:  eta: 2:08:25  iter: 13359  total_loss: 4.036  loss_ce: 0.6376  loss_giou: 0.4089  loss_bbox: 0.3704  loss_ce_0: 0.6381  loss_giou_0: 0.4751  loss_bbox_0: 0.4016  loss_rpn_cls: 0.3339  loss_rpn_reg: 0.5494  time: 0.1896  last_time: 0.1848  data_time: 0.0049  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:26:29] d2.utils.events INFO:  eta: 2:08:21  iter: 13379  total_loss: 3.687  loss_ce: 0.6048  loss_giou: 0.4232  loss_bbox: 0.3431  loss_ce_0: 0.6322  loss_giou_0: 0.4328  loss_bbox_0: 0.3764  loss_rpn_cls: 0.2962  loss_rpn_reg: 0.5138  time: 0.1896  last_time: 0.1989  data_time: 0.0051  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:26:33] d2.utils.events INFO:  eta: 2:08:12  iter: 13399  total_loss: 3.349  loss_ce: 0.58  loss_giou: 0.4067  loss_bbox: 0.3264  loss_ce_0: 0.5883  loss_giou_0: 0.4351  loss_bbox_0: 0.3916  loss_rpn_cls: 0.3038  loss_rpn_reg: 0.4965  time: 0.1896  last_time: 0.1892  data_time: 0.0070  last_data_time: 0.0022   lr: 5e-05  max_mem: 3029M
[03/05 12:26:37] d2.utils.events INFO:  eta: 2:08:05  iter: 13419  total_loss: 3.59  loss_ce: 0.6096  loss_giou: 0.3515  loss_bbox: 0.4169  loss_ce_0: 0.6477  loss_giou_0: 0.383  loss_bbox_0: 0.4692  loss_rpn_cls: 0.2727  loss_rpn_reg: 0.5342  time: 0.1896  last_time: 0.1716  data_time: 0.0049  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:26:41] d2.utils.events INFO:  eta: 2:08:06  iter: 13439  total_loss: 4.023  loss_ce: 0.678  loss_giou: 0.4526  loss_bbox: 0.3729  loss_ce_0: 0.6896  loss_giou_0: 0.4694  loss_bbox_0: 0.3769  loss_rpn_cls: 0.3523  loss_rpn_reg: 0.5082  time: 0.1896  last_time: 0.1980  data_time: 0.0046  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:26:44] d2.utils.events INFO:  eta: 2:07:59  iter: 13459  total_loss: 3.855  loss_ce: 0.5831  loss_giou: 0.4638  loss_bbox: 0.3928  loss_ce_0: 0.6212  loss_giou_0: 0.4775  loss_bbox_0: 0.4211  loss_rpn_cls: 0.3353  loss_rpn_reg: 0.5426  time: 0.1896  last_time: 0.2019  data_time: 0.0047  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:26:48] d2.utils.events INFO:  eta: 2:07:53  iter: 13479  total_loss: 3.763  loss_ce: 0.6241  loss_giou: 0.429  loss_bbox: 0.388  loss_ce_0: 0.653  loss_giou_0: 0.457  loss_bbox_0: 0.4442  loss_rpn_cls: 0.2702  loss_rpn_reg: 0.5301  time: 0.1896  last_time: 0.1692  data_time: 0.0043  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:26:52] d2.utils.events INFO:  eta: 2:07:49  iter: 13499  total_loss: 3.62  loss_ce: 0.5594  loss_giou: 0.4003  loss_bbox: 0.3946  loss_ce_0: 0.5719  loss_giou_0: 0.4493  loss_bbox_0: 0.4227  loss_rpn_cls: 0.2839  loss_rpn_reg: 0.5499  time: 0.1896  last_time: 0.2289  data_time: 0.0050  last_data_time: 0.0089   lr: 5e-05  max_mem: 3029M
[03/05 12:26:56] d2.utils.events INFO:  eta: 2:07:45  iter: 13519  total_loss: 3.657  loss_ce: 0.631  loss_giou: 0.3656  loss_bbox: 0.3271  loss_ce_0: 0.6378  loss_giou_0: 0.375  loss_bbox_0: 0.3408  loss_rpn_cls: 0.2885  loss_rpn_reg: 0.4975  time: 0.1896  last_time: 0.1886  data_time: 0.0050  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:27:00] d2.utils.events INFO:  eta: 2:07:40  iter: 13539  total_loss: 3.373  loss_ce: 0.5979  loss_giou: 0.3326  loss_bbox: 0.3115  loss_ce_0: 0.6159  loss_giou_0: 0.3609  loss_bbox_0: 0.3415  loss_rpn_cls: 0.2786  loss_rpn_reg: 0.5046  time: 0.1896  last_time: 0.1903  data_time: 0.0049  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:27:03] d2.utils.events INFO:  eta: 2:07:36  iter: 13559  total_loss: 3.797  loss_ce: 0.6316  loss_giou: 0.4077  loss_bbox: 0.4025  loss_ce_0: 0.6464  loss_giou_0: 0.438  loss_bbox_0: 0.445  loss_rpn_cls: 0.3097  loss_rpn_reg: 0.525  time: 0.1896  last_time: 0.1949  data_time: 0.0049  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:27:07] d2.utils.events INFO:  eta: 2:07:30  iter: 13579  total_loss: 3.534  loss_ce: 0.598  loss_giou: 0.4333  loss_bbox: 0.3884  loss_ce_0: 0.5848  loss_giou_0: 0.488  loss_bbox_0: 0.4462  loss_rpn_cls: 0.3014  loss_rpn_reg: 0.5307  time: 0.1896  last_time: 0.1855  data_time: 0.0047  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:27:11] d2.utils.events INFO:  eta: 2:07:21  iter: 13599  total_loss: 3.668  loss_ce: 0.6128  loss_giou: 0.4297  loss_bbox: 0.3191  loss_ce_0: 0.6084  loss_giou_0: 0.4307  loss_bbox_0: 0.3539  loss_rpn_cls: 0.3012  loss_rpn_reg: 0.5348  time: 0.1896  last_time: 0.1889  data_time: 0.0047  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:27:15] d2.utils.events INFO:  eta: 2:07:17  iter: 13619  total_loss: 3.646  loss_ce: 0.6341  loss_giou: 0.3771  loss_bbox: 0.3357  loss_ce_0: 0.6168  loss_giou_0: 0.4053  loss_bbox_0: 0.3689  loss_rpn_cls: 0.2993  loss_rpn_reg: 0.5365  time: 0.1896  last_time: 0.1922  data_time: 0.0047  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:27:19] d2.utils.events INFO:  eta: 2:07:20  iter: 13639  total_loss: 3.667  loss_ce: 0.6354  loss_giou: 0.4193  loss_bbox: 0.3148  loss_ce_0: 0.6116  loss_giou_0: 0.4664  loss_bbox_0: 0.3481  loss_rpn_cls: 0.3157  loss_rpn_reg: 0.5101  time: 0.1896  last_time: 0.2007  data_time: 0.0045  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:27:23] d2.utils.events INFO:  eta: 2:07:17  iter: 13659  total_loss: 3.486  loss_ce: 0.6099  loss_giou: 0.3765  loss_bbox: 0.3462  loss_ce_0: 0.5796  loss_giou_0: 0.414  loss_bbox_0: 0.4  loss_rpn_cls: 0.2667  loss_rpn_reg: 0.4967  time: 0.1896  last_time: 0.2003  data_time: 0.0047  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:27:27] d2.utils.events INFO:  eta: 2:07:13  iter: 13679  total_loss: 3.685  loss_ce: 0.5898  loss_giou: 0.4231  loss_bbox: 0.3461  loss_ce_0: 0.5826  loss_giou_0: 0.4388  loss_bbox_0: 0.379  loss_rpn_cls: 0.284  loss_rpn_reg: 0.5284  time: 0.1896  last_time: 0.1871  data_time: 0.0049  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 12:27:31] d2.utils.events INFO:  eta: 2:07:11  iter: 13699  total_loss: 3.976  loss_ce: 0.6628  loss_giou: 0.4796  loss_bbox: 0.4046  loss_ce_0: 0.6497  loss_giou_0: 0.5167  loss_bbox_0: 0.4354  loss_rpn_cls: 0.3336  loss_rpn_reg: 0.5598  time: 0.1896  last_time: 0.1865  data_time: 0.0049  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:27:35] d2.utils.events INFO:  eta: 2:07:10  iter: 13719  total_loss: 3.624  loss_ce: 0.6511  loss_giou: 0.385  loss_bbox: 0.322  loss_ce_0: 0.6534  loss_giou_0: 0.4254  loss_bbox_0: 0.3457  loss_rpn_cls: 0.2862  loss_rpn_reg: 0.5339  time: 0.1896  last_time: 0.1858  data_time: 0.0049  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:27:39] d2.utils.events INFO:  eta: 2:07:07  iter: 13739  total_loss: 4.003  loss_ce: 0.5877  loss_giou: 0.5144  loss_bbox: 0.3806  loss_ce_0: 0.6087  loss_giou_0: 0.5185  loss_bbox_0: 0.4567  loss_rpn_cls: 0.3116  loss_rpn_reg: 0.5701  time: 0.1896  last_time: 0.1741  data_time: 0.0049  last_data_time: 0.0025   lr: 5e-05  max_mem: 3029M
[03/05 12:27:42] d2.utils.events INFO:  eta: 2:07:01  iter: 13759  total_loss: 3.776  loss_ce: 0.6082  loss_giou: 0.4178  loss_bbox: 0.3808  loss_ce_0: 0.6408  loss_giou_0: 0.4434  loss_bbox_0: 0.4129  loss_rpn_cls: 0.2866  loss_rpn_reg: 0.5462  time: 0.1896  last_time: 0.1862  data_time: 0.0052  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:27:46] d2.utils.events INFO:  eta: 2:06:57  iter: 13779  total_loss: 3.579  loss_ce: 0.587  loss_giou: 0.4196  loss_bbox: 0.3975  loss_ce_0: 0.5685  loss_giou_0: 0.4259  loss_bbox_0: 0.4244  loss_rpn_cls: 0.2927  loss_rpn_reg: 0.5149  time: 0.1896  last_time: 0.2029  data_time: 0.0046  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:27:50] d2.utils.events INFO:  eta: 2:06:51  iter: 13799  total_loss: 3.568  loss_ce: 0.5845  loss_giou: 0.4086  loss_bbox: 0.3267  loss_ce_0: 0.5938  loss_giou_0: 0.4377  loss_bbox_0: 0.3765  loss_rpn_cls: 0.3001  loss_rpn_reg: 0.5427  time: 0.1896  last_time: 0.1965  data_time: 0.0048  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 12:27:54] d2.utils.events INFO:  eta: 2:06:47  iter: 13819  total_loss: 3.935  loss_ce: 0.7312  loss_giou: 0.4859  loss_bbox: 0.4097  loss_ce_0: 0.7142  loss_giou_0: 0.4722  loss_bbox_0: 0.4605  loss_rpn_cls: 0.319  loss_rpn_reg: 0.5496  time: 0.1896  last_time: 0.1766  data_time: 0.0046  last_data_time: 0.0027   lr: 5e-05  max_mem: 3029M
[03/05 12:27:58] d2.utils.events INFO:  eta: 2:06:39  iter: 13839  total_loss: 3.714  loss_ce: 0.5807  loss_giou: 0.3842  loss_bbox: 0.3712  loss_ce_0: 0.5796  loss_giou_0: 0.4155  loss_bbox_0: 0.4168  loss_rpn_cls: 0.2957  loss_rpn_reg: 0.5111  time: 0.1896  last_time: 0.1932  data_time: 0.0045  last_data_time: 0.0028   lr: 5e-05  max_mem: 3029M
[03/05 12:28:01] d2.utils.events INFO:  eta: 2:06:30  iter: 13859  total_loss: 3.726  loss_ce: 0.6502  loss_giou: 0.416  loss_bbox: 0.3856  loss_ce_0: 0.6295  loss_giou_0: 0.4345  loss_bbox_0: 0.4151  loss_rpn_cls: 0.3017  loss_rpn_reg: 0.5672  time: 0.1896  last_time: 0.1799  data_time: 0.0048  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:28:05] d2.utils.events INFO:  eta: 2:06:23  iter: 13879  total_loss: 3.613  loss_ce: 0.5867  loss_giou: 0.4322  loss_bbox: 0.3765  loss_ce_0: 0.6329  loss_giou_0: 0.4655  loss_bbox_0: 0.3845  loss_rpn_cls: 0.3078  loss_rpn_reg: 0.5128  time: 0.1896  last_time: 0.1616  data_time: 0.0050  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:28:09] d2.utils.events INFO:  eta: 2:06:14  iter: 13899  total_loss: 3.486  loss_ce: 0.6037  loss_giou: 0.3442  loss_bbox: 0.3309  loss_ce_0: 0.6123  loss_giou_0: 0.395  loss_bbox_0: 0.3625  loss_rpn_cls: 0.2738  loss_rpn_reg: 0.5059  time: 0.1896  last_time: 0.1805  data_time: 0.0046  last_data_time: 0.0020   lr: 5e-05  max_mem: 3029M
[03/05 12:28:13] d2.utils.events INFO:  eta: 2:06:10  iter: 13919  total_loss: 3.8  loss_ce: 0.6126  loss_giou: 0.392  loss_bbox: 0.3673  loss_ce_0: 0.6815  loss_giou_0: 0.3978  loss_bbox_0: 0.4157  loss_rpn_cls: 0.3203  loss_rpn_reg: 0.5556  time: 0.1896  last_time: 0.2074  data_time: 0.0047  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:28:17] d2.utils.events INFO:  eta: 2:06:06  iter: 13939  total_loss: 3.754  loss_ce: 0.5689  loss_giou: 0.3738  loss_bbox: 0.3117  loss_ce_0: 0.5637  loss_giou_0: 0.4185  loss_bbox_0: 0.3761  loss_rpn_cls: 0.3127  loss_rpn_reg: 0.5167  time: 0.1896  last_time: 0.2092  data_time: 0.0048  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 12:28:20] d2.utils.events INFO:  eta: 2:06:03  iter: 13959  total_loss: 3.64  loss_ce: 0.5975  loss_giou: 0.3811  loss_bbox: 0.3564  loss_ce_0: 0.6465  loss_giou_0: 0.3968  loss_bbox_0: 0.3913  loss_rpn_cls: 0.2886  loss_rpn_reg: 0.5271  time: 0.1896  last_time: 0.1866  data_time: 0.0050  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 12:28:24] d2.utils.events INFO:  eta: 2:05:55  iter: 13979  total_loss: 3.573  loss_ce: 0.6497  loss_giou: 0.3689  loss_bbox: 0.3033  loss_ce_0: 0.6323  loss_giou_0: 0.4018  loss_bbox_0: 0.3532  loss_rpn_cls: 0.298  loss_rpn_reg: 0.4941  time: 0.1896  last_time: 0.1857  data_time: 0.0047  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:28:28] d2.utils.events INFO:  eta: 2:05:55  iter: 13999  total_loss: 3.289  loss_ce: 0.4679  loss_giou: 0.3744  loss_bbox: 0.3388  loss_ce_0: 0.4944  loss_giou_0: 0.3731  loss_bbox_0: 0.3551  loss_rpn_cls: 0.2449  loss_rpn_reg: 0.5082  time: 0.1896  last_time: 0.1910  data_time: 0.0051  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 12:28:32] d2.utils.events INFO:  eta: 2:05:51  iter: 14019  total_loss: 3.487  loss_ce: 0.6144  loss_giou: 0.3561  loss_bbox: 0.3724  loss_ce_0: 0.6004  loss_giou_0: 0.3874  loss_bbox_0: 0.3685  loss_rpn_cls: 0.2948  loss_rpn_reg: 0.5267  time: 0.1896  last_time: 0.1944  data_time: 0.0045  last_data_time: 0.0026   lr: 5e-05  max_mem: 3029M
[03/05 12:28:36] d2.utils.events INFO:  eta: 2:05:47  iter: 14039  total_loss: 3.546  loss_ce: 0.565  loss_giou: 0.3722  loss_bbox: 0.3573  loss_ce_0: 0.6002  loss_giou_0: 0.4087  loss_bbox_0: 0.3897  loss_rpn_cls: 0.3259  loss_rpn_reg: 0.5369  time: 0.1896  last_time: 0.1790  data_time: 0.0046  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:28:40] d2.utils.events INFO:  eta: 2:05:49  iter: 14059  total_loss: 3.418  loss_ce: 0.5534  loss_giou: 0.3799  loss_bbox: 0.4175  loss_ce_0: 0.5678  loss_giou_0: 0.4104  loss_bbox_0: 0.3775  loss_rpn_cls: 0.2651  loss_rpn_reg: 0.4805  time: 0.1896  last_time: 0.2093  data_time: 0.0050  last_data_time: 0.0165   lr: 5e-05  max_mem: 3029M
[03/05 12:28:44] d2.utils.events INFO:  eta: 2:05:55  iter: 14079  total_loss: 3.803  loss_ce: 0.5736  loss_giou: 0.4095  loss_bbox: 0.34  loss_ce_0: 0.5789  loss_giou_0: 0.4391  loss_bbox_0: 0.4386  loss_rpn_cls: 0.2846  loss_rpn_reg: 0.5695  time: 0.1896  last_time: 0.1825  data_time: 0.0047  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 12:28:47] d2.utils.events INFO:  eta: 2:05:40  iter: 14099  total_loss: 3.507  loss_ce: 0.606  loss_giou: 0.3538  loss_bbox: 0.3323  loss_ce_0: 0.6034  loss_giou_0: 0.403  loss_bbox_0: 0.3764  loss_rpn_cls: 0.2738  loss_rpn_reg: 0.5084  time: 0.1896  last_time: 0.1597  data_time: 0.0044  last_data_time: 0.0031   lr: 5e-05  max_mem: 3029M
[03/05 12:28:51] d2.utils.events INFO:  eta: 2:05:36  iter: 14119  total_loss: 3.572  loss_ce: 0.5678  loss_giou: 0.3965  loss_bbox: 0.3808  loss_ce_0: 0.5712  loss_giou_0: 0.3853  loss_bbox_0: 0.3524  loss_rpn_cls: 0.2645  loss_rpn_reg: 0.5082  time: 0.1896  last_time: 0.1764  data_time: 0.0050  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 12:28:55] d2.utils.events INFO:  eta: 2:05:32  iter: 14139  total_loss: 4.112  loss_ce: 0.6606  loss_giou: 0.4863  loss_bbox: 0.4248  loss_ce_0: 0.6709  loss_giou_0: 0.4812  loss_bbox_0: 0.4987  loss_rpn_cls: 0.3315  loss_rpn_reg: 0.5149  time: 0.1896  last_time: 0.1598  data_time: 0.0051  last_data_time: 0.0027   lr: 5e-05  max_mem: 3029M
[03/05 12:28:59] d2.utils.events INFO:  eta: 2:05:26  iter: 14159  total_loss: 3.736  loss_ce: 0.6645  loss_giou: 0.3602  loss_bbox: 0.3706  loss_ce_0: 0.684  loss_giou_0: 0.3395  loss_bbox_0: 0.3947  loss_rpn_cls: 0.3051  loss_rpn_reg: 0.5265  time: 0.1896  last_time: 0.1833  data_time: 0.0049  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:29:03] d2.utils.events INFO:  eta: 2:05:23  iter: 14179  total_loss: 3.536  loss_ce: 0.5188  loss_giou: 0.3901  loss_bbox: 0.3419  loss_ce_0: 0.554  loss_giou_0: 0.3928  loss_bbox_0: 0.3874  loss_rpn_cls: 0.2818  loss_rpn_reg: 0.503  time: 0.1896  last_time: 0.1825  data_time: 0.0050  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:29:06] d2.utils.events INFO:  eta: 2:05:17  iter: 14199  total_loss: 3.496  loss_ce: 0.59  loss_giou: 0.4367  loss_bbox: 0.3442  loss_ce_0: 0.5913  loss_giou_0: 0.431  loss_bbox_0: 0.3688  loss_rpn_cls: 0.2623  loss_rpn_reg: 0.5038  time: 0.1896  last_time: 0.1798  data_time: 0.0045  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:29:10] d2.utils.events INFO:  eta: 2:05:06  iter: 14219  total_loss: 3.409  loss_ce: 0.5935  loss_giou: 0.3501  loss_bbox: 0.3288  loss_ce_0: 0.6036  loss_giou_0: 0.3763  loss_bbox_0: 0.3724  loss_rpn_cls: 0.2957  loss_rpn_reg: 0.4737  time: 0.1896  last_time: 0.1960  data_time: 0.0049  last_data_time: 0.0031   lr: 5e-05  max_mem: 3029M
[03/05 12:29:14] d2.utils.events INFO:  eta: 2:04:59  iter: 14239  total_loss: 3.639  loss_ce: 0.5916  loss_giou: 0.42  loss_bbox: 0.4244  loss_ce_0: 0.626  loss_giou_0: 0.4556  loss_bbox_0: 0.4513  loss_rpn_cls: 0.2934  loss_rpn_reg: 0.5245  time: 0.1896  last_time: 0.2171  data_time: 0.0053  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:29:18] d2.utils.events INFO:  eta: 2:05:06  iter: 14259  total_loss: 3.865  loss_ce: 0.6565  loss_giou: 0.3473  loss_bbox: 0.4188  loss_ce_0: 0.6512  loss_giou_0: 0.3794  loss_bbox_0: 0.4383  loss_rpn_cls: 0.3077  loss_rpn_reg: 0.5025  time: 0.1896  last_time: 0.1924  data_time: 0.0053  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:29:22] d2.utils.events INFO:  eta: 2:05:03  iter: 14279  total_loss: 3.573  loss_ce: 0.6306  loss_giou: 0.4273  loss_bbox: 0.3559  loss_ce_0: 0.5984  loss_giou_0: 0.4459  loss_bbox_0: 0.3807  loss_rpn_cls: 0.3125  loss_rpn_reg: 0.5195  time: 0.1896  last_time: 0.1778  data_time: 0.0050  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:29:26] d2.utils.events INFO:  eta: 2:04:59  iter: 14299  total_loss: 3.566  loss_ce: 0.5209  loss_giou: 0.4026  loss_bbox: 0.3523  loss_ce_0: 0.5396  loss_giou_0: 0.4181  loss_bbox_0: 0.4142  loss_rpn_cls: 0.2768  loss_rpn_reg: 0.5118  time: 0.1896  last_time: 0.1899  data_time: 0.0050  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:29:30] d2.utils.events INFO:  eta: 2:04:55  iter: 14319  total_loss: 3.184  loss_ce: 0.5705  loss_giou: 0.3264  loss_bbox: 0.3353  loss_ce_0: 0.5489  loss_giou_0: 0.3341  loss_bbox_0: 0.3376  loss_rpn_cls: 0.2411  loss_rpn_reg: 0.5175  time: 0.1896  last_time: 0.1988  data_time: 0.0047  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:29:34] d2.utils.events INFO:  eta: 2:04:52  iter: 14339  total_loss: 3.587  loss_ce: 0.6384  loss_giou: 0.3668  loss_bbox: 0.3309  loss_ce_0: 0.6581  loss_giou_0: 0.413  loss_bbox_0: 0.3763  loss_rpn_cls: 0.2824  loss_rpn_reg: 0.5052  time: 0.1896  last_time: 0.2220  data_time: 0.0051  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:29:38] d2.utils.events INFO:  eta: 2:04:54  iter: 14359  total_loss: 3.457  loss_ce: 0.5343  loss_giou: 0.3795  loss_bbox: 0.3641  loss_ce_0: 0.6067  loss_giou_0: 0.3898  loss_bbox_0: 0.3998  loss_rpn_cls: 0.2718  loss_rpn_reg: 0.4972  time: 0.1896  last_time: 0.2112  data_time: 0.0046  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:29:42] d2.utils.events INFO:  eta: 2:04:48  iter: 14379  total_loss: 3.417  loss_ce: 0.5253  loss_giou: 0.4194  loss_bbox: 0.35  loss_ce_0: 0.5001  loss_giou_0: 0.461  loss_bbox_0: 0.401  loss_rpn_cls: 0.2786  loss_rpn_reg: 0.5219  time: 0.1896  last_time: 0.1824  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:29:46] d2.utils.events INFO:  eta: 2:04:43  iter: 14399  total_loss: 3.699  loss_ce: 0.5749  loss_giou: 0.4192  loss_bbox: 0.3616  loss_ce_0: 0.5648  loss_giou_0: 0.448  loss_bbox_0: 0.3691  loss_rpn_cls: 0.2695  loss_rpn_reg: 0.5084  time: 0.1896  last_time: 0.1829  data_time: 0.0046  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:29:49] d2.utils.events INFO:  eta: 2:04:38  iter: 14419  total_loss: 3.207  loss_ce: 0.5603  loss_giou: 0.3455  loss_bbox: 0.3282  loss_ce_0: 0.5812  loss_giou_0: 0.3692  loss_bbox_0: 0.3418  loss_rpn_cls: 0.2726  loss_rpn_reg: 0.4932  time: 0.1896  last_time: 0.1771  data_time: 0.0053  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:29:54] d2.utils.events INFO:  eta: 2:04:46  iter: 14439  total_loss: 3.752  loss_ce: 0.6381  loss_giou: 0.3941  loss_bbox: 0.4158  loss_ce_0: 0.6404  loss_giou_0: 0.4534  loss_bbox_0: 0.4735  loss_rpn_cls: 0.2629  loss_rpn_reg: 0.5724  time: 0.1896  last_time: 0.2094  data_time: 0.0048  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:29:57] d2.utils.events INFO:  eta: 2:04:32  iter: 14459  total_loss: 3.8  loss_ce: 0.6012  loss_giou: 0.4216  loss_bbox: 0.4049  loss_ce_0: 0.6332  loss_giou_0: 0.4242  loss_bbox_0: 0.3583  loss_rpn_cls: 0.3057  loss_rpn_reg: 0.534  time: 0.1896  last_time: 0.2132  data_time: 0.0054  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 12:30:01] d2.utils.events INFO:  eta: 2:04:39  iter: 14479  total_loss: 3.772  loss_ce: 0.5977  loss_giou: 0.4887  loss_bbox: 0.3594  loss_ce_0: 0.5735  loss_giou_0: 0.5145  loss_bbox_0: 0.3888  loss_rpn_cls: 0.311  loss_rpn_reg: 0.5368  time: 0.1897  last_time: 0.1893  data_time: 0.0055  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:30:05] d2.utils.events INFO:  eta: 2:04:41  iter: 14499  total_loss: 3.729  loss_ce: 0.6151  loss_giou: 0.4113  loss_bbox: 0.4044  loss_ce_0: 0.604  loss_giou_0: 0.4229  loss_bbox_0: 0.4396  loss_rpn_cls: 0.2981  loss_rpn_reg: 0.5432  time: 0.1897  last_time: 0.2005  data_time: 0.0049  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:30:09] d2.utils.events INFO:  eta: 2:04:38  iter: 14519  total_loss: 3.629  loss_ce: 0.5852  loss_giou: 0.3855  loss_bbox: 0.4155  loss_ce_0: 0.569  loss_giou_0: 0.4095  loss_bbox_0: 0.4061  loss_rpn_cls: 0.3042  loss_rpn_reg: 0.519  time: 0.1897  last_time: 0.2101  data_time: 0.0051  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 12:30:13] d2.utils.events INFO:  eta: 2:04:45  iter: 14539  total_loss: 3.609  loss_ce: 0.5874  loss_giou: 0.3677  loss_bbox: 0.327  loss_ce_0: 0.6183  loss_giou_0: 0.4044  loss_bbox_0: 0.3809  loss_rpn_cls: 0.3093  loss_rpn_reg: 0.5039  time: 0.1897  last_time: 0.2043  data_time: 0.0047  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 12:30:17] d2.utils.events INFO:  eta: 2:04:45  iter: 14559  total_loss: 3.531  loss_ce: 0.5598  loss_giou: 0.3909  loss_bbox: 0.3646  loss_ce_0: 0.5806  loss_giou_0: 0.4485  loss_bbox_0: 0.4262  loss_rpn_cls: 0.3003  loss_rpn_reg: 0.5082  time: 0.1897  last_time: 0.2252  data_time: 0.0059  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:30:21] d2.utils.events INFO:  eta: 2:04:41  iter: 14579  total_loss: 3.659  loss_ce: 0.5846  loss_giou: 0.3904  loss_bbox: 0.3832  loss_ce_0: 0.6011  loss_giou_0: 0.4105  loss_bbox_0: 0.4239  loss_rpn_cls: 0.2732  loss_rpn_reg: 0.5259  time: 0.1897  last_time: 0.2091  data_time: 0.0056  last_data_time: 0.0149   lr: 5e-05  max_mem: 3029M
[03/05 12:30:25] d2.utils.events INFO:  eta: 2:04:50  iter: 14599  total_loss: 3.711  loss_ce: 0.581  loss_giou: 0.4015  loss_bbox: 0.3815  loss_ce_0: 0.5812  loss_giou_0: 0.4265  loss_bbox_0: 0.4317  loss_rpn_cls: 0.276  loss_rpn_reg: 0.5433  time: 0.1897  last_time: 0.1956  data_time: 0.0059  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:30:29] d2.utils.events INFO:  eta: 2:04:49  iter: 14619  total_loss: 3.591  loss_ce: 0.592  loss_giou: 0.4224  loss_bbox: 0.3426  loss_ce_0: 0.568  loss_giou_0: 0.441  loss_bbox_0: 0.3666  loss_rpn_cls: 0.3021  loss_rpn_reg: 0.5232  time: 0.1897  last_time: 0.1879  data_time: 0.0045  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:30:33] d2.utils.events INFO:  eta: 2:04:43  iter: 14639  total_loss: 3.569  loss_ce: 0.6085  loss_giou: 0.398  loss_bbox: 0.3918  loss_ce_0: 0.603  loss_giou_0: 0.4367  loss_bbox_0: 0.3786  loss_rpn_cls: 0.3139  loss_rpn_reg: 0.5059  time: 0.1897  last_time: 0.2153  data_time: 0.0065  last_data_time: 0.0271   lr: 5e-05  max_mem: 3029M
[03/05 12:30:37] d2.utils.events INFO:  eta: 2:04:41  iter: 14659  total_loss: 3.875  loss_ce: 0.6453  loss_giou: 0.4329  loss_bbox: 0.3914  loss_ce_0: 0.6408  loss_giou_0: 0.4662  loss_bbox_0: 0.4227  loss_rpn_cls: 0.3097  loss_rpn_reg: 0.5478  time: 0.1897  last_time: 0.1968  data_time: 0.0054  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:30:41] d2.utils.events INFO:  eta: 2:04:42  iter: 14679  total_loss: 3.926  loss_ce: 0.6382  loss_giou: 0.4145  loss_bbox: 0.3748  loss_ce_0: 0.603  loss_giou_0: 0.4489  loss_bbox_0: 0.4317  loss_rpn_cls: 0.3432  loss_rpn_reg: 0.5482  time: 0.1897  last_time: 0.2060  data_time: 0.0056  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:30:45] d2.utils.events INFO:  eta: 2:04:37  iter: 14699  total_loss: 3.463  loss_ce: 0.5306  loss_giou: 0.3868  loss_bbox: 0.3206  loss_ce_0: 0.5671  loss_giou_0: 0.4136  loss_bbox_0: 0.3401  loss_rpn_cls: 0.2827  loss_rpn_reg: 0.5028  time: 0.1897  last_time: 0.1792  data_time: 0.0047  last_data_time: 0.0009   lr: 5e-05  max_mem: 3029M
[03/05 12:30:49] d2.utils.events INFO:  eta: 2:04:29  iter: 14719  total_loss: 3.671  loss_ce: 0.5662  loss_giou: 0.3852  loss_bbox: 0.4036  loss_ce_0: 0.5577  loss_giou_0: 0.4177  loss_bbox_0: 0.4433  loss_rpn_cls: 0.312  loss_rpn_reg: 0.5346  time: 0.1897  last_time: 0.1843  data_time: 0.0052  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 12:30:52] d2.utils.events INFO:  eta: 2:04:22  iter: 14739  total_loss: 3.805  loss_ce: 0.5601  loss_giou: 0.4013  loss_bbox: 0.3439  loss_ce_0: 0.6321  loss_giou_0: 0.4062  loss_bbox_0: 0.3902  loss_rpn_cls: 0.3072  loss_rpn_reg: 0.5066  time: 0.1897  last_time: 0.1891  data_time: 0.0057  last_data_time: 0.0064   lr: 5e-05  max_mem: 3029M
[03/05 12:30:56] d2.utils.events INFO:  eta: 2:04:24  iter: 14759  total_loss: 3.522  loss_ce: 0.5045  loss_giou: 0.3863  loss_bbox: 0.3382  loss_ce_0: 0.4905  loss_giou_0: 0.4033  loss_bbox_0: 0.3953  loss_rpn_cls: 0.2895  loss_rpn_reg: 0.5098  time: 0.1897  last_time: 0.2132  data_time: 0.0051  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:31:00] d2.utils.events INFO:  eta: 2:04:25  iter: 14779  total_loss: 3.691  loss_ce: 0.5695  loss_giou: 0.3634  loss_bbox: 0.3909  loss_ce_0: 0.6285  loss_giou_0: 0.3871  loss_bbox_0: 0.4197  loss_rpn_cls: 0.2786  loss_rpn_reg: 0.5082  time: 0.1897  last_time: 0.1921  data_time: 0.0048  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:31:04] d2.utils.events INFO:  eta: 2:04:31  iter: 14799  total_loss: 3.648  loss_ce: 0.6438  loss_giou: 0.3453  loss_bbox: 0.3557  loss_ce_0: 0.6516  loss_giou_0: 0.3491  loss_bbox_0: 0.3865  loss_rpn_cls: 0.2879  loss_rpn_reg: 0.5064  time: 0.1897  last_time: 0.1907  data_time: 0.0048  last_data_time: 0.0030   lr: 5e-05  max_mem: 3029M
[03/05 12:31:08] d2.utils.events INFO:  eta: 2:04:31  iter: 14819  total_loss: 3.821  loss_ce: 0.598  loss_giou: 0.4496  loss_bbox: 0.4019  loss_ce_0: 0.6228  loss_giou_0: 0.4599  loss_bbox_0: 0.4224  loss_rpn_cls: 0.2962  loss_rpn_reg: 0.5357  time: 0.1897  last_time: 0.1910  data_time: 0.0054  last_data_time: 0.0026   lr: 5e-05  max_mem: 3029M
[03/05 12:31:12] d2.utils.events INFO:  eta: 2:04:34  iter: 14839  total_loss: 3.827  loss_ce: 0.5793  loss_giou: 0.4057  loss_bbox: 0.3449  loss_ce_0: 0.614  loss_giou_0: 0.4175  loss_bbox_0: 0.3852  loss_rpn_cls: 0.2956  loss_rpn_reg: 0.5368  time: 0.1897  last_time: 0.1793  data_time: 0.0052  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:31:16] d2.utils.events INFO:  eta: 2:04:36  iter: 14859  total_loss: 3.414  loss_ce: 0.5367  loss_giou: 0.3554  loss_bbox: 0.3541  loss_ce_0: 0.5958  loss_giou_0: 0.378  loss_bbox_0: 0.4063  loss_rpn_cls: 0.2778  loss_rpn_reg: 0.4704  time: 0.1897  last_time: 0.1865  data_time: 0.0050  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 12:31:19] d2.utils.events INFO:  eta: 2:04:33  iter: 14879  total_loss: 3.73  loss_ce: 0.6065  loss_giou: 0.4571  loss_bbox: 0.3649  loss_ce_0: 0.5896  loss_giou_0: 0.4822  loss_bbox_0: 0.4079  loss_rpn_cls: 0.3027  loss_rpn_reg: 0.5394  time: 0.1897  last_time: 0.1725  data_time: 0.0047  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:31:23] d2.utils.events INFO:  eta: 2:04:33  iter: 14899  total_loss: 3.586  loss_ce: 0.6125  loss_giou: 0.3584  loss_bbox: 0.3472  loss_ce_0: 0.6375  loss_giou_0: 0.3794  loss_bbox_0: 0.3944  loss_rpn_cls: 0.2991  loss_rpn_reg: 0.4785  time: 0.1897  last_time: 0.1915  data_time: 0.0051  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:31:27] d2.utils.events INFO:  eta: 2:04:29  iter: 14919  total_loss: 3.458  loss_ce: 0.4919  loss_giou: 0.4037  loss_bbox: 0.3194  loss_ce_0: 0.5325  loss_giou_0: 0.4272  loss_bbox_0: 0.3607  loss_rpn_cls: 0.2546  loss_rpn_reg: 0.4978  time: 0.1897  last_time: 0.1635  data_time: 0.0047  last_data_time: 0.0024   lr: 5e-05  max_mem: 3029M
[03/05 12:31:31] d2.utils.events INFO:  eta: 2:04:26  iter: 14939  total_loss: 3.531  loss_ce: 0.6028  loss_giou: 0.391  loss_bbox: 0.3431  loss_ce_0: 0.5725  loss_giou_0: 0.4227  loss_bbox_0: 0.3601  loss_rpn_cls: 0.2785  loss_rpn_reg: 0.5089  time: 0.1897  last_time: 0.1719  data_time: 0.0059  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:31:35] d2.utils.events INFO:  eta: 2:04:20  iter: 14959  total_loss: 3.726  loss_ce: 0.678  loss_giou: 0.3392  loss_bbox: 0.3847  loss_ce_0: 0.6336  loss_giou_0: 0.3645  loss_bbox_0: 0.4644  loss_rpn_cls: 0.3042  loss_rpn_reg: 0.5507  time: 0.1897  last_time: 0.1873  data_time: 0.0045  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 12:31:39] d2.utils.events INFO:  eta: 2:04:15  iter: 14979  total_loss: 3.76  loss_ce: 0.5884  loss_giou: 0.4443  loss_bbox: 0.3704  loss_ce_0: 0.6162  loss_giou_0: 0.4521  loss_bbox_0: 0.3822  loss_rpn_cls: 0.3076  loss_rpn_reg: 0.5377  time: 0.1897  last_time: 0.1978  data_time: 0.0056  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:31:42] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/t1/model_0014999.pth
[03/05 12:31:44] d2.utils.events INFO:  eta: 2:04:11  iter: 14999  total_loss: 3.57  loss_ce: 0.5796  loss_giou: 0.395  loss_bbox: 0.3576  loss_ce_0: 0.5975  loss_giou_0: 0.3976  loss_bbox_0: 0.4017  loss_rpn_cls: 0.3316  loss_rpn_reg: 0.4904  time: 0.1897  last_time: 0.1787  data_time: 0.0050  last_data_time: 0.0067   lr: 5e-05  max_mem: 3029M
[03/05 12:31:48] d2.utils.events INFO:  eta: 2:04:03  iter: 15019  total_loss: 3.585  loss_ce: 0.53  loss_giou: 0.382  loss_bbox: 0.3671  loss_ce_0: 0.54  loss_giou_0: 0.4299  loss_bbox_0: 0.3915  loss_rpn_cls: 0.2873  loss_rpn_reg: 0.5182  time: 0.1897  last_time: 0.1660  data_time: 0.0062  last_data_time: 0.0126   lr: 5e-05  max_mem: 3029M
[03/05 12:31:51] d2.utils.events INFO:  eta: 2:04:00  iter: 15039  total_loss: 3.356  loss_ce: 0.5389  loss_giou: 0.333  loss_bbox: 0.3145  loss_ce_0: 0.5811  loss_giou_0: 0.3775  loss_bbox_0: 0.4028  loss_rpn_cls: 0.259  loss_rpn_reg: 0.5057  time: 0.1897  last_time: 0.2086  data_time: 0.0050  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:31:55] d2.utils.events INFO:  eta: 2:03:41  iter: 15059  total_loss: 3.711  loss_ce: 0.5657  loss_giou: 0.4468  loss_bbox: 0.3178  loss_ce_0: 0.5624  loss_giou_0: 0.4714  loss_bbox_0: 0.3485  loss_rpn_cls: 0.3032  loss_rpn_reg: 0.5333  time: 0.1897  last_time: 0.1870  data_time: 0.0050  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:31:59] d2.utils.events INFO:  eta: 2:03:32  iter: 15079  total_loss: 3.653  loss_ce: 0.6439  loss_giou: 0.3776  loss_bbox: 0.3877  loss_ce_0: 0.6443  loss_giou_0: 0.3908  loss_bbox_0: 0.4304  loss_rpn_cls: 0.2808  loss_rpn_reg: 0.5253  time: 0.1897  last_time: 0.2000  data_time: 0.0049  last_data_time: 0.0075   lr: 5e-05  max_mem: 3029M
[03/05 12:32:03] d2.utils.events INFO:  eta: 2:03:29  iter: 15099  total_loss: 3.913  loss_ce: 0.6626  loss_giou: 0.4016  loss_bbox: 0.3989  loss_ce_0: 0.6439  loss_giou_0: 0.4087  loss_bbox_0: 0.435  loss_rpn_cls: 0.2824  loss_rpn_reg: 0.5141  time: 0.1897  last_time: 0.1810  data_time: 0.0049  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:32:07] d2.utils.events INFO:  eta: 2:03:31  iter: 15119  total_loss: 3.948  loss_ce: 0.6662  loss_giou: 0.4209  loss_bbox: 0.4303  loss_ce_0: 0.7296  loss_giou_0: 0.436  loss_bbox_0: 0.4629  loss_rpn_cls: 0.3167  loss_rpn_reg: 0.5499  time: 0.1897  last_time: 0.1987  data_time: 0.0056  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:32:11] d2.utils.events INFO:  eta: 2:03:30  iter: 15139  total_loss: 3.673  loss_ce: 0.6005  loss_giou: 0.4244  loss_bbox: 0.3232  loss_ce_0: 0.6118  loss_giou_0: 0.4545  loss_bbox_0: 0.3551  loss_rpn_cls: 0.256  loss_rpn_reg: 0.5301  time: 0.1897  last_time: 0.2006  data_time: 0.0052  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 12:32:15] d2.utils.events INFO:  eta: 2:03:39  iter: 15159  total_loss: 3.475  loss_ce: 0.6248  loss_giou: 0.3929  loss_bbox: 0.3299  loss_ce_0: 0.6144  loss_giou_0: 0.4118  loss_bbox_0: 0.3441  loss_rpn_cls: 0.2862  loss_rpn_reg: 0.5006  time: 0.1897  last_time: 0.1581  data_time: 0.0051  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:32:19] d2.utils.events INFO:  eta: 2:03:38  iter: 15179  total_loss: 3.466  loss_ce: 0.5534  loss_giou: 0.3466  loss_bbox: 0.3641  loss_ce_0: 0.5707  loss_giou_0: 0.3784  loss_bbox_0: 0.4134  loss_rpn_cls: 0.2853  loss_rpn_reg: 0.4963  time: 0.1897  last_time: 0.1775  data_time: 0.0049  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:32:23] d2.utils.events INFO:  eta: 2:03:36  iter: 15199  total_loss: 3.41  loss_ce: 0.6104  loss_giou: 0.3508  loss_bbox: 0.3671  loss_ce_0: 0.591  loss_giou_0: 0.3734  loss_bbox_0: 0.4501  loss_rpn_cls: 0.2786  loss_rpn_reg: 0.4861  time: 0.1897  last_time: 0.1880  data_time: 0.0045  last_data_time: 0.0064   lr: 5e-05  max_mem: 3029M
[03/05 12:32:27] d2.utils.events INFO:  eta: 2:03:33  iter: 15219  total_loss: 3.532  loss_ce: 0.4853  loss_giou: 0.4015  loss_bbox: 0.3808  loss_ce_0: 0.5755  loss_giou_0: 0.4036  loss_bbox_0: 0.4274  loss_rpn_cls: 0.2727  loss_rpn_reg: 0.4682  time: 0.1898  last_time: 0.2159  data_time: 0.0051  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:32:31] d2.utils.events INFO:  eta: 2:03:29  iter: 15239  total_loss: 3.938  loss_ce: 0.6456  loss_giou: 0.3915  loss_bbox: 0.4233  loss_ce_0: 0.6021  loss_giou_0: 0.4443  loss_bbox_0: 0.494  loss_rpn_cls: 0.2683  loss_rpn_reg: 0.5303  time: 0.1898  last_time: 0.1905  data_time: 0.0049  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 12:32:34] d2.utils.events INFO:  eta: 2:03:22  iter: 15259  total_loss: 3.695  loss_ce: 0.5888  loss_giou: 0.4338  loss_bbox: 0.3315  loss_ce_0: 0.5911  loss_giou_0: 0.4341  loss_bbox_0: 0.365  loss_rpn_cls: 0.2765  loss_rpn_reg: 0.5197  time: 0.1897  last_time: 0.2037  data_time: 0.0048  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:32:38] d2.utils.events INFO:  eta: 2:03:20  iter: 15279  total_loss: 3.474  loss_ce: 0.5868  loss_giou: 0.3972  loss_bbox: 0.3091  loss_ce_0: 0.5716  loss_giou_0: 0.4424  loss_bbox_0: 0.3737  loss_rpn_cls: 0.2895  loss_rpn_reg: 0.5336  time: 0.1897  last_time: 0.1679  data_time: 0.0054  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:32:42] d2.utils.events INFO:  eta: 2:03:15  iter: 15299  total_loss: 3.637  loss_ce: 0.5733  loss_giou: 0.3565  loss_bbox: 0.4068  loss_ce_0: 0.5765  loss_giou_0: 0.3867  loss_bbox_0: 0.4272  loss_rpn_cls: 0.2591  loss_rpn_reg: 0.5277  time: 0.1897  last_time: 0.1658  data_time: 0.0053  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:32:46] d2.utils.events INFO:  eta: 2:03:07  iter: 15319  total_loss: 3.849  loss_ce: 0.5808  loss_giou: 0.3888  loss_bbox: 0.4209  loss_ce_0: 0.5886  loss_giou_0: 0.432  loss_bbox_0: 0.4412  loss_rpn_cls: 0.2642  loss_rpn_reg: 0.5562  time: 0.1897  last_time: 0.1647  data_time: 0.0060  last_data_time: 0.0019   lr: 5e-05  max_mem: 3029M
[03/05 12:32:50] d2.utils.events INFO:  eta: 2:03:00  iter: 15339  total_loss: 3.519  loss_ce: 0.6202  loss_giou: 0.351  loss_bbox: 0.3898  loss_ce_0: 0.5881  loss_giou_0: 0.3652  loss_bbox_0: 0.3971  loss_rpn_cls: 0.2552  loss_rpn_reg: 0.5438  time: 0.1897  last_time: 0.1687  data_time: 0.0049  last_data_time: 0.0031   lr: 5e-05  max_mem: 3029M
[03/05 12:32:54] d2.utils.events INFO:  eta: 2:03:00  iter: 15359  total_loss: 3.971  loss_ce: 0.6005  loss_giou: 0.3878  loss_bbox: 0.402  loss_ce_0: 0.6329  loss_giou_0: 0.4207  loss_bbox_0: 0.4293  loss_rpn_cls: 0.3131  loss_rpn_reg: 0.5244  time: 0.1897  last_time: 0.2010  data_time: 0.0047  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:32:57] d2.utils.events INFO:  eta: 2:02:58  iter: 15379  total_loss: 3.657  loss_ce: 0.5774  loss_giou: 0.4273  loss_bbox: 0.363  loss_ce_0: 0.5921  loss_giou_0: 0.4395  loss_bbox_0: 0.4632  loss_rpn_cls: 0.3094  loss_rpn_reg: 0.5596  time: 0.1897  last_time: 0.2009  data_time: 0.0048  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:33:01] d2.utils.events INFO:  eta: 2:02:52  iter: 15399  total_loss: 3.302  loss_ce: 0.6315  loss_giou: 0.3313  loss_bbox: 0.3359  loss_ce_0: 0.6172  loss_giou_0: 0.3744  loss_bbox_0: 0.3438  loss_rpn_cls: 0.2617  loss_rpn_reg: 0.5099  time: 0.1897  last_time: 0.1808  data_time: 0.0048  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:33:05] d2.utils.events INFO:  eta: 2:02:44  iter: 15419  total_loss: 3.744  loss_ce: 0.5961  loss_giou: 0.4241  loss_bbox: 0.3709  loss_ce_0: 0.5639  loss_giou_0: 0.4453  loss_bbox_0: 0.4198  loss_rpn_cls: 0.2961  loss_rpn_reg: 0.5319  time: 0.1897  last_time: 0.2019  data_time: 0.0041  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:33:09] d2.utils.events INFO:  eta: 2:02:26  iter: 15439  total_loss: 3.76  loss_ce: 0.5282  loss_giou: 0.4049  loss_bbox: 0.3665  loss_ce_0: 0.5703  loss_giou_0: 0.4371  loss_bbox_0: 0.3943  loss_rpn_cls: 0.2808  loss_rpn_reg: 0.5714  time: 0.1897  last_time: 0.1854  data_time: 0.0045  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:33:13] d2.utils.events INFO:  eta: 2:02:23  iter: 15459  total_loss: 3.719  loss_ce: 0.5813  loss_giou: 0.4847  loss_bbox: 0.4242  loss_ce_0: 0.6366  loss_giou_0: 0.4438  loss_bbox_0: 0.4302  loss_rpn_cls: 0.3091  loss_rpn_reg: 0.4887  time: 0.1897  last_time: 0.1957  data_time: 0.0045  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:33:17] d2.utils.events INFO:  eta: 2:02:22  iter: 15479  total_loss: 3.579  loss_ce: 0.6175  loss_giou: 0.417  loss_bbox: 0.36  loss_ce_0: 0.5735  loss_giou_0: 0.4506  loss_bbox_0: 0.3947  loss_rpn_cls: 0.2795  loss_rpn_reg: 0.5268  time: 0.1897  last_time: 0.1965  data_time: 0.0049  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:33:21] d2.utils.events INFO:  eta: 2:02:17  iter: 15499  total_loss: 3.094  loss_ce: 0.5241  loss_giou: 0.3145  loss_bbox: 0.284  loss_ce_0: 0.5341  loss_giou_0: 0.3454  loss_bbox_0: 0.3119  loss_rpn_cls: 0.2517  loss_rpn_reg: 0.4725  time: 0.1897  last_time: 0.1566  data_time: 0.0048  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:33:24] d2.utils.events INFO:  eta: 2:02:07  iter: 15519  total_loss: 3.784  loss_ce: 0.5727  loss_giou: 0.4176  loss_bbox: 0.3799  loss_ce_0: 0.5997  loss_giou_0: 0.4341  loss_bbox_0: 0.4384  loss_rpn_cls: 0.253  loss_rpn_reg: 0.5348  time: 0.1897  last_time: 0.1536  data_time: 0.0050  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:33:28] d2.utils.events INFO:  eta: 2:02:04  iter: 15539  total_loss: 3.314  loss_ce: 0.5648  loss_giou: 0.3481  loss_bbox: 0.3277  loss_ce_0: 0.5777  loss_giou_0: 0.3788  loss_bbox_0: 0.358  loss_rpn_cls: 0.283  loss_rpn_reg: 0.4892  time: 0.1897  last_time: 0.2323  data_time: 0.0051  last_data_time: 0.0090   lr: 5e-05  max_mem: 3029M
[03/05 12:33:32] d2.utils.events INFO:  eta: 2:02:01  iter: 15559  total_loss: 3.371  loss_ce: 0.4905  loss_giou: 0.3965  loss_bbox: 0.3454  loss_ce_0: 0.5444  loss_giou_0: 0.3954  loss_bbox_0: 0.3673  loss_rpn_cls: 0.293  loss_rpn_reg: 0.517  time: 0.1897  last_time: 0.2168  data_time: 0.0060  last_data_time: 0.0142   lr: 5e-05  max_mem: 3029M
[03/05 12:33:36] d2.utils.events INFO:  eta: 2:01:58  iter: 15579  total_loss: 3.57  loss_ce: 0.609  loss_giou: 0.3238  loss_bbox: 0.3603  loss_ce_0: 0.5904  loss_giou_0: 0.3495  loss_bbox_0: 0.4255  loss_rpn_cls: 0.2906  loss_rpn_reg: 0.4764  time: 0.1897  last_time: 0.1903  data_time: 0.0053  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:33:40] d2.utils.events INFO:  eta: 2:01:47  iter: 15599  total_loss: 3.475  loss_ce: 0.5555  loss_giou: 0.3721  loss_bbox: 0.3545  loss_ce_0: 0.5338  loss_giou_0: 0.3915  loss_bbox_0: 0.3875  loss_rpn_cls: 0.2915  loss_rpn_reg: 0.4695  time: 0.1897  last_time: 0.1887  data_time: 0.0046  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 12:33:43] d2.utils.events INFO:  eta: 2:01:41  iter: 15619  total_loss: 3.46  loss_ce: 0.5484  loss_giou: 0.3654  loss_bbox: 0.3467  loss_ce_0: 0.6012  loss_giou_0: 0.4131  loss_bbox_0: 0.3548  loss_rpn_cls: 0.262  loss_rpn_reg: 0.4841  time: 0.1897  last_time: 0.1737  data_time: 0.0049  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:33:47] d2.utils.events INFO:  eta: 2:01:36  iter: 15639  total_loss: 3.269  loss_ce: 0.5434  loss_giou: 0.3279  loss_bbox: 0.3161  loss_ce_0: 0.5981  loss_giou_0: 0.3562  loss_bbox_0: 0.3728  loss_rpn_cls: 0.261  loss_rpn_reg: 0.5013  time: 0.1897  last_time: 0.1875  data_time: 0.0050  last_data_time: 0.0030   lr: 5e-05  max_mem: 3029M
[03/05 12:33:51] d2.utils.events INFO:  eta: 2:01:30  iter: 15659  total_loss: 3.716  loss_ce: 0.5511  loss_giou: 0.4043  loss_bbox: 0.3162  loss_ce_0: 0.5937  loss_giou_0: 0.4243  loss_bbox_0: 0.4053  loss_rpn_cls: 0.2877  loss_rpn_reg: 0.5372  time: 0.1897  last_time: 0.1977  data_time: 0.0048  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:33:55] d2.utils.events INFO:  eta: 2:01:20  iter: 15679  total_loss: 3.535  loss_ce: 0.605  loss_giou: 0.3829  loss_bbox: 0.3775  loss_ce_0: 0.6144  loss_giou_0: 0.4057  loss_bbox_0: 0.4176  loss_rpn_cls: 0.3191  loss_rpn_reg: 0.485  time: 0.1897  last_time: 0.1999  data_time: 0.0045  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:33:59] d2.utils.events INFO:  eta: 2:01:19  iter: 15699  total_loss: 3.448  loss_ce: 0.616  loss_giou: 0.3483  loss_bbox: 0.3387  loss_ce_0: 0.5949  loss_giou_0: 0.4021  loss_bbox_0: 0.3552  loss_rpn_cls: 0.2957  loss_rpn_reg: 0.5243  time: 0.1897  last_time: 0.2547  data_time: 0.0045  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:34:03] d2.utils.events INFO:  eta: 2:01:22  iter: 15719  total_loss: 3.744  loss_ce: 0.6289  loss_giou: 0.383  loss_bbox: 0.3728  loss_ce_0: 0.6278  loss_giou_0: 0.4258  loss_bbox_0: 0.4096  loss_rpn_cls: 0.3204  loss_rpn_reg: 0.5168  time: 0.1897  last_time: 0.2120  data_time: 0.0048  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:34:07] d2.utils.events INFO:  eta: 2:01:21  iter: 15739  total_loss: 3.599  loss_ce: 0.5616  loss_giou: 0.398  loss_bbox: 0.3057  loss_ce_0: 0.5845  loss_giou_0: 0.4004  loss_bbox_0: 0.3261  loss_rpn_cls: 0.3081  loss_rpn_reg: 0.5148  time: 0.1898  last_time: 0.1963  data_time: 0.0057  last_data_time: 0.0076   lr: 5e-05  max_mem: 3029M
[03/05 12:34:11] d2.utils.events INFO:  eta: 2:01:09  iter: 15759  total_loss: 3.414  loss_ce: 0.5372  loss_giou: 0.3553  loss_bbox: 0.3184  loss_ce_0: 0.5247  loss_giou_0: 0.3909  loss_bbox_0: 0.3876  loss_rpn_cls: 0.2909  loss_rpn_reg: 0.5015  time: 0.1897  last_time: 0.1915  data_time: 0.0049  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:34:15] d2.utils.events INFO:  eta: 2:00:59  iter: 15779  total_loss: 3.701  loss_ce: 0.6107  loss_giou: 0.3899  loss_bbox: 0.3591  loss_ce_0: 0.602  loss_giou_0: 0.3959  loss_bbox_0: 0.4174  loss_rpn_cls: 0.2769  loss_rpn_reg: 0.4968  time: 0.1897  last_time: 0.1889  data_time: 0.0048  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:34:19] d2.utils.events INFO:  eta: 2:00:55  iter: 15799  total_loss: 3.286  loss_ce: 0.4969  loss_giou: 0.376  loss_bbox: 0.3299  loss_ce_0: 0.4788  loss_giou_0: 0.4144  loss_bbox_0: 0.3759  loss_rpn_cls: 0.2597  loss_rpn_reg: 0.4869  time: 0.1898  last_time: 0.1920  data_time: 0.0048  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 12:34:22] d2.utils.events INFO:  eta: 2:00:50  iter: 15819  total_loss: 3.417  loss_ce: 0.5048  loss_giou: 0.3955  loss_bbox: 0.425  loss_ce_0: 0.5411  loss_giou_0: 0.4021  loss_bbox_0: 0.4264  loss_rpn_cls: 0.2756  loss_rpn_reg: 0.5107  time: 0.1898  last_time: 0.2046  data_time: 0.0055  last_data_time: 0.0104   lr: 5e-05  max_mem: 3029M
[03/05 12:34:26] d2.utils.events INFO:  eta: 2:00:42  iter: 15839  total_loss: 3.526  loss_ce: 0.4758  loss_giou: 0.3872  loss_bbox: 0.3819  loss_ce_0: 0.5285  loss_giou_0: 0.4145  loss_bbox_0: 0.4379  loss_rpn_cls: 0.2846  loss_rpn_reg: 0.5282  time: 0.1898  last_time: 0.2169  data_time: 0.0047  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:34:30] d2.utils.events INFO:  eta: 2:00:34  iter: 15859  total_loss: 3.896  loss_ce: 0.5885  loss_giou: 0.4263  loss_bbox: 0.3326  loss_ce_0: 0.5881  loss_giou_0: 0.4688  loss_bbox_0: 0.3757  loss_rpn_cls: 0.2863  loss_rpn_reg: 0.5654  time: 0.1898  last_time: 0.2071  data_time: 0.0048  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:34:34] d2.utils.events INFO:  eta: 2:00:30  iter: 15879  total_loss: 3.632  loss_ce: 0.5383  loss_giou: 0.3932  loss_bbox: 0.3349  loss_ce_0: 0.5967  loss_giou_0: 0.4207  loss_bbox_0: 0.4022  loss_rpn_cls: 0.2939  loss_rpn_reg: 0.526  time: 0.1898  last_time: 0.1972  data_time: 0.0049  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 12:34:38] d2.utils.events INFO:  eta: 2:00:25  iter: 15899  total_loss: 3.572  loss_ce: 0.5438  loss_giou: 0.4171  loss_bbox: 0.3571  loss_ce_0: 0.5386  loss_giou_0: 0.4339  loss_bbox_0: 0.384  loss_rpn_cls: 0.2865  loss_rpn_reg: 0.571  time: 0.1897  last_time: 0.1941  data_time: 0.0049  last_data_time: 0.0071   lr: 5e-05  max_mem: 3029M
[03/05 12:34:42] d2.utils.events INFO:  eta: 2:00:23  iter: 15919  total_loss: 3.429  loss_ce: 0.5663  loss_giou: 0.3431  loss_bbox: 0.3197  loss_ce_0: 0.5724  loss_giou_0: 0.3827  loss_bbox_0: 0.3457  loss_rpn_cls: 0.283  loss_rpn_reg: 0.5049  time: 0.1897  last_time: 0.1849  data_time: 0.0046  last_data_time: 0.0026   lr: 5e-05  max_mem: 3029M
[03/05 12:34:45] d2.utils.events INFO:  eta: 2:00:06  iter: 15939  total_loss: 3.593  loss_ce: 0.5417  loss_giou: 0.3994  loss_bbox: 0.3644  loss_ce_0: 0.5723  loss_giou_0: 0.4623  loss_bbox_0: 0.4005  loss_rpn_cls: 0.2968  loss_rpn_reg: 0.5399  time: 0.1897  last_time: 0.1955  data_time: 0.0053  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:34:49] d2.utils.events INFO:  eta: 2:00:15  iter: 15959  total_loss: 3.622  loss_ce: 0.501  loss_giou: 0.4474  loss_bbox: 0.406  loss_ce_0: 0.4858  loss_giou_0: 0.4815  loss_bbox_0: 0.4323  loss_rpn_cls: 0.2588  loss_rpn_reg: 0.534  time: 0.1897  last_time: 0.2148  data_time: 0.0048  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:34:53] d2.utils.events INFO:  eta: 2:00:12  iter: 15979  total_loss: 3.528  loss_ce: 0.6114  loss_giou: 0.3708  loss_bbox: 0.4051  loss_ce_0: 0.5895  loss_giou_0: 0.3971  loss_bbox_0: 0.4532  loss_rpn_cls: 0.2696  loss_rpn_reg: 0.5524  time: 0.1897  last_time: 0.1800  data_time: 0.0052  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:34:57] d2.utils.events INFO:  eta: 2:00:14  iter: 15999  total_loss: 3.733  loss_ce: 0.5873  loss_giou: 0.4364  loss_bbox: 0.3417  loss_ce_0: 0.6061  loss_giou_0: 0.4549  loss_bbox_0: 0.3632  loss_rpn_cls: 0.3055  loss_rpn_reg: 0.5091  time: 0.1897  last_time: 0.1768  data_time: 0.0051  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:35:01] d2.utils.events INFO:  eta: 2:00:02  iter: 16019  total_loss: 3.774  loss_ce: 0.5759  loss_giou: 0.41  loss_bbox: 0.32  loss_ce_0: 0.6206  loss_giou_0: 0.4459  loss_bbox_0: 0.3779  loss_rpn_cls: 0.3159  loss_rpn_reg: 0.4949  time: 0.1897  last_time: 0.1654  data_time: 0.0058  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:35:05] d2.utils.events INFO:  eta: 1:59:54  iter: 16039  total_loss: 3.484  loss_ce: 0.5646  loss_giou: 0.3872  loss_bbox: 0.3205  loss_ce_0: 0.5598  loss_giou_0: 0.4383  loss_bbox_0: 0.367  loss_rpn_cls: 0.268  loss_rpn_reg: 0.5409  time: 0.1897  last_time: 0.1984  data_time: 0.0053  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:35:08] d2.utils.events INFO:  eta: 2:00:00  iter: 16059  total_loss: 3.675  loss_ce: 0.6397  loss_giou: 0.3304  loss_bbox: 0.3297  loss_ce_0: 0.6155  loss_giou_0: 0.3684  loss_bbox_0: 0.3704  loss_rpn_cls: 0.2673  loss_rpn_reg: 0.5246  time: 0.1897  last_time: 0.1926  data_time: 0.0048  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:35:12] d2.utils.events INFO:  eta: 1:59:59  iter: 16079  total_loss: 3.648  loss_ce: 0.5521  loss_giou: 0.3269  loss_bbox: 0.335  loss_ce_0: 0.5765  loss_giou_0: 0.3634  loss_bbox_0: 0.3903  loss_rpn_cls: 0.3017  loss_rpn_reg: 0.4845  time: 0.1897  last_time: 0.1877  data_time: 0.0051  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:35:16] d2.utils.events INFO:  eta: 1:59:58  iter: 16099  total_loss: 3.36  loss_ce: 0.5477  loss_giou: 0.3633  loss_bbox: 0.3348  loss_ce_0: 0.5928  loss_giou_0: 0.3471  loss_bbox_0: 0.3414  loss_rpn_cls: 0.2473  loss_rpn_reg: 0.4983  time: 0.1897  last_time: 0.1814  data_time: 0.0050  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:35:20] d2.utils.events INFO:  eta: 1:59:51  iter: 16119  total_loss: 3.947  loss_ce: 0.6143  loss_giou: 0.4285  loss_bbox: 0.3575  loss_ce_0: 0.6397  loss_giou_0: 0.4573  loss_bbox_0: 0.3833  loss_rpn_cls: 0.2931  loss_rpn_reg: 0.5582  time: 0.1897  last_time: 0.2032  data_time: 0.0054  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:35:24] d2.utils.events INFO:  eta: 1:59:47  iter: 16139  total_loss: 3.445  loss_ce: 0.5406  loss_giou: 0.4315  loss_bbox: 0.375  loss_ce_0: 0.5877  loss_giou_0: 0.449  loss_bbox_0: 0.418  loss_rpn_cls: 0.2905  loss_rpn_reg: 0.5404  time: 0.1897  last_time: 0.2127  data_time: 0.0052  last_data_time: 0.0074   lr: 5e-05  max_mem: 3029M
[03/05 12:35:28] d2.utils.events INFO:  eta: 1:59:43  iter: 16159  total_loss: 3.948  loss_ce: 0.6265  loss_giou: 0.4425  loss_bbox: 0.3861  loss_ce_0: 0.6345  loss_giou_0: 0.4412  loss_bbox_0: 0.4119  loss_rpn_cls: 0.3192  loss_rpn_reg: 0.5351  time: 0.1898  last_time: 0.1916  data_time: 0.0050  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:35:32] d2.utils.events INFO:  eta: 1:59:33  iter: 16179  total_loss: 3.435  loss_ce: 0.4996  loss_giou: 0.3853  loss_bbox: 0.373  loss_ce_0: 0.547  loss_giou_0: 0.3907  loss_bbox_0: 0.4178  loss_rpn_cls: 0.2802  loss_rpn_reg: 0.5262  time: 0.1898  last_time: 0.1989  data_time: 0.0051  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:35:36] d2.utils.events INFO:  eta: 1:59:40  iter: 16199  total_loss: 3.744  loss_ce: 0.6137  loss_giou: 0.4496  loss_bbox: 0.4017  loss_ce_0: 0.5427  loss_giou_0: 0.4782  loss_bbox_0: 0.4251  loss_rpn_cls: 0.3012  loss_rpn_reg: 0.5184  time: 0.1898  last_time: 0.2000  data_time: 0.0053  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:35:40] d2.utils.events INFO:  eta: 1:59:26  iter: 16219  total_loss: 3.742  loss_ce: 0.5436  loss_giou: 0.4488  loss_bbox: 0.3328  loss_ce_0: 0.6166  loss_giou_0: 0.4669  loss_bbox_0: 0.3659  loss_rpn_cls: 0.278  loss_rpn_reg: 0.5472  time: 0.1898  last_time: 0.1952  data_time: 0.0047  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:35:43] d2.utils.events INFO:  eta: 1:58:57  iter: 16239  total_loss: 3.642  loss_ce: 0.5503  loss_giou: 0.4539  loss_bbox: 0.3341  loss_ce_0: 0.5718  loss_giou_0: 0.4848  loss_bbox_0: 0.3804  loss_rpn_cls: 0.307  loss_rpn_reg: 0.505  time: 0.1897  last_time: 0.1844  data_time: 0.0049  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 12:35:47] d2.utils.events INFO:  eta: 1:58:54  iter: 16259  total_loss: 3.207  loss_ce: 0.5975  loss_giou: 0.3742  loss_bbox: 0.261  loss_ce_0: 0.5839  loss_giou_0: 0.3838  loss_bbox_0: 0.3028  loss_rpn_cls: 0.2703  loss_rpn_reg: 0.5226  time: 0.1897  last_time: 0.1971  data_time: 0.0049  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:35:51] d2.utils.events INFO:  eta: 1:58:52  iter: 16279  total_loss: 3.646  loss_ce: 0.571  loss_giou: 0.4021  loss_bbox: 0.3607  loss_ce_0: 0.5902  loss_giou_0: 0.4391  loss_bbox_0: 0.3947  loss_rpn_cls: 0.2883  loss_rpn_reg: 0.5398  time: 0.1897  last_time: 0.1782  data_time: 0.0045  last_data_time: 0.0031   lr: 5e-05  max_mem: 3029M
[03/05 12:35:55] d2.utils.events INFO:  eta: 1:58:58  iter: 16299  total_loss: 3.836  loss_ce: 0.5993  loss_giou: 0.3707  loss_bbox: 0.3755  loss_ce_0: 0.6139  loss_giou_0: 0.4223  loss_bbox_0: 0.4262  loss_rpn_cls: 0.3168  loss_rpn_reg: 0.5575  time: 0.1897  last_time: 0.1760  data_time: 0.0060  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:35:58] d2.utils.events INFO:  eta: 1:58:54  iter: 16319  total_loss: 3.776  loss_ce: 0.6152  loss_giou: 0.4438  loss_bbox: 0.3822  loss_ce_0: 0.6358  loss_giou_0: 0.4537  loss_bbox_0: 0.4068  loss_rpn_cls: 0.2942  loss_rpn_reg: 0.551  time: 0.1897  last_time: 0.1721  data_time: 0.0047  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:36:02] d2.utils.events INFO:  eta: 1:58:53  iter: 16339  total_loss: 3.719  loss_ce: 0.5759  loss_giou: 0.4128  loss_bbox: 0.3845  loss_ce_0: 0.6333  loss_giou_0: 0.405  loss_bbox_0: 0.4103  loss_rpn_cls: 0.3045  loss_rpn_reg: 0.5383  time: 0.1897  last_time: 0.1887  data_time: 0.0048  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:36:06] d2.utils.events INFO:  eta: 1:58:37  iter: 16359  total_loss: 3.734  loss_ce: 0.6191  loss_giou: 0.3714  loss_bbox: 0.3905  loss_ce_0: 0.6196  loss_giou_0: 0.4166  loss_bbox_0: 0.4304  loss_rpn_cls: 0.2933  loss_rpn_reg: 0.5268  time: 0.1897  last_time: 0.1870  data_time: 0.0056  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 12:36:10] d2.utils.events INFO:  eta: 1:58:34  iter: 16379  total_loss: 3.864  loss_ce: 0.5998  loss_giou: 0.4064  loss_bbox: 0.3954  loss_ce_0: 0.601  loss_giou_0: 0.4218  loss_bbox_0: 0.3946  loss_rpn_cls: 0.2859  loss_rpn_reg: 0.5298  time: 0.1897  last_time: 0.1805  data_time: 0.0043  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:36:14] d2.utils.events INFO:  eta: 1:58:27  iter: 16399  total_loss: 3.739  loss_ce: 0.5568  loss_giou: 0.427  loss_bbox: 0.3555  loss_ce_0: 0.5648  loss_giou_0: 0.4523  loss_bbox_0: 0.3973  loss_rpn_cls: 0.2896  loss_rpn_reg: 0.5292  time: 0.1897  last_time: 0.1919  data_time: 0.0050  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:36:17] d2.utils.events INFO:  eta: 1:58:18  iter: 16419  total_loss: 3.609  loss_ce: 0.5433  loss_giou: 0.4095  loss_bbox: 0.3889  loss_ce_0: 0.5804  loss_giou_0: 0.4151  loss_bbox_0: 0.413  loss_rpn_cls: 0.294  loss_rpn_reg: 0.5042  time: 0.1897  last_time: 0.2190  data_time: 0.0051  last_data_time: 0.0082   lr: 5e-05  max_mem: 3029M
[03/05 12:36:21] d2.utils.events INFO:  eta: 1:58:15  iter: 16439  total_loss: 3.448  loss_ce: 0.5964  loss_giou: 0.4058  loss_bbox: 0.342  loss_ce_0: 0.5891  loss_giou_0: 0.4217  loss_bbox_0: 0.3558  loss_rpn_cls: 0.298  loss_rpn_reg: 0.5027  time: 0.1897  last_time: 0.2006  data_time: 0.0047  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:36:25] d2.utils.events INFO:  eta: 1:58:20  iter: 16459  total_loss: 3.562  loss_ce: 0.5723  loss_giou: 0.4196  loss_bbox: 0.2963  loss_ce_0: 0.6295  loss_giou_0: 0.4189  loss_bbox_0: 0.3323  loss_rpn_cls: 0.2797  loss_rpn_reg: 0.5006  time: 0.1897  last_time: 0.1955  data_time: 0.0050  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:36:29] d2.utils.events INFO:  eta: 1:58:12  iter: 16479  total_loss: 3.576  loss_ce: 0.5823  loss_giou: 0.3639  loss_bbox: 0.3512  loss_ce_0: 0.6008  loss_giou_0: 0.3812  loss_bbox_0: 0.3689  loss_rpn_cls: 0.2791  loss_rpn_reg: 0.4957  time: 0.1897  last_time: 0.1768  data_time: 0.0052  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:36:32] d2.utils.events INFO:  eta: 1:57:56  iter: 16499  total_loss: 3.73  loss_ce: 0.5958  loss_giou: 0.4444  loss_bbox: 0.4367  loss_ce_0: 0.6136  loss_giou_0: 0.465  loss_bbox_0: 0.3976  loss_rpn_cls: 0.2755  loss_rpn_reg: 0.5467  time: 0.1897  last_time: 0.1738  data_time: 0.0049  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 12:36:36] d2.utils.events INFO:  eta: 1:57:55  iter: 16519  total_loss: 3.914  loss_ce: 0.6241  loss_giou: 0.4532  loss_bbox: 0.3777  loss_ce_0: 0.6482  loss_giou_0: 0.4726  loss_bbox_0: 0.4159  loss_rpn_cls: 0.2633  loss_rpn_reg: 0.5428  time: 0.1897  last_time: 0.1989  data_time: 0.0049  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:36:40] d2.utils.events INFO:  eta: 1:57:47  iter: 16539  total_loss: 3.565  loss_ce: 0.5965  loss_giou: 0.3668  loss_bbox: 0.3473  loss_ce_0: 0.6418  loss_giou_0: 0.3982  loss_bbox_0: 0.3992  loss_rpn_cls: 0.2779  loss_rpn_reg: 0.5314  time: 0.1897  last_time: 0.1805  data_time: 0.0056  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 12:36:44] d2.utils.events INFO:  eta: 1:57:43  iter: 16559  total_loss: 3.523  loss_ce: 0.5595  loss_giou: 0.3637  loss_bbox: 0.3626  loss_ce_0: 0.5599  loss_giou_0: 0.3852  loss_bbox_0: 0.3986  loss_rpn_cls: 0.2646  loss_rpn_reg: 0.4765  time: 0.1897  last_time: 0.1893  data_time: 0.0053  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:36:48] d2.utils.events INFO:  eta: 1:57:39  iter: 16579  total_loss: 3.382  loss_ce: 0.5761  loss_giou: 0.4086  loss_bbox: 0.3658  loss_ce_0: 0.5791  loss_giou_0: 0.4203  loss_bbox_0: 0.3877  loss_rpn_cls: 0.3148  loss_rpn_reg: 0.5731  time: 0.1897  last_time: 0.1758  data_time: 0.0054  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:36:52] d2.utils.events INFO:  eta: 1:57:31  iter: 16599  total_loss: 3.787  loss_ce: 0.6354  loss_giou: 0.4107  loss_bbox: 0.3785  loss_ce_0: 0.6079  loss_giou_0: 0.4392  loss_bbox_0: 0.4494  loss_rpn_cls: 0.286  loss_rpn_reg: 0.5219  time: 0.1897  last_time: 0.1747  data_time: 0.0050  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:36:56] d2.utils.events INFO:  eta: 1:57:25  iter: 16619  total_loss: 3.517  loss_ce: 0.5658  loss_giou: 0.3898  loss_bbox: 0.3293  loss_ce_0: 0.616  loss_giou_0: 0.4288  loss_bbox_0: 0.3724  loss_rpn_cls: 0.2858  loss_rpn_reg: 0.5445  time: 0.1897  last_time: 0.1842  data_time: 0.0048  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:36:59] d2.utils.events INFO:  eta: 1:57:21  iter: 16639  total_loss: 3.508  loss_ce: 0.5659  loss_giou: 0.407  loss_bbox: 0.3864  loss_ce_0: 0.5855  loss_giou_0: 0.3879  loss_bbox_0: 0.3923  loss_rpn_cls: 0.2748  loss_rpn_reg: 0.528  time: 0.1897  last_time: 0.2024  data_time: 0.0054  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:37:03] d2.utils.events INFO:  eta: 1:57:16  iter: 16659  total_loss: 3.435  loss_ce: 0.4969  loss_giou: 0.3322  loss_bbox: 0.3543  loss_ce_0: 0.5415  loss_giou_0: 0.3779  loss_bbox_0: 0.3609  loss_rpn_cls: 0.2723  loss_rpn_reg: 0.5025  time: 0.1897  last_time: 0.1903  data_time: 0.0044  last_data_time: 0.0032   lr: 5e-05  max_mem: 3029M
[03/05 12:37:07] d2.utils.events INFO:  eta: 1:57:05  iter: 16679  total_loss: 3.24  loss_ce: 0.5134  loss_giou: 0.3788  loss_bbox: 0.3474  loss_ce_0: 0.5312  loss_giou_0: 0.3709  loss_bbox_0: 0.3383  loss_rpn_cls: 0.2544  loss_rpn_reg: 0.5064  time: 0.1897  last_time: 0.1858  data_time: 0.0049  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:37:11] d2.utils.events INFO:  eta: 1:56:48  iter: 16699  total_loss: 3.418  loss_ce: 0.5749  loss_giou: 0.3935  loss_bbox: 0.3491  loss_ce_0: 0.5765  loss_giou_0: 0.388  loss_bbox_0: 0.3835  loss_rpn_cls: 0.3079  loss_rpn_reg: 0.4879  time: 0.1897  last_time: 0.1701  data_time: 0.0047  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:37:15] d2.utils.events INFO:  eta: 1:56:45  iter: 16719  total_loss: 3.255  loss_ce: 0.5083  loss_giou: 0.3368  loss_bbox: 0.269  loss_ce_0: 0.5197  loss_giou_0: 0.3664  loss_bbox_0: 0.328  loss_rpn_cls: 0.257  loss_rpn_reg: 0.4915  time: 0.1897  last_time: 0.1684  data_time: 0.0054  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:37:19] d2.utils.events INFO:  eta: 1:56:41  iter: 16739  total_loss: 3.434  loss_ce: 0.5262  loss_giou: 0.4005  loss_bbox: 0.3535  loss_ce_0: 0.5447  loss_giou_0: 0.4148  loss_bbox_0: 0.4279  loss_rpn_cls: 0.2627  loss_rpn_reg: 0.49  time: 0.1897  last_time: 0.2018  data_time: 0.0048  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:37:22] d2.utils.events INFO:  eta: 1:56:52  iter: 16759  total_loss: 3.481  loss_ce: 0.5671  loss_giou: 0.4204  loss_bbox: 0.3201  loss_ce_0: 0.5425  loss_giou_0: 0.456  loss_bbox_0: 0.3163  loss_rpn_cls: 0.271  loss_rpn_reg: 0.5543  time: 0.1897  last_time: 0.1707  data_time: 0.0050  last_data_time: 0.0064   lr: 5e-05  max_mem: 3029M
[03/05 12:37:26] d2.utils.events INFO:  eta: 1:56:40  iter: 16779  total_loss: 3.293  loss_ce: 0.5648  loss_giou: 0.3337  loss_bbox: 0.3576  loss_ce_0: 0.5664  loss_giou_0: 0.3709  loss_bbox_0: 0.3765  loss_rpn_cls: 0.2404  loss_rpn_reg: 0.5422  time: 0.1897  last_time: 0.2041  data_time: 0.0054  last_data_time: 0.0069   lr: 5e-05  max_mem: 3029M
[03/05 12:37:30] d2.utils.events INFO:  eta: 1:56:28  iter: 16799  total_loss: 3.314  loss_ce: 0.5026  loss_giou: 0.3443  loss_bbox: 0.328  loss_ce_0: 0.5261  loss_giou_0: 0.35  loss_bbox_0: 0.3737  loss_rpn_cls: 0.2505  loss_rpn_reg: 0.5339  time: 0.1897  last_time: 0.1706  data_time: 0.0051  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:37:34] d2.utils.events INFO:  eta: 1:56:20  iter: 16819  total_loss: 3.477  loss_ce: 0.505  loss_giou: 0.3767  loss_bbox: 0.3423  loss_ce_0: 0.4985  loss_giou_0: 0.4174  loss_bbox_0: 0.3908  loss_rpn_cls: 0.2909  loss_rpn_reg: 0.5059  time: 0.1897  last_time: 0.2109  data_time: 0.0047  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:37:38] d2.utils.events INFO:  eta: 1:56:16  iter: 16839  total_loss: 3.541  loss_ce: 0.5555  loss_giou: 0.3904  loss_bbox: 0.398  loss_ce_0: 0.5463  loss_giou_0: 0.4055  loss_bbox_0: 0.4206  loss_rpn_cls: 0.2741  loss_rpn_reg: 0.4995  time: 0.1897  last_time: 0.1880  data_time: 0.0045  last_data_time: 0.0021   lr: 5e-05  max_mem: 3029M
[03/05 12:37:41] d2.utils.events INFO:  eta: 1:56:12  iter: 16859  total_loss: 3.482  loss_ce: 0.5567  loss_giou: 0.3598  loss_bbox: 0.3966  loss_ce_0: 0.5197  loss_giou_0: 0.3603  loss_bbox_0: 0.432  loss_rpn_cls: 0.2753  loss_rpn_reg: 0.5284  time: 0.1897  last_time: 0.2068  data_time: 0.0053  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:37:45] d2.utils.events INFO:  eta: 1:56:02  iter: 16879  total_loss: 3.66  loss_ce: 0.6098  loss_giou: 0.4517  loss_bbox: 0.3886  loss_ce_0: 0.6501  loss_giou_0: 0.4622  loss_bbox_0: 0.4311  loss_rpn_cls: 0.2891  loss_rpn_reg: 0.4942  time: 0.1897  last_time: 0.1737  data_time: 0.0058  last_data_time: 0.0064   lr: 5e-05  max_mem: 3029M
[03/05 12:37:49] d2.utils.events INFO:  eta: 1:56:06  iter: 16899  total_loss: 3.203  loss_ce: 0.4959  loss_giou: 0.3293  loss_bbox: 0.3925  loss_ce_0: 0.5267  loss_giou_0: 0.3721  loss_bbox_0: 0.4339  loss_rpn_cls: 0.2753  loss_rpn_reg: 0.5053  time: 0.1897  last_time: 0.1941  data_time: 0.0057  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:37:53] d2.utils.events INFO:  eta: 1:56:04  iter: 16919  total_loss: 3.31  loss_ce: 0.5684  loss_giou: 0.349  loss_bbox: 0.3057  loss_ce_0: 0.5856  loss_giou_0: 0.3703  loss_bbox_0: 0.3243  loss_rpn_cls: 0.273  loss_rpn_reg: 0.4972  time: 0.1897  last_time: 0.1841  data_time: 0.0048  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:37:57] d2.utils.events INFO:  eta: 1:55:58  iter: 16939  total_loss: 3.258  loss_ce: 0.4709  loss_giou: 0.3854  loss_bbox: 0.3294  loss_ce_0: 0.5068  loss_giou_0: 0.4208  loss_bbox_0: 0.3526  loss_rpn_cls: 0.2643  loss_rpn_reg: 0.5198  time: 0.1897  last_time: 0.1789  data_time: 0.0054  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:38:00] d2.utils.events INFO:  eta: 1:55:46  iter: 16959  total_loss: 3.798  loss_ce: 0.5965  loss_giou: 0.3528  loss_bbox: 0.4002  loss_ce_0: 0.607  loss_giou_0: 0.4003  loss_bbox_0: 0.4537  loss_rpn_cls: 0.3003  loss_rpn_reg: 0.5414  time: 0.1896  last_time: 0.1801  data_time: 0.0048  last_data_time: 0.0080   lr: 5e-05  max_mem: 3029M
[03/05 12:38:04] d2.utils.events INFO:  eta: 1:55:42  iter: 16979  total_loss: 3.715  loss_ce: 0.5454  loss_giou: 0.4085  loss_bbox: 0.3854  loss_ce_0: 0.5981  loss_giou_0: 0.4277  loss_bbox_0: 0.4571  loss_rpn_cls: 0.3018  loss_rpn_reg: 0.5087  time: 0.1896  last_time: 0.1969  data_time: 0.0054  last_data_time: 0.0100   lr: 5e-05  max_mem: 3029M
[03/05 12:38:08] d2.utils.events INFO:  eta: 1:55:33  iter: 16999  total_loss: 3.377  loss_ce: 0.5112  loss_giou: 0.3528  loss_bbox: 0.349  loss_ce_0: 0.5649  loss_giou_0: 0.3584  loss_bbox_0: 0.3758  loss_rpn_cls: 0.2613  loss_rpn_reg: 0.4976  time: 0.1896  last_time: 0.1974  data_time: 0.0050  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:38:12] d2.utils.events INFO:  eta: 1:55:31  iter: 17019  total_loss: 3.285  loss_ce: 0.4768  loss_giou: 0.4026  loss_bbox: 0.3746  loss_ce_0: 0.5249  loss_giou_0: 0.4139  loss_bbox_0: 0.3927  loss_rpn_cls: 0.2386  loss_rpn_reg: 0.5236  time: 0.1896  last_time: 0.1814  data_time: 0.0047  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:38:16] d2.utils.events INFO:  eta: 1:55:32  iter: 17039  total_loss: 3.483  loss_ce: 0.5739  loss_giou: 0.3789  loss_bbox: 0.3992  loss_ce_0: 0.6077  loss_giou_0: 0.3917  loss_bbox_0: 0.3888  loss_rpn_cls: 0.2595  loss_rpn_reg: 0.4982  time: 0.1896  last_time: 0.2012  data_time: 0.0059  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:38:20] d2.utils.events INFO:  eta: 1:55:38  iter: 17059  total_loss: 3.583  loss_ce: 0.5891  loss_giou: 0.385  loss_bbox: 0.3276  loss_ce_0: 0.6064  loss_giou_0: 0.3834  loss_bbox_0: 0.3651  loss_rpn_cls: 0.3103  loss_rpn_reg: 0.5344  time: 0.1896  last_time: 0.2094  data_time: 0.0048  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:38:23] d2.utils.events INFO:  eta: 1:55:29  iter: 17079  total_loss: 3.423  loss_ce: 0.5605  loss_giou: 0.3772  loss_bbox: 0.3337  loss_ce_0: 0.5444  loss_giou_0: 0.4103  loss_bbox_0: 0.3823  loss_rpn_cls: 0.2503  loss_rpn_reg: 0.5135  time: 0.1896  last_time: 0.1622  data_time: 0.0050  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:38:27] d2.utils.events INFO:  eta: 1:55:21  iter: 17099  total_loss: 3.484  loss_ce: 0.5175  loss_giou: 0.3708  loss_bbox: 0.3507  loss_ce_0: 0.5191  loss_giou_0: 0.4079  loss_bbox_0: 0.3559  loss_rpn_cls: 0.2732  loss_rpn_reg: 0.5199  time: 0.1896  last_time: 0.1701  data_time: 0.0049  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:38:31] d2.utils.events INFO:  eta: 1:55:11  iter: 17119  total_loss: 3.433  loss_ce: 0.5323  loss_giou: 0.4017  loss_bbox: 0.3642  loss_ce_0: 0.579  loss_giou_0: 0.3974  loss_bbox_0: 0.391  loss_rpn_cls: 0.2621  loss_rpn_reg: 0.5238  time: 0.1896  last_time: 0.1831  data_time: 0.0045  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:38:34] d2.utils.events INFO:  eta: 1:55:00  iter: 17139  total_loss: 3.412  loss_ce: 0.5305  loss_giou: 0.3838  loss_bbox: 0.3319  loss_ce_0: 0.5575  loss_giou_0: 0.4226  loss_bbox_0: 0.3716  loss_rpn_cls: 0.2542  loss_rpn_reg: 0.5136  time: 0.1896  last_time: 0.1694  data_time: 0.0049  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:38:38] d2.utils.events INFO:  eta: 1:54:43  iter: 17159  total_loss: 3.377  loss_ce: 0.587  loss_giou: 0.3827  loss_bbox: 0.325  loss_ce_0: 0.6325  loss_giou_0: 0.4046  loss_bbox_0: 0.3456  loss_rpn_cls: 0.2539  loss_rpn_reg: 0.4745  time: 0.1896  last_time: 0.1813  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:38:42] d2.utils.events INFO:  eta: 1:54:30  iter: 17179  total_loss: 3.487  loss_ce: 0.5406  loss_giou: 0.3841  loss_bbox: 0.3635  loss_ce_0: 0.5385  loss_giou_0: 0.4103  loss_bbox_0: 0.4129  loss_rpn_cls: 0.2795  loss_rpn_reg: 0.519  time: 0.1896  last_time: 0.1780  data_time: 0.0049  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 12:38:46] d2.utils.events INFO:  eta: 1:54:23  iter: 17199  total_loss: 3.392  loss_ce: 0.5587  loss_giou: 0.3997  loss_bbox: 0.2985  loss_ce_0: 0.5838  loss_giou_0: 0.3732  loss_bbox_0: 0.3244  loss_rpn_cls: 0.2914  loss_rpn_reg: 0.4892  time: 0.1896  last_time: 0.1881  data_time: 0.0049  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:38:49] d2.utils.events INFO:  eta: 1:54:19  iter: 17219  total_loss: 3.38  loss_ce: 0.5304  loss_giou: 0.3394  loss_bbox: 0.3836  loss_ce_0: 0.5836  loss_giou_0: 0.3396  loss_bbox_0: 0.3933  loss_rpn_cls: 0.2582  loss_rpn_reg: 0.4907  time: 0.1896  last_time: 0.1639  data_time: 0.0049  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:38:53] d2.utils.events INFO:  eta: 1:54:26  iter: 17239  total_loss: 3.449  loss_ce: 0.5431  loss_giou: 0.4033  loss_bbox: 0.3712  loss_ce_0: 0.5539  loss_giou_0: 0.4435  loss_bbox_0: 0.3579  loss_rpn_cls: 0.3084  loss_rpn_reg: 0.5098  time: 0.1896  last_time: 0.2177  data_time: 0.0049  last_data_time: 0.0029   lr: 5e-05  max_mem: 3029M
[03/05 12:38:57] d2.utils.events INFO:  eta: 1:54:30  iter: 17259  total_loss: 3.304  loss_ce: 0.5222  loss_giou: 0.3577  loss_bbox: 0.3226  loss_ce_0: 0.5311  loss_giou_0: 0.402  loss_bbox_0: 0.3605  loss_rpn_cls: 0.2799  loss_rpn_reg: 0.4928  time: 0.1896  last_time: 0.1695  data_time: 0.0048  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:39:01] d2.utils.events INFO:  eta: 1:54:28  iter: 17279  total_loss: 3.434  loss_ce: 0.537  loss_giou: 0.4135  loss_bbox: 0.3355  loss_ce_0: 0.5558  loss_giou_0: 0.4362  loss_bbox_0: 0.3356  loss_rpn_cls: 0.271  loss_rpn_reg: 0.4967  time: 0.1896  last_time: 0.2233  data_time: 0.0059  last_data_time: 0.0091   lr: 5e-05  max_mem: 3029M
[03/05 12:39:05] d2.utils.events INFO:  eta: 1:54:21  iter: 17299  total_loss: 3.324  loss_ce: 0.5176  loss_giou: 0.364  loss_bbox: 0.381  loss_ce_0: 0.5501  loss_giou_0: 0.3723  loss_bbox_0: 0.4227  loss_rpn_cls: 0.2484  loss_rpn_reg: 0.4646  time: 0.1896  last_time: 0.1776  data_time: 0.0049  last_data_time: 0.0029   lr: 5e-05  max_mem: 3029M
[03/05 12:39:09] d2.utils.events INFO:  eta: 1:54:27  iter: 17319  total_loss: 3.582  loss_ce: 0.581  loss_giou: 0.3677  loss_bbox: 0.3452  loss_ce_0: 0.5897  loss_giou_0: 0.3979  loss_bbox_0: 0.3616  loss_rpn_cls: 0.2808  loss_rpn_reg: 0.5161  time: 0.1896  last_time: 0.2005  data_time: 0.0043  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:39:13] d2.utils.events INFO:  eta: 1:54:19  iter: 17339  total_loss: 3.502  loss_ce: 0.5527  loss_giou: 0.3897  loss_bbox: 0.3316  loss_ce_0: 0.5774  loss_giou_0: 0.3974  loss_bbox_0: 0.3896  loss_rpn_cls: 0.2768  loss_rpn_reg: 0.4867  time: 0.1896  last_time: 0.1946  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:39:17] d2.utils.events INFO:  eta: 1:54:19  iter: 17359  total_loss: 3.458  loss_ce: 0.5228  loss_giou: 0.4041  loss_bbox: 0.3501  loss_ce_0: 0.5388  loss_giou_0: 0.4243  loss_bbox_0: 0.3662  loss_rpn_cls: 0.2775  loss_rpn_reg: 0.5237  time: 0.1896  last_time: 0.2028  data_time: 0.0046  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:39:20] d2.utils.events INFO:  eta: 1:54:12  iter: 17379  total_loss: 3.366  loss_ce: 0.5442  loss_giou: 0.3538  loss_bbox: 0.318  loss_ce_0: 0.5684  loss_giou_0: 0.3835  loss_bbox_0: 0.3613  loss_rpn_cls: 0.2614  loss_rpn_reg: 0.5102  time: 0.1896  last_time: 0.1876  data_time: 0.0050  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:39:24] d2.utils.events INFO:  eta: 1:54:05  iter: 17399  total_loss: 3.465  loss_ce: 0.5658  loss_giou: 0.43  loss_bbox: 0.3286  loss_ce_0: 0.5488  loss_giou_0: 0.4464  loss_bbox_0: 0.3309  loss_rpn_cls: 0.2771  loss_rpn_reg: 0.52  time: 0.1896  last_time: 0.1753  data_time: 0.0046  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:39:28] d2.utils.events INFO:  eta: 1:54:08  iter: 17419  total_loss: 3.135  loss_ce: 0.44  loss_giou: 0.3204  loss_bbox: 0.3265  loss_ce_0: 0.486  loss_giou_0: 0.3952  loss_bbox_0: 0.3708  loss_rpn_cls: 0.2596  loss_rpn_reg: 0.4714  time: 0.1896  last_time: 0.2132  data_time: 0.0050  last_data_time: 0.0069   lr: 5e-05  max_mem: 3029M
[03/05 12:39:32] d2.utils.events INFO:  eta: 1:54:06  iter: 17439  total_loss: 3.574  loss_ce: 0.6188  loss_giou: 0.3707  loss_bbox: 0.3907  loss_ce_0: 0.5795  loss_giou_0: 0.3918  loss_bbox_0: 0.4591  loss_rpn_cls: 0.2968  loss_rpn_reg: 0.5121  time: 0.1896  last_time: 0.1785  data_time: 0.0054  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:39:36] d2.utils.events INFO:  eta: 1:54:03  iter: 17459  total_loss: 3.422  loss_ce: 0.517  loss_giou: 0.3513  loss_bbox: 0.3322  loss_ce_0: 0.5431  loss_giou_0: 0.3661  loss_bbox_0: 0.3925  loss_rpn_cls: 0.2749  loss_rpn_reg: 0.5381  time: 0.1896  last_time: 0.2039  data_time: 0.0054  last_data_time: 0.0150   lr: 5e-05  max_mem: 3029M
[03/05 12:39:40] d2.utils.events INFO:  eta: 1:53:55  iter: 17479  total_loss: 3.907  loss_ce: 0.5267  loss_giou: 0.4055  loss_bbox: 0.3389  loss_ce_0: 0.5877  loss_giou_0: 0.4381  loss_bbox_0: 0.3398  loss_rpn_cls: 0.3019  loss_rpn_reg: 0.5163  time: 0.1896  last_time: 0.1785  data_time: 0.0051  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:39:43] d2.utils.events INFO:  eta: 1:53:54  iter: 17499  total_loss: 3.647  loss_ce: 0.5807  loss_giou: 0.3875  loss_bbox: 0.3658  loss_ce_0: 0.5986  loss_giou_0: 0.4014  loss_bbox_0: 0.3935  loss_rpn_cls: 0.2748  loss_rpn_reg: 0.5301  time: 0.1896  last_time: 0.1704  data_time: 0.0046  last_data_time: 0.0069   lr: 5e-05  max_mem: 3029M
[03/05 12:39:47] d2.utils.events INFO:  eta: 1:53:47  iter: 17519  total_loss: 3.434  loss_ce: 0.5785  loss_giou: 0.367  loss_bbox: 0.3051  loss_ce_0: 0.5811  loss_giou_0: 0.3976  loss_bbox_0: 0.399  loss_rpn_cls: 0.2792  loss_rpn_reg: 0.5096  time: 0.1896  last_time: 0.1806  data_time: 0.0049  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:39:51] d2.utils.events INFO:  eta: 1:53:57  iter: 17539  total_loss: 3.6  loss_ce: 0.5501  loss_giou: 0.426  loss_bbox: 0.3466  loss_ce_0: 0.5544  loss_giou_0: 0.473  loss_bbox_0: 0.3655  loss_rpn_cls: 0.2799  loss_rpn_reg: 0.5257  time: 0.1896  last_time: 0.1857  data_time: 0.0056  last_data_time: 0.0082   lr: 5e-05  max_mem: 3029M
[03/05 12:39:55] d2.utils.events INFO:  eta: 1:53:49  iter: 17559  total_loss: 3.256  loss_ce: 0.5332  loss_giou: 0.3379  loss_bbox: 0.3434  loss_ce_0: 0.5223  loss_giou_0: 0.3882  loss_bbox_0: 0.3912  loss_rpn_cls: 0.2537  loss_rpn_reg: 0.4728  time: 0.1896  last_time: 0.1836  data_time: 0.0050  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:39:59] d2.utils.events INFO:  eta: 1:53:42  iter: 17579  total_loss: 3.201  loss_ce: 0.4585  loss_giou: 0.3805  loss_bbox: 0.3379  loss_ce_0: 0.4877  loss_giou_0: 0.4015  loss_bbox_0: 0.3319  loss_rpn_cls: 0.2732  loss_rpn_reg: 0.5117  time: 0.1896  last_time: 0.1874  data_time: 0.0052  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:40:03] d2.utils.events INFO:  eta: 1:53:46  iter: 17599  total_loss: 3.222  loss_ce: 0.5187  loss_giou: 0.3649  loss_bbox: 0.3929  loss_ce_0: 0.5005  loss_giou_0: 0.3925  loss_bbox_0: 0.3673  loss_rpn_cls: 0.2262  loss_rpn_reg: 0.507  time: 0.1896  last_time: 0.2082  data_time: 0.0059  last_data_time: 0.0239   lr: 5e-05  max_mem: 3029M
[03/05 12:40:07] d2.utils.events INFO:  eta: 1:53:42  iter: 17619  total_loss: 3.466  loss_ce: 0.4649  loss_giou: 0.3796  loss_bbox: 0.3245  loss_ce_0: 0.4814  loss_giou_0: 0.4102  loss_bbox_0: 0.3621  loss_rpn_cls: 0.2677  loss_rpn_reg: 0.495  time: 0.1896  last_time: 0.1727  data_time: 0.0049  last_data_time: 0.0077   lr: 5e-05  max_mem: 3029M
[03/05 12:40:10] d2.utils.events INFO:  eta: 1:53:27  iter: 17639  total_loss: 3.439  loss_ce: 0.5637  loss_giou: 0.383  loss_bbox: 0.3077  loss_ce_0: 0.5772  loss_giou_0: 0.4085  loss_bbox_0: 0.328  loss_rpn_cls: 0.3159  loss_rpn_reg: 0.4693  time: 0.1896  last_time: 0.1710  data_time: 0.0047  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:40:14] d2.utils.events INFO:  eta: 1:53:23  iter: 17659  total_loss: 3.345  loss_ce: 0.5151  loss_giou: 0.3231  loss_bbox: 0.3246  loss_ce_0: 0.5068  loss_giou_0: 0.3527  loss_bbox_0: 0.3518  loss_rpn_cls: 0.2551  loss_rpn_reg: 0.5301  time: 0.1896  last_time: 0.1984  data_time: 0.0052  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:40:18] d2.utils.events INFO:  eta: 1:53:20  iter: 17679  total_loss: 3.432  loss_ce: 0.5408  loss_giou: 0.341  loss_bbox: 0.2992  loss_ce_0: 0.567  loss_giou_0: 0.3899  loss_bbox_0: 0.3376  loss_rpn_cls: 0.301  loss_rpn_reg: 0.5298  time: 0.1896  last_time: 0.1810  data_time: 0.0045  last_data_time: 0.0027   lr: 5e-05  max_mem: 3029M
[03/05 12:40:21] d2.utils.events INFO:  eta: 1:53:17  iter: 17699  total_loss: 3.378  loss_ce: 0.5142  loss_giou: 0.3763  loss_bbox: 0.308  loss_ce_0: 0.531  loss_giou_0: 0.3777  loss_bbox_0: 0.3556  loss_rpn_cls: 0.2832  loss_rpn_reg: 0.5175  time: 0.1896  last_time: 0.1945  data_time: 0.0050  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:40:25] d2.utils.events INFO:  eta: 1:53:12  iter: 17719  total_loss: 3.12  loss_ce: 0.5084  loss_giou: 0.3333  loss_bbox: 0.3511  loss_ce_0: 0.536  loss_giou_0: 0.3573  loss_bbox_0: 0.3913  loss_rpn_cls: 0.2656  loss_rpn_reg: 0.4977  time: 0.1896  last_time: 0.2047  data_time: 0.0056  last_data_time: 0.0074   lr: 5e-05  max_mem: 3029M
[03/05 12:40:30] d2.utils.events INFO:  eta: 1:53:11  iter: 17739  total_loss: 3.557  loss_ce: 0.5518  loss_giou: 0.3694  loss_bbox: 0.3514  loss_ce_0: 0.5403  loss_giou_0: 0.3953  loss_bbox_0: 0.4173  loss_rpn_cls: 0.2648  loss_rpn_reg: 0.5384  time: 0.1896  last_time: 0.1813  data_time: 0.0056  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:40:33] d2.utils.events INFO:  eta: 1:53:06  iter: 17759  total_loss: 3.635  loss_ce: 0.5905  loss_giou: 0.346  loss_bbox: 0.3515  loss_ce_0: 0.5888  loss_giou_0: 0.3656  loss_bbox_0: 0.4228  loss_rpn_cls: 0.2707  loss_rpn_reg: 0.5194  time: 0.1896  last_time: 0.1803  data_time: 0.0047  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:40:37] d2.utils.events INFO:  eta: 1:53:02  iter: 17779  total_loss: 3.142  loss_ce: 0.4984  loss_giou: 0.3555  loss_bbox: 0.3174  loss_ce_0: 0.5127  loss_giou_0: 0.3843  loss_bbox_0: 0.3484  loss_rpn_cls: 0.2499  loss_rpn_reg: 0.4909  time: 0.1896  last_time: 0.1903  data_time: 0.0049  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:40:41] d2.utils.events INFO:  eta: 1:52:56  iter: 17799  total_loss: 3.38  loss_ce: 0.5858  loss_giou: 0.379  loss_bbox: 0.4034  loss_ce_0: 0.6125  loss_giou_0: 0.4098  loss_bbox_0: 0.4611  loss_rpn_cls: 0.2702  loss_rpn_reg: 0.5387  time: 0.1896  last_time: 0.1833  data_time: 0.0046  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 12:40:45] d2.utils.events INFO:  eta: 1:52:52  iter: 17819  total_loss: 3.134  loss_ce: 0.483  loss_giou: 0.3389  loss_bbox: 0.3156  loss_ce_0: 0.4747  loss_giou_0: 0.3437  loss_bbox_0: 0.3336  loss_rpn_cls: 0.2528  loss_rpn_reg: 0.4775  time: 0.1896  last_time: 0.1578  data_time: 0.0047  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:40:48] d2.utils.events INFO:  eta: 1:52:47  iter: 17839  total_loss: 3.826  loss_ce: 0.5608  loss_giou: 0.3797  loss_bbox: 0.3674  loss_ce_0: 0.5762  loss_giou_0: 0.4408  loss_bbox_0: 0.3972  loss_rpn_cls: 0.296  loss_rpn_reg: 0.5574  time: 0.1896  last_time: 0.1653  data_time: 0.0051  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:40:52] d2.utils.events INFO:  eta: 1:52:47  iter: 17859  total_loss: 3.396  loss_ce: 0.4879  loss_giou: 0.4225  loss_bbox: 0.3314  loss_ce_0: 0.5266  loss_giou_0: 0.4207  loss_bbox_0: 0.3532  loss_rpn_cls: 0.2538  loss_rpn_reg: 0.5036  time: 0.1896  last_time: 0.2012  data_time: 0.0055  last_data_time: 0.0025   lr: 5e-05  max_mem: 3029M
[03/05 12:40:56] d2.utils.events INFO:  eta: 1:52:59  iter: 17879  total_loss: 3.552  loss_ce: 0.5442  loss_giou: 0.4038  loss_bbox: 0.3253  loss_ce_0: 0.5661  loss_giou_0: 0.4301  loss_bbox_0: 0.3678  loss_rpn_cls: 0.2569  loss_rpn_reg: 0.5091  time: 0.1896  last_time: 0.2137  data_time: 0.0055  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:41:00] d2.utils.events INFO:  eta: 1:52:44  iter: 17899  total_loss: 3.287  loss_ce: 0.4946  loss_giou: 0.3738  loss_bbox: 0.315  loss_ce_0: 0.5183  loss_giou_0: 0.4255  loss_bbox_0: 0.3556  loss_rpn_cls: 0.255  loss_rpn_reg: 0.5033  time: 0.1896  last_time: 0.1823  data_time: 0.0050  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:41:04] d2.utils.events INFO:  eta: 1:52:44  iter: 17919  total_loss: 3.185  loss_ce: 0.5595  loss_giou: 0.3652  loss_bbox: 0.3367  loss_ce_0: 0.5407  loss_giou_0: 0.3824  loss_bbox_0: 0.3133  loss_rpn_cls: 0.2639  loss_rpn_reg: 0.5012  time: 0.1896  last_time: 0.2059  data_time: 0.0054  last_data_time: 0.0070   lr: 5e-05  max_mem: 3029M
[03/05 12:41:08] d2.utils.events INFO:  eta: 1:52:43  iter: 17939  total_loss: 3.498  loss_ce: 0.5  loss_giou: 0.3824  loss_bbox: 0.3729  loss_ce_0: 0.5358  loss_giou_0: 0.4613  loss_bbox_0: 0.4025  loss_rpn_cls: 0.2753  loss_rpn_reg: 0.5265  time: 0.1896  last_time: 0.2027  data_time: 0.0050  last_data_time: 0.0070   lr: 5e-05  max_mem: 3029M
[03/05 12:41:12] d2.utils.events INFO:  eta: 1:52:48  iter: 17959  total_loss: 3.637  loss_ce: 0.577  loss_giou: 0.4196  loss_bbox: 0.3555  loss_ce_0: 0.5611  loss_giou_0: 0.4406  loss_bbox_0: 0.3829  loss_rpn_cls: 0.2857  loss_rpn_reg: 0.5556  time: 0.1896  last_time: 0.1914  data_time: 0.0051  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:41:15] d2.utils.events INFO:  eta: 1:52:40  iter: 17979  total_loss: 3.202  loss_ce: 0.5361  loss_giou: 0.3452  loss_bbox: 0.2772  loss_ce_0: 0.5494  loss_giou_0: 0.3735  loss_bbox_0: 0.3346  loss_rpn_cls: 0.2447  loss_rpn_reg: 0.4953  time: 0.1896  last_time: 0.1969  data_time: 0.0053  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:41:19] d2.utils.events INFO:  eta: 1:52:54  iter: 17999  total_loss: 3.798  loss_ce: 0.5928  loss_giou: 0.4066  loss_bbox: 0.4145  loss_ce_0: 0.5835  loss_giou_0: 0.4396  loss_bbox_0: 0.4283  loss_rpn_cls: 0.2946  loss_rpn_reg: 0.5236  time: 0.1896  last_time: 0.1910  data_time: 0.0053  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:41:23] d2.utils.events INFO:  eta: 1:52:51  iter: 18019  total_loss: 2.856  loss_ce: 0.5214  loss_giou: 0.3326  loss_bbox: 0.2788  loss_ce_0: 0.5393  loss_giou_0: 0.3362  loss_bbox_0: 0.2808  loss_rpn_cls: 0.271  loss_rpn_reg: 0.4828  time: 0.1896  last_time: 0.1972  data_time: 0.0045  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:41:27] d2.utils.events INFO:  eta: 1:52:45  iter: 18039  total_loss: 3.353  loss_ce: 0.4788  loss_giou: 0.3848  loss_bbox: 0.315  loss_ce_0: 0.5554  loss_giou_0: 0.4  loss_bbox_0: 0.3492  loss_rpn_cls: 0.2755  loss_rpn_reg: 0.5147  time: 0.1896  last_time: 0.1919  data_time: 0.0049  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:41:31] d2.utils.events INFO:  eta: 1:52:36  iter: 18059  total_loss: 3.271  loss_ce: 0.5316  loss_giou: 0.4213  loss_bbox: 0.3401  loss_ce_0: 0.5044  loss_giou_0: 0.4262  loss_bbox_0: 0.3548  loss_rpn_cls: 0.258  loss_rpn_reg: 0.5067  time: 0.1896  last_time: 0.1977  data_time: 0.0049  last_data_time: 0.0069   lr: 5e-05  max_mem: 3029M
[03/05 12:41:35] d2.utils.events INFO:  eta: 1:52:35  iter: 18079  total_loss: 3.378  loss_ce: 0.5304  loss_giou: 0.3865  loss_bbox: 0.3094  loss_ce_0: 0.5208  loss_giou_0: 0.4212  loss_bbox_0: 0.3453  loss_rpn_cls: 0.293  loss_rpn_reg: 0.5512  time: 0.1896  last_time: 0.1994  data_time: 0.0043  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:41:39] d2.utils.events INFO:  eta: 1:52:37  iter: 18099  total_loss: 3.509  loss_ce: 0.557  loss_giou: 0.4002  loss_bbox: 0.3785  loss_ce_0: 0.5653  loss_giou_0: 0.4394  loss_bbox_0: 0.4159  loss_rpn_cls: 0.281  loss_rpn_reg: 0.5142  time: 0.1896  last_time: 0.2126  data_time: 0.0051  last_data_time: 0.0093   lr: 5e-05  max_mem: 3029M
[03/05 12:41:42] d2.utils.events INFO:  eta: 1:52:32  iter: 18119  total_loss: 3.211  loss_ce: 0.49  loss_giou: 0.3557  loss_bbox: 0.2961  loss_ce_0: 0.5254  loss_giou_0: 0.3793  loss_bbox_0: 0.3362  loss_rpn_cls: 0.2618  loss_rpn_reg: 0.5239  time: 0.1896  last_time: 0.1861  data_time: 0.0045  last_data_time: 0.0025   lr: 5e-05  max_mem: 3029M
[03/05 12:41:46] d2.utils.events INFO:  eta: 1:52:31  iter: 18139  total_loss: 3.128  loss_ce: 0.533  loss_giou: 0.3373  loss_bbox: 0.3395  loss_ce_0: 0.5207  loss_giou_0: 0.3755  loss_bbox_0: 0.4089  loss_rpn_cls: 0.2358  loss_rpn_reg: 0.4802  time: 0.1896  last_time: 0.1923  data_time: 0.0048  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:41:50] d2.utils.events INFO:  eta: 1:52:33  iter: 18159  total_loss: 3.588  loss_ce: 0.5666  loss_giou: 0.3629  loss_bbox: 0.4062  loss_ce_0: 0.5701  loss_giou_0: 0.4052  loss_bbox_0: 0.4493  loss_rpn_cls: 0.2792  loss_rpn_reg: 0.5246  time: 0.1896  last_time: 0.1840  data_time: 0.0049  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:41:53] d2.utils.events INFO:  eta: 1:52:37  iter: 18179  total_loss: 3.229  loss_ce: 0.5043  loss_giou: 0.3122  loss_bbox: 0.2926  loss_ce_0: 0.5347  loss_giou_0: 0.3665  loss_bbox_0: 0.3781  loss_rpn_cls: 0.2761  loss_rpn_reg: 0.5157  time: 0.1895  last_time: 0.1666  data_time: 0.0049  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:41:57] d2.utils.events INFO:  eta: 1:52:42  iter: 18199  total_loss: 3.337  loss_ce: 0.5389  loss_giou: 0.3738  loss_bbox: 0.3395  loss_ce_0: 0.5547  loss_giou_0: 0.3981  loss_bbox_0: 0.3608  loss_rpn_cls: 0.2714  loss_rpn_reg: 0.5164  time: 0.1895  last_time: 0.1954  data_time: 0.0053  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 12:42:01] d2.utils.events INFO:  eta: 1:52:40  iter: 18219  total_loss: 3.27  loss_ce: 0.4824  loss_giou: 0.4024  loss_bbox: 0.3513  loss_ce_0: 0.5033  loss_giou_0: 0.4386  loss_bbox_0: 0.409  loss_rpn_cls: 0.2393  loss_rpn_reg: 0.5319  time: 0.1895  last_time: 0.1843  data_time: 0.0049  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:42:05] d2.utils.events INFO:  eta: 1:52:29  iter: 18239  total_loss: 3.355  loss_ce: 0.5534  loss_giou: 0.337  loss_bbox: 0.355  loss_ce_0: 0.5919  loss_giou_0: 0.3568  loss_bbox_0: 0.4355  loss_rpn_cls: 0.2922  loss_rpn_reg: 0.4718  time: 0.1895  last_time: 0.1600  data_time: 0.0048  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:42:09] d2.utils.events INFO:  eta: 1:52:20  iter: 18259  total_loss: 3.524  loss_ce: 0.5719  loss_giou: 0.4613  loss_bbox: 0.3206  loss_ce_0: 0.611  loss_giou_0: 0.4541  loss_bbox_0: 0.3528  loss_rpn_cls: 0.2961  loss_rpn_reg: 0.5255  time: 0.1895  last_time: 0.1942  data_time: 0.0048  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:42:13] d2.utils.events INFO:  eta: 1:52:11  iter: 18279  total_loss: 3.481  loss_ce: 0.5784  loss_giou: 0.3681  loss_bbox: 0.3169  loss_ce_0: 0.5993  loss_giou_0: 0.3904  loss_bbox_0: 0.3433  loss_rpn_cls: 0.2856  loss_rpn_reg: 0.5107  time: 0.1895  last_time: 0.1866  data_time: 0.0053  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:42:16] d2.utils.events INFO:  eta: 1:52:09  iter: 18299  total_loss: 3.733  loss_ce: 0.5938  loss_giou: 0.3607  loss_bbox: 0.354  loss_ce_0: 0.6259  loss_giou_0: 0.3786  loss_bbox_0: 0.3621  loss_rpn_cls: 0.2897  loss_rpn_reg: 0.5359  time: 0.1895  last_time: 0.1946  data_time: 0.0056  last_data_time: 0.0119   lr: 5e-05  max_mem: 3029M
[03/05 12:42:20] d2.utils.events INFO:  eta: 1:51:58  iter: 18319  total_loss: 3.115  loss_ce: 0.4627  loss_giou: 0.3253  loss_bbox: 0.3044  loss_ce_0: 0.5082  loss_giou_0: 0.3381  loss_bbox_0: 0.3134  loss_rpn_cls: 0.249  loss_rpn_reg: 0.4751  time: 0.1895  last_time: 0.1915  data_time: 0.0056  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:42:24] d2.utils.events INFO:  eta: 1:51:46  iter: 18339  total_loss: 3.291  loss_ce: 0.5551  loss_giou: 0.3609  loss_bbox: 0.3079  loss_ce_0: 0.5403  loss_giou_0: 0.388  loss_bbox_0: 0.3404  loss_rpn_cls: 0.2721  loss_rpn_reg: 0.5056  time: 0.1895  last_time: 0.1674  data_time: 0.0045  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:42:28] d2.utils.events INFO:  eta: 1:51:42  iter: 18359  total_loss: 3.508  loss_ce: 0.5701  loss_giou: 0.3799  loss_bbox: 0.3655  loss_ce_0: 0.5746  loss_giou_0: 0.3926  loss_bbox_0: 0.4225  loss_rpn_cls: 0.2855  loss_rpn_reg: 0.4808  time: 0.1895  last_time: 0.1798  data_time: 0.0048  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:42:31] d2.utils.events INFO:  eta: 1:51:40  iter: 18379  total_loss: 3.373  loss_ce: 0.5426  loss_giou: 0.381  loss_bbox: 0.324  loss_ce_0: 0.5253  loss_giou_0: 0.4084  loss_bbox_0: 0.3605  loss_rpn_cls: 0.2582  loss_rpn_reg: 0.5062  time: 0.1895  last_time: 0.2032  data_time: 0.0053  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:42:35] d2.utils.events INFO:  eta: 1:51:35  iter: 18399  total_loss: 3.421  loss_ce: 0.5327  loss_giou: 0.3565  loss_bbox: 0.3392  loss_ce_0: 0.5437  loss_giou_0: 0.3685  loss_bbox_0: 0.3675  loss_rpn_cls: 0.3073  loss_rpn_reg: 0.5005  time: 0.1895  last_time: 0.1717  data_time: 0.0050  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:42:39] d2.utils.events INFO:  eta: 1:51:31  iter: 18419  total_loss: 3.472  loss_ce: 0.5821  loss_giou: 0.4225  loss_bbox: 0.345  loss_ce_0: 0.5646  loss_giou_0: 0.4334  loss_bbox_0: 0.3789  loss_rpn_cls: 0.2907  loss_rpn_reg: 0.5113  time: 0.1895  last_time: 0.2191  data_time: 0.0051  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:42:43] d2.utils.events INFO:  eta: 1:51:18  iter: 18439  total_loss: 3.396  loss_ce: 0.5188  loss_giou: 0.4013  loss_bbox: 0.4113  loss_ce_0: 0.5425  loss_giou_0: 0.406  loss_bbox_0: 0.4124  loss_rpn_cls: 0.2349  loss_rpn_reg: 0.5129  time: 0.1895  last_time: 0.2035  data_time: 0.0055  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:42:47] d2.utils.events INFO:  eta: 1:51:11  iter: 18459  total_loss: 3.603  loss_ce: 0.4876  loss_giou: 0.4424  loss_bbox: 0.3812  loss_ce_0: 0.4944  loss_giou_0: 0.4577  loss_bbox_0: 0.3836  loss_rpn_cls: 0.2635  loss_rpn_reg: 0.532  time: 0.1895  last_time: 0.1934  data_time: 0.0052  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 12:42:51] d2.utils.events INFO:  eta: 1:51:19  iter: 18479  total_loss: 3.452  loss_ce: 0.5614  loss_giou: 0.3442  loss_bbox: 0.3499  loss_ce_0: 0.5855  loss_giou_0: 0.3678  loss_bbox_0: 0.3627  loss_rpn_cls: 0.2391  loss_rpn_reg: 0.5083  time: 0.1895  last_time: 0.2090  data_time: 0.0051  last_data_time: 0.0085   lr: 5e-05  max_mem: 3029M
[03/05 12:42:54] d2.utils.events INFO:  eta: 1:51:14  iter: 18499  total_loss: 3.535  loss_ce: 0.5848  loss_giou: 0.3753  loss_bbox: 0.3609  loss_ce_0: 0.587  loss_giou_0: 0.4053  loss_bbox_0: 0.4272  loss_rpn_cls: 0.2724  loss_rpn_reg: 0.5054  time: 0.1895  last_time: 0.1853  data_time: 0.0047  last_data_time: 0.0067   lr: 5e-05  max_mem: 3029M
[03/05 12:42:58] d2.utils.events INFO:  eta: 1:51:14  iter: 18519  total_loss: 3.376  loss_ce: 0.5018  loss_giou: 0.4072  loss_bbox: 0.3771  loss_ce_0: 0.5263  loss_giou_0: 0.4174  loss_bbox_0: 0.3825  loss_rpn_cls: 0.2773  loss_rpn_reg: 0.5345  time: 0.1895  last_time: 0.1779  data_time: 0.0047  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:43:02] d2.utils.events INFO:  eta: 1:50:58  iter: 18539  total_loss: 3.221  loss_ce: 0.5497  loss_giou: 0.3464  loss_bbox: 0.3131  loss_ce_0: 0.5591  loss_giou_0: 0.3594  loss_bbox_0: 0.3263  loss_rpn_cls: 0.2585  loss_rpn_reg: 0.4955  time: 0.1895  last_time: 0.1948  data_time: 0.0048  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:43:06] d2.utils.events INFO:  eta: 1:50:51  iter: 18559  total_loss: 3.629  loss_ce: 0.5827  loss_giou: 0.4169  loss_bbox: 0.325  loss_ce_0: 0.6148  loss_giou_0: 0.4437  loss_bbox_0: 0.3707  loss_rpn_cls: 0.3059  loss_rpn_reg: 0.557  time: 0.1895  last_time: 0.1794  data_time: 0.0048  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:43:10] d2.utils.events INFO:  eta: 1:50:45  iter: 18579  total_loss: 3.357  loss_ce: 0.5312  loss_giou: 0.4128  loss_bbox: 0.2895  loss_ce_0: 0.5368  loss_giou_0: 0.3791  loss_bbox_0: 0.3419  loss_rpn_cls: 0.2764  loss_rpn_reg: 0.5086  time: 0.1895  last_time: 0.1882  data_time: 0.0049  last_data_time: 0.0133   lr: 5e-05  max_mem: 3029M
[03/05 12:43:13] d2.utils.events INFO:  eta: 1:50:29  iter: 18599  total_loss: 3.356  loss_ce: 0.5793  loss_giou: 0.3708  loss_bbox: 0.2946  loss_ce_0: 0.5994  loss_giou_0: 0.3553  loss_bbox_0: 0.3447  loss_rpn_cls: 0.275  loss_rpn_reg: 0.4869  time: 0.1895  last_time: 0.1837  data_time: 0.0047  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:43:17] d2.utils.events INFO:  eta: 1:50:30  iter: 18619  total_loss: 3.09  loss_ce: 0.4711  loss_giou: 0.3751  loss_bbox: 0.2954  loss_ce_0: 0.4772  loss_giou_0: 0.4152  loss_bbox_0: 0.3167  loss_rpn_cls: 0.2273  loss_rpn_reg: 0.5199  time: 0.1895  last_time: 0.1914  data_time: 0.0046  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:43:21] d2.utils.events INFO:  eta: 1:50:36  iter: 18639  total_loss: 3.365  loss_ce: 0.5709  loss_giou: 0.3446  loss_bbox: 0.3365  loss_ce_0: 0.5639  loss_giou_0: 0.3734  loss_bbox_0: 0.3897  loss_rpn_cls: 0.2643  loss_rpn_reg: 0.5214  time: 0.1895  last_time: 0.1847  data_time: 0.0052  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:43:25] d2.utils.events INFO:  eta: 1:50:33  iter: 18659  total_loss: 3.511  loss_ce: 0.5739  loss_giou: 0.4246  loss_bbox: 0.3676  loss_ce_0: 0.613  loss_giou_0: 0.4397  loss_bbox_0: 0.4067  loss_rpn_cls: 0.2907  loss_rpn_reg: 0.5173  time: 0.1895  last_time: 0.2016  data_time: 0.0051  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:43:29] d2.utils.events INFO:  eta: 1:50:33  iter: 18679  total_loss: 3.577  loss_ce: 0.5309  loss_giou: 0.3744  loss_bbox: 0.3409  loss_ce_0: 0.5457  loss_giou_0: 0.4072  loss_bbox_0: 0.3883  loss_rpn_cls: 0.2785  loss_rpn_reg: 0.5196  time: 0.1895  last_time: 0.1996  data_time: 0.0047  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:43:33] d2.utils.events INFO:  eta: 1:50:32  iter: 18699  total_loss: 2.999  loss_ce: 0.5296  loss_giou: 0.3612  loss_bbox: 0.3147  loss_ce_0: 0.5104  loss_giou_0: 0.3703  loss_bbox_0: 0.3943  loss_rpn_cls: 0.2729  loss_rpn_reg: 0.4896  time: 0.1895  last_time: 0.1788  data_time: 0.0047  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 12:43:36] d2.utils.events INFO:  eta: 1:50:36  iter: 18719  total_loss: 3.601  loss_ce: 0.5442  loss_giou: 0.3771  loss_bbox: 0.3076  loss_ce_0: 0.56  loss_giou_0: 0.4397  loss_bbox_0: 0.3247  loss_rpn_cls: 0.2562  loss_rpn_reg: 0.5466  time: 0.1895  last_time: 0.1850  data_time: 0.0051  last_data_time: 0.0078   lr: 5e-05  max_mem: 3029M
[03/05 12:43:40] d2.utils.events INFO:  eta: 1:50:13  iter: 18739  total_loss: 3.286  loss_ce: 0.5273  loss_giou: 0.3605  loss_bbox: 0.3188  loss_ce_0: 0.5634  loss_giou_0: 0.3766  loss_bbox_0: 0.3182  loss_rpn_cls: 0.2864  loss_rpn_reg: 0.5069  time: 0.1895  last_time: 0.1896  data_time: 0.0051  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 12:43:44] d2.utils.events INFO:  eta: 1:50:01  iter: 18759  total_loss: 3.404  loss_ce: 0.5365  loss_giou: 0.3847  loss_bbox: 0.2816  loss_ce_0: 0.621  loss_giou_0: 0.4167  loss_bbox_0: 0.3037  loss_rpn_cls: 0.2783  loss_rpn_reg: 0.5178  time: 0.1895  last_time: 0.1845  data_time: 0.0043  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:43:48] d2.utils.events INFO:  eta: 1:49:53  iter: 18779  total_loss: 3.547  loss_ce: 0.5741  loss_giou: 0.3718  loss_bbox: 0.3798  loss_ce_0: 0.5681  loss_giou_0: 0.4372  loss_bbox_0: 0.4137  loss_rpn_cls: 0.264  loss_rpn_reg: 0.4992  time: 0.1895  last_time: 0.1864  data_time: 0.0044  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:43:51] d2.utils.events INFO:  eta: 1:49:56  iter: 18799  total_loss: 3.517  loss_ce: 0.5298  loss_giou: 0.4368  loss_bbox: 0.3403  loss_ce_0: 0.5239  loss_giou_0: 0.4408  loss_bbox_0: 0.3739  loss_rpn_cls: 0.2955  loss_rpn_reg: 0.5456  time: 0.1895  last_time: 0.1889  data_time: 0.0050  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:43:55] d2.utils.events INFO:  eta: 1:49:53  iter: 18819  total_loss: 3.434  loss_ce: 0.581  loss_giou: 0.335  loss_bbox: 0.3199  loss_ce_0: 0.5992  loss_giou_0: 0.3568  loss_bbox_0: 0.3611  loss_rpn_cls: 0.2824  loss_rpn_reg: 0.4944  time: 0.1895  last_time: 0.2082  data_time: 0.0051  last_data_time: 0.0070   lr: 5e-05  max_mem: 3029M
[03/05 12:43:59] d2.utils.events INFO:  eta: 1:49:49  iter: 18839  total_loss: 3.454  loss_ce: 0.542  loss_giou: 0.4312  loss_bbox: 0.3001  loss_ce_0: 0.5565  loss_giou_0: 0.4418  loss_bbox_0: 0.349  loss_rpn_cls: 0.2967  loss_rpn_reg: 0.5043  time: 0.1895  last_time: 0.1613  data_time: 0.0049  last_data_time: 0.0030   lr: 5e-05  max_mem: 3029M
[03/05 12:44:03] d2.utils.events INFO:  eta: 1:49:35  iter: 18859  total_loss: 3.531  loss_ce: 0.5576  loss_giou: 0.4464  loss_bbox: 0.3139  loss_ce_0: 0.5483  loss_giou_0: 0.4562  loss_bbox_0: 0.3841  loss_rpn_cls: 0.2849  loss_rpn_reg: 0.5482  time: 0.1895  last_time: 0.1781  data_time: 0.0050  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:44:06] d2.utils.events INFO:  eta: 1:49:19  iter: 18879  total_loss: 3.445  loss_ce: 0.503  loss_giou: 0.3581  loss_bbox: 0.3794  loss_ce_0: 0.5146  loss_giou_0: 0.4044  loss_bbox_0: 0.4006  loss_rpn_cls: 0.2752  loss_rpn_reg: 0.5701  time: 0.1895  last_time: 0.1895  data_time: 0.0049  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:44:10] d2.utils.events INFO:  eta: 1:49:18  iter: 18899  total_loss: 3.131  loss_ce: 0.4881  loss_giou: 0.3258  loss_bbox: 0.3165  loss_ce_0: 0.5139  loss_giou_0: 0.3773  loss_bbox_0: 0.3536  loss_rpn_cls: 0.2382  loss_rpn_reg: 0.5114  time: 0.1894  last_time: 0.1897  data_time: 0.0047  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:44:14] d2.utils.events INFO:  eta: 1:49:08  iter: 18919  total_loss: 3.436  loss_ce: 0.4895  loss_giou: 0.3473  loss_bbox: 0.3322  loss_ce_0: 0.5478  loss_giou_0: 0.3961  loss_bbox_0: 0.3701  loss_rpn_cls: 0.2556  loss_rpn_reg: 0.5233  time: 0.1894  last_time: 0.1880  data_time: 0.0046  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:44:18] d2.utils.events INFO:  eta: 1:49:01  iter: 18939  total_loss: 3.447  loss_ce: 0.5225  loss_giou: 0.4245  loss_bbox: 0.3734  loss_ce_0: 0.5581  loss_giou_0: 0.4568  loss_bbox_0: 0.3937  loss_rpn_cls: 0.2765  loss_rpn_reg: 0.5487  time: 0.1894  last_time: 0.1648  data_time: 0.0051  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:44:22] d2.utils.events INFO:  eta: 1:49:02  iter: 18959  total_loss: 3.484  loss_ce: 0.5027  loss_giou: 0.4115  loss_bbox: 0.3018  loss_ce_0: 0.5506  loss_giou_0: 0.4288  loss_bbox_0: 0.3098  loss_rpn_cls: 0.2747  loss_rpn_reg: 0.5153  time: 0.1894  last_time: 0.1884  data_time: 0.0046  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:44:26] d2.utils.events INFO:  eta: 1:49:09  iter: 18979  total_loss: 3.678  loss_ce: 0.5902  loss_giou: 0.3533  loss_bbox: 0.3232  loss_ce_0: 0.5652  loss_giou_0: 0.384  loss_bbox_0: 0.3784  loss_rpn_cls: 0.258  loss_rpn_reg: 0.524  time: 0.1895  last_time: 0.1979  data_time: 0.0049  last_data_time: 0.0028   lr: 5e-05  max_mem: 3029M
[03/05 12:44:30] d2.utils.events INFO:  eta: 1:49:04  iter: 18999  total_loss: 3.525  loss_ce: 0.5743  loss_giou: 0.3773  loss_bbox: 0.3347  loss_ce_0: 0.5915  loss_giou_0: 0.4082  loss_bbox_0: 0.3778  loss_rpn_cls: 0.2874  loss_rpn_reg: 0.5371  time: 0.1895  last_time: 0.2154  data_time: 0.0058  last_data_time: 0.0067   lr: 5e-05  max_mem: 3029M
[03/05 12:44:34] d2.utils.events INFO:  eta: 1:49:05  iter: 19019  total_loss: 3.488  loss_ce: 0.5687  loss_giou: 0.3916  loss_bbox: 0.366  loss_ce_0: 0.568  loss_giou_0: 0.4069  loss_bbox_0: 0.403  loss_rpn_cls: 0.2963  loss_rpn_reg: 0.5297  time: 0.1895  last_time: 0.2010  data_time: 0.0054  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:44:38] d2.utils.events INFO:  eta: 1:49:03  iter: 19039  total_loss: 3.53  loss_ce: 0.561  loss_giou: 0.4037  loss_bbox: 0.3602  loss_ce_0: 0.5968  loss_giou_0: 0.4164  loss_bbox_0: 0.3852  loss_rpn_cls: 0.3001  loss_rpn_reg: 0.5029  time: 0.1895  last_time: 0.2083  data_time: 0.0049  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:44:41] d2.utils.events INFO:  eta: 1:48:59  iter: 19059  total_loss: 3.669  loss_ce: 0.5303  loss_giou: 0.4462  loss_bbox: 0.3368  loss_ce_0: 0.5811  loss_giou_0: 0.493  loss_bbox_0: 0.3925  loss_rpn_cls: 0.2807  loss_rpn_reg: 0.5222  time: 0.1895  last_time: 0.1693  data_time: 0.0050  last_data_time: 0.0071   lr: 5e-05  max_mem: 3029M
[03/05 12:44:45] d2.utils.events INFO:  eta: 1:48:50  iter: 19079  total_loss: 3.31  loss_ce: 0.4896  loss_giou: 0.4073  loss_bbox: 0.3201  loss_ce_0: 0.506  loss_giou_0: 0.4323  loss_bbox_0: 0.3355  loss_rpn_cls: 0.2817  loss_rpn_reg: 0.5357  time: 0.1895  last_time: 0.1699  data_time: 0.0047  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:44:49] d2.utils.events INFO:  eta: 1:48:36  iter: 19099  total_loss: 3.413  loss_ce: 0.5548  loss_giou: 0.3651  loss_bbox: 0.3333  loss_ce_0: 0.5339  loss_giou_0: 0.3817  loss_bbox_0: 0.3458  loss_rpn_cls: 0.276  loss_rpn_reg: 0.5086  time: 0.1895  last_time: 0.1812  data_time: 0.0047  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:44:53] d2.utils.events INFO:  eta: 1:48:35  iter: 19119  total_loss: 3.56  loss_ce: 0.5328  loss_giou: 0.4343  loss_bbox: 0.3193  loss_ce_0: 0.5804  loss_giou_0: 0.4453  loss_bbox_0: 0.3343  loss_rpn_cls: 0.3192  loss_rpn_reg: 0.5319  time: 0.1895  last_time: 0.1703  data_time: 0.0046  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:44:56] d2.utils.events INFO:  eta: 1:48:39  iter: 19139  total_loss: 3.402  loss_ce: 0.5628  loss_giou: 0.3335  loss_bbox: 0.3894  loss_ce_0: 0.5894  loss_giou_0: 0.3676  loss_bbox_0: 0.3917  loss_rpn_cls: 0.2736  loss_rpn_reg: 0.5111  time: 0.1895  last_time: 0.1835  data_time: 0.0044  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:45:00] d2.utils.events INFO:  eta: 1:48:31  iter: 19159  total_loss: 3.203  loss_ce: 0.5204  loss_giou: 0.3615  loss_bbox: 0.3172  loss_ce_0: 0.4958  loss_giou_0: 0.383  loss_bbox_0: 0.3597  loss_rpn_cls: 0.2521  loss_rpn_reg: 0.5134  time: 0.1894  last_time: 0.1962  data_time: 0.0044  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:45:04] d2.utils.events INFO:  eta: 1:48:28  iter: 19179  total_loss: 3.21  loss_ce: 0.4981  loss_giou: 0.3351  loss_bbox: 0.3507  loss_ce_0: 0.5218  loss_giou_0: 0.3314  loss_bbox_0: 0.356  loss_rpn_cls: 0.2601  loss_rpn_reg: 0.4828  time: 0.1894  last_time: 0.1664  data_time: 0.0044  last_data_time: 0.0010   lr: 5e-05  max_mem: 3029M
[03/05 12:45:08] d2.utils.events INFO:  eta: 1:48:21  iter: 19199  total_loss: 3.533  loss_ce: 0.5392  loss_giou: 0.4029  loss_bbox: 0.3475  loss_ce_0: 0.578  loss_giou_0: 0.4488  loss_bbox_0: 0.3667  loss_rpn_cls: 0.2907  loss_rpn_reg: 0.5283  time: 0.1894  last_time: 0.1925  data_time: 0.0051  last_data_time: 0.0086   lr: 5e-05  max_mem: 3029M
[03/05 12:45:12] d2.utils.events INFO:  eta: 1:48:25  iter: 19219  total_loss: 3.436  loss_ce: 0.4933  loss_giou: 0.4253  loss_bbox: 0.3401  loss_ce_0: 0.5335  loss_giou_0: 0.4407  loss_bbox_0: 0.3694  loss_rpn_cls: 0.2674  loss_rpn_reg: 0.5359  time: 0.1894  last_time: 0.2012  data_time: 0.0047  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:45:15] d2.utils.events INFO:  eta: 1:48:13  iter: 19239  total_loss: 3.328  loss_ce: 0.5453  loss_giou: 0.3649  loss_bbox: 0.3282  loss_ce_0: 0.5598  loss_giou_0: 0.3835  loss_bbox_0: 0.3491  loss_rpn_cls: 0.282  loss_rpn_reg: 0.47  time: 0.1894  last_time: 0.1707  data_time: 0.0050  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:45:19] d2.utils.events INFO:  eta: 1:48:06  iter: 19259  total_loss: 3.602  loss_ce: 0.537  loss_giou: 0.3756  loss_bbox: 0.4029  loss_ce_0: 0.5512  loss_giou_0: 0.4125  loss_bbox_0: 0.4281  loss_rpn_cls: 0.2699  loss_rpn_reg: 0.5249  time: 0.1894  last_time: 0.2005  data_time: 0.0048  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 12:45:23] d2.utils.events INFO:  eta: 1:48:02  iter: 19279  total_loss: 3.531  loss_ce: 0.5378  loss_giou: 0.424  loss_bbox: 0.3333  loss_ce_0: 0.5851  loss_giou_0: 0.4594  loss_bbox_0: 0.3844  loss_rpn_cls: 0.3019  loss_rpn_reg: 0.4733  time: 0.1894  last_time: 0.2056  data_time: 0.0046  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:45:27] d2.utils.events INFO:  eta: 1:48:00  iter: 19299  total_loss: 3.048  loss_ce: 0.5025  loss_giou: 0.3176  loss_bbox: 0.3  loss_ce_0: 0.5444  loss_giou_0: 0.3539  loss_bbox_0: 0.344  loss_rpn_cls: 0.2671  loss_rpn_reg: 0.4528  time: 0.1894  last_time: 0.2009  data_time: 0.0053  last_data_time: 0.0078   lr: 5e-05  max_mem: 3029M
[03/05 12:45:31] d2.utils.events INFO:  eta: 1:47:57  iter: 19319  total_loss: 3.483  loss_ce: 0.5473  loss_giou: 0.4059  loss_bbox: 0.3542  loss_ce_0: 0.5764  loss_giou_0: 0.4404  loss_bbox_0: 0.3745  loss_rpn_cls: 0.2894  loss_rpn_reg: 0.5025  time: 0.1894  last_time: 0.1973  data_time: 0.0049  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:45:35] d2.utils.events INFO:  eta: 1:48:06  iter: 19339  total_loss: 3.515  loss_ce: 0.5091  loss_giou: 0.46  loss_bbox: 0.3482  loss_ce_0: 0.5389  loss_giou_0: 0.4547  loss_bbox_0: 0.3898  loss_rpn_cls: 0.3133  loss_rpn_reg: 0.4904  time: 0.1894  last_time: 0.1832  data_time: 0.0047  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 12:45:38] d2.utils.events INFO:  eta: 1:48:04  iter: 19359  total_loss: 3.329  loss_ce: 0.5466  loss_giou: 0.3748  loss_bbox: 0.365  loss_ce_0: 0.5742  loss_giou_0: 0.392  loss_bbox_0: 0.3567  loss_rpn_cls: 0.2769  loss_rpn_reg: 0.5171  time: 0.1894  last_time: 0.1973  data_time: 0.0044  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:45:42] d2.utils.events INFO:  eta: 1:47:59  iter: 19379  total_loss: 3.053  loss_ce: 0.4707  loss_giou: 0.3573  loss_bbox: 0.3237  loss_ce_0: 0.5162  loss_giou_0: 0.3692  loss_bbox_0: 0.3334  loss_rpn_cls: 0.2501  loss_rpn_reg: 0.4902  time: 0.1894  last_time: 0.1849  data_time: 0.0046  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:45:46] d2.utils.events INFO:  eta: 1:47:58  iter: 19399  total_loss: 3.444  loss_ce: 0.5328  loss_giou: 0.3633  loss_bbox: 0.297  loss_ce_0: 0.5771  loss_giou_0: 0.4031  loss_bbox_0: 0.313  loss_rpn_cls: 0.2597  loss_rpn_reg: 0.5092  time: 0.1894  last_time: 0.1968  data_time: 0.0048  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:45:50] d2.utils.events INFO:  eta: 1:47:50  iter: 19419  total_loss: 3.315  loss_ce: 0.5162  loss_giou: 0.3928  loss_bbox: 0.3326  loss_ce_0: 0.5646  loss_giou_0: 0.38  loss_bbox_0: 0.4076  loss_rpn_cls: 0.3019  loss_rpn_reg: 0.5381  time: 0.1894  last_time: 0.1803  data_time: 0.0047  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:45:54] d2.utils.events INFO:  eta: 1:47:35  iter: 19439  total_loss: 2.937  loss_ce: 0.5116  loss_giou: 0.3274  loss_bbox: 0.2626  loss_ce_0: 0.5369  loss_giou_0: 0.3704  loss_bbox_0: 0.3355  loss_rpn_cls: 0.2553  loss_rpn_reg: 0.4718  time: 0.1894  last_time: 0.2037  data_time: 0.0047  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:45:57] d2.utils.events INFO:  eta: 1:47:33  iter: 19459  total_loss: 3.272  loss_ce: 0.5427  loss_giou: 0.3228  loss_bbox: 0.3299  loss_ce_0: 0.561  loss_giou_0: 0.3467  loss_bbox_0: 0.3289  loss_rpn_cls: 0.2551  loss_rpn_reg: 0.5062  time: 0.1894  last_time: 0.1903  data_time: 0.0049  last_data_time: 0.0064   lr: 5e-05  max_mem: 3029M
[03/05 12:46:01] d2.utils.events INFO:  eta: 1:47:38  iter: 19479  total_loss: 3.733  loss_ce: 0.5501  loss_giou: 0.4046  loss_bbox: 0.365  loss_ce_0: 0.6304  loss_giou_0: 0.4244  loss_bbox_0: 0.3576  loss_rpn_cls: 0.2893  loss_rpn_reg: 0.516  time: 0.1894  last_time: 0.1981  data_time: 0.0049  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:46:05] d2.utils.events INFO:  eta: 1:47:38  iter: 19499  total_loss: 3.537  loss_ce: 0.5489  loss_giou: 0.4188  loss_bbox: 0.3243  loss_ce_0: 0.5646  loss_giou_0: 0.4475  loss_bbox_0: 0.3825  loss_rpn_cls: 0.2769  loss_rpn_reg: 0.5347  time: 0.1894  last_time: 0.1924  data_time: 0.0049  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:46:09] d2.utils.events INFO:  eta: 1:47:31  iter: 19519  total_loss: 3.431  loss_ce: 0.5546  loss_giou: 0.3206  loss_bbox: 0.351  loss_ce_0: 0.559  loss_giou_0: 0.3358  loss_bbox_0: 0.4105  loss_rpn_cls: 0.2704  loss_rpn_reg: 0.5188  time: 0.1894  last_time: 0.2042  data_time: 0.0051  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 12:46:13] d2.utils.events INFO:  eta: 1:47:18  iter: 19539  total_loss: 3.415  loss_ce: 0.5579  loss_giou: 0.3701  loss_bbox: 0.3606  loss_ce_0: 0.544  loss_giou_0: 0.3817  loss_bbox_0: 0.3774  loss_rpn_cls: 0.2794  loss_rpn_reg: 0.4956  time: 0.1894  last_time: 0.1938  data_time: 0.0061  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:46:17] d2.utils.events INFO:  eta: 1:47:13  iter: 19559  total_loss: 3.304  loss_ce: 0.5646  loss_giou: 0.4029  loss_bbox: 0.2779  loss_ce_0: 0.5396  loss_giou_0: 0.4269  loss_bbox_0: 0.322  loss_rpn_cls: 0.2907  loss_rpn_reg: 0.5309  time: 0.1894  last_time: 0.1852  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:46:20] d2.utils.events INFO:  eta: 1:47:09  iter: 19579  total_loss: 3.535  loss_ce: 0.574  loss_giou: 0.4016  loss_bbox: 0.3788  loss_ce_0: 0.6032  loss_giou_0: 0.405  loss_bbox_0: 0.4391  loss_rpn_cls: 0.2689  loss_rpn_reg: 0.5317  time: 0.1894  last_time: 0.1995  data_time: 0.0048  last_data_time: 0.0075   lr: 5e-05  max_mem: 3029M
[03/05 12:46:24] d2.utils.events INFO:  eta: 1:47:20  iter: 19599  total_loss: 3.087  loss_ce: 0.4552  loss_giou: 0.3454  loss_bbox: 0.3398  loss_ce_0: 0.5407  loss_giou_0: 0.3678  loss_bbox_0: 0.3587  loss_rpn_cls: 0.2919  loss_rpn_reg: 0.4903  time: 0.1894  last_time: 0.1968  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:46:28] d2.utils.events INFO:  eta: 1:47:02  iter: 19619  total_loss: 3.21  loss_ce: 0.4938  loss_giou: 0.3862  loss_bbox: 0.3024  loss_ce_0: 0.4966  loss_giou_0: 0.4219  loss_bbox_0: 0.3167  loss_rpn_cls: 0.2652  loss_rpn_reg: 0.4934  time: 0.1894  last_time: 0.1808  data_time: 0.0054  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:46:32] d2.utils.events INFO:  eta: 1:47:08  iter: 19639  total_loss: 3.266  loss_ce: 0.5383  loss_giou: 0.3448  loss_bbox: 0.3183  loss_ce_0: 0.5838  loss_giou_0: 0.3947  loss_bbox_0: 0.3735  loss_rpn_cls: 0.2581  loss_rpn_reg: 0.489  time: 0.1894  last_time: 0.1724  data_time: 0.0048  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:46:36] d2.utils.events INFO:  eta: 1:47:08  iter: 19659  total_loss: 3.539  loss_ce: 0.5648  loss_giou: 0.4123  loss_bbox: 0.2869  loss_ce_0: 0.5854  loss_giou_0: 0.4483  loss_bbox_0: 0.3304  loss_rpn_cls: 0.2872  loss_rpn_reg: 0.5084  time: 0.1894  last_time: 0.1888  data_time: 0.0050  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:46:39] d2.utils.events INFO:  eta: 1:47:00  iter: 19679  total_loss: 3.16  loss_ce: 0.5927  loss_giou: 0.3383  loss_bbox: 0.2935  loss_ce_0: 0.5531  loss_giou_0: 0.3792  loss_bbox_0: 0.3512  loss_rpn_cls: 0.2489  loss_rpn_reg: 0.5076  time: 0.1894  last_time: 0.1902  data_time: 0.0050  last_data_time: 0.0078   lr: 5e-05  max_mem: 3029M
[03/05 12:46:43] d2.utils.events INFO:  eta: 1:47:03  iter: 19699  total_loss: 3.368  loss_ce: 0.5155  loss_giou: 0.3792  loss_bbox: 0.3273  loss_ce_0: 0.5071  loss_giou_0: 0.4112  loss_bbox_0: 0.3502  loss_rpn_cls: 0.2764  loss_rpn_reg: 0.4903  time: 0.1894  last_time: 0.1841  data_time: 0.0049  last_data_time: 0.0074   lr: 5e-05  max_mem: 3029M
[03/05 12:46:47] d2.utils.events INFO:  eta: 1:46:57  iter: 19719  total_loss: 3.595  loss_ce: 0.4993  loss_giou: 0.4351  loss_bbox: 0.3529  loss_ce_0: 0.5506  loss_giou_0: 0.4551  loss_bbox_0: 0.4105  loss_rpn_cls: 0.2684  loss_rpn_reg: 0.5205  time: 0.1894  last_time: 0.1994  data_time: 0.0048  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:46:51] d2.utils.events INFO:  eta: 1:46:53  iter: 19739  total_loss: 3.394  loss_ce: 0.5218  loss_giou: 0.3839  loss_bbox: 0.2981  loss_ce_0: 0.5204  loss_giou_0: 0.4035  loss_bbox_0: 0.3343  loss_rpn_cls: 0.3087  loss_rpn_reg: 0.5231  time: 0.1894  last_time: 0.1876  data_time: 0.0051  last_data_time: 0.0095   lr: 5e-05  max_mem: 3029M
[03/05 12:46:55] d2.utils.events INFO:  eta: 1:46:51  iter: 19759  total_loss: 3.025  loss_ce: 0.4616  loss_giou: 0.3377  loss_bbox: 0.2838  loss_ce_0: 0.5666  loss_giou_0: 0.3605  loss_bbox_0: 0.3231  loss_rpn_cls: 0.267  loss_rpn_reg: 0.4837  time: 0.1894  last_time: 0.1858  data_time: 0.0050  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:46:58] d2.utils.events INFO:  eta: 1:46:48  iter: 19779  total_loss: 3.475  loss_ce: 0.5884  loss_giou: 0.3992  loss_bbox: 0.3106  loss_ce_0: 0.5449  loss_giou_0: 0.4675  loss_bbox_0: 0.3721  loss_rpn_cls: 0.2902  loss_rpn_reg: 0.5138  time: 0.1894  last_time: 0.1773  data_time: 0.0050  last_data_time: 0.0031   lr: 5e-05  max_mem: 3029M
[03/05 12:47:02] d2.utils.events INFO:  eta: 1:46:44  iter: 19799  total_loss: 3.427  loss_ce: 0.4875  loss_giou: 0.3674  loss_bbox: 0.3588  loss_ce_0: 0.5385  loss_giou_0: 0.4033  loss_bbox_0: 0.3828  loss_rpn_cls: 0.2626  loss_rpn_reg: 0.507  time: 0.1894  last_time: 0.1612  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:47:06] d2.utils.events INFO:  eta: 1:46:48  iter: 19819  total_loss: 3.989  loss_ce: 0.6089  loss_giou: 0.4167  loss_bbox: 0.3966  loss_ce_0: 0.6159  loss_giou_0: 0.4328  loss_bbox_0: 0.4552  loss_rpn_cls: 0.3013  loss_rpn_reg: 0.5037  time: 0.1894  last_time: 0.1930  data_time: 0.0045  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:47:10] d2.utils.events INFO:  eta: 1:46:48  iter: 19839  total_loss: 3.377  loss_ce: 0.5271  loss_giou: 0.3523  loss_bbox: 0.3553  loss_ce_0: 0.5559  loss_giou_0: 0.3681  loss_bbox_0: 0.4202  loss_rpn_cls: 0.25  loss_rpn_reg: 0.4971  time: 0.1894  last_time: 0.2122  data_time: 0.0053  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:47:14] d2.utils.events INFO:  eta: 1:46:44  iter: 19859  total_loss: 3.472  loss_ce: 0.5026  loss_giou: 0.396  loss_bbox: 0.339  loss_ce_0: 0.5594  loss_giou_0: 0.4078  loss_bbox_0: 0.3465  loss_rpn_cls: 0.2752  loss_rpn_reg: 0.5468  time: 0.1894  last_time: 0.1862  data_time: 0.0054  last_data_time: 0.0032   lr: 5e-05  max_mem: 3029M
[03/05 12:47:18] d2.utils.events INFO:  eta: 1:46:41  iter: 19879  total_loss: 3.241  loss_ce: 0.5798  loss_giou: 0.3487  loss_bbox: 0.3232  loss_ce_0: 0.5577  loss_giou_0: 0.3629  loss_bbox_0: 0.3759  loss_rpn_cls: 0.2635  loss_rpn_reg: 0.4885  time: 0.1894  last_time: 0.1962  data_time: 0.0054  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 12:47:22] d2.utils.events INFO:  eta: 1:46:38  iter: 19899  total_loss: 3.366  loss_ce: 0.4682  loss_giou: 0.4078  loss_bbox: 0.359  loss_ce_0: 0.5291  loss_giou_0: 0.4228  loss_bbox_0: 0.3609  loss_rpn_cls: 0.2538  loss_rpn_reg: 0.5078  time: 0.1894  last_time: 0.1725  data_time: 0.0055  last_data_time: 0.0024   lr: 5e-05  max_mem: 3029M
[03/05 12:47:25] d2.utils.events INFO:  eta: 1:46:35  iter: 19919  total_loss: 3.255  loss_ce: 0.4967  loss_giou: 0.4067  loss_bbox: 0.37  loss_ce_0: 0.5149  loss_giou_0: 0.4015  loss_bbox_0: 0.4013  loss_rpn_cls: 0.2669  loss_rpn_reg: 0.5184  time: 0.1894  last_time: 0.1953  data_time: 0.0047  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:47:29] d2.utils.events INFO:  eta: 1:46:36  iter: 19939  total_loss: 3.349  loss_ce: 0.5388  loss_giou: 0.3569  loss_bbox: 0.3849  loss_ce_0: 0.5594  loss_giou_0: 0.3845  loss_bbox_0: 0.4118  loss_rpn_cls: 0.2472  loss_rpn_reg: 0.4981  time: 0.1894  last_time: 0.1849  data_time: 0.0051  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:47:33] d2.utils.events INFO:  eta: 1:46:26  iter: 19959  total_loss: 3.373  loss_ce: 0.4711  loss_giou: 0.3944  loss_bbox: 0.3336  loss_ce_0: 0.5089  loss_giou_0: 0.4063  loss_bbox_0: 0.3583  loss_rpn_cls: 0.2433  loss_rpn_reg: 0.4993  time: 0.1894  last_time: 0.1810  data_time: 0.0051  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:47:37] d2.utils.events INFO:  eta: 1:46:16  iter: 19979  total_loss: 3.439  loss_ce: 0.5361  loss_giou: 0.391  loss_bbox: 0.359  loss_ce_0: 0.5586  loss_giou_0: 0.4408  loss_bbox_0: 0.4408  loss_rpn_cls: 0.2831  loss_rpn_reg: 0.5209  time: 0.1894  last_time: 0.2093  data_time: 0.0049  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:47:41] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/t1/model_0019999.pth
[03/05 12:47:42] d2.utils.events INFO:  eta: 1:46:11  iter: 19999  total_loss: 3.565  loss_ce: 0.5966  loss_giou: 0.4233  loss_bbox: 0.3253  loss_ce_0: 0.5787  loss_giou_0: 0.4643  loss_bbox_0: 0.3489  loss_rpn_cls: 0.282  loss_rpn_reg: 0.5187  time: 0.1894  last_time: 0.1955  data_time: 0.0053  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:47:46] d2.utils.events INFO:  eta: 1:46:04  iter: 20019  total_loss: 3.577  loss_ce: 0.5392  loss_giou: 0.4486  loss_bbox: 0.305  loss_ce_0: 0.587  loss_giou_0: 0.4704  loss_bbox_0: 0.3251  loss_rpn_cls: 0.2884  loss_rpn_reg: 0.5204  time: 0.1894  last_time: 0.2117  data_time: 0.0053  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 12:47:50] d2.utils.events INFO:  eta: 1:45:58  iter: 20039  total_loss: 3.251  loss_ce: 0.4596  loss_giou: 0.3672  loss_bbox: 0.3146  loss_ce_0: 0.4742  loss_giou_0: 0.4118  loss_bbox_0: 0.3399  loss_rpn_cls: 0.2552  loss_rpn_reg: 0.5262  time: 0.1894  last_time: 0.1925  data_time: 0.0052  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:47:53] d2.utils.events INFO:  eta: 1:45:56  iter: 20059  total_loss: 3.548  loss_ce: 0.5961  loss_giou: 0.3331  loss_bbox: 0.3115  loss_ce_0: 0.5904  loss_giou_0: 0.3544  loss_bbox_0: 0.3343  loss_rpn_cls: 0.2682  loss_rpn_reg: 0.5174  time: 0.1894  last_time: 0.1957  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:47:57] d2.utils.events INFO:  eta: 1:45:56  iter: 20079  total_loss: 3.28  loss_ce: 0.5587  loss_giou: 0.3888  loss_bbox: 0.3299  loss_ce_0: 0.6096  loss_giou_0: 0.3937  loss_bbox_0: 0.3364  loss_rpn_cls: 0.2757  loss_rpn_reg: 0.5202  time: 0.1894  last_time: 0.1857  data_time: 0.0048  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:48:01] d2.utils.events INFO:  eta: 1:45:54  iter: 20099  total_loss: 3.504  loss_ce: 0.5357  loss_giou: 0.377  loss_bbox: 0.3034  loss_ce_0: 0.5824  loss_giou_0: 0.3799  loss_bbox_0: 0.3483  loss_rpn_cls: 0.2609  loss_rpn_reg: 0.5  time: 0.1894  last_time: 0.1750  data_time: 0.0054  last_data_time: 0.0090   lr: 5e-05  max_mem: 3029M
[03/05 12:48:05] d2.utils.events INFO:  eta: 1:45:47  iter: 20119  total_loss: 3.158  loss_ce: 0.4925  loss_giou: 0.3689  loss_bbox: 0.3185  loss_ce_0: 0.5352  loss_giou_0: 0.341  loss_bbox_0: 0.3356  loss_rpn_cls: 0.2635  loss_rpn_reg: 0.4649  time: 0.1894  last_time: 0.1867  data_time: 0.0048  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 12:48:09] d2.utils.events INFO:  eta: 1:45:40  iter: 20139  total_loss: 3.453  loss_ce: 0.5923  loss_giou: 0.3476  loss_bbox: 0.2981  loss_ce_0: 0.6197  loss_giou_0: 0.3909  loss_bbox_0: 0.3335  loss_rpn_cls: 0.2671  loss_rpn_reg: 0.5186  time: 0.1894  last_time: 0.1886  data_time: 0.0046  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:48:12] d2.utils.events INFO:  eta: 1:45:41  iter: 20159  total_loss: 3.416  loss_ce: 0.5548  loss_giou: 0.4258  loss_bbox: 0.3219  loss_ce_0: 0.5731  loss_giou_0: 0.447  loss_bbox_0: 0.3278  loss_rpn_cls: 0.2817  loss_rpn_reg: 0.5043  time: 0.1894  last_time: 0.1842  data_time: 0.0049  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 12:48:16] d2.utils.events INFO:  eta: 1:45:36  iter: 20179  total_loss: 3.117  loss_ce: 0.5322  loss_giou: 0.3514  loss_bbox: 0.2709  loss_ce_0: 0.5407  loss_giou_0: 0.3809  loss_bbox_0: 0.3144  loss_rpn_cls: 0.2866  loss_rpn_reg: 0.5099  time: 0.1894  last_time: 0.1899  data_time: 0.0051  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:48:20] d2.utils.events INFO:  eta: 1:45:32  iter: 20199  total_loss: 3.489  loss_ce: 0.5612  loss_giou: 0.3552  loss_bbox: 0.3304  loss_ce_0: 0.5911  loss_giou_0: 0.3786  loss_bbox_0: 0.3629  loss_rpn_cls: 0.293  loss_rpn_reg: 0.5367  time: 0.1894  last_time: 0.1752  data_time: 0.0053  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 12:48:24] d2.utils.events INFO:  eta: 1:45:21  iter: 20219  total_loss: 3.151  loss_ce: 0.5833  loss_giou: 0.3712  loss_bbox: 0.3055  loss_ce_0: 0.5486  loss_giou_0: 0.3708  loss_bbox_0: 0.3379  loss_rpn_cls: 0.2652  loss_rpn_reg: 0.4893  time: 0.1894  last_time: 0.1926  data_time: 0.0048  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 12:48:28] d2.utils.events INFO:  eta: 1:45:19  iter: 20239  total_loss: 3.394  loss_ce: 0.5368  loss_giou: 0.378  loss_bbox: 0.3385  loss_ce_0: 0.5362  loss_giou_0: 0.3863  loss_bbox_0: 0.3458  loss_rpn_cls: 0.2575  loss_rpn_reg: 0.5269  time: 0.1894  last_time: 0.1967  data_time: 0.0049  last_data_time: 0.0021   lr: 5e-05  max_mem: 3029M
[03/05 12:48:32] d2.utils.events INFO:  eta: 1:45:18  iter: 20259  total_loss: 3.434  loss_ce: 0.5569  loss_giou: 0.3743  loss_bbox: 0.3489  loss_ce_0: 0.5376  loss_giou_0: 0.4068  loss_bbox_0: 0.374  loss_rpn_cls: 0.3006  loss_rpn_reg: 0.4979  time: 0.1894  last_time: 0.2399  data_time: 0.0049  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:48:36] d2.utils.events INFO:  eta: 1:45:21  iter: 20279  total_loss: 3.286  loss_ce: 0.5276  loss_giou: 0.4041  loss_bbox: 0.3113  loss_ce_0: 0.5373  loss_giou_0: 0.4037  loss_bbox_0: 0.3429  loss_rpn_cls: 0.274  loss_rpn_reg: 0.5072  time: 0.1894  last_time: 0.2192  data_time: 0.0047  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:48:39] d2.utils.events INFO:  eta: 1:45:12  iter: 20299  total_loss: 3.4  loss_ce: 0.5009  loss_giou: 0.3803  loss_bbox: 0.3508  loss_ce_0: 0.492  loss_giou_0: 0.3957  loss_bbox_0: 0.4081  loss_rpn_cls: 0.2445  loss_rpn_reg: 0.5083  time: 0.1894  last_time: 0.1872  data_time: 0.0045  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:48:43] d2.utils.events INFO:  eta: 1:45:09  iter: 20319  total_loss: 3.481  loss_ce: 0.5489  loss_giou: 0.4121  loss_bbox: 0.33  loss_ce_0: 0.5638  loss_giou_0: 0.4415  loss_bbox_0: 0.3548  loss_rpn_cls: 0.2695  loss_rpn_reg: 0.5426  time: 0.1894  last_time: 0.1976  data_time: 0.0047  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:48:47] d2.utils.events INFO:  eta: 1:45:01  iter: 20339  total_loss: 3.246  loss_ce: 0.4935  loss_giou: 0.3023  loss_bbox: 0.328  loss_ce_0: 0.5017  loss_giou_0: 0.3483  loss_bbox_0: 0.3565  loss_rpn_cls: 0.2563  loss_rpn_reg: 0.5014  time: 0.1894  last_time: 0.1900  data_time: 0.0046  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:48:51] d2.utils.events INFO:  eta: 1:44:56  iter: 20359  total_loss: 3.17  loss_ce: 0.4704  loss_giou: 0.3973  loss_bbox: 0.3289  loss_ce_0: 0.5016  loss_giou_0: 0.4304  loss_bbox_0: 0.356  loss_rpn_cls: 0.271  loss_rpn_reg: 0.4858  time: 0.1894  last_time: 0.1737  data_time: 0.0048  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:48:55] d2.utils.events INFO:  eta: 1:44:58  iter: 20379  total_loss: 3.478  loss_ce: 0.4858  loss_giou: 0.4013  loss_bbox: 0.3569  loss_ce_0: 0.5233  loss_giou_0: 0.4304  loss_bbox_0: 0.3808  loss_rpn_cls: 0.2823  loss_rpn_reg: 0.4822  time: 0.1894  last_time: 0.1814  data_time: 0.0049  last_data_time: 0.0024   lr: 5e-05  max_mem: 3029M
[03/05 12:48:58] d2.utils.events INFO:  eta: 1:44:57  iter: 20399  total_loss: 3.315  loss_ce: 0.4703  loss_giou: 0.3915  loss_bbox: 0.3625  loss_ce_0: 0.4941  loss_giou_0: 0.3897  loss_bbox_0: 0.35  loss_rpn_cls: 0.2733  loss_rpn_reg: 0.4962  time: 0.1894  last_time: 0.1575  data_time: 0.0045  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:49:02] d2.utils.events INFO:  eta: 1:44:56  iter: 20419  total_loss: 3.56  loss_ce: 0.5917  loss_giou: 0.4202  loss_bbox: 0.3198  loss_ce_0: 0.5902  loss_giou_0: 0.4253  loss_bbox_0: 0.38  loss_rpn_cls: 0.2796  loss_rpn_reg: 0.5067  time: 0.1894  last_time: 0.1765  data_time: 0.0051  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 12:49:06] d2.utils.events INFO:  eta: 1:45:00  iter: 20439  total_loss: 3.076  loss_ce: 0.513  loss_giou: 0.3284  loss_bbox: 0.2786  loss_ce_0: 0.4945  loss_giou_0: 0.3503  loss_bbox_0: 0.3069  loss_rpn_cls: 0.265  loss_rpn_reg: 0.4919  time: 0.1894  last_time: 0.1812  data_time: 0.0048  last_data_time: 0.0027   lr: 5e-05  max_mem: 3029M
[03/05 12:49:10] d2.utils.events INFO:  eta: 1:44:51  iter: 20459  total_loss: 3.225  loss_ce: 0.447  loss_giou: 0.3681  loss_bbox: 0.3978  loss_ce_0: 0.4833  loss_giou_0: 0.3588  loss_bbox_0: 0.4259  loss_rpn_cls: 0.2736  loss_rpn_reg: 0.5068  time: 0.1894  last_time: 0.1667  data_time: 0.0049  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:49:14] d2.utils.events INFO:  eta: 1:44:41  iter: 20479  total_loss: 3.245  loss_ce: 0.5457  loss_giou: 0.3573  loss_bbox: 0.3205  loss_ce_0: 0.5926  loss_giou_0: 0.3639  loss_bbox_0: 0.3199  loss_rpn_cls: 0.2661  loss_rpn_reg: 0.4871  time: 0.1894  last_time: 0.1893  data_time: 0.0046  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:49:17] d2.utils.events INFO:  eta: 1:44:35  iter: 20499  total_loss: 3.156  loss_ce: 0.5259  loss_giou: 0.2805  loss_bbox: 0.3472  loss_ce_0: 0.5688  loss_giou_0: 0.3074  loss_bbox_0: 0.3466  loss_rpn_cls: 0.2619  loss_rpn_reg: 0.4738  time: 0.1893  last_time: 0.1912  data_time: 0.0042  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:49:21] d2.utils.events INFO:  eta: 1:44:36  iter: 20519  total_loss: 3.439  loss_ce: 0.5507  loss_giou: 0.3998  loss_bbox: 0.3916  loss_ce_0: 0.5548  loss_giou_0: 0.4238  loss_bbox_0: 0.4428  loss_rpn_cls: 0.2726  loss_rpn_reg: 0.5157  time: 0.1893  last_time: 0.1989  data_time: 0.0047  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:49:25] d2.utils.events INFO:  eta: 1:44:34  iter: 20539  total_loss: 3.563  loss_ce: 0.5544  loss_giou: 0.3946  loss_bbox: 0.3539  loss_ce_0: 0.5291  loss_giou_0: 0.3959  loss_bbox_0: 0.3862  loss_rpn_cls: 0.2697  loss_rpn_reg: 0.512  time: 0.1893  last_time: 0.1959  data_time: 0.0049  last_data_time: 0.0069   lr: 5e-05  max_mem: 3029M
[03/05 12:49:29] d2.utils.events INFO:  eta: 1:44:33  iter: 20559  total_loss: 3.576  loss_ce: 0.5966  loss_giou: 0.4606  loss_bbox: 0.3393  loss_ce_0: 0.5876  loss_giou_0: 0.495  loss_bbox_0: 0.392  loss_rpn_cls: 0.29  loss_rpn_reg: 0.5465  time: 0.1893  last_time: 0.1942  data_time: 0.0044  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:49:33] d2.utils.events INFO:  eta: 1:44:29  iter: 20579  total_loss: 3.13  loss_ce: 0.4398  loss_giou: 0.3734  loss_bbox: 0.2704  loss_ce_0: 0.5242  loss_giou_0: 0.3962  loss_bbox_0: 0.2874  loss_rpn_cls: 0.2525  loss_rpn_reg: 0.5273  time: 0.1893  last_time: 0.2029  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:49:36] d2.utils.events INFO:  eta: 1:44:23  iter: 20599  total_loss: 3.538  loss_ce: 0.575  loss_giou: 0.3555  loss_bbox: 0.3726  loss_ce_0: 0.5947  loss_giou_0: 0.3926  loss_bbox_0: 0.4526  loss_rpn_cls: 0.2407  loss_rpn_reg: 0.5174  time: 0.1893  last_time: 0.1766  data_time: 0.0047  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:49:40] d2.utils.events INFO:  eta: 1:44:22  iter: 20619  total_loss: 3.276  loss_ce: 0.5122  loss_giou: 0.3983  loss_bbox: 0.2665  loss_ce_0: 0.5632  loss_giou_0: 0.3987  loss_bbox_0: 0.3216  loss_rpn_cls: 0.2632  loss_rpn_reg: 0.5086  time: 0.1893  last_time: 0.1546  data_time: 0.0045  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:49:44] d2.utils.events INFO:  eta: 1:44:14  iter: 20639  total_loss: 3.226  loss_ce: 0.5414  loss_giou: 0.3669  loss_bbox: 0.3201  loss_ce_0: 0.5756  loss_giou_0: 0.3875  loss_bbox_0: 0.3378  loss_rpn_cls: 0.2559  loss_rpn_reg: 0.456  time: 0.1893  last_time: 0.1747  data_time: 0.0046  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:49:48] d2.utils.events INFO:  eta: 1:44:13  iter: 20659  total_loss: 3.444  loss_ce: 0.5411  loss_giou: 0.3336  loss_bbox: 0.278  loss_ce_0: 0.5205  loss_giou_0: 0.3788  loss_bbox_0: 0.3302  loss_rpn_cls: 0.2818  loss_rpn_reg: 0.5186  time: 0.1893  last_time: 0.1912  data_time: 0.0051  last_data_time: 0.0071   lr: 5e-05  max_mem: 3029M
[03/05 12:49:51] d2.utils.events INFO:  eta: 1:44:08  iter: 20679  total_loss: 3.35  loss_ce: 0.548  loss_giou: 0.399  loss_bbox: 0.3456  loss_ce_0: 0.5358  loss_giou_0: 0.4177  loss_bbox_0: 0.3533  loss_rpn_cls: 0.2828  loss_rpn_reg: 0.5077  time: 0.1893  last_time: 0.1946  data_time: 0.0048  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:49:55] d2.utils.events INFO:  eta: 1:44:02  iter: 20699  total_loss: 3.143  loss_ce: 0.4706  loss_giou: 0.2997  loss_bbox: 0.2629  loss_ce_0: 0.542  loss_giou_0: 0.3441  loss_bbox_0: 0.3005  loss_rpn_cls: 0.2534  loss_rpn_reg: 0.463  time: 0.1893  last_time: 0.1900  data_time: 0.0045  last_data_time: 0.0032   lr: 5e-05  max_mem: 3029M
[03/05 12:49:59] d2.utils.events INFO:  eta: 1:43:54  iter: 20719  total_loss: 3.19  loss_ce: 0.4981  loss_giou: 0.3723  loss_bbox: 0.2996  loss_ce_0: 0.5006  loss_giou_0: 0.3872  loss_bbox_0: 0.3364  loss_rpn_cls: 0.2246  loss_rpn_reg: 0.5234  time: 0.1893  last_time: 0.1823  data_time: 0.0043  last_data_time: 0.0020   lr: 5e-05  max_mem: 3029M
[03/05 12:50:03] d2.utils.events INFO:  eta: 1:43:55  iter: 20739  total_loss: 3.349  loss_ce: 0.539  loss_giou: 0.4393  loss_bbox: 0.3405  loss_ce_0: 0.525  loss_giou_0: 0.474  loss_bbox_0: 0.3443  loss_rpn_cls: 0.2731  loss_rpn_reg: 0.5135  time: 0.1893  last_time: 0.1863  data_time: 0.0050  last_data_time: 0.0094   lr: 5e-05  max_mem: 3029M
[03/05 12:50:07] d2.utils.events INFO:  eta: 1:43:51  iter: 20759  total_loss: 3.133  loss_ce: 0.5062  loss_giou: 0.3728  loss_bbox: 0.2899  loss_ce_0: 0.5219  loss_giou_0: 0.4007  loss_bbox_0: 0.3221  loss_rpn_cls: 0.2789  loss_rpn_reg: 0.5059  time: 0.1893  last_time: 0.1866  data_time: 0.0044  last_data_time: 0.0028   lr: 5e-05  max_mem: 3029M
[03/05 12:50:10] d2.utils.events INFO:  eta: 1:43:47  iter: 20779  total_loss: 3.126  loss_ce: 0.491  loss_giou: 0.3894  loss_bbox: 0.3619  loss_ce_0: 0.5371  loss_giou_0: 0.39  loss_bbox_0: 0.3753  loss_rpn_cls: 0.2569  loss_rpn_reg: 0.4987  time: 0.1893  last_time: 0.1937  data_time: 0.0045  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:50:14] d2.utils.events INFO:  eta: 1:43:44  iter: 20799  total_loss: 2.902  loss_ce: 0.4429  loss_giou: 0.3031  loss_bbox: 0.3277  loss_ce_0: 0.4735  loss_giou_0: 0.3485  loss_bbox_0: 0.3588  loss_rpn_cls: 0.2376  loss_rpn_reg: 0.4828  time: 0.1893  last_time: 0.2040  data_time: 0.0047  last_data_time: 0.0064   lr: 5e-05  max_mem: 3029M
[03/05 12:50:18] d2.utils.events INFO:  eta: 1:43:36  iter: 20819  total_loss: 3.107  loss_ce: 0.4992  loss_giou: 0.3089  loss_bbox: 0.2844  loss_ce_0: 0.5516  loss_giou_0: 0.3452  loss_bbox_0: 0.3319  loss_rpn_cls: 0.242  loss_rpn_reg: 0.4729  time: 0.1893  last_time: 0.1756  data_time: 0.0051  last_data_time: 0.0067   lr: 5e-05  max_mem: 3029M
[03/05 12:50:22] d2.utils.events INFO:  eta: 1:43:34  iter: 20839  total_loss: 3.062  loss_ce: 0.4029  loss_giou: 0.3626  loss_bbox: 0.2845  loss_ce_0: 0.4799  loss_giou_0: 0.3715  loss_bbox_0: 0.3492  loss_rpn_cls: 0.2606  loss_rpn_reg: 0.4739  time: 0.1893  last_time: 0.1797  data_time: 0.0047  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:50:26] d2.utils.events INFO:  eta: 1:43:32  iter: 20859  total_loss: 3.15  loss_ce: 0.5387  loss_giou: 0.3748  loss_bbox: 0.2898  loss_ce_0: 0.542  loss_giou_0: 0.3819  loss_bbox_0: 0.2901  loss_rpn_cls: 0.2381  loss_rpn_reg: 0.4946  time: 0.1893  last_time: 0.2073  data_time: 0.0050  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:50:30] d2.utils.events INFO:  eta: 1:43:32  iter: 20879  total_loss: 3.457  loss_ce: 0.4952  loss_giou: 0.343  loss_bbox: 0.3878  loss_ce_0: 0.5015  loss_giou_0: 0.3772  loss_bbox_0: 0.4047  loss_rpn_cls: 0.2768  loss_rpn_reg: 0.5257  time: 0.1893  last_time: 0.1864  data_time: 0.0046  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:50:33] d2.utils.events INFO:  eta: 1:43:28  iter: 20899  total_loss: 3.392  loss_ce: 0.515  loss_giou: 0.3864  loss_bbox: 0.3284  loss_ce_0: 0.5641  loss_giou_0: 0.3781  loss_bbox_0: 0.3332  loss_rpn_cls: 0.2857  loss_rpn_reg: 0.5055  time: 0.1893  last_time: 0.1854  data_time: 0.0047  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:50:37] d2.utils.events INFO:  eta: 1:43:27  iter: 20919  total_loss: 3.357  loss_ce: 0.5696  loss_giou: 0.392  loss_bbox: 0.3599  loss_ce_0: 0.5719  loss_giou_0: 0.4467  loss_bbox_0: 0.3801  loss_rpn_cls: 0.2586  loss_rpn_reg: 0.5384  time: 0.1893  last_time: 0.1857  data_time: 0.0049  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:50:41] d2.utils.events INFO:  eta: 1:43:19  iter: 20939  total_loss: 3.188  loss_ce: 0.4398  loss_giou: 0.3662  loss_bbox: 0.3232  loss_ce_0: 0.4357  loss_giou_0: 0.4142  loss_bbox_0: 0.3576  loss_rpn_cls: 0.2274  loss_rpn_reg: 0.511  time: 0.1893  last_time: 0.1748  data_time: 0.0048  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:50:45] d2.utils.events INFO:  eta: 1:43:12  iter: 20959  total_loss: 3.163  loss_ce: 0.4625  loss_giou: 0.388  loss_bbox: 0.3423  loss_ce_0: 0.497  loss_giou_0: 0.4064  loss_bbox_0: 0.377  loss_rpn_cls: 0.2747  loss_rpn_reg: 0.493  time: 0.1893  last_time: 0.1871  data_time: 0.0043  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:50:49] d2.utils.events INFO:  eta: 1:43:06  iter: 20979  total_loss: 3.148  loss_ce: 0.4436  loss_giou: 0.3889  loss_bbox: 0.3009  loss_ce_0: 0.4571  loss_giou_0: 0.4231  loss_bbox_0: 0.3512  loss_rpn_cls: 0.2364  loss_rpn_reg: 0.4787  time: 0.1893  last_time: 0.1744  data_time: 0.0048  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:50:52] d2.utils.events INFO:  eta: 1:42:57  iter: 20999  total_loss: 2.951  loss_ce: 0.4479  loss_giou: 0.32  loss_bbox: 0.3084  loss_ce_0: 0.4518  loss_giou_0: 0.3772  loss_bbox_0: 0.3719  loss_rpn_cls: 0.2539  loss_rpn_reg: 0.5059  time: 0.1893  last_time: 0.1815  data_time: 0.0047  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 12:50:56] d2.utils.events INFO:  eta: 1:42:58  iter: 21019  total_loss: 3.11  loss_ce: 0.4469  loss_giou: 0.3857  loss_bbox: 0.3011  loss_ce_0: 0.4777  loss_giou_0: 0.3862  loss_bbox_0: 0.321  loss_rpn_cls: 0.2631  loss_rpn_reg: 0.4689  time: 0.1893  last_time: 0.1850  data_time: 0.0052  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:51:00] d2.utils.events INFO:  eta: 1:42:54  iter: 21039  total_loss: 3.383  loss_ce: 0.5252  loss_giou: 0.4156  loss_bbox: 0.3508  loss_ce_0: 0.4982  loss_giou_0: 0.4354  loss_bbox_0: 0.3814  loss_rpn_cls: 0.2683  loss_rpn_reg: 0.4956  time: 0.1893  last_time: 0.1676  data_time: 0.0044  last_data_time: 0.0028   lr: 5e-05  max_mem: 3029M
[03/05 12:51:04] d2.utils.events INFO:  eta: 1:42:45  iter: 21059  total_loss: 3.027  loss_ce: 0.4724  loss_giou: 0.4059  loss_bbox: 0.3376  loss_ce_0: 0.4826  loss_giou_0: 0.4159  loss_bbox_0: 0.3645  loss_rpn_cls: 0.2349  loss_rpn_reg: 0.5221  time: 0.1893  last_time: 0.1882  data_time: 0.0044  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:51:07] d2.utils.events INFO:  eta: 1:42:41  iter: 21079  total_loss: 3.342  loss_ce: 0.4401  loss_giou: 0.4231  loss_bbox: 0.3614  loss_ce_0: 0.4811  loss_giou_0: 0.4315  loss_bbox_0: 0.3978  loss_rpn_cls: 0.2565  loss_rpn_reg: 0.5175  time: 0.1893  last_time: 0.1979  data_time: 0.0046  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 12:51:11] d2.utils.events INFO:  eta: 1:42:35  iter: 21099  total_loss: 3.133  loss_ce: 0.4632  loss_giou: 0.3276  loss_bbox: 0.3183  loss_ce_0: 0.5105  loss_giou_0: 0.3436  loss_bbox_0: 0.3631  loss_rpn_cls: 0.2533  loss_rpn_reg: 0.5274  time: 0.1893  last_time: 0.1854  data_time: 0.0052  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 12:51:15] d2.utils.events INFO:  eta: 1:42:33  iter: 21119  total_loss: 3.097  loss_ce: 0.4647  loss_giou: 0.3485  loss_bbox: 0.2887  loss_ce_0: 0.4987  loss_giou_0: 0.3725  loss_bbox_0: 0.3303  loss_rpn_cls: 0.2534  loss_rpn_reg: 0.5013  time: 0.1893  last_time: 0.1845  data_time: 0.0053  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 12:51:19] d2.utils.events INFO:  eta: 1:42:28  iter: 21139  total_loss: 3.218  loss_ce: 0.4795  loss_giou: 0.3149  loss_bbox: 0.3669  loss_ce_0: 0.5379  loss_giou_0: 0.3334  loss_bbox_0: 0.3554  loss_rpn_cls: 0.2252  loss_rpn_reg: 0.4813  time: 0.1893  last_time: 0.1786  data_time: 0.0052  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:51:22] d2.utils.events INFO:  eta: 1:42:13  iter: 21159  total_loss: 3.312  loss_ce: 0.5706  loss_giou: 0.3788  loss_bbox: 0.3208  loss_ce_0: 0.5825  loss_giou_0: 0.4294  loss_bbox_0: 0.3752  loss_rpn_cls: 0.2952  loss_rpn_reg: 0.5104  time: 0.1893  last_time: 0.1845  data_time: 0.0046  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:51:26] d2.utils.events INFO:  eta: 1:42:00  iter: 21179  total_loss: 3.284  loss_ce: 0.5064  loss_giou: 0.3875  loss_bbox: 0.3175  loss_ce_0: 0.5252  loss_giou_0: 0.3812  loss_bbox_0: 0.2934  loss_rpn_cls: 0.2959  loss_rpn_reg: 0.5219  time: 0.1893  last_time: 0.1740  data_time: 0.0047  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:51:30] d2.utils.events INFO:  eta: 1:41:54  iter: 21199  total_loss: 3.327  loss_ce: 0.5191  loss_giou: 0.3366  loss_bbox: 0.3278  loss_ce_0: 0.5244  loss_giou_0: 0.3719  loss_bbox_0: 0.3293  loss_rpn_cls: 0.2571  loss_rpn_reg: 0.5094  time: 0.1892  last_time: 0.1962  data_time: 0.0051  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:51:34] d2.utils.events INFO:  eta: 1:41:54  iter: 21219  total_loss: 3.373  loss_ce: 0.4622  loss_giou: 0.3435  loss_bbox: 0.3315  loss_ce_0: 0.4993  loss_giou_0: 0.3628  loss_bbox_0: 0.3792  loss_rpn_cls: 0.2666  loss_rpn_reg: 0.5035  time: 0.1892  last_time: 0.1757  data_time: 0.0048  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:51:37] d2.utils.events INFO:  eta: 1:41:52  iter: 21239  total_loss: 3.432  loss_ce: 0.5414  loss_giou: 0.402  loss_bbox: 0.3466  loss_ce_0: 0.549  loss_giou_0: 0.4091  loss_bbox_0: 0.3664  loss_rpn_cls: 0.2602  loss_rpn_reg: 0.4811  time: 0.1892  last_time: 0.1997  data_time: 0.0046  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 12:51:41] d2.utils.events INFO:  eta: 1:41:48  iter: 21259  total_loss: 3.073  loss_ce: 0.4963  loss_giou: 0.3494  loss_bbox: 0.3004  loss_ce_0: 0.5213  loss_giou_0: 0.3705  loss_bbox_0: 0.3337  loss_rpn_cls: 0.2649  loss_rpn_reg: 0.4959  time: 0.1892  last_time: 0.1784  data_time: 0.0046  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:51:45] d2.utils.events INFO:  eta: 1:41:40  iter: 21279  total_loss: 3.23  loss_ce: 0.5021  loss_giou: 0.3878  loss_bbox: 0.3446  loss_ce_0: 0.5247  loss_giou_0: 0.3933  loss_bbox_0: 0.3771  loss_rpn_cls: 0.2565  loss_rpn_reg: 0.4942  time: 0.1892  last_time: 0.1956  data_time: 0.0050  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:51:49] d2.utils.events INFO:  eta: 1:41:41  iter: 21299  total_loss: 3.358  loss_ce: 0.5763  loss_giou: 0.4051  loss_bbox: 0.3062  loss_ce_0: 0.5385  loss_giou_0: 0.3971  loss_bbox_0: 0.3346  loss_rpn_cls: 0.2896  loss_rpn_reg: 0.495  time: 0.1892  last_time: 0.1901  data_time: 0.0050  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:51:53] d2.utils.events INFO:  eta: 1:41:33  iter: 21319  total_loss: 3.227  loss_ce: 0.5331  loss_giou: 0.4222  loss_bbox: 0.2921  loss_ce_0: 0.5314  loss_giou_0: 0.4323  loss_bbox_0: 0.3362  loss_rpn_cls: 0.2641  loss_rpn_reg: 0.5183  time: 0.1892  last_time: 0.1733  data_time: 0.0048  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:51:56] d2.utils.events INFO:  eta: 1:41:28  iter: 21339  total_loss: 3.053  loss_ce: 0.5155  loss_giou: 0.3423  loss_bbox: 0.2989  loss_ce_0: 0.5389  loss_giou_0: 0.3492  loss_bbox_0: 0.3285  loss_rpn_cls: 0.2572  loss_rpn_reg: 0.4484  time: 0.1892  last_time: 0.1608  data_time: 0.0051  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:52:00] d2.utils.events INFO:  eta: 1:41:22  iter: 21359  total_loss: 3.312  loss_ce: 0.5036  loss_giou: 0.4153  loss_bbox: 0.3653  loss_ce_0: 0.5282  loss_giou_0: 0.4217  loss_bbox_0: 0.3917  loss_rpn_cls: 0.2418  loss_rpn_reg: 0.5411  time: 0.1892  last_time: 0.1753  data_time: 0.0044  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:52:04] d2.utils.events INFO:  eta: 1:41:17  iter: 21379  total_loss: 3.271  loss_ce: 0.5103  loss_giou: 0.3806  loss_bbox: 0.3273  loss_ce_0: 0.5297  loss_giou_0: 0.3778  loss_bbox_0: 0.36  loss_rpn_cls: 0.2488  loss_rpn_reg: 0.5059  time: 0.1892  last_time: 0.1644  data_time: 0.0050  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:52:08] d2.utils.events INFO:  eta: 1:41:14  iter: 21399  total_loss: 3.247  loss_ce: 0.5653  loss_giou: 0.3713  loss_bbox: 0.3496  loss_ce_0: 0.543  loss_giou_0: 0.4091  loss_bbox_0: 0.4223  loss_rpn_cls: 0.267  loss_rpn_reg: 0.5111  time: 0.1892  last_time: 0.1976  data_time: 0.0049  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:52:11] d2.utils.events INFO:  eta: 1:41:13  iter: 21419  total_loss: 3.24  loss_ce: 0.4291  loss_giou: 0.3746  loss_bbox: 0.3235  loss_ce_0: 0.4908  loss_giou_0: 0.4081  loss_bbox_0: 0.3514  loss_rpn_cls: 0.2551  loss_rpn_reg: 0.5192  time: 0.1892  last_time: 0.1953  data_time: 0.0044  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:52:15] d2.utils.events INFO:  eta: 1:41:10  iter: 21439  total_loss: 3.471  loss_ce: 0.4957  loss_giou: 0.4506  loss_bbox: 0.2964  loss_ce_0: 0.5278  loss_giou_0: 0.4661  loss_bbox_0: 0.3271  loss_rpn_cls: 0.2756  loss_rpn_reg: 0.518  time: 0.1892  last_time: 0.1949  data_time: 0.0048  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:52:19] d2.utils.events INFO:  eta: 1:41:04  iter: 21459  total_loss: 3.124  loss_ce: 0.4647  loss_giou: 0.3519  loss_bbox: 0.2803  loss_ce_0: 0.4718  loss_giou_0: 0.3694  loss_bbox_0: 0.3305  loss_rpn_cls: 0.2389  loss_rpn_reg: 0.472  time: 0.1892  last_time: 0.1673  data_time: 0.0043  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:52:23] d2.utils.events INFO:  eta: 1:41:01  iter: 21479  total_loss: 3.206  loss_ce: 0.4585  loss_giou: 0.4135  loss_bbox: 0.3375  loss_ce_0: 0.4857  loss_giou_0: 0.4316  loss_bbox_0: 0.3752  loss_rpn_cls: 0.2546  loss_rpn_reg: 0.5004  time: 0.1892  last_time: 0.1958  data_time: 0.0046  last_data_time: 0.0070   lr: 5e-05  max_mem: 3029M
[03/05 12:52:26] d2.utils.events INFO:  eta: 1:40:58  iter: 21499  total_loss: 3.167  loss_ce: 0.4717  loss_giou: 0.3757  loss_bbox: 0.3352  loss_ce_0: 0.4755  loss_giou_0: 0.422  loss_bbox_0: 0.3378  loss_rpn_cls: 0.2449  loss_rpn_reg: 0.4695  time: 0.1892  last_time: 0.1863  data_time: 0.0045  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:52:30] d2.utils.events INFO:  eta: 1:40:53  iter: 21519  total_loss: 3.219  loss_ce: 0.4478  loss_giou: 0.3949  loss_bbox: 0.3585  loss_ce_0: 0.4526  loss_giou_0: 0.42  loss_bbox_0: 0.3682  loss_rpn_cls: 0.2548  loss_rpn_reg: 0.4862  time: 0.1892  last_time: 0.1592  data_time: 0.0046  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:52:34] d2.utils.events INFO:  eta: 1:40:46  iter: 21539  total_loss: 3.112  loss_ce: 0.4523  loss_giou: 0.3015  loss_bbox: 0.3555  loss_ce_0: 0.5143  loss_giou_0: 0.3184  loss_bbox_0: 0.3744  loss_rpn_cls: 0.2302  loss_rpn_reg: 0.4923  time: 0.1892  last_time: 0.1779  data_time: 0.0052  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 12:52:38] d2.utils.events INFO:  eta: 1:40:43  iter: 21559  total_loss: 3.326  loss_ce: 0.4907  loss_giou: 0.4025  loss_bbox: 0.3385  loss_ce_0: 0.5582  loss_giou_0: 0.416  loss_bbox_0: 0.4135  loss_rpn_cls: 0.2872  loss_rpn_reg: 0.5309  time: 0.1892  last_time: 0.2077  data_time: 0.0048  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:52:42] d2.utils.events INFO:  eta: 1:40:40  iter: 21579  total_loss: 2.889  loss_ce: 0.4684  loss_giou: 0.3184  loss_bbox: 0.3094  loss_ce_0: 0.5027  loss_giou_0: 0.3309  loss_bbox_0: 0.3322  loss_rpn_cls: 0.2418  loss_rpn_reg: 0.4919  time: 0.1892  last_time: 0.1798  data_time: 0.0044  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:52:45] d2.utils.events INFO:  eta: 1:40:35  iter: 21599  total_loss: 3.168  loss_ce: 0.4648  loss_giou: 0.2876  loss_bbox: 0.3603  loss_ce_0: 0.4715  loss_giou_0: 0.325  loss_bbox_0: 0.3866  loss_rpn_cls: 0.2222  loss_rpn_reg: 0.4762  time: 0.1892  last_time: 0.1696  data_time: 0.0053  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:52:49] d2.utils.events INFO:  eta: 1:40:34  iter: 21619  total_loss: 3.297  loss_ce: 0.4948  loss_giou: 0.3567  loss_bbox: 0.3296  loss_ce_0: 0.5408  loss_giou_0: 0.3809  loss_bbox_0: 0.3629  loss_rpn_cls: 0.258  loss_rpn_reg: 0.4959  time: 0.1892  last_time: 0.1997  data_time: 0.0044  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 12:52:53] d2.utils.events INFO:  eta: 1:40:32  iter: 21639  total_loss: 3.207  loss_ce: 0.4484  loss_giou: 0.3964  loss_bbox: 0.291  loss_ce_0: 0.518  loss_giou_0: 0.4  loss_bbox_0: 0.3303  loss_rpn_cls: 0.2565  loss_rpn_reg: 0.5309  time: 0.1892  last_time: 0.1778  data_time: 0.0048  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 12:52:57] d2.utils.events INFO:  eta: 1:40:25  iter: 21659  total_loss: 3.41  loss_ce: 0.5279  loss_giou: 0.3544  loss_bbox: 0.3876  loss_ce_0: 0.5645  loss_giou_0: 0.3946  loss_bbox_0: 0.376  loss_rpn_cls: 0.2681  loss_rpn_reg: 0.4961  time: 0.1892  last_time: 0.1895  data_time: 0.0046  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:53:01] d2.utils.events INFO:  eta: 1:40:25  iter: 21679  total_loss: 3.73  loss_ce: 0.4983  loss_giou: 0.4209  loss_bbox: 0.3781  loss_ce_0: 0.5561  loss_giou_0: 0.4356  loss_bbox_0: 0.3846  loss_rpn_cls: 0.2765  loss_rpn_reg: 0.5473  time: 0.1892  last_time: 0.1883  data_time: 0.0051  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:53:05] d2.utils.events INFO:  eta: 1:40:21  iter: 21699  total_loss: 3.326  loss_ce: 0.4801  loss_giou: 0.3931  loss_bbox: 0.3905  loss_ce_0: 0.4889  loss_giou_0: 0.4197  loss_bbox_0: 0.4102  loss_rpn_cls: 0.2377  loss_rpn_reg: 0.4914  time: 0.1892  last_time: 0.1857  data_time: 0.0050  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:53:09] d2.utils.events INFO:  eta: 1:40:28  iter: 21719  total_loss: 3.439  loss_ce: 0.5351  loss_giou: 0.4028  loss_bbox: 0.3426  loss_ce_0: 0.572  loss_giou_0: 0.4135  loss_bbox_0: 0.3593  loss_rpn_cls: 0.2605  loss_rpn_reg: 0.5153  time: 0.1892  last_time: 0.2048  data_time: 0.0053  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:53:13] d2.utils.events INFO:  eta: 1:40:26  iter: 21739  total_loss: 3.036  loss_ce: 0.4197  loss_giou: 0.352  loss_bbox: 0.255  loss_ce_0: 0.5017  loss_giou_0: 0.3686  loss_bbox_0: 0.2875  loss_rpn_cls: 0.2428  loss_rpn_reg: 0.4866  time: 0.1892  last_time: 0.2013  data_time: 0.0053  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:53:16] d2.utils.events INFO:  eta: 1:40:21  iter: 21759  total_loss: 3.034  loss_ce: 0.5057  loss_giou: 0.3049  loss_bbox: 0.3214  loss_ce_0: 0.5051  loss_giou_0: 0.3539  loss_bbox_0: 0.3735  loss_rpn_cls: 0.2329  loss_rpn_reg: 0.4905  time: 0.1892  last_time: 0.1958  data_time: 0.0053  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 12:53:20] d2.utils.events INFO:  eta: 1:40:12  iter: 21779  total_loss: 2.961  loss_ce: 0.4622  loss_giou: 0.2689  loss_bbox: 0.3188  loss_ce_0: 0.5262  loss_giou_0: 0.2846  loss_bbox_0: 0.3419  loss_rpn_cls: 0.2408  loss_rpn_reg: 0.4568  time: 0.1892  last_time: 0.1830  data_time: 0.0047  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:53:24] d2.utils.events INFO:  eta: 1:40:09  iter: 21799  total_loss: 3.096  loss_ce: 0.5222  loss_giou: 0.2995  loss_bbox: 0.284  loss_ce_0: 0.5448  loss_giou_0: 0.3353  loss_bbox_0: 0.3251  loss_rpn_cls: 0.2418  loss_rpn_reg: 0.4418  time: 0.1892  last_time: 0.1890  data_time: 0.0047  last_data_time: 0.0024   lr: 5e-05  max_mem: 3029M
[03/05 12:53:28] d2.utils.events INFO:  eta: 1:40:02  iter: 21819  total_loss: 3.445  loss_ce: 0.5511  loss_giou: 0.3936  loss_bbox: 0.3224  loss_ce_0: 0.498  loss_giou_0: 0.4126  loss_bbox_0: 0.3449  loss_rpn_cls: 0.2933  loss_rpn_reg: 0.4975  time: 0.1892  last_time: 0.2082  data_time: 0.0045  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 12:53:32] d2.utils.events INFO:  eta: 1:40:02  iter: 21839  total_loss: 2.879  loss_ce: 0.4584  loss_giou: 0.3417  loss_bbox: 0.3138  loss_ce_0: 0.4846  loss_giou_0: 0.3743  loss_bbox_0: 0.3331  loss_rpn_cls: 0.2438  loss_rpn_reg: 0.4937  time: 0.1892  last_time: 0.2070  data_time: 0.0049  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:53:36] d2.utils.events INFO:  eta: 1:40:01  iter: 21859  total_loss: 3.133  loss_ce: 0.4713  loss_giou: 0.4032  loss_bbox: 0.2908  loss_ce_0: 0.4685  loss_giou_0: 0.4131  loss_bbox_0: 0.3319  loss_rpn_cls: 0.2601  loss_rpn_reg: 0.4938  time: 0.1892  last_time: 0.1871  data_time: 0.0055  last_data_time: 0.0027   lr: 5e-05  max_mem: 3029M
[03/05 12:53:39] d2.utils.events INFO:  eta: 1:39:51  iter: 21879  total_loss: 3.158  loss_ce: 0.4738  loss_giou: 0.3392  loss_bbox: 0.3268  loss_ce_0: 0.4898  loss_giou_0: 0.3674  loss_bbox_0: 0.3942  loss_rpn_cls: 0.2497  loss_rpn_reg: 0.4677  time: 0.1892  last_time: 0.1908  data_time: 0.0049  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:53:43] d2.utils.events INFO:  eta: 1:39:48  iter: 21899  total_loss: 3.344  loss_ce: 0.5233  loss_giou: 0.4283  loss_bbox: 0.3303  loss_ce_0: 0.5223  loss_giou_0: 0.4376  loss_bbox_0: 0.3545  loss_rpn_cls: 0.2865  loss_rpn_reg: 0.4798  time: 0.1892  last_time: 0.1838  data_time: 0.0046  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:53:47] d2.utils.events INFO:  eta: 1:39:49  iter: 21919  total_loss: 3.289  loss_ce: 0.4866  loss_giou: 0.41  loss_bbox: 0.3091  loss_ce_0: 0.4809  loss_giou_0: 0.4088  loss_bbox_0: 0.3552  loss_rpn_cls: 0.2564  loss_rpn_reg: 0.5179  time: 0.1892  last_time: 0.1723  data_time: 0.0047  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:53:51] d2.utils.events INFO:  eta: 1:39:46  iter: 21939  total_loss: 3.218  loss_ce: 0.4802  loss_giou: 0.394  loss_bbox: 0.3058  loss_ce_0: 0.4986  loss_giou_0: 0.4045  loss_bbox_0: 0.3255  loss_rpn_cls: 0.2492  loss_rpn_reg: 0.4925  time: 0.1892  last_time: 0.2064  data_time: 0.0046  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:53:55] d2.utils.events INFO:  eta: 1:39:42  iter: 21959  total_loss: 3.266  loss_ce: 0.5287  loss_giou: 0.3717  loss_bbox: 0.3154  loss_ce_0: 0.5499  loss_giou_0: 0.3995  loss_bbox_0: 0.3576  loss_rpn_cls: 0.2657  loss_rpn_reg: 0.5017  time: 0.1892  last_time: 0.1844  data_time: 0.0053  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 12:53:58] d2.utils.events INFO:  eta: 1:39:38  iter: 21979  total_loss: 2.837  loss_ce: 0.4264  loss_giou: 0.3094  loss_bbox: 0.2975  loss_ce_0: 0.465  loss_giou_0: 0.3423  loss_bbox_0: 0.3331  loss_rpn_cls: 0.2423  loss_rpn_reg: 0.4855  time: 0.1892  last_time: 0.1815  data_time: 0.0046  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:54:02] d2.utils.events INFO:  eta: 1:39:40  iter: 21999  total_loss: 2.909  loss_ce: 0.3796  loss_giou: 0.3204  loss_bbox: 0.3484  loss_ce_0: 0.3921  loss_giou_0: 0.3238  loss_bbox_0: 0.3487  loss_rpn_cls: 0.2325  loss_rpn_reg: 0.4916  time: 0.1892  last_time: 0.2110  data_time: 0.0045  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:54:06] d2.utils.events INFO:  eta: 1:39:35  iter: 22019  total_loss: 3.136  loss_ce: 0.4884  loss_giou: 0.3468  loss_bbox: 0.3023  loss_ce_0: 0.4396  loss_giou_0: 0.3663  loss_bbox_0: 0.3077  loss_rpn_cls: 0.2221  loss_rpn_reg: 0.4878  time: 0.1892  last_time: 0.1766  data_time: 0.0052  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:54:10] d2.utils.events INFO:  eta: 1:39:39  iter: 22039  total_loss: 3.119  loss_ce: 0.4634  loss_giou: 0.3415  loss_bbox: 0.3088  loss_ce_0: 0.4783  loss_giou_0: 0.361  loss_bbox_0: 0.3318  loss_rpn_cls: 0.2498  loss_rpn_reg: 0.4772  time: 0.1892  last_time: 0.2030  data_time: 0.0050  last_data_time: 0.0069   lr: 5e-05  max_mem: 3029M
[03/05 12:54:14] d2.utils.events INFO:  eta: 1:39:36  iter: 22059  total_loss: 3.071  loss_ce: 0.5242  loss_giou: 0.3397  loss_bbox: 0.2998  loss_ce_0: 0.5032  loss_giou_0: 0.3701  loss_bbox_0: 0.3285  loss_rpn_cls: 0.2968  loss_rpn_reg: 0.4437  time: 0.1892  last_time: 0.1723  data_time: 0.0047  last_data_time: 0.0026   lr: 5e-05  max_mem: 3029M
[03/05 12:54:18] d2.utils.events INFO:  eta: 1:39:40  iter: 22079  total_loss: 3.404  loss_ce: 0.4926  loss_giou: 0.323  loss_bbox: 0.3621  loss_ce_0: 0.528  loss_giou_0: 0.3425  loss_bbox_0: 0.3849  loss_rpn_cls: 0.2704  loss_rpn_reg: 0.5154  time: 0.1892  last_time: 0.1934  data_time: 0.0052  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:54:22] d2.utils.events INFO:  eta: 1:39:43  iter: 22099  total_loss: 3.277  loss_ce: 0.5454  loss_giou: 0.3559  loss_bbox: 0.3025  loss_ce_0: 0.5075  loss_giou_0: 0.3683  loss_bbox_0: 0.2995  loss_rpn_cls: 0.2475  loss_rpn_reg: 0.469  time: 0.1892  last_time: 0.1795  data_time: 0.0051  last_data_time: 0.0064   lr: 5e-05  max_mem: 3029M
[03/05 12:54:26] d2.utils.events INFO:  eta: 1:39:55  iter: 22119  total_loss: 3.273  loss_ce: 0.479  loss_giou: 0.396  loss_bbox: 0.3848  loss_ce_0: 0.504  loss_giou_0: 0.4051  loss_bbox_0: 0.3826  loss_rpn_cls: 0.258  loss_rpn_reg: 0.4973  time: 0.1892  last_time: 0.1864  data_time: 0.0046  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:54:29] d2.utils.events INFO:  eta: 1:39:54  iter: 22139  total_loss: 2.947  loss_ce: 0.4473  loss_giou: 0.3566  loss_bbox: 0.2667  loss_ce_0: 0.4511  loss_giou_0: 0.3874  loss_bbox_0: 0.2973  loss_rpn_cls: 0.2548  loss_rpn_reg: 0.5153  time: 0.1892  last_time: 0.1640  data_time: 0.0043  last_data_time: 0.0025   lr: 5e-05  max_mem: 3029M
[03/05 12:54:33] d2.utils.events INFO:  eta: 1:39:54  iter: 22159  total_loss: 3.002  loss_ce: 0.4637  loss_giou: 0.2971  loss_bbox: 0.3221  loss_ce_0: 0.4988  loss_giou_0: 0.3388  loss_bbox_0: 0.3451  loss_rpn_cls: 0.2434  loss_rpn_reg: 0.4644  time: 0.1892  last_time: 0.1978  data_time: 0.0052  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:54:37] d2.utils.events INFO:  eta: 1:39:51  iter: 22179  total_loss: 3.281  loss_ce: 0.535  loss_giou: 0.3479  loss_bbox: 0.3607  loss_ce_0: 0.5607  loss_giou_0: 0.3712  loss_bbox_0: 0.3862  loss_rpn_cls: 0.2968  loss_rpn_reg: 0.5076  time: 0.1892  last_time: 0.1893  data_time: 0.0052  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 12:54:41] d2.utils.events INFO:  eta: 1:39:47  iter: 22199  total_loss: 3.394  loss_ce: 0.5906  loss_giou: 0.3506  loss_bbox: 0.3406  loss_ce_0: 0.5811  loss_giou_0: 0.3714  loss_bbox_0: 0.3724  loss_rpn_cls: 0.2887  loss_rpn_reg: 0.4895  time: 0.1892  last_time: 0.1804  data_time: 0.0048  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 12:54:45] d2.utils.events INFO:  eta: 1:39:49  iter: 22219  total_loss: 3.119  loss_ce: 0.4582  loss_giou: 0.3214  loss_bbox: 0.3098  loss_ce_0: 0.5498  loss_giou_0: 0.3511  loss_bbox_0: 0.3412  loss_rpn_cls: 0.2539  loss_rpn_reg: 0.5027  time: 0.1892  last_time: 0.1958  data_time: 0.0051  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:54:48] d2.utils.events INFO:  eta: 1:39:43  iter: 22239  total_loss: 3.164  loss_ce: 0.5401  loss_giou: 0.3455  loss_bbox: 0.3318  loss_ce_0: 0.5163  loss_giou_0: 0.3834  loss_bbox_0: 0.362  loss_rpn_cls: 0.2696  loss_rpn_reg: 0.482  time: 0.1892  last_time: 0.2021  data_time: 0.0044  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:54:52] d2.utils.events INFO:  eta: 1:39:39  iter: 22259  total_loss: 2.923  loss_ce: 0.4935  loss_giou: 0.3387  loss_bbox: 0.2982  loss_ce_0: 0.4968  loss_giou_0: 0.3764  loss_bbox_0: 0.3572  loss_rpn_cls: 0.2528  loss_rpn_reg: 0.4406  time: 0.1892  last_time: 0.1503  data_time: 0.0049  last_data_time: 0.0026   lr: 5e-05  max_mem: 3029M
[03/05 12:54:56] d2.utils.events INFO:  eta: 1:39:32  iter: 22279  total_loss: 3.083  loss_ce: 0.4513  loss_giou: 0.3399  loss_bbox: 0.2934  loss_ce_0: 0.4781  loss_giou_0: 0.3802  loss_bbox_0: 0.3332  loss_rpn_cls: 0.2504  loss_rpn_reg: 0.5133  time: 0.1892  last_time: 0.1954  data_time: 0.0053  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:55:00] d2.utils.events INFO:  eta: 1:39:28  iter: 22299  total_loss: 3.019  loss_ce: 0.4602  loss_giou: 0.3391  loss_bbox: 0.2876  loss_ce_0: 0.4861  loss_giou_0: 0.3484  loss_bbox_0: 0.2802  loss_rpn_cls: 0.2418  loss_rpn_reg: 0.5042  time: 0.1892  last_time: 0.1854  data_time: 0.0048  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 12:55:04] d2.utils.events INFO:  eta: 1:39:25  iter: 22319  total_loss: 3.084  loss_ce: 0.4688  loss_giou: 0.3147  loss_bbox: 0.2989  loss_ce_0: 0.4812  loss_giou_0: 0.3553  loss_bbox_0: 0.3431  loss_rpn_cls: 0.2333  loss_rpn_reg: 0.4837  time: 0.1892  last_time: 0.1942  data_time: 0.0050  last_data_time: 0.0080   lr: 5e-05  max_mem: 3029M
[03/05 12:55:08] d2.utils.events INFO:  eta: 1:39:33  iter: 22339  total_loss: 3.693  loss_ce: 0.5891  loss_giou: 0.3712  loss_bbox: 0.3583  loss_ce_0: 0.6246  loss_giou_0: 0.3733  loss_bbox_0: 0.3765  loss_rpn_cls: 0.2891  loss_rpn_reg: 0.5424  time: 0.1892  last_time: 0.1743  data_time: 0.0048  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:55:11] d2.utils.events INFO:  eta: 1:39:25  iter: 22359  total_loss: 3.091  loss_ce: 0.4924  loss_giou: 0.34  loss_bbox: 0.3349  loss_ce_0: 0.5225  loss_giou_0: 0.355  loss_bbox_0: 0.3339  loss_rpn_cls: 0.2434  loss_rpn_reg: 0.4879  time: 0.1892  last_time: 0.1732  data_time: 0.0042  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 12:55:15] d2.utils.events INFO:  eta: 1:39:23  iter: 22379  total_loss: 3.192  loss_ce: 0.5556  loss_giou: 0.3102  loss_bbox: 0.2502  loss_ce_0: 0.5127  loss_giou_0: 0.3319  loss_bbox_0: 0.2638  loss_rpn_cls: 0.2512  loss_rpn_reg: 0.4704  time: 0.1892  last_time: 0.1948  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:55:19] d2.utils.events INFO:  eta: 1:39:11  iter: 22399  total_loss: 3.002  loss_ce: 0.4714  loss_giou: 0.3351  loss_bbox: 0.283  loss_ce_0: 0.4839  loss_giou_0: 0.3355  loss_bbox_0: 0.3053  loss_rpn_cls: 0.232  loss_rpn_reg: 0.4537  time: 0.1892  last_time: 0.1963  data_time: 0.0050  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:55:23] d2.utils.events INFO:  eta: 1:39:15  iter: 22419  total_loss: 3.085  loss_ce: 0.465  loss_giou: 0.3422  loss_bbox: 0.2978  loss_ce_0: 0.4728  loss_giou_0: 0.3688  loss_bbox_0: 0.3303  loss_rpn_cls: 0.2435  loss_rpn_reg: 0.4991  time: 0.1892  last_time: 0.1986  data_time: 0.0050  last_data_time: 0.0100   lr: 5e-05  max_mem: 3029M
[03/05 12:55:26] d2.utils.events INFO:  eta: 1:39:02  iter: 22439  total_loss: 3.058  loss_ce: 0.5188  loss_giou: 0.3035  loss_bbox: 0.3106  loss_ce_0: 0.553  loss_giou_0: 0.3396  loss_bbox_0: 0.3231  loss_rpn_cls: 0.2433  loss_rpn_reg: 0.4569  time: 0.1892  last_time: 0.1607  data_time: 0.0047  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:55:30] d2.utils.events INFO:  eta: 1:38:55  iter: 22459  total_loss: 3.24  loss_ce: 0.5306  loss_giou: 0.3651  loss_bbox: 0.3228  loss_ce_0: 0.5319  loss_giou_0: 0.377  loss_bbox_0: 0.3714  loss_rpn_cls: 0.2502  loss_rpn_reg: 0.5203  time: 0.1892  last_time: 0.1762  data_time: 0.0047  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 12:55:34] d2.utils.events INFO:  eta: 1:38:55  iter: 22479  total_loss: 3.034  loss_ce: 0.4663  loss_giou: 0.3113  loss_bbox: 0.3031  loss_ce_0: 0.5181  loss_giou_0: 0.353  loss_bbox_0: 0.3324  loss_rpn_cls: 0.269  loss_rpn_reg: 0.5125  time: 0.1892  last_time: 0.1920  data_time: 0.0051  last_data_time: 0.0026   lr: 5e-05  max_mem: 3029M
[03/05 12:55:38] d2.utils.events INFO:  eta: 1:39:01  iter: 22499  total_loss: 2.955  loss_ce: 0.485  loss_giou: 0.3339  loss_bbox: 0.3159  loss_ce_0: 0.5058  loss_giou_0: 0.362  loss_bbox_0: 0.3792  loss_rpn_cls: 0.2317  loss_rpn_reg: 0.4762  time: 0.1892  last_time: 0.1978  data_time: 0.0050  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:55:42] d2.utils.events INFO:  eta: 1:39:01  iter: 22519  total_loss: 3.32  loss_ce: 0.4691  loss_giou: 0.3898  loss_bbox: 0.2922  loss_ce_0: 0.4799  loss_giou_0: 0.4142  loss_bbox_0: 0.3205  loss_rpn_cls: 0.2517  loss_rpn_reg: 0.4949  time: 0.1892  last_time: 0.1667  data_time: 0.0051  last_data_time: 0.0078   lr: 5e-05  max_mem: 3029M
[03/05 12:55:45] d2.utils.events INFO:  eta: 1:38:58  iter: 22539  total_loss: 3.048  loss_ce: 0.432  loss_giou: 0.4032  loss_bbox: 0.3347  loss_ce_0: 0.4455  loss_giou_0: 0.4308  loss_bbox_0: 0.3467  loss_rpn_cls: 0.2333  loss_rpn_reg: 0.5193  time: 0.1892  last_time: 0.1611  data_time: 0.0047  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 12:55:49] d2.utils.events INFO:  eta: 1:38:54  iter: 22559  total_loss: 3.132  loss_ce: 0.4619  loss_giou: 0.3468  loss_bbox: 0.2958  loss_ce_0: 0.5138  loss_giou_0: 0.3902  loss_bbox_0: 0.3316  loss_rpn_cls: 0.2534  loss_rpn_reg: 0.4515  time: 0.1892  last_time: 0.1908  data_time: 0.0055  last_data_time: 0.0089   lr: 5e-05  max_mem: 3029M
[03/05 12:55:53] d2.utils.events INFO:  eta: 1:38:51  iter: 22579  total_loss: 3.543  loss_ce: 0.4991  loss_giou: 0.3675  loss_bbox: 0.457  loss_ce_0: 0.5108  loss_giou_0: 0.4093  loss_bbox_0: 0.4361  loss_rpn_cls: 0.27  loss_rpn_reg: 0.5251  time: 0.1892  last_time: 0.1733  data_time: 0.0049  last_data_time: 0.0032   lr: 5e-05  max_mem: 3029M
[03/05 12:55:57] d2.utils.events INFO:  eta: 1:38:51  iter: 22599  total_loss: 3.398  loss_ce: 0.5237  loss_giou: 0.3743  loss_bbox: 0.3481  loss_ce_0: 0.5495  loss_giou_0: 0.3935  loss_bbox_0: 0.3735  loss_rpn_cls: 0.2749  loss_rpn_reg: 0.5164  time: 0.1892  last_time: 0.1927  data_time: 0.0052  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:56:00] d2.utils.events INFO:  eta: 1:38:38  iter: 22619  total_loss: 3.45  loss_ce: 0.5124  loss_giou: 0.4088  loss_bbox: 0.3492  loss_ce_0: 0.5251  loss_giou_0: 0.4413  loss_bbox_0: 0.4064  loss_rpn_cls: 0.2472  loss_rpn_reg: 0.5249  time: 0.1892  last_time: 0.2006  data_time: 0.0050  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:56:04] d2.utils.events INFO:  eta: 1:38:27  iter: 22639  total_loss: 3.239  loss_ce: 0.508  loss_giou: 0.3401  loss_bbox: 0.2932  loss_ce_0: 0.4791  loss_giou_0: 0.3728  loss_bbox_0: 0.3303  loss_rpn_cls: 0.2593  loss_rpn_reg: 0.4727  time: 0.1891  last_time: 0.1783  data_time: 0.0049  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:56:08] d2.utils.events INFO:  eta: 1:38:21  iter: 22659  total_loss: 3.52  loss_ce: 0.5027  loss_giou: 0.4294  loss_bbox: 0.354  loss_ce_0: 0.516  loss_giou_0: 0.4507  loss_bbox_0: 0.4247  loss_rpn_cls: 0.2889  loss_rpn_reg: 0.5012  time: 0.1891  last_time: 0.1849  data_time: 0.0048  last_data_time: 0.0080   lr: 5e-05  max_mem: 3029M
[03/05 12:56:12] d2.utils.events INFO:  eta: 1:38:21  iter: 22679  total_loss: 3.261  loss_ce: 0.4565  loss_giou: 0.3562  loss_bbox: 0.3146  loss_ce_0: 0.4504  loss_giou_0: 0.3479  loss_bbox_0: 0.3108  loss_rpn_cls: 0.2579  loss_rpn_reg: 0.4911  time: 0.1892  last_time: 0.1777  data_time: 0.0047  last_data_time: 0.0027   lr: 5e-05  max_mem: 3029M
[03/05 12:56:16] d2.utils.events INFO:  eta: 1:38:20  iter: 22699  total_loss: 3.302  loss_ce: 0.5129  loss_giou: 0.3555  loss_bbox: 0.3195  loss_ce_0: 0.5728  loss_giou_0: 0.3848  loss_bbox_0: 0.3489  loss_rpn_cls: 0.2673  loss_rpn_reg: 0.4678  time: 0.1892  last_time: 0.2043  data_time: 0.0049  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:56:20] d2.utils.events INFO:  eta: 1:38:11  iter: 22719  total_loss: 3.479  loss_ce: 0.5319  loss_giou: 0.375  loss_bbox: 0.3704  loss_ce_0: 0.5663  loss_giou_0: 0.3931  loss_bbox_0: 0.3812  loss_rpn_cls: 0.2805  loss_rpn_reg: 0.4999  time: 0.1892  last_time: 0.2089  data_time: 0.0054  last_data_time: 0.0088   lr: 5e-05  max_mem: 3029M
[03/05 12:56:24] d2.utils.events INFO:  eta: 1:38:08  iter: 22739  total_loss: 3.187  loss_ce: 0.5493  loss_giou: 0.3822  loss_bbox: 0.2503  loss_ce_0: 0.5534  loss_giou_0: 0.4085  loss_bbox_0: 0.2825  loss_rpn_cls: 0.2587  loss_rpn_reg: 0.5109  time: 0.1892  last_time: 0.2008  data_time: 0.0052  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:56:27] d2.utils.events INFO:  eta: 1:37:57  iter: 22759  total_loss: 3.291  loss_ce: 0.5049  loss_giou: 0.3858  loss_bbox: 0.3425  loss_ce_0: 0.5134  loss_giou_0: 0.4073  loss_bbox_0: 0.3554  loss_rpn_cls: 0.2578  loss_rpn_reg: 0.498  time: 0.1891  last_time: 0.1868  data_time: 0.0048  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:56:31] d2.utils.events INFO:  eta: 1:38:02  iter: 22779  total_loss: 3.061  loss_ce: 0.4636  loss_giou: 0.3576  loss_bbox: 0.2901  loss_ce_0: 0.4828  loss_giou_0: 0.386  loss_bbox_0: 0.3183  loss_rpn_cls: 0.2245  loss_rpn_reg: 0.51  time: 0.1892  last_time: 0.1990  data_time: 0.0053  last_data_time: 0.0072   lr: 5e-05  max_mem: 3029M
[03/05 12:56:35] d2.utils.events INFO:  eta: 1:38:01  iter: 22799  total_loss: 3.054  loss_ce: 0.4225  loss_giou: 0.3755  loss_bbox: 0.3076  loss_ce_0: 0.503  loss_giou_0: 0.3867  loss_bbox_0: 0.3388  loss_rpn_cls: 0.2498  loss_rpn_reg: 0.501  time: 0.1892  last_time: 0.1868  data_time: 0.0050  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:56:39] d2.utils.events INFO:  eta: 1:37:55  iter: 22819  total_loss: 3.563  loss_ce: 0.4815  loss_giou: 0.4046  loss_bbox: 0.3971  loss_ce_0: 0.558  loss_giou_0: 0.4208  loss_bbox_0: 0.4153  loss_rpn_cls: 0.2639  loss_rpn_reg: 0.4868  time: 0.1891  last_time: 0.2025  data_time: 0.0051  last_data_time: 0.0106   lr: 5e-05  max_mem: 3029M
[03/05 12:56:43] d2.utils.events INFO:  eta: 1:37:49  iter: 22839  total_loss: 3.015  loss_ce: 0.435  loss_giou: 0.331  loss_bbox: 0.3446  loss_ce_0: 0.4495  loss_giou_0: 0.3656  loss_bbox_0: 0.3779  loss_rpn_cls: 0.2176  loss_rpn_reg: 0.4619  time: 0.1892  last_time: 0.2006  data_time: 0.0053  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 12:56:47] d2.utils.events INFO:  eta: 1:37:41  iter: 22859  total_loss: 2.583  loss_ce: 0.4036  loss_giou: 0.2796  loss_bbox: 0.2586  loss_ce_0: 0.4685  loss_giou_0: 0.3319  loss_bbox_0: 0.2924  loss_rpn_cls: 0.2157  loss_rpn_reg: 0.4843  time: 0.1892  last_time: 0.1790  data_time: 0.0050  last_data_time: 0.0032   lr: 5e-05  max_mem: 3029M
[03/05 12:56:50] d2.utils.events INFO:  eta: 1:37:42  iter: 22879  total_loss: 3.237  loss_ce: 0.5027  loss_giou: 0.3691  loss_bbox: 0.3291  loss_ce_0: 0.5149  loss_giou_0: 0.4031  loss_bbox_0: 0.3675  loss_rpn_cls: 0.258  loss_rpn_reg: 0.4964  time: 0.1891  last_time: 0.1866  data_time: 0.0048  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 12:56:54] d2.utils.events INFO:  eta: 1:37:37  iter: 22899  total_loss: 3.457  loss_ce: 0.4996  loss_giou: 0.4118  loss_bbox: 0.2795  loss_ce_0: 0.5302  loss_giou_0: 0.474  loss_bbox_0: 0.3472  loss_rpn_cls: 0.2809  loss_rpn_reg: 0.4944  time: 0.1891  last_time: 0.2112  data_time: 0.0054  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:56:58] d2.utils.events INFO:  eta: 1:37:32  iter: 22919  total_loss: 3.27  loss_ce: 0.5584  loss_giou: 0.3536  loss_bbox: 0.3287  loss_ce_0: 0.5586  loss_giou_0: 0.3696  loss_bbox_0: 0.3398  loss_rpn_cls: 0.2685  loss_rpn_reg: 0.4673  time: 0.1891  last_time: 0.1913  data_time: 0.0052  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 12:57:02] d2.utils.events INFO:  eta: 1:37:32  iter: 22939  total_loss: 3.526  loss_ce: 0.5594  loss_giou: 0.4004  loss_bbox: 0.331  loss_ce_0: 0.5509  loss_giou_0: 0.4471  loss_bbox_0: 0.3955  loss_rpn_cls: 0.2745  loss_rpn_reg: 0.5462  time: 0.1892  last_time: 0.2010  data_time: 0.0057  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:57:06] d2.utils.events INFO:  eta: 1:37:30  iter: 22959  total_loss: 3.465  loss_ce: 0.5016  loss_giou: 0.3877  loss_bbox: 0.3247  loss_ce_0: 0.5363  loss_giou_0: 0.4055  loss_bbox_0: 0.3785  loss_rpn_cls: 0.2652  loss_rpn_reg: 0.529  time: 0.1892  last_time: 0.1844  data_time: 0.0049  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:57:10] d2.utils.events INFO:  eta: 1:37:33  iter: 22979  total_loss: 3.423  loss_ce: 0.5029  loss_giou: 0.3789  loss_bbox: 0.3754  loss_ce_0: 0.539  loss_giou_0: 0.4025  loss_bbox_0: 0.4311  loss_rpn_cls: 0.2641  loss_rpn_reg: 0.5087  time: 0.1892  last_time: 0.1879  data_time: 0.0054  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:57:14] d2.utils.events INFO:  eta: 1:37:31  iter: 22999  total_loss: 3.653  loss_ce: 0.5836  loss_giou: 0.3861  loss_bbox: 0.3837  loss_ce_0: 0.5933  loss_giou_0: 0.4053  loss_bbox_0: 0.4056  loss_rpn_cls: 0.2823  loss_rpn_reg: 0.5085  time: 0.1892  last_time: 0.1943  data_time: 0.0053  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 12:57:17] d2.utils.events INFO:  eta: 1:37:27  iter: 23019  total_loss: 3.02  loss_ce: 0.4767  loss_giou: 0.3383  loss_bbox: 0.3141  loss_ce_0: 0.4976  loss_giou_0: 0.3829  loss_bbox_0: 0.3453  loss_rpn_cls: 0.2379  loss_rpn_reg: 0.4891  time: 0.1892  last_time: 0.2030  data_time: 0.0055  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 12:57:21] d2.utils.events INFO:  eta: 1:37:22  iter: 23039  total_loss: 3.077  loss_ce: 0.4084  loss_giou: 0.3273  loss_bbox: 0.2929  loss_ce_0: 0.4356  loss_giou_0: 0.3561  loss_bbox_0: 0.337  loss_rpn_cls: 0.2487  loss_rpn_reg: 0.4857  time: 0.1892  last_time: 0.1714  data_time: 0.0053  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:57:25] d2.utils.events INFO:  eta: 1:37:18  iter: 23059  total_loss: 3.149  loss_ce: 0.5276  loss_giou: 0.3543  loss_bbox: 0.2924  loss_ce_0: 0.5571  loss_giou_0: 0.3753  loss_bbox_0: 0.3563  loss_rpn_cls: 0.2715  loss_rpn_reg: 0.4938  time: 0.1892  last_time: 0.1623  data_time: 0.0059  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:57:29] d2.utils.events INFO:  eta: 1:37:07  iter: 23079  total_loss: 3.29  loss_ce: 0.5077  loss_giou: 0.3632  loss_bbox: 0.3463  loss_ce_0: 0.5206  loss_giou_0: 0.3761  loss_bbox_0: 0.4156  loss_rpn_cls: 0.2681  loss_rpn_reg: 0.4653  time: 0.1892  last_time: 0.1962  data_time: 0.0065  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 12:57:33] d2.utils.events INFO:  eta: 1:37:04  iter: 23099  total_loss: 3.249  loss_ce: 0.5333  loss_giou: 0.34  loss_bbox: 0.2845  loss_ce_0: 0.5323  loss_giou_0: 0.3911  loss_bbox_0: 0.3374  loss_rpn_cls: 0.2464  loss_rpn_reg: 0.501  time: 0.1892  last_time: 0.1948  data_time: 0.0047  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:57:37] d2.utils.events INFO:  eta: 1:36:50  iter: 23119  total_loss: 3.578  loss_ce: 0.4667  loss_giou: 0.4742  loss_bbox: 0.3327  loss_ce_0: 0.4839  loss_giou_0: 0.4461  loss_bbox_0: 0.3635  loss_rpn_cls: 0.2405  loss_rpn_reg: 0.5066  time: 0.1892  last_time: 0.1856  data_time: 0.0050  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:57:41] d2.utils.events INFO:  eta: 1:36:55  iter: 23139  total_loss: 3.107  loss_ce: 0.4113  loss_giou: 0.3573  loss_bbox: 0.3545  loss_ce_0: 0.4801  loss_giou_0: 0.3486  loss_bbox_0: 0.4024  loss_rpn_cls: 0.2246  loss_rpn_reg: 0.4813  time: 0.1892  last_time: 0.2104  data_time: 0.0051  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:57:45] d2.utils.events INFO:  eta: 1:36:54  iter: 23159  total_loss: 3.331  loss_ce: 0.5321  loss_giou: 0.396  loss_bbox: 0.3091  loss_ce_0: 0.5186  loss_giou_0: 0.4011  loss_bbox_0: 0.3404  loss_rpn_cls: 0.2811  loss_rpn_reg: 0.5134  time: 0.1892  last_time: 0.2254  data_time: 0.0054  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:57:48] d2.utils.events INFO:  eta: 1:36:56  iter: 23179  total_loss: 3.268  loss_ce: 0.4853  loss_giou: 0.3244  loss_bbox: 0.3602  loss_ce_0: 0.534  loss_giou_0: 0.3528  loss_bbox_0: 0.3563  loss_rpn_cls: 0.2408  loss_rpn_reg: 0.4702  time: 0.1892  last_time: 0.1978  data_time: 0.0045  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:57:52] d2.utils.events INFO:  eta: 1:36:52  iter: 23199  total_loss: 3.396  loss_ce: 0.5537  loss_giou: 0.3916  loss_bbox: 0.312  loss_ce_0: 0.5595  loss_giou_0: 0.4065  loss_bbox_0: 0.3656  loss_rpn_cls: 0.2859  loss_rpn_reg: 0.5091  time: 0.1892  last_time: 0.2008  data_time: 0.0055  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 12:57:56] d2.utils.events INFO:  eta: 1:36:48  iter: 23219  total_loss: 3.21  loss_ce: 0.5392  loss_giou: 0.3194  loss_bbox: 0.289  loss_ce_0: 0.5606  loss_giou_0: 0.3403  loss_bbox_0: 0.337  loss_rpn_cls: 0.2615  loss_rpn_reg: 0.4802  time: 0.1892  last_time: 0.1829  data_time: 0.0049  last_data_time: 0.0024   lr: 5e-05  max_mem: 3029M
[03/05 12:58:00] d2.utils.events INFO:  eta: 1:36:44  iter: 23239  total_loss: 3.233  loss_ce: 0.5064  loss_giou: 0.3099  loss_bbox: 0.3241  loss_ce_0: 0.5465  loss_giou_0: 0.3415  loss_bbox_0: 0.3593  loss_rpn_cls: 0.2492  loss_rpn_reg: 0.4906  time: 0.1892  last_time: 0.1851  data_time: 0.0056  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:58:04] d2.utils.events INFO:  eta: 1:36:38  iter: 23259  total_loss: 3.304  loss_ce: 0.4998  loss_giou: 0.3725  loss_bbox: 0.2978  loss_ce_0: 0.5351  loss_giou_0: 0.3896  loss_bbox_0: 0.3536  loss_rpn_cls: 0.2669  loss_rpn_reg: 0.509  time: 0.1892  last_time: 0.2055  data_time: 0.0047  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 12:58:07] d2.utils.events INFO:  eta: 1:36:31  iter: 23279  total_loss: 3.177  loss_ce: 0.4514  loss_giou: 0.3291  loss_bbox: 0.3436  loss_ce_0: 0.4759  loss_giou_0: 0.3735  loss_bbox_0: 0.3435  loss_rpn_cls: 0.2323  loss_rpn_reg: 0.472  time: 0.1892  last_time: 0.1910  data_time: 0.0052  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 12:58:11] d2.utils.events INFO:  eta: 1:36:25  iter: 23299  total_loss: 3.305  loss_ce: 0.5403  loss_giou: 0.3537  loss_bbox: 0.343  loss_ce_0: 0.5553  loss_giou_0: 0.3807  loss_bbox_0: 0.4096  loss_rpn_cls: 0.2531  loss_rpn_reg: 0.5088  time: 0.1892  last_time: 0.1876  data_time: 0.0048  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 12:58:15] d2.utils.events INFO:  eta: 1:36:21  iter: 23319  total_loss: 3.221  loss_ce: 0.4918  loss_giou: 0.3784  loss_bbox: 0.3341  loss_ce_0: 0.5239  loss_giou_0: 0.4009  loss_bbox_0: 0.3387  loss_rpn_cls: 0.2657  loss_rpn_reg: 0.5121  time: 0.1892  last_time: 0.1957  data_time: 0.0053  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:58:19] d2.utils.events INFO:  eta: 1:36:17  iter: 23339  total_loss: 3.206  loss_ce: 0.5048  loss_giou: 0.3777  loss_bbox: 0.2853  loss_ce_0: 0.5197  loss_giou_0: 0.4114  loss_bbox_0: 0.3284  loss_rpn_cls: 0.2568  loss_rpn_reg: 0.5214  time: 0.1892  last_time: 0.1853  data_time: 0.0062  last_data_time: 0.0098   lr: 5e-05  max_mem: 3029M
[03/05 12:58:23] d2.utils.events INFO:  eta: 1:36:22  iter: 23359  total_loss: 3.355  loss_ce: 0.4696  loss_giou: 0.4115  loss_bbox: 0.3333  loss_ce_0: 0.507  loss_giou_0: 0.4065  loss_bbox_0: 0.372  loss_rpn_cls: 0.2685  loss_rpn_reg: 0.5243  time: 0.1892  last_time: 0.2016  data_time: 0.0055  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 12:58:27] d2.utils.events INFO:  eta: 1:36:19  iter: 23379  total_loss: 3.053  loss_ce: 0.4893  loss_giou: 0.3239  loss_bbox: 0.3168  loss_ce_0: 0.5233  loss_giou_0: 0.3479  loss_bbox_0: 0.3216  loss_rpn_cls: 0.2677  loss_rpn_reg: 0.5084  time: 0.1892  last_time: 0.1737  data_time: 0.0056  last_data_time: 0.0091   lr: 5e-05  max_mem: 3029M
[03/05 12:58:31] d2.utils.events INFO:  eta: 1:36:21  iter: 23399  total_loss: 3.435  loss_ce: 0.4949  loss_giou: 0.3974  loss_bbox: 0.3283  loss_ce_0: 0.5697  loss_giou_0: 0.3972  loss_bbox_0: 0.3448  loss_rpn_cls: 0.2716  loss_rpn_reg: 0.5171  time: 0.1892  last_time: 0.2059  data_time: 0.0053  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 12:58:35] d2.utils.events INFO:  eta: 1:36:11  iter: 23419  total_loss: 3.188  loss_ce: 0.554  loss_giou: 0.3334  loss_bbox: 0.3074  loss_ce_0: 0.5533  loss_giou_0: 0.367  loss_bbox_0: 0.3324  loss_rpn_cls: 0.2397  loss_rpn_reg: 0.4741  time: 0.1892  last_time: 0.1957  data_time: 0.0046  last_data_time: 0.0031   lr: 5e-05  max_mem: 3029M
[03/05 12:58:38] d2.utils.events INFO:  eta: 1:36:13  iter: 23439  total_loss: 3.024  loss_ce: 0.5196  loss_giou: 0.3561  loss_bbox: 0.3113  loss_ce_0: 0.5287  loss_giou_0: 0.3678  loss_bbox_0: 0.3438  loss_rpn_cls: 0.2421  loss_rpn_reg: 0.4729  time: 0.1892  last_time: 0.1969  data_time: 0.0049  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 12:58:42] d2.utils.events INFO:  eta: 1:36:17  iter: 23459  total_loss: 3.485  loss_ce: 0.6344  loss_giou: 0.3513  loss_bbox: 0.3262  loss_ce_0: 0.5953  loss_giou_0: 0.3609  loss_bbox_0: 0.3842  loss_rpn_cls: 0.272  loss_rpn_reg: 0.5062  time: 0.1892  last_time: 0.1947  data_time: 0.0046  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:58:46] d2.utils.events INFO:  eta: 1:36:11  iter: 23479  total_loss: 3.164  loss_ce: 0.4911  loss_giou: 0.3703  loss_bbox: 0.307  loss_ce_0: 0.4929  loss_giou_0: 0.4052  loss_bbox_0: 0.338  loss_rpn_cls: 0.2802  loss_rpn_reg: 0.5069  time: 0.1892  last_time: 0.2068  data_time: 0.0049  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 12:58:50] d2.utils.events INFO:  eta: 1:36:02  iter: 23499  total_loss: 2.963  loss_ce: 0.4472  loss_giou: 0.3304  loss_bbox: 0.2824  loss_ce_0: 0.5069  loss_giou_0: 0.3281  loss_bbox_0: 0.2686  loss_rpn_cls: 0.223  loss_rpn_reg: 0.5027  time: 0.1892  last_time: 0.1932  data_time: 0.0052  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:58:54] d2.utils.events INFO:  eta: 1:35:56  iter: 23519  total_loss: 3.07  loss_ce: 0.5114  loss_giou: 0.3184  loss_bbox: 0.3092  loss_ce_0: 0.5458  loss_giou_0: 0.3281  loss_bbox_0: 0.3231  loss_rpn_cls: 0.2465  loss_rpn_reg: 0.4543  time: 0.1892  last_time: 0.1896  data_time: 0.0055  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:58:58] d2.utils.events INFO:  eta: 1:35:48  iter: 23539  total_loss: 2.986  loss_ce: 0.4991  loss_giou: 0.3298  loss_bbox: 0.2745  loss_ce_0: 0.5106  loss_giou_0: 0.3569  loss_bbox_0: 0.2974  loss_rpn_cls: 0.2163  loss_rpn_reg: 0.4664  time: 0.1892  last_time: 0.1791  data_time: 0.0051  last_data_time: 0.0085   lr: 5e-05  max_mem: 3029M
[03/05 12:59:02] d2.utils.events INFO:  eta: 1:35:40  iter: 23559  total_loss: 3.249  loss_ce: 0.5336  loss_giou: 0.3305  loss_bbox: 0.3701  loss_ce_0: 0.5942  loss_giou_0: 0.3635  loss_bbox_0: 0.4299  loss_rpn_cls: 0.2626  loss_rpn_reg: 0.4812  time: 0.1892  last_time: 0.1961  data_time: 0.0045  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 12:59:05] d2.utils.events INFO:  eta: 1:35:34  iter: 23579  total_loss: 3.197  loss_ce: 0.5264  loss_giou: 0.3587  loss_bbox: 0.3598  loss_ce_0: 0.5181  loss_giou_0: 0.3916  loss_bbox_0: 0.3813  loss_rpn_cls: 0.2485  loss_rpn_reg: 0.486  time: 0.1892  last_time: 0.1813  data_time: 0.0051  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 12:59:09] d2.utils.events INFO:  eta: 1:35:36  iter: 23599  total_loss: 3.108  loss_ce: 0.5588  loss_giou: 0.3605  loss_bbox: 0.3046  loss_ce_0: 0.5454  loss_giou_0: 0.3831  loss_bbox_0: 0.3366  loss_rpn_cls: 0.2445  loss_rpn_reg: 0.474  time: 0.1892  last_time: 0.1881  data_time: 0.0051  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:59:13] d2.utils.events INFO:  eta: 1:35:48  iter: 23619  total_loss: 3.423  loss_ce: 0.5253  loss_giou: 0.3465  loss_bbox: 0.321  loss_ce_0: 0.5832  loss_giou_0: 0.3725  loss_bbox_0: 0.3479  loss_rpn_cls: 0.2692  loss_rpn_reg: 0.5275  time: 0.1892  last_time: 0.1869  data_time: 0.0057  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:59:17] d2.utils.events INFO:  eta: 1:35:55  iter: 23639  total_loss: 3.284  loss_ce: 0.5436  loss_giou: 0.3834  loss_bbox: 0.3552  loss_ce_0: 0.5292  loss_giou_0: 0.4154  loss_bbox_0: 0.3851  loss_rpn_cls: 0.2592  loss_rpn_reg: 0.4974  time: 0.1892  last_time: 0.1833  data_time: 0.0051  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 12:59:21] d2.utils.events INFO:  eta: 1:35:56  iter: 23659  total_loss: 3.245  loss_ce: 0.46  loss_giou: 0.3758  loss_bbox: 0.339  loss_ce_0: 0.5068  loss_giou_0: 0.3679  loss_bbox_0: 0.3336  loss_rpn_cls: 0.2829  loss_rpn_reg: 0.4951  time: 0.1892  last_time: 0.1979  data_time: 0.0049  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 12:59:25] d2.utils.events INFO:  eta: 1:35:51  iter: 23679  total_loss: 3.013  loss_ce: 0.4573  loss_giou: 0.3505  loss_bbox: 0.3195  loss_ce_0: 0.4771  loss_giou_0: 0.3829  loss_bbox_0: 0.3421  loss_rpn_cls: 0.2553  loss_rpn_reg: 0.5018  time: 0.1892  last_time: 0.1956  data_time: 0.0044  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 12:59:29] d2.utils.events INFO:  eta: 1:35:43  iter: 23699  total_loss: 3.226  loss_ce: 0.55  loss_giou: 0.3578  loss_bbox: 0.2433  loss_ce_0: 0.575  loss_giou_0: 0.3791  loss_bbox_0: 0.2775  loss_rpn_cls: 0.2783  loss_rpn_reg: 0.4889  time: 0.1892  last_time: 0.1870  data_time: 0.0054  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 12:59:32] d2.utils.events INFO:  eta: 1:35:30  iter: 23719  total_loss: 3.466  loss_ce: 0.4863  loss_giou: 0.3931  loss_bbox: 0.3722  loss_ce_0: 0.5126  loss_giou_0: 0.4237  loss_bbox_0: 0.4259  loss_rpn_cls: 0.2875  loss_rpn_reg: 0.4797  time: 0.1892  last_time: 0.1993  data_time: 0.0049  last_data_time: 0.0072   lr: 5e-05  max_mem: 3029M
[03/05 12:59:36] d2.utils.events INFO:  eta: 1:35:24  iter: 23739  total_loss: 3.26  loss_ce: 0.5018  loss_giou: 0.3916  loss_bbox: 0.3068  loss_ce_0: 0.5422  loss_giou_0: 0.4419  loss_bbox_0: 0.3853  loss_rpn_cls: 0.2985  loss_rpn_reg: 0.479  time: 0.1892  last_time: 0.1925  data_time: 0.0053  last_data_time: 0.0075   lr: 5e-05  max_mem: 3029M
[03/05 12:59:40] d2.utils.events INFO:  eta: 1:35:22  iter: 23759  total_loss: 3.185  loss_ce: 0.5035  loss_giou: 0.3606  loss_bbox: 0.3148  loss_ce_0: 0.5457  loss_giou_0: 0.3814  loss_bbox_0: 0.3273  loss_rpn_cls: 0.2496  loss_rpn_reg: 0.4829  time: 0.1892  last_time: 0.1855  data_time: 0.0046  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 12:59:44] d2.utils.events INFO:  eta: 1:35:18  iter: 23779  total_loss: 3.399  loss_ce: 0.5203  loss_giou: 0.3486  loss_bbox: 0.3612  loss_ce_0: 0.5832  loss_giou_0: 0.3991  loss_bbox_0: 0.3817  loss_rpn_cls: 0.2822  loss_rpn_reg: 0.5112  time: 0.1892  last_time: 0.1945  data_time: 0.0051  last_data_time: 0.0067   lr: 5e-05  max_mem: 3029M
[03/05 12:59:48] d2.utils.events INFO:  eta: 1:35:13  iter: 23799  total_loss: 3.12  loss_ce: 0.4816  loss_giou: 0.3308  loss_bbox: 0.2832  loss_ce_0: 0.5231  loss_giou_0: 0.3975  loss_bbox_0: 0.3591  loss_rpn_cls: 0.2551  loss_rpn_reg: 0.4601  time: 0.1892  last_time: 0.2089  data_time: 0.0050  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 12:59:52] d2.utils.events INFO:  eta: 1:35:11  iter: 23819  total_loss: 3.116  loss_ce: 0.517  loss_giou: 0.3534  loss_bbox: 0.3073  loss_ce_0: 0.5116  loss_giou_0: 0.3878  loss_bbox_0: 0.333  loss_rpn_cls: 0.2632  loss_rpn_reg: 0.5058  time: 0.1892  last_time: 0.1753  data_time: 0.0049  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:59:55] d2.utils.events INFO:  eta: 1:35:06  iter: 23839  total_loss: 3.143  loss_ce: 0.5081  loss_giou: 0.3531  loss_bbox: 0.3051  loss_ce_0: 0.4977  loss_giou_0: 0.3642  loss_bbox_0: 0.312  loss_rpn_cls: 0.2667  loss_rpn_reg: 0.4669  time: 0.1892  last_time: 0.1728  data_time: 0.0043  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 12:59:59] d2.utils.events INFO:  eta: 1:35:03  iter: 23859  total_loss: 3.268  loss_ce: 0.5065  loss_giou: 0.3394  loss_bbox: 0.2729  loss_ce_0: 0.5496  loss_giou_0: 0.3772  loss_bbox_0: 0.3365  loss_rpn_cls: 0.2783  loss_rpn_reg: 0.4839  time: 0.1892  last_time: 0.2128  data_time: 0.0045  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:00:03] d2.utils.events INFO:  eta: 1:35:10  iter: 23879  total_loss: 3.219  loss_ce: 0.5783  loss_giou: 0.3647  loss_bbox: 0.3243  loss_ce_0: 0.5844  loss_giou_0: 0.4017  loss_bbox_0: 0.3356  loss_rpn_cls: 0.2728  loss_rpn_reg: 0.5026  time: 0.1892  last_time: 0.1941  data_time: 0.0049  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 13:00:07] d2.utils.events INFO:  eta: 1:35:07  iter: 23899  total_loss: 3.282  loss_ce: 0.5207  loss_giou: 0.3536  loss_bbox: 0.3304  loss_ce_0: 0.5358  loss_giou_0: 0.3799  loss_bbox_0: 0.3896  loss_rpn_cls: 0.2592  loss_rpn_reg: 0.4867  time: 0.1892  last_time: 0.1913  data_time: 0.0050  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:00:11] d2.utils.events INFO:  eta: 1:35:02  iter: 23919  total_loss: 3.344  loss_ce: 0.5027  loss_giou: 0.3692  loss_bbox: 0.3888  loss_ce_0: 0.5071  loss_giou_0: 0.3694  loss_bbox_0: 0.3966  loss_rpn_cls: 0.2747  loss_rpn_reg: 0.4857  time: 0.1892  last_time: 0.1942  data_time: 0.0049  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 13:00:15] d2.utils.events INFO:  eta: 1:34:48  iter: 23939  total_loss: 3.023  loss_ce: 0.4423  loss_giou: 0.3527  loss_bbox: 0.3112  loss_ce_0: 0.467  loss_giou_0: 0.3615  loss_bbox_0: 0.3221  loss_rpn_cls: 0.2546  loss_rpn_reg: 0.4889  time: 0.1892  last_time: 0.1952  data_time: 0.0050  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 13:00:19] d2.utils.events INFO:  eta: 1:34:42  iter: 23959  total_loss: 3.494  loss_ce: 0.5528  loss_giou: 0.4181  loss_bbox: 0.3145  loss_ce_0: 0.5661  loss_giou_0: 0.4482  loss_bbox_0: 0.3637  loss_rpn_cls: 0.3026  loss_rpn_reg: 0.5207  time: 0.1892  last_time: 0.2116  data_time: 0.0049  last_data_time: 0.0021   lr: 5e-05  max_mem: 3029M
[03/05 13:00:22] d2.utils.events INFO:  eta: 1:34:40  iter: 23979  total_loss: 3.109  loss_ce: 0.5042  loss_giou: 0.3113  loss_bbox: 0.2822  loss_ce_0: 0.5257  loss_giou_0: 0.3275  loss_bbox_0: 0.3287  loss_rpn_cls: 0.2225  loss_rpn_reg: 0.4912  time: 0.1892  last_time: 0.1908  data_time: 0.0055  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 13:00:26] d2.utils.events INFO:  eta: 1:34:34  iter: 23999  total_loss: 2.929  loss_ce: 0.4521  loss_giou: 0.364  loss_bbox: 0.2808  loss_ce_0: 0.5029  loss_giou_0: 0.3795  loss_bbox_0: 0.3349  loss_rpn_cls: 0.2705  loss_rpn_reg: 0.4783  time: 0.1892  last_time: 0.1802  data_time: 0.0053  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:00:30] d2.utils.events INFO:  eta: 1:34:22  iter: 24019  total_loss: 3.009  loss_ce: 0.4914  loss_giou: 0.3338  loss_bbox: 0.3208  loss_ce_0: 0.5122  loss_giou_0: 0.3403  loss_bbox_0: 0.3504  loss_rpn_cls: 0.2529  loss_rpn_reg: 0.4363  time: 0.1892  last_time: 0.1788  data_time: 0.0052  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 13:00:34] d2.utils.events INFO:  eta: 1:34:11  iter: 24039  total_loss: 3.213  loss_ce: 0.4846  loss_giou: 0.3802  loss_bbox: 0.3177  loss_ce_0: 0.4916  loss_giou_0: 0.3826  loss_bbox_0: 0.3492  loss_rpn_cls: 0.2463  loss_rpn_reg: 0.4922  time: 0.1892  last_time: 0.1972  data_time: 0.0056  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:00:38] d2.utils.events INFO:  eta: 1:34:13  iter: 24059  total_loss: 3.029  loss_ce: 0.4532  loss_giou: 0.3624  loss_bbox: 0.3048  loss_ce_0: 0.4706  loss_giou_0: 0.3712  loss_bbox_0: 0.3337  loss_rpn_cls: 0.2289  loss_rpn_reg: 0.4789  time: 0.1892  last_time: 0.1801  data_time: 0.0054  last_data_time: 0.0093   lr: 5e-05  max_mem: 3029M
[03/05 13:00:41] d2.utils.events INFO:  eta: 1:34:09  iter: 24079  total_loss: 3.254  loss_ce: 0.478  loss_giou: 0.394  loss_bbox: 0.3078  loss_ce_0: 0.4774  loss_giou_0: 0.4104  loss_bbox_0: 0.3539  loss_rpn_cls: 0.2541  loss_rpn_reg: 0.4908  time: 0.1892  last_time: 0.1804  data_time: 0.0052  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:00:45] d2.utils.events INFO:  eta: 1:33:54  iter: 24099  total_loss: 3.19  loss_ce: 0.4858  loss_giou: 0.3434  loss_bbox: 0.2843  loss_ce_0: 0.4887  loss_giou_0: 0.3685  loss_bbox_0: 0.3197  loss_rpn_cls: 0.271  loss_rpn_reg: 0.4687  time: 0.1892  last_time: 0.1875  data_time: 0.0051  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 13:00:49] d2.utils.events INFO:  eta: 1:33:53  iter: 24119  total_loss: 3.246  loss_ce: 0.4597  loss_giou: 0.3597  loss_bbox: 0.3396  loss_ce_0: 0.4889  loss_giou_0: 0.3964  loss_bbox_0: 0.3807  loss_rpn_cls: 0.264  loss_rpn_reg: 0.4919  time: 0.1892  last_time: 0.1900  data_time: 0.0043  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 13:00:53] d2.utils.events INFO:  eta: 1:33:41  iter: 24139  total_loss: 3.324  loss_ce: 0.4413  loss_giou: 0.3376  loss_bbox: 0.3451  loss_ce_0: 0.5479  loss_giou_0: 0.3361  loss_bbox_0: 0.3688  loss_rpn_cls: 0.266  loss_rpn_reg: 0.5041  time: 0.1892  last_time: 0.1786  data_time: 0.0052  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:00:56] d2.utils.events INFO:  eta: 1:33:29  iter: 24159  total_loss: 3.241  loss_ce: 0.5255  loss_giou: 0.3658  loss_bbox: 0.3617  loss_ce_0: 0.522  loss_giou_0: 0.3938  loss_bbox_0: 0.3917  loss_rpn_cls: 0.2608  loss_rpn_reg: 0.4885  time: 0.1892  last_time: 0.1872  data_time: 0.0057  last_data_time: 0.0109   lr: 5e-05  max_mem: 3029M
[03/05 13:01:00] d2.utils.events INFO:  eta: 1:33:25  iter: 24179  total_loss: 3.108  loss_ce: 0.4768  loss_giou: 0.3631  loss_bbox: 0.3079  loss_ce_0: 0.5249  loss_giou_0: 0.4104  loss_bbox_0: 0.3268  loss_rpn_cls: 0.2582  loss_rpn_reg: 0.4948  time: 0.1892  last_time: 0.1982  data_time: 0.0051  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 13:01:04] d2.utils.events INFO:  eta: 1:33:23  iter: 24199  total_loss: 3.307  loss_ce: 0.5389  loss_giou: 0.3746  loss_bbox: 0.3312  loss_ce_0: 0.6072  loss_giou_0: 0.4347  loss_bbox_0: 0.3688  loss_rpn_cls: 0.2977  loss_rpn_reg: 0.5007  time: 0.1892  last_time: 0.1877  data_time: 0.0048  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 13:01:08] d2.utils.events INFO:  eta: 1:33:21  iter: 24219  total_loss: 3.224  loss_ce: 0.4614  loss_giou: 0.3573  loss_bbox: 0.2841  loss_ce_0: 0.4749  loss_giou_0: 0.3925  loss_bbox_0: 0.3308  loss_rpn_cls: 0.2692  loss_rpn_reg: 0.4754  time: 0.1892  last_time: 0.1836  data_time: 0.0050  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 13:01:12] d2.utils.events INFO:  eta: 1:33:20  iter: 24239  total_loss: 3.049  loss_ce: 0.4686  loss_giou: 0.3458  loss_bbox: 0.2546  loss_ce_0: 0.4507  loss_giou_0: 0.3733  loss_bbox_0: 0.3053  loss_rpn_cls: 0.2689  loss_rpn_reg: 0.4919  time: 0.1892  last_time: 0.1918  data_time: 0.0047  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:01:16] d2.utils.events INFO:  eta: 1:33:21  iter: 24259  total_loss: 3.496  loss_ce: 0.5338  loss_giou: 0.337  loss_bbox: 0.3619  loss_ce_0: 0.5893  loss_giou_0: 0.3602  loss_bbox_0: 0.3877  loss_rpn_cls: 0.254  loss_rpn_reg: 0.5286  time: 0.1892  last_time: 0.2199  data_time: 0.0053  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 13:01:19] d2.utils.events INFO:  eta: 1:33:22  iter: 24279  total_loss: 2.936  loss_ce: 0.4898  loss_giou: 0.3407  loss_bbox: 0.2738  loss_ce_0: 0.5032  loss_giou_0: 0.3616  loss_bbox_0: 0.3126  loss_rpn_cls: 0.2444  loss_rpn_reg: 0.4838  time: 0.1892  last_time: 0.1908  data_time: 0.0050  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 13:01:23] d2.utils.events INFO:  eta: 1:33:19  iter: 24299  total_loss: 2.961  loss_ce: 0.4449  loss_giou: 0.2894  loss_bbox: 0.2864  loss_ce_0: 0.4586  loss_giou_0: 0.3212  loss_bbox_0: 0.3214  loss_rpn_cls: 0.205  loss_rpn_reg: 0.448  time: 0.1892  last_time: 0.1704  data_time: 0.0050  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:01:27] d2.utils.events INFO:  eta: 1:33:13  iter: 24319  total_loss: 3.104  loss_ce: 0.5273  loss_giou: 0.3471  loss_bbox: 0.3119  loss_ce_0: 0.495  loss_giou_0: 0.3979  loss_bbox_0: 0.3489  loss_rpn_cls: 0.2474  loss_rpn_reg: 0.4815  time: 0.1892  last_time: 0.1825  data_time: 0.0044  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:01:31] d2.utils.events INFO:  eta: 1:33:12  iter: 24339  total_loss: 3.421  loss_ce: 0.5613  loss_giou: 0.3439  loss_bbox: 0.3404  loss_ce_0: 0.5957  loss_giou_0: 0.3748  loss_bbox_0: 0.353  loss_rpn_cls: 0.2977  loss_rpn_reg: 0.5015  time: 0.1892  last_time: 0.1829  data_time: 0.0050  last_data_time: 0.0077   lr: 5e-05  max_mem: 3029M
[03/05 13:01:35] d2.utils.events INFO:  eta: 1:32:59  iter: 24359  total_loss: 3.144  loss_ce: 0.4756  loss_giou: 0.3356  loss_bbox: 0.3329  loss_ce_0: 0.4976  loss_giou_0: 0.3682  loss_bbox_0: 0.389  loss_rpn_cls: 0.2554  loss_rpn_reg: 0.5289  time: 0.1892  last_time: 0.1999  data_time: 0.0049  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 13:01:39] d2.utils.events INFO:  eta: 1:32:52  iter: 24379  total_loss: 2.878  loss_ce: 0.5298  loss_giou: 0.292  loss_bbox: 0.2883  loss_ce_0: 0.5325  loss_giou_0: 0.3278  loss_bbox_0: 0.3361  loss_rpn_cls: 0.2332  loss_rpn_reg: 0.4695  time: 0.1892  last_time: 0.1925  data_time: 0.0052  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:01:42] d2.utils.events INFO:  eta: 1:32:47  iter: 24399  total_loss: 2.923  loss_ce: 0.5137  loss_giou: 0.321  loss_bbox: 0.2292  loss_ce_0: 0.4875  loss_giou_0: 0.3401  loss_bbox_0: 0.2797  loss_rpn_cls: 0.2446  loss_rpn_reg: 0.4653  time: 0.1892  last_time: 0.1901  data_time: 0.0054  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:01:46] d2.utils.events INFO:  eta: 1:32:45  iter: 24419  total_loss: 2.998  loss_ce: 0.4599  loss_giou: 0.3591  loss_bbox: 0.3066  loss_ce_0: 0.491  loss_giou_0: 0.3623  loss_bbox_0: 0.3477  loss_rpn_cls: 0.2231  loss_rpn_reg: 0.4968  time: 0.1892  last_time: 0.1913  data_time: 0.0051  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:01:50] d2.utils.events INFO:  eta: 1:32:44  iter: 24439  total_loss: 3.272  loss_ce: 0.4438  loss_giou: 0.3965  loss_bbox: 0.3679  loss_ce_0: 0.4805  loss_giou_0: 0.3938  loss_bbox_0: 0.3838  loss_rpn_cls: 0.2323  loss_rpn_reg: 0.5023  time: 0.1892  last_time: 0.1904  data_time: 0.0051  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:01:54] d2.utils.events INFO:  eta: 1:32:42  iter: 24459  total_loss: 3.483  loss_ce: 0.5218  loss_giou: 0.406  loss_bbox: 0.3598  loss_ce_0: 0.5446  loss_giou_0: 0.4038  loss_bbox_0: 0.3823  loss_rpn_cls: 0.2405  loss_rpn_reg: 0.5164  time: 0.1892  last_time: 0.1904  data_time: 0.0048  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:01:58] d2.utils.events INFO:  eta: 1:32:40  iter: 24479  total_loss: 2.976  loss_ce: 0.4624  loss_giou: 0.3557  loss_bbox: 0.3231  loss_ce_0: 0.4901  loss_giou_0: 0.381  loss_bbox_0: 0.343  loss_rpn_cls: 0.2425  loss_rpn_reg: 0.4894  time: 0.1892  last_time: 0.1974  data_time: 0.0055  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:02:02] d2.utils.events INFO:  eta: 1:32:38  iter: 24499  total_loss: 3.233  loss_ce: 0.4768  loss_giou: 0.358  loss_bbox: 0.347  loss_ce_0: 0.4825  loss_giou_0: 0.3855  loss_bbox_0: 0.3707  loss_rpn_cls: 0.2733  loss_rpn_reg: 0.5064  time: 0.1892  last_time: 0.1978  data_time: 0.0053  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 13:02:06] d2.utils.events INFO:  eta: 1:32:31  iter: 24519  total_loss: 2.704  loss_ce: 0.4514  loss_giou: 0.2975  loss_bbox: 0.2481  loss_ce_0: 0.448  loss_giou_0: 0.325  loss_bbox_0: 0.322  loss_rpn_cls: 0.2366  loss_rpn_reg: 0.4351  time: 0.1892  last_time: 0.1894  data_time: 0.0050  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 13:02:10] d2.utils.events INFO:  eta: 1:32:30  iter: 24539  total_loss: 3.174  loss_ce: 0.4156  loss_giou: 0.3644  loss_bbox: 0.3307  loss_ce_0: 0.4855  loss_giou_0: 0.3892  loss_bbox_0: 0.3288  loss_rpn_cls: 0.2163  loss_rpn_reg: 0.4949  time: 0.1892  last_time: 0.1676  data_time: 0.0049  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 13:02:13] d2.utils.events INFO:  eta: 1:32:29  iter: 24559  total_loss: 3.105  loss_ce: 0.5  loss_giou: 0.3262  loss_bbox: 0.3354  loss_ce_0: 0.5601  loss_giou_0: 0.3783  loss_bbox_0: 0.3712  loss_rpn_cls: 0.2387  loss_rpn_reg: 0.4989  time: 0.1892  last_time: 0.1921  data_time: 0.0045  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:02:17] d2.utils.events INFO:  eta: 1:32:27  iter: 24579  total_loss: 3.401  loss_ce: 0.4934  loss_giou: 0.3896  loss_bbox: 0.3402  loss_ce_0: 0.5108  loss_giou_0: 0.4085  loss_bbox_0: 0.3665  loss_rpn_cls: 0.2683  loss_rpn_reg: 0.524  time: 0.1892  last_time: 0.1715  data_time: 0.0050  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:02:21] d2.utils.events INFO:  eta: 1:32:16  iter: 24599  total_loss: 2.999  loss_ce: 0.5086  loss_giou: 0.346  loss_bbox: 0.2965  loss_ce_0: 0.5306  loss_giou_0: 0.3825  loss_bbox_0: 0.3178  loss_rpn_cls: 0.2484  loss_rpn_reg: 0.4755  time: 0.1892  last_time: 0.1650  data_time: 0.0049  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:02:25] d2.utils.events INFO:  eta: 1:32:11  iter: 24619  total_loss: 3.15  loss_ce: 0.5016  loss_giou: 0.3556  loss_bbox: 0.3285  loss_ce_0: 0.5116  loss_giou_0: 0.3743  loss_bbox_0: 0.3542  loss_rpn_cls: 0.2429  loss_rpn_reg: 0.4764  time: 0.1892  last_time: 0.1968  data_time: 0.0048  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:02:29] d2.utils.events INFO:  eta: 1:32:03  iter: 24639  total_loss: 3.145  loss_ce: 0.4411  loss_giou: 0.3955  loss_bbox: 0.2771  loss_ce_0: 0.4969  loss_giou_0: 0.4165  loss_bbox_0: 0.3257  loss_rpn_cls: 0.2387  loss_rpn_reg: 0.5072  time: 0.1892  last_time: 0.1982  data_time: 0.0054  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:02:32] d2.utils.events INFO:  eta: 1:31:55  iter: 24659  total_loss: 3.302  loss_ce: 0.5396  loss_giou: 0.4175  loss_bbox: 0.3394  loss_ce_0: 0.5067  loss_giou_0: 0.4399  loss_bbox_0: 0.3465  loss_rpn_cls: 0.2792  loss_rpn_reg: 0.5172  time: 0.1892  last_time: 0.2245  data_time: 0.0049  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 13:02:36] d2.utils.events INFO:  eta: 1:31:51  iter: 24679  total_loss: 3.281  loss_ce: 0.5017  loss_giou: 0.3543  loss_bbox: 0.314  loss_ce_0: 0.4935  loss_giou_0: 0.3799  loss_bbox_0: 0.346  loss_rpn_cls: 0.2596  loss_rpn_reg: 0.5021  time: 0.1892  last_time: 0.1787  data_time: 0.0050  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:02:40] d2.utils.events INFO:  eta: 1:31:47  iter: 24699  total_loss: 3.116  loss_ce: 0.4426  loss_giou: 0.3599  loss_bbox: 0.3113  loss_ce_0: 0.4843  loss_giou_0: 0.3459  loss_bbox_0: 0.3294  loss_rpn_cls: 0.2546  loss_rpn_reg: 0.4764  time: 0.1892  last_time: 0.1749  data_time: 0.0050  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:02:44] d2.utils.events INFO:  eta: 1:31:45  iter: 24719  total_loss: 3.272  loss_ce: 0.4774  loss_giou: 0.4024  loss_bbox: 0.3517  loss_ce_0: 0.4972  loss_giou_0: 0.4133  loss_bbox_0: 0.3628  loss_rpn_cls: 0.2765  loss_rpn_reg: 0.4825  time: 0.1892  last_time: 0.1949  data_time: 0.0048  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 13:02:48] d2.utils.events INFO:  eta: 1:31:43  iter: 24739  total_loss: 3.151  loss_ce: 0.459  loss_giou: 0.3314  loss_bbox: 0.3066  loss_ce_0: 0.445  loss_giou_0: 0.3461  loss_bbox_0: 0.3346  loss_rpn_cls: 0.2613  loss_rpn_reg: 0.4616  time: 0.1892  last_time: 0.1924  data_time: 0.0058  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 13:02:51] d2.utils.events INFO:  eta: 1:31:35  iter: 24759  total_loss: 3.405  loss_ce: 0.5741  loss_giou: 0.3623  loss_bbox: 0.3667  loss_ce_0: 0.5779  loss_giou_0: 0.3753  loss_bbox_0: 0.3873  loss_rpn_cls: 0.2566  loss_rpn_reg: 0.4817  time: 0.1891  last_time: 0.2090  data_time: 0.0047  last_data_time: 0.0076   lr: 5e-05  max_mem: 3029M
[03/05 13:02:55] d2.utils.events INFO:  eta: 1:31:31  iter: 24779  total_loss: 3.068  loss_ce: 0.4521  loss_giou: 0.3926  loss_bbox: 0.2969  loss_ce_0: 0.488  loss_giou_0: 0.412  loss_bbox_0: 0.3378  loss_rpn_cls: 0.2349  loss_rpn_reg: 0.5069  time: 0.1891  last_time: 0.1999  data_time: 0.0049  last_data_time: 0.0109   lr: 5e-05  max_mem: 3029M
[03/05 13:02:59] d2.utils.events INFO:  eta: 1:31:25  iter: 24799  total_loss: 3.143  loss_ce: 0.5082  loss_giou: 0.3519  loss_bbox: 0.2998  loss_ce_0: 0.5536  loss_giou_0: 0.3689  loss_bbox_0: 0.326  loss_rpn_cls: 0.2657  loss_rpn_reg: 0.4877  time: 0.1891  last_time: 0.1643  data_time: 0.0051  last_data_time: 0.0032   lr: 5e-05  max_mem: 3029M
[03/05 13:03:03] d2.utils.events INFO:  eta: 1:31:21  iter: 24819  total_loss: 3.296  loss_ce: 0.5164  loss_giou: 0.3481  loss_bbox: 0.3306  loss_ce_0: 0.547  loss_giou_0: 0.3621  loss_bbox_0: 0.3997  loss_rpn_cls: 0.2584  loss_rpn_reg: 0.5013  time: 0.1891  last_time: 0.1979  data_time: 0.0048  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:03:07] d2.utils.events INFO:  eta: 1:31:19  iter: 24839  total_loss: 2.904  loss_ce: 0.4527  loss_giou: 0.3794  loss_bbox: 0.3168  loss_ce_0: 0.4847  loss_giou_0: 0.4151  loss_bbox_0: 0.3779  loss_rpn_cls: 0.216  loss_rpn_reg: 0.4835  time: 0.1891  last_time: 0.1782  data_time: 0.0048  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 13:03:10] d2.utils.events INFO:  eta: 1:31:16  iter: 24859  total_loss: 2.829  loss_ce: 0.4257  loss_giou: 0.3066  loss_bbox: 0.3111  loss_ce_0: 0.4432  loss_giou_0: 0.3116  loss_bbox_0: 0.3419  loss_rpn_cls: 0.2252  loss_rpn_reg: 0.4719  time: 0.1891  last_time: 0.1971  data_time: 0.0048  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 13:03:14] d2.utils.events INFO:  eta: 1:31:09  iter: 24879  total_loss: 3.028  loss_ce: 0.4197  loss_giou: 0.3741  loss_bbox: 0.2478  loss_ce_0: 0.4659  loss_giou_0: 0.3757  loss_bbox_0: 0.2827  loss_rpn_cls: 0.2389  loss_rpn_reg: 0.4951  time: 0.1891  last_time: 0.1896  data_time: 0.0048  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 13:03:18] d2.utils.events INFO:  eta: 1:31:08  iter: 24899  total_loss: 2.801  loss_ce: 0.4146  loss_giou: 0.345  loss_bbox: 0.2685  loss_ce_0: 0.4351  loss_giou_0: 0.3477  loss_bbox_0: 0.3148  loss_rpn_cls: 0.2408  loss_rpn_reg: 0.4328  time: 0.1891  last_time: 0.1905  data_time: 0.0049  last_data_time: 0.0114   lr: 5e-05  max_mem: 3029M
[03/05 13:03:22] d2.utils.events INFO:  eta: 1:31:07  iter: 24919  total_loss: 3.157  loss_ce: 0.4848  loss_giou: 0.3595  loss_bbox: 0.3384  loss_ce_0: 0.4938  loss_giou_0: 0.3749  loss_bbox_0: 0.3762  loss_rpn_cls: 0.262  loss_rpn_reg: 0.505  time: 0.1892  last_time: 0.2136  data_time: 0.0056  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 13:03:26] d2.utils.events INFO:  eta: 1:31:03  iter: 24939  total_loss: 2.888  loss_ce: 0.4343  loss_giou: 0.3375  loss_bbox: 0.2787  loss_ce_0: 0.4689  loss_giou_0: 0.3627  loss_bbox_0: 0.3188  loss_rpn_cls: 0.2205  loss_rpn_reg: 0.4983  time: 0.1892  last_time: 0.2121  data_time: 0.0049  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 13:03:30] d2.utils.events INFO:  eta: 1:30:57  iter: 24959  total_loss: 3.014  loss_ce: 0.449  loss_giou: 0.3751  loss_bbox: 0.2918  loss_ce_0: 0.4724  loss_giou_0: 0.394  loss_bbox_0: 0.3124  loss_rpn_cls: 0.2375  loss_rpn_reg: 0.4977  time: 0.1891  last_time: 0.2344  data_time: 0.0047  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 13:03:34] d2.utils.events INFO:  eta: 1:30:49  iter: 24979  total_loss: 2.913  loss_ce: 0.4372  loss_giou: 0.355  loss_bbox: 0.3275  loss_ce_0: 0.498  loss_giou_0: 0.3581  loss_bbox_0: 0.3425  loss_rpn_cls: 0.2262  loss_rpn_reg: 0.4771  time: 0.1891  last_time: 0.1886  data_time: 0.0045  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:03:37] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/t1/model_0024999.pth
[03/05 13:03:38] d2.utils.events INFO:  eta: 1:30:45  iter: 24999  total_loss: 3.152  loss_ce: 0.4395  loss_giou: 0.3977  loss_bbox: 0.3231  loss_ce_0: 0.457  loss_giou_0: 0.4113  loss_bbox_0: 0.3582  loss_rpn_cls: 0.2563  loss_rpn_reg: 0.5213  time: 0.1891  last_time: 0.1648  data_time: 0.0045  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 13:03:42] d2.utils.events INFO:  eta: 1:30:42  iter: 25019  total_loss: 3.437  loss_ce: 0.5452  loss_giou: 0.3664  loss_bbox: 0.3145  loss_ce_0: 0.5203  loss_giou_0: 0.3555  loss_bbox_0: 0.3404  loss_rpn_cls: 0.2674  loss_rpn_reg: 0.4933  time: 0.1891  last_time: 0.2275  data_time: 0.0049  last_data_time: 0.0085   lr: 5e-05  max_mem: 3029M
[03/05 13:03:47] d2.utils.events INFO:  eta: 1:30:43  iter: 25039  total_loss: 3.068  loss_ce: 0.4768  loss_giou: 0.3429  loss_bbox: 0.273  loss_ce_0: 0.4746  loss_giou_0: 0.3699  loss_bbox_0: 0.2965  loss_rpn_cls: 0.2642  loss_rpn_reg: 0.4738  time: 0.1892  last_time: 0.1900  data_time: 0.0065  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 13:03:50] d2.utils.events INFO:  eta: 1:30:38  iter: 25059  total_loss: 2.99  loss_ce: 0.4545  loss_giou: 0.3199  loss_bbox: 0.3579  loss_ce_0: 0.5016  loss_giou_0: 0.3497  loss_bbox_0: 0.4006  loss_rpn_cls: 0.2264  loss_rpn_reg: 0.5202  time: 0.1891  last_time: 0.1861  data_time: 0.0050  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 13:03:54] d2.utils.events INFO:  eta: 1:30:31  iter: 25079  total_loss: 3.225  loss_ce: 0.4564  loss_giou: 0.4007  loss_bbox: 0.325  loss_ce_0: 0.5156  loss_giou_0: 0.4155  loss_bbox_0: 0.3329  loss_rpn_cls: 0.2423  loss_rpn_reg: 0.4941  time: 0.1891  last_time: 0.1802  data_time: 0.0052  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:03:58] d2.utils.events INFO:  eta: 1:30:32  iter: 25099  total_loss: 3.318  loss_ce: 0.4681  loss_giou: 0.3874  loss_bbox: 0.2791  loss_ce_0: 0.4857  loss_giou_0: 0.4043  loss_bbox_0: 0.3281  loss_rpn_cls: 0.2651  loss_rpn_reg: 0.4886  time: 0.1891  last_time: 0.1985  data_time: 0.0049  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 13:04:02] d2.utils.events INFO:  eta: 1:30:33  iter: 25119  total_loss: 2.88  loss_ce: 0.4711  loss_giou: 0.3087  loss_bbox: 0.299  loss_ce_0: 0.4677  loss_giou_0: 0.3299  loss_bbox_0: 0.3392  loss_rpn_cls: 0.2264  loss_rpn_reg: 0.4994  time: 0.1891  last_time: 0.1889  data_time: 0.0050  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 13:04:06] d2.utils.events INFO:  eta: 1:30:33  iter: 25139  total_loss: 2.983  loss_ce: 0.48  loss_giou: 0.3449  loss_bbox: 0.3127  loss_ce_0: 0.5301  loss_giou_0: 0.345  loss_bbox_0: 0.3612  loss_rpn_cls: 0.2654  loss_rpn_reg: 0.4701  time: 0.1891  last_time: 0.1804  data_time: 0.0048  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:04:09] d2.utils.events INFO:  eta: 1:30:29  iter: 25159  total_loss: 2.892  loss_ce: 0.3829  loss_giou: 0.2978  loss_bbox: 0.3191  loss_ce_0: 0.3967  loss_giou_0: 0.3574  loss_bbox_0: 0.3719  loss_rpn_cls: 0.2322  loss_rpn_reg: 0.4927  time: 0.1891  last_time: 0.2104  data_time: 0.0047  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 13:04:13] d2.utils.events INFO:  eta: 1:30:19  iter: 25179  total_loss: 2.921  loss_ce: 0.3879  loss_giou: 0.3456  loss_bbox: 0.3081  loss_ce_0: 0.426  loss_giou_0: 0.344  loss_bbox_0: 0.3185  loss_rpn_cls: 0.227  loss_rpn_reg: 0.4786  time: 0.1891  last_time: 0.1723  data_time: 0.0054  last_data_time: 0.0029   lr: 5e-05  max_mem: 3029M
[03/05 13:04:17] d2.utils.events INFO:  eta: 1:30:12  iter: 25199  total_loss: 3.053  loss_ce: 0.4286  loss_giou: 0.329  loss_bbox: 0.3074  loss_ce_0: 0.4669  loss_giou_0: 0.3589  loss_bbox_0: 0.3433  loss_rpn_cls: 0.2579  loss_rpn_reg: 0.5133  time: 0.1891  last_time: 0.2192  data_time: 0.0058  last_data_time: 0.0077   lr: 5e-05  max_mem: 3029M
[03/05 13:04:21] d2.utils.events INFO:  eta: 1:30:06  iter: 25219  total_loss: 3.024  loss_ce: 0.4179  loss_giou: 0.3888  loss_bbox: 0.2892  loss_ce_0: 0.4463  loss_giou_0: 0.414  loss_bbox_0: 0.3375  loss_rpn_cls: 0.2306  loss_rpn_reg: 0.5287  time: 0.1891  last_time: 0.2079  data_time: 0.0054  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 13:04:25] d2.utils.events INFO:  eta: 1:30:04  iter: 25239  total_loss: 2.83  loss_ce: 0.3892  loss_giou: 0.3302  loss_bbox: 0.3  loss_ce_0: 0.4239  loss_giou_0: 0.3406  loss_bbox_0: 0.3158  loss_rpn_cls: 0.2239  loss_rpn_reg: 0.5015  time: 0.1891  last_time: 0.1659  data_time: 0.0049  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:04:29] d2.utils.events INFO:  eta: 1:30:00  iter: 25259  total_loss: 3.216  loss_ce: 0.4502  loss_giou: 0.3409  loss_bbox: 0.3083  loss_ce_0: 0.4503  loss_giou_0: 0.3846  loss_bbox_0: 0.3227  loss_rpn_cls: 0.2589  loss_rpn_reg: 0.5049  time: 0.1891  last_time: 0.1788  data_time: 0.0048  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:04:32] d2.utils.events INFO:  eta: 1:29:53  iter: 25279  total_loss: 3.243  loss_ce: 0.5013  loss_giou: 0.3782  loss_bbox: 0.3206  loss_ce_0: 0.5243  loss_giou_0: 0.403  loss_bbox_0: 0.3386  loss_rpn_cls: 0.2728  loss_rpn_reg: 0.5127  time: 0.1891  last_time: 0.1798  data_time: 0.0047  last_data_time: 0.0088   lr: 5e-05  max_mem: 3029M
[03/05 13:04:36] d2.utils.events INFO:  eta: 1:29:49  iter: 25299  total_loss: 3.164  loss_ce: 0.5095  loss_giou: 0.3745  loss_bbox: 0.313  loss_ce_0: 0.4971  loss_giou_0: 0.3837  loss_bbox_0: 0.3419  loss_rpn_cls: 0.2383  loss_rpn_reg: 0.5128  time: 0.1891  last_time: 0.1702  data_time: 0.0055  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 13:04:40] d2.utils.events INFO:  eta: 1:29:45  iter: 25319  total_loss: 2.848  loss_ce: 0.464  loss_giou: 0.3116  loss_bbox: 0.2707  loss_ce_0: 0.4663  loss_giou_0: 0.3389  loss_bbox_0: 0.3282  loss_rpn_cls: 0.2507  loss_rpn_reg: 0.477  time: 0.1891  last_time: 0.1589  data_time: 0.0047  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:04:44] d2.utils.events INFO:  eta: 1:29:28  iter: 25339  total_loss: 2.98  loss_ce: 0.4737  loss_giou: 0.3446  loss_bbox: 0.2753  loss_ce_0: 0.454  loss_giou_0: 0.3727  loss_bbox_0: 0.3218  loss_rpn_cls: 0.2366  loss_rpn_reg: 0.4794  time: 0.1891  last_time: 0.1939  data_time: 0.0043  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:04:47] d2.utils.events INFO:  eta: 1:29:30  iter: 25359  total_loss: 2.903  loss_ce: 0.4892  loss_giou: 0.3453  loss_bbox: 0.2742  loss_ce_0: 0.5465  loss_giou_0: 0.3591  loss_bbox_0: 0.2754  loss_rpn_cls: 0.244  loss_rpn_reg: 0.4622  time: 0.1891  last_time: 0.1733  data_time: 0.0066  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 13:04:51] d2.utils.events INFO:  eta: 1:29:27  iter: 25379  total_loss: 3.029  loss_ce: 0.5127  loss_giou: 0.3773  loss_bbox: 0.3285  loss_ce_0: 0.521  loss_giou_0: 0.3791  loss_bbox_0: 0.3142  loss_rpn_cls: 0.2386  loss_rpn_reg: 0.4825  time: 0.1891  last_time: 0.1780  data_time: 0.0053  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 13:04:55] d2.utils.events INFO:  eta: 1:29:23  iter: 25399  total_loss: 3.375  loss_ce: 0.5421  loss_giou: 0.3474  loss_bbox: 0.3131  loss_ce_0: 0.5228  loss_giou_0: 0.3645  loss_bbox_0: 0.3772  loss_rpn_cls: 0.2475  loss_rpn_reg: 0.4994  time: 0.1891  last_time: 0.1825  data_time: 0.0051  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 13:04:59] d2.utils.events INFO:  eta: 1:29:13  iter: 25419  total_loss: 2.878  loss_ce: 0.4319  loss_giou: 0.3496  loss_bbox: 0.3285  loss_ce_0: 0.4885  loss_giou_0: 0.3526  loss_bbox_0: 0.3367  loss_rpn_cls: 0.2442  loss_rpn_reg: 0.4897  time: 0.1891  last_time: 0.1738  data_time: 0.0046  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:05:02] d2.utils.events INFO:  eta: 1:29:02  iter: 25439  total_loss: 3.003  loss_ce: 0.4645  loss_giou: 0.4008  loss_bbox: 0.3223  loss_ce_0: 0.4743  loss_giou_0: 0.4117  loss_bbox_0: 0.3345  loss_rpn_cls: 0.2473  loss_rpn_reg: 0.5061  time: 0.1891  last_time: 0.1854  data_time: 0.0049  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:05:06] d2.utils.events INFO:  eta: 1:28:55  iter: 25459  total_loss: 3.297  loss_ce: 0.4303  loss_giou: 0.434  loss_bbox: 0.3205  loss_ce_0: 0.4642  loss_giou_0: 0.4493  loss_bbox_0: 0.3663  loss_rpn_cls: 0.26  loss_rpn_reg: 0.5179  time: 0.1891  last_time: 0.1991  data_time: 0.0049  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:05:10] d2.utils.events INFO:  eta: 1:28:53  iter: 25479  total_loss: 3.146  loss_ce: 0.5823  loss_giou: 0.3411  loss_bbox: 0.328  loss_ce_0: 0.5836  loss_giou_0: 0.366  loss_bbox_0: 0.3758  loss_rpn_cls: 0.2541  loss_rpn_reg: 0.5037  time: 0.1891  last_time: 0.1894  data_time: 0.0052  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:05:14] d2.utils.events INFO:  eta: 1:28:43  iter: 25499  total_loss: 3.181  loss_ce: 0.4542  loss_giou: 0.3761  loss_bbox: 0.3122  loss_ce_0: 0.5038  loss_giou_0: 0.4019  loss_bbox_0: 0.3497  loss_rpn_cls: 0.25  loss_rpn_reg: 0.5217  time: 0.1891  last_time: 0.1976  data_time: 0.0045  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:05:17] d2.utils.events INFO:  eta: 1:28:40  iter: 25519  total_loss: 3.489  loss_ce: 0.5156  loss_giou: 0.3736  loss_bbox: 0.3028  loss_ce_0: 0.485  loss_giou_0: 0.4264  loss_bbox_0: 0.3492  loss_rpn_cls: 0.2965  loss_rpn_reg: 0.5615  time: 0.1891  last_time: 0.1968  data_time: 0.0044  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 13:05:21] d2.utils.events INFO:  eta: 1:28:39  iter: 25539  total_loss: 3.147  loss_ce: 0.4806  loss_giou: 0.3477  loss_bbox: 0.2667  loss_ce_0: 0.4671  loss_giou_0: 0.3808  loss_bbox_0: 0.3291  loss_rpn_cls: 0.2353  loss_rpn_reg: 0.4771  time: 0.1891  last_time: 0.1863  data_time: 0.0048  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 13:05:25] d2.utils.events INFO:  eta: 1:28:36  iter: 25559  total_loss: 3.33  loss_ce: 0.4844  loss_giou: 0.3478  loss_bbox: 0.2723  loss_ce_0: 0.4821  loss_giou_0: 0.3728  loss_bbox_0: 0.3246  loss_rpn_cls: 0.2571  loss_rpn_reg: 0.4731  time: 0.1891  last_time: 0.2039  data_time: 0.0048  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:05:29] d2.utils.events INFO:  eta: 1:28:33  iter: 25579  total_loss: 3.13  loss_ce: 0.5214  loss_giou: 0.3199  loss_bbox: 0.3022  loss_ce_0: 0.5279  loss_giou_0: 0.3344  loss_bbox_0: 0.3249  loss_rpn_cls: 0.2614  loss_rpn_reg: 0.4796  time: 0.1891  last_time: 0.1971  data_time: 0.0052  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 13:05:33] d2.utils.events INFO:  eta: 1:28:32  iter: 25599  total_loss: 2.932  loss_ce: 0.4489  loss_giou: 0.3188  loss_bbox: 0.2798  loss_ce_0: 0.4881  loss_giou_0: 0.3575  loss_bbox_0: 0.3384  loss_rpn_cls: 0.2483  loss_rpn_reg: 0.4441  time: 0.1891  last_time: 0.1747  data_time: 0.0049  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:05:37] d2.utils.events INFO:  eta: 1:28:28  iter: 25619  total_loss: 2.906  loss_ce: 0.4265  loss_giou: 0.3219  loss_bbox: 0.2704  loss_ce_0: 0.443  loss_giou_0: 0.3419  loss_bbox_0: 0.2826  loss_rpn_cls: 0.224  loss_rpn_reg: 0.4554  time: 0.1891  last_time: 0.2008  data_time: 0.0051  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:05:41] d2.utils.events INFO:  eta: 1:28:23  iter: 25639  total_loss: 3.505  loss_ce: 0.4892  loss_giou: 0.4076  loss_bbox: 0.3633  loss_ce_0: 0.5056  loss_giou_0: 0.422  loss_bbox_0: 0.3573  loss_rpn_cls: 0.2573  loss_rpn_reg: 0.5207  time: 0.1891  last_time: 0.1839  data_time: 0.0049  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:05:44] d2.utils.events INFO:  eta: 1:28:21  iter: 25659  total_loss: 3.267  loss_ce: 0.4722  loss_giou: 0.2985  loss_bbox: 0.3174  loss_ce_0: 0.5116  loss_giou_0: 0.3376  loss_bbox_0: 0.3781  loss_rpn_cls: 0.2411  loss_rpn_reg: 0.4649  time: 0.1891  last_time: 0.1871  data_time: 0.0052  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:05:48] d2.utils.events INFO:  eta: 1:28:16  iter: 25679  total_loss: 3.003  loss_ce: 0.4498  loss_giou: 0.3329  loss_bbox: 0.291  loss_ce_0: 0.487  loss_giou_0: 0.3665  loss_bbox_0: 0.3318  loss_rpn_cls: 0.2411  loss_rpn_reg: 0.5081  time: 0.1891  last_time: 0.1829  data_time: 0.0050  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:05:52] d2.utils.events INFO:  eta: 1:28:12  iter: 25699  total_loss: 2.785  loss_ce: 0.4624  loss_giou: 0.3171  loss_bbox: 0.2491  loss_ce_0: 0.4513  loss_giou_0: 0.3648  loss_bbox_0: 0.3291  loss_rpn_cls: 0.2421  loss_rpn_reg: 0.4318  time: 0.1891  last_time: 0.1782  data_time: 0.0055  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:05:56] d2.utils.events INFO:  eta: 1:28:11  iter: 25719  total_loss: 3.415  loss_ce: 0.5044  loss_giou: 0.3933  loss_bbox: 0.3212  loss_ce_0: 0.4779  loss_giou_0: 0.4114  loss_bbox_0: 0.3825  loss_rpn_cls: 0.2393  loss_rpn_reg: 0.5552  time: 0.1891  last_time: 0.1841  data_time: 0.0045  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:06:00] d2.utils.events INFO:  eta: 1:28:08  iter: 25739  total_loss: 3.113  loss_ce: 0.5106  loss_giou: 0.2946  loss_bbox: 0.3138  loss_ce_0: 0.5406  loss_giou_0: 0.328  loss_bbox_0: 0.3461  loss_rpn_cls: 0.2293  loss_rpn_reg: 0.4834  time: 0.1891  last_time: 0.1893  data_time: 0.0051  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:06:04] d2.utils.events INFO:  eta: 1:28:08  iter: 25759  total_loss: 3.11  loss_ce: 0.4749  loss_giou: 0.3353  loss_bbox: 0.2904  loss_ce_0: 0.5217  loss_giou_0: 0.3855  loss_bbox_0: 0.3483  loss_rpn_cls: 0.2449  loss_rpn_reg: 0.4832  time: 0.1891  last_time: 0.1886  data_time: 0.0052  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:06:07] d2.utils.events INFO:  eta: 1:28:05  iter: 25779  total_loss: 2.942  loss_ce: 0.4387  loss_giou: 0.3625  loss_bbox: 0.2692  loss_ce_0: 0.4791  loss_giou_0: 0.3683  loss_bbox_0: 0.2891  loss_rpn_cls: 0.2508  loss_rpn_reg: 0.4779  time: 0.1891  last_time: 0.2297  data_time: 0.0050  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:06:11] d2.utils.events INFO:  eta: 1:28:09  iter: 25799  total_loss: 2.951  loss_ce: 0.4334  loss_giou: 0.3277  loss_bbox: 0.2611  loss_ce_0: 0.4477  loss_giou_0: 0.3604  loss_bbox_0: 0.2944  loss_rpn_cls: 0.217  loss_rpn_reg: 0.4784  time: 0.1891  last_time: 0.1916  data_time: 0.0050  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:06:15] d2.utils.events INFO:  eta: 1:28:12  iter: 25819  total_loss: 3.082  loss_ce: 0.4819  loss_giou: 0.3124  loss_bbox: 0.3338  loss_ce_0: 0.5027  loss_giou_0: 0.3399  loss_bbox_0: 0.3453  loss_rpn_cls: 0.2203  loss_rpn_reg: 0.4672  time: 0.1891  last_time: 0.2209  data_time: 0.0057  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:06:19] d2.utils.events INFO:  eta: 1:28:08  iter: 25839  total_loss: 3.28  loss_ce: 0.5077  loss_giou: 0.389  loss_bbox: 0.3471  loss_ce_0: 0.5081  loss_giou_0: 0.4239  loss_bbox_0: 0.3718  loss_rpn_cls: 0.2463  loss_rpn_reg: 0.5177  time: 0.1891  last_time: 0.1994  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:06:23] d2.utils.events INFO:  eta: 1:28:02  iter: 25859  total_loss: 3.109  loss_ce: 0.44  loss_giou: 0.3546  loss_bbox: 0.3006  loss_ce_0: 0.4512  loss_giou_0: 0.3702  loss_bbox_0: 0.3423  loss_rpn_cls: 0.2427  loss_rpn_reg: 0.5002  time: 0.1891  last_time: 0.2094  data_time: 0.0053  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:06:27] d2.utils.events INFO:  eta: 1:28:01  iter: 25879  total_loss: 3.014  loss_ce: 0.4836  loss_giou: 0.294  loss_bbox: 0.307  loss_ce_0: 0.5155  loss_giou_0: 0.2941  loss_bbox_0: 0.3328  loss_rpn_cls: 0.2379  loss_rpn_reg: 0.4583  time: 0.1891  last_time: 0.1945  data_time: 0.0049  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:06:31] d2.utils.events INFO:  eta: 1:27:50  iter: 25899  total_loss: 3.562  loss_ce: 0.5239  loss_giou: 0.4614  loss_bbox: 0.3277  loss_ce_0: 0.559  loss_giou_0: 0.4869  loss_bbox_0: 0.3524  loss_rpn_cls: 0.2996  loss_rpn_reg: 0.5506  time: 0.1891  last_time: 0.1646  data_time: 0.0046  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:06:35] d2.utils.events INFO:  eta: 1:27:40  iter: 25919  total_loss: 3.444  loss_ce: 0.5234  loss_giou: 0.3851  loss_bbox: 0.3692  loss_ce_0: 0.5314  loss_giou_0: 0.3864  loss_bbox_0: 0.4011  loss_rpn_cls: 0.2578  loss_rpn_reg: 0.51  time: 0.1891  last_time: 0.1745  data_time: 0.0054  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:06:38] d2.utils.events INFO:  eta: 1:27:35  iter: 25939  total_loss: 3.305  loss_ce: 0.5023  loss_giou: 0.3651  loss_bbox: 0.3608  loss_ce_0: 0.5336  loss_giou_0: 0.3967  loss_bbox_0: 0.3796  loss_rpn_cls: 0.2807  loss_rpn_reg: 0.4736  time: 0.1891  last_time: 0.2025  data_time: 0.0053  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 13:06:42] d2.utils.events INFO:  eta: 1:27:41  iter: 25959  total_loss: 3.207  loss_ce: 0.4825  loss_giou: 0.3524  loss_bbox: 0.2899  loss_ce_0: 0.4813  loss_giou_0: 0.3677  loss_bbox_0: 0.3325  loss_rpn_cls: 0.2517  loss_rpn_reg: 0.5044  time: 0.1891  last_time: 0.2005  data_time: 0.0056  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:06:46] d2.utils.events INFO:  eta: 1:27:37  iter: 25979  total_loss: 3.218  loss_ce: 0.4606  loss_giou: 0.3806  loss_bbox: 0.2819  loss_ce_0: 0.4666  loss_giou_0: 0.4109  loss_bbox_0: 0.3308  loss_rpn_cls: 0.2511  loss_rpn_reg: 0.5232  time: 0.1891  last_time: 0.2021  data_time: 0.0046  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:06:50] d2.utils.events INFO:  eta: 1:27:40  iter: 25999  total_loss: 3.034  loss_ce: 0.4628  loss_giou: 0.3405  loss_bbox: 0.3521  loss_ce_0: 0.4559  loss_giou_0: 0.3927  loss_bbox_0: 0.3675  loss_rpn_cls: 0.2454  loss_rpn_reg: 0.4712  time: 0.1891  last_time: 0.1907  data_time: 0.0052  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 13:06:54] d2.utils.events INFO:  eta: 1:27:37  iter: 26019  total_loss: 3.192  loss_ce: 0.4915  loss_giou: 0.3568  loss_bbox: 0.2753  loss_ce_0: 0.5199  loss_giou_0: 0.3866  loss_bbox_0: 0.3025  loss_rpn_cls: 0.2644  loss_rpn_reg: 0.4732  time: 0.1891  last_time: 0.1716  data_time: 0.0051  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:06:58] d2.utils.events INFO:  eta: 1:27:33  iter: 26039  total_loss: 3.11  loss_ce: 0.4265  loss_giou: 0.3767  loss_bbox: 0.3056  loss_ce_0: 0.4685  loss_giou_0: 0.3964  loss_bbox_0: 0.3297  loss_rpn_cls: 0.2533  loss_rpn_reg: 0.4995  time: 0.1891  last_time: 0.1945  data_time: 0.0058  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:07:02] d2.utils.events INFO:  eta: 1:27:33  iter: 26059  total_loss: 3.08  loss_ce: 0.4636  loss_giou: 0.3589  loss_bbox: 0.2964  loss_ce_0: 0.5081  loss_giou_0: 0.3721  loss_bbox_0: 0.335  loss_rpn_cls: 0.2348  loss_rpn_reg: 0.4841  time: 0.1891  last_time: 0.1755  data_time: 0.0050  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 13:07:06] d2.utils.events INFO:  eta: 1:27:33  iter: 26079  total_loss: 3.145  loss_ce: 0.4748  loss_giou: 0.3583  loss_bbox: 0.3144  loss_ce_0: 0.5367  loss_giou_0: 0.3864  loss_bbox_0: 0.3496  loss_rpn_cls: 0.2389  loss_rpn_reg: 0.4721  time: 0.1891  last_time: 0.1942  data_time: 0.0049  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 13:07:10] d2.utils.events INFO:  eta: 1:27:27  iter: 26099  total_loss: 2.88  loss_ce: 0.4264  loss_giou: 0.3706  loss_bbox: 0.2493  loss_ce_0: 0.5033  loss_giou_0: 0.3929  loss_bbox_0: 0.2803  loss_rpn_cls: 0.2426  loss_rpn_reg: 0.4921  time: 0.1891  last_time: 0.1841  data_time: 0.0049  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 13:07:13] d2.utils.events INFO:  eta: 1:27:17  iter: 26119  total_loss: 3.31  loss_ce: 0.4954  loss_giou: 0.4081  loss_bbox: 0.3076  loss_ce_0: 0.4981  loss_giou_0: 0.4219  loss_bbox_0: 0.3206  loss_rpn_cls: 0.2799  loss_rpn_reg: 0.5074  time: 0.1891  last_time: 0.1768  data_time: 0.0053  last_data_time: 0.0099   lr: 5e-05  max_mem: 3029M
[03/05 13:07:17] d2.utils.events INFO:  eta: 1:27:09  iter: 26139  total_loss: 2.954  loss_ce: 0.4843  loss_giou: 0.3241  loss_bbox: 0.2774  loss_ce_0: 0.4803  loss_giou_0: 0.353  loss_bbox_0: 0.2946  loss_rpn_cls: 0.2648  loss_rpn_reg: 0.4824  time: 0.1891  last_time: 0.1566  data_time: 0.0051  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:07:21] d2.utils.events INFO:  eta: 1:27:10  iter: 26159  total_loss: 2.915  loss_ce: 0.4257  loss_giou: 0.2967  loss_bbox: 0.3249  loss_ce_0: 0.465  loss_giou_0: 0.3066  loss_bbox_0: 0.3461  loss_rpn_cls: 0.2452  loss_rpn_reg: 0.4592  time: 0.1891  last_time: 0.1958  data_time: 0.0051  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 13:07:25] d2.utils.events INFO:  eta: 1:27:03  iter: 26179  total_loss: 3.11  loss_ce: 0.4285  loss_giou: 0.4  loss_bbox: 0.3252  loss_ce_0: 0.4557  loss_giou_0: 0.416  loss_bbox_0: 0.3736  loss_rpn_cls: 0.2501  loss_rpn_reg: 0.5123  time: 0.1891  last_time: 0.1832  data_time: 0.0048  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:07:28] d2.utils.events INFO:  eta: 1:27:00  iter: 26199  total_loss: 3.327  loss_ce: 0.5022  loss_giou: 0.3339  loss_bbox: 0.3136  loss_ce_0: 0.4961  loss_giou_0: 0.3774  loss_bbox_0: 0.3427  loss_rpn_cls: 0.271  loss_rpn_reg: 0.5099  time: 0.1891  last_time: 0.1885  data_time: 0.0048  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:07:32] d2.utils.events INFO:  eta: 1:26:59  iter: 26219  total_loss: 3.16  loss_ce: 0.4529  loss_giou: 0.3532  loss_bbox: 0.3373  loss_ce_0: 0.4842  loss_giou_0: 0.3658  loss_bbox_0: 0.3615  loss_rpn_cls: 0.2705  loss_rpn_reg: 0.4851  time: 0.1891  last_time: 0.1667  data_time: 0.0049  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:07:36] d2.utils.events INFO:  eta: 1:26:44  iter: 26239  total_loss: 3.307  loss_ce: 0.4954  loss_giou: 0.3989  loss_bbox: 0.278  loss_ce_0: 0.5044  loss_giou_0: 0.4306  loss_bbox_0: 0.3006  loss_rpn_cls: 0.2743  loss_rpn_reg: 0.4865  time: 0.1891  last_time: 0.1953  data_time: 0.0052  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:07:40] d2.utils.events INFO:  eta: 1:26:49  iter: 26259  total_loss: 3.084  loss_ce: 0.4288  loss_giou: 0.3435  loss_bbox: 0.3621  loss_ce_0: 0.4575  loss_giou_0: 0.3671  loss_bbox_0: 0.3694  loss_rpn_cls: 0.2448  loss_rpn_reg: 0.5229  time: 0.1891  last_time: 0.1986  data_time: 0.0051  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 13:07:44] d2.utils.events INFO:  eta: 1:26:45  iter: 26279  total_loss: 3.011  loss_ce: 0.3843  loss_giou: 0.3424  loss_bbox: 0.2917  loss_ce_0: 0.4706  loss_giou_0: 0.3639  loss_bbox_0: 0.3134  loss_rpn_cls: 0.2469  loss_rpn_reg: 0.484  time: 0.1891  last_time: 0.1766  data_time: 0.0049  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:07:47] d2.utils.events INFO:  eta: 1:26:44  iter: 26299  total_loss: 3.085  loss_ce: 0.451  loss_giou: 0.3165  loss_bbox: 0.323  loss_ce_0: 0.4984  loss_giou_0: 0.335  loss_bbox_0: 0.3633  loss_rpn_cls: 0.2681  loss_rpn_reg: 0.491  time: 0.1891  last_time: 0.2004  data_time: 0.0051  last_data_time: 0.0069   lr: 5e-05  max_mem: 3029M
[03/05 13:07:52] d2.utils.events INFO:  eta: 1:26:50  iter: 26319  total_loss: 3.468  loss_ce: 0.5263  loss_giou: 0.3867  loss_bbox: 0.3157  loss_ce_0: 0.4887  loss_giou_0: 0.3983  loss_bbox_0: 0.31  loss_rpn_cls: 0.2686  loss_rpn_reg: 0.5385  time: 0.1891  last_time: 0.1887  data_time: 0.0047  last_data_time: 0.0010   lr: 5e-05  max_mem: 3029M
[03/05 13:07:55] d2.utils.events INFO:  eta: 1:26:48  iter: 26339  total_loss: 2.696  loss_ce: 0.4051  loss_giou: 0.2565  loss_bbox: 0.2597  loss_ce_0: 0.4413  loss_giou_0: 0.2853  loss_bbox_0: 0.289  loss_rpn_cls: 0.2173  loss_rpn_reg: 0.4334  time: 0.1891  last_time: 0.1649  data_time: 0.0048  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:07:59] d2.utils.events INFO:  eta: 1:26:43  iter: 26359  total_loss: 2.97  loss_ce: 0.4072  loss_giou: 0.3139  loss_bbox: 0.3174  loss_ce_0: 0.4572  loss_giou_0: 0.3398  loss_bbox_0: 0.3134  loss_rpn_cls: 0.2338  loss_rpn_reg: 0.4295  time: 0.1891  last_time: 0.1813  data_time: 0.0054  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 13:08:03] d2.utils.events INFO:  eta: 1:26:38  iter: 26379  total_loss: 3.076  loss_ce: 0.4789  loss_giou: 0.3249  loss_bbox: 0.3452  loss_ce_0: 0.5002  loss_giou_0: 0.3533  loss_bbox_0: 0.3641  loss_rpn_cls: 0.278  loss_rpn_reg: 0.4708  time: 0.1891  last_time: 0.2130  data_time: 0.0047  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:08:07] d2.utils.events INFO:  eta: 1:26:33  iter: 26399  total_loss: 3.141  loss_ce: 0.4662  loss_giou: 0.3384  loss_bbox: 0.3362  loss_ce_0: 0.5126  loss_giou_0: 0.3617  loss_bbox_0: 0.346  loss_rpn_cls: 0.2765  loss_rpn_reg: 0.4727  time: 0.1891  last_time: 0.2170  data_time: 0.0050  last_data_time: 0.0028   lr: 5e-05  max_mem: 3029M
[03/05 13:08:11] d2.utils.events INFO:  eta: 1:26:32  iter: 26419  total_loss: 2.95  loss_ce: 0.4601  loss_giou: 0.3132  loss_bbox: 0.2965  loss_ce_0: 0.4834  loss_giou_0: 0.3353  loss_bbox_0: 0.321  loss_rpn_cls: 0.2581  loss_rpn_reg: 0.4529  time: 0.1891  last_time: 0.1846  data_time: 0.0053  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:08:14] d2.utils.events INFO:  eta: 1:26:38  iter: 26439  total_loss: 3.005  loss_ce: 0.4468  loss_giou: 0.3348  loss_bbox: 0.2739  loss_ce_0: 0.5084  loss_giou_0: 0.3654  loss_bbox_0: 0.3283  loss_rpn_cls: 0.2724  loss_rpn_reg: 0.4836  time: 0.1891  last_time: 0.2033  data_time: 0.0061  last_data_time: 0.0196   lr: 5e-05  max_mem: 3029M
[03/05 13:08:18] d2.utils.events INFO:  eta: 1:26:37  iter: 26459  total_loss: 3.024  loss_ce: 0.4572  loss_giou: 0.3624  loss_bbox: 0.321  loss_ce_0: 0.5007  loss_giou_0: 0.3613  loss_bbox_0: 0.3085  loss_rpn_cls: 0.2274  loss_rpn_reg: 0.4793  time: 0.1891  last_time: 0.1628  data_time: 0.0051  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:08:22] d2.utils.events INFO:  eta: 1:26:30  iter: 26479  total_loss: 2.926  loss_ce: 0.479  loss_giou: 0.3206  loss_bbox: 0.2396  loss_ce_0: 0.4991  loss_giou_0: 0.3592  loss_bbox_0: 0.3075  loss_rpn_cls: 0.2513  loss_rpn_reg: 0.4888  time: 0.1891  last_time: 0.1997  data_time: 0.0050  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 13:08:26] d2.utils.events INFO:  eta: 1:26:28  iter: 26499  total_loss: 3.285  loss_ce: 0.4994  loss_giou: 0.3501  loss_bbox: 0.2911  loss_ce_0: 0.5443  loss_giou_0: 0.3856  loss_bbox_0: 0.3619  loss_rpn_cls: 0.2502  loss_rpn_reg: 0.5317  time: 0.1891  last_time: 0.1791  data_time: 0.0044  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:08:30] d2.utils.events INFO:  eta: 1:26:25  iter: 26519  total_loss: 3.121  loss_ce: 0.4534  loss_giou: 0.3524  loss_bbox: 0.3081  loss_ce_0: 0.5039  loss_giou_0: 0.3835  loss_bbox_0: 0.3182  loss_rpn_cls: 0.2582  loss_rpn_reg: 0.4792  time: 0.1891  last_time: 0.1799  data_time: 0.0050  last_data_time: 0.0081   lr: 5e-05  max_mem: 3029M
[03/05 13:08:33] d2.utils.events INFO:  eta: 1:26:20  iter: 26539  total_loss: 3.282  loss_ce: 0.4852  loss_giou: 0.3705  loss_bbox: 0.3493  loss_ce_0: 0.5153  loss_giou_0: 0.3935  loss_bbox_0: 0.3428  loss_rpn_cls: 0.2846  loss_rpn_reg: 0.469  time: 0.1891  last_time: 0.2059  data_time: 0.0049  last_data_time: 0.0027   lr: 5e-05  max_mem: 3029M
[03/05 13:08:37] d2.utils.events INFO:  eta: 1:26:15  iter: 26559  total_loss: 2.921  loss_ce: 0.4453  loss_giou: 0.3367  loss_bbox: 0.2774  loss_ce_0: 0.5037  loss_giou_0: 0.3553  loss_bbox_0: 0.3252  loss_rpn_cls: 0.2169  loss_rpn_reg: 0.4803  time: 0.1891  last_time: 0.1710  data_time: 0.0049  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:08:41] d2.utils.events INFO:  eta: 1:26:10  iter: 26579  total_loss: 3.263  loss_ce: 0.4692  loss_giou: 0.367  loss_bbox: 0.299  loss_ce_0: 0.4996  loss_giou_0: 0.3954  loss_bbox_0: 0.324  loss_rpn_cls: 0.2792  loss_rpn_reg: 0.484  time: 0.1891  last_time: 0.1834  data_time: 0.0052  last_data_time: 0.0069   lr: 5e-05  max_mem: 3029M
[03/05 13:08:45] d2.utils.events INFO:  eta: 1:26:04  iter: 26599  total_loss: 3.231  loss_ce: 0.4288  loss_giou: 0.3255  loss_bbox: 0.3219  loss_ce_0: 0.4716  loss_giou_0: 0.3617  loss_bbox_0: 0.3344  loss_rpn_cls: 0.2903  loss_rpn_reg: 0.4871  time: 0.1891  last_time: 0.1931  data_time: 0.0046  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:08:49] d2.utils.events INFO:  eta: 1:26:04  iter: 26619  total_loss: 3.277  loss_ce: 0.4572  loss_giou: 0.3853  loss_bbox: 0.3282  loss_ce_0: 0.4817  loss_giou_0: 0.3881  loss_bbox_0: 0.3886  loss_rpn_cls: 0.2567  loss_rpn_reg: 0.4828  time: 0.1891  last_time: 0.1996  data_time: 0.0049  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 13:08:53] d2.utils.events INFO:  eta: 1:26:00  iter: 26639  total_loss: 3.127  loss_ce: 0.4545  loss_giou: 0.423  loss_bbox: 0.2533  loss_ce_0: 0.482  loss_giou_0: 0.4045  loss_bbox_0: 0.2933  loss_rpn_cls: 0.2779  loss_rpn_reg: 0.491  time: 0.1891  last_time: 0.1873  data_time: 0.0049  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:08:56] d2.utils.events INFO:  eta: 1:25:55  iter: 26659  total_loss: 3.072  loss_ce: 0.4713  loss_giou: 0.3443  loss_bbox: 0.3213  loss_ce_0: 0.5339  loss_giou_0: 0.3552  loss_bbox_0: 0.322  loss_rpn_cls: 0.271  loss_rpn_reg: 0.4325  time: 0.1891  last_time: 0.2067  data_time: 0.0048  last_data_time: 0.0072   lr: 5e-05  max_mem: 3029M
[03/05 13:09:00] d2.utils.events INFO:  eta: 1:25:51  iter: 26679  total_loss: 3.136  loss_ce: 0.4593  loss_giou: 0.3708  loss_bbox: 0.3145  loss_ce_0: 0.5478  loss_giou_0: 0.3799  loss_bbox_0: 0.3348  loss_rpn_cls: 0.2764  loss_rpn_reg: 0.4965  time: 0.1891  last_time: 0.1729  data_time: 0.0052  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:09:04] d2.utils.events INFO:  eta: 1:25:47  iter: 26699  total_loss: 3.134  loss_ce: 0.5301  loss_giou: 0.3925  loss_bbox: 0.2712  loss_ce_0: 0.5431  loss_giou_0: 0.4044  loss_bbox_0: 0.2767  loss_rpn_cls: 0.2733  loss_rpn_reg: 0.4736  time: 0.1891  last_time: 0.1810  data_time: 0.0048  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:09:08] d2.utils.events INFO:  eta: 1:25:43  iter: 26719  total_loss: 3.15  loss_ce: 0.4798  loss_giou: 0.3764  loss_bbox: 0.2958  loss_ce_0: 0.4944  loss_giou_0: 0.4  loss_bbox_0: 0.3063  loss_rpn_cls: 0.2728  loss_rpn_reg: 0.4891  time: 0.1891  last_time: 0.2104  data_time: 0.0046  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:09:12] d2.utils.events INFO:  eta: 1:25:41  iter: 26739  total_loss: 3.266  loss_ce: 0.4994  loss_giou: 0.352  loss_bbox: 0.3058  loss_ce_0: 0.5298  loss_giou_0: 0.3867  loss_bbox_0: 0.3399  loss_rpn_cls: 0.25  loss_rpn_reg: 0.4783  time: 0.1891  last_time: 0.2043  data_time: 0.0049  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:09:16] d2.utils.events INFO:  eta: 1:25:40  iter: 26759  total_loss: 3.153  loss_ce: 0.4982  loss_giou: 0.3478  loss_bbox: 0.3587  loss_ce_0: 0.5076  loss_giou_0: 0.3956  loss_bbox_0: 0.3634  loss_rpn_cls: 0.2411  loss_rpn_reg: 0.4818  time: 0.1891  last_time: 0.1937  data_time: 0.0051  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:09:19] d2.utils.events INFO:  eta: 1:25:39  iter: 26779  total_loss: 2.829  loss_ce: 0.4427  loss_giou: 0.3622  loss_bbox: 0.2597  loss_ce_0: 0.4638  loss_giou_0: 0.3764  loss_bbox_0: 0.2838  loss_rpn_cls: 0.2245  loss_rpn_reg: 0.4464  time: 0.1891  last_time: 0.1923  data_time: 0.0055  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:09:23] d2.utils.events INFO:  eta: 1:25:33  iter: 26799  total_loss: 3.326  loss_ce: 0.469  loss_giou: 0.367  loss_bbox: 0.2937  loss_ce_0: 0.4608  loss_giou_0: 0.4064  loss_bbox_0: 0.3231  loss_rpn_cls: 0.2482  loss_rpn_reg: 0.5031  time: 0.1891  last_time: 0.1907  data_time: 0.0048  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:09:27] d2.utils.events INFO:  eta: 1:25:28  iter: 26819  total_loss: 3.315  loss_ce: 0.4772  loss_giou: 0.3467  loss_bbox: 0.3313  loss_ce_0: 0.499  loss_giou_0: 0.3866  loss_bbox_0: 0.3389  loss_rpn_cls: 0.2596  loss_rpn_reg: 0.5053  time: 0.1891  last_time: 0.1890  data_time: 0.0050  last_data_time: 0.0070   lr: 5e-05  max_mem: 3029M
[03/05 13:09:31] d2.utils.events INFO:  eta: 1:25:23  iter: 26839  total_loss: 3.05  loss_ce: 0.425  loss_giou: 0.356  loss_bbox: 0.3244  loss_ce_0: 0.4446  loss_giou_0: 0.3806  loss_bbox_0: 0.325  loss_rpn_cls: 0.2285  loss_rpn_reg: 0.4994  time: 0.1891  last_time: 0.1985  data_time: 0.0050  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:09:35] d2.utils.events INFO:  eta: 1:25:15  iter: 26859  total_loss: 3.282  loss_ce: 0.5197  loss_giou: 0.3548  loss_bbox: 0.3032  loss_ce_0: 0.5488  loss_giou_0: 0.357  loss_bbox_0: 0.3422  loss_rpn_cls: 0.2612  loss_rpn_reg: 0.4699  time: 0.1891  last_time: 0.1830  data_time: 0.0050  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:09:38] d2.utils.events INFO:  eta: 1:25:04  iter: 26879  total_loss: 3.013  loss_ce: 0.3715  loss_giou: 0.355  loss_bbox: 0.2998  loss_ce_0: 0.4173  loss_giou_0: 0.3689  loss_bbox_0: 0.3386  loss_rpn_cls: 0.259  loss_rpn_reg: 0.5061  time: 0.1891  last_time: 0.2202  data_time: 0.0048  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 13:09:42] d2.utils.events INFO:  eta: 1:25:08  iter: 26899  total_loss: 3.167  loss_ce: 0.4399  loss_giou: 0.4005  loss_bbox: 0.3061  loss_ce_0: 0.4981  loss_giou_0: 0.3995  loss_bbox_0: 0.3719  loss_rpn_cls: 0.245  loss_rpn_reg: 0.5339  time: 0.1891  last_time: 0.2012  data_time: 0.0056  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:09:46] d2.utils.events INFO:  eta: 1:25:07  iter: 26919  total_loss: 3.111  loss_ce: 0.5301  loss_giou: 0.3253  loss_bbox: 0.2354  loss_ce_0: 0.5079  loss_giou_0: 0.3581  loss_bbox_0: 0.2947  loss_rpn_cls: 0.2539  loss_rpn_reg: 0.4628  time: 0.1891  last_time: 0.2000  data_time: 0.0055  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:09:50] d2.utils.events INFO:  eta: 1:25:04  iter: 26939  total_loss: 3.148  loss_ce: 0.5038  loss_giou: 0.3457  loss_bbox: 0.2732  loss_ce_0: 0.4951  loss_giou_0: 0.3778  loss_bbox_0: 0.3011  loss_rpn_cls: 0.2724  loss_rpn_reg: 0.4994  time: 0.1891  last_time: 0.2258  data_time: 0.0050  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:09:54] d2.utils.events INFO:  eta: 1:24:59  iter: 26959  total_loss: 2.92  loss_ce: 0.4042  loss_giou: 0.3004  loss_bbox: 0.3123  loss_ce_0: 0.4358  loss_giou_0: 0.3209  loss_bbox_0: 0.3481  loss_rpn_cls: 0.2226  loss_rpn_reg: 0.4519  time: 0.1891  last_time: 0.2189  data_time: 0.0056  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 13:09:58] d2.utils.events INFO:  eta: 1:24:56  iter: 26979  total_loss: 3.125  loss_ce: 0.4542  loss_giou: 0.362  loss_bbox: 0.2909  loss_ce_0: 0.4582  loss_giou_0: 0.3697  loss_bbox_0: 0.3337  loss_rpn_cls: 0.2332  loss_rpn_reg: 0.4925  time: 0.1891  last_time: 0.1889  data_time: 0.0052  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 13:10:02] d2.utils.events INFO:  eta: 1:24:47  iter: 26999  total_loss: 2.851  loss_ce: 0.4527  loss_giou: 0.283  loss_bbox: 0.2844  loss_ce_0: 0.4682  loss_giou_0: 0.3231  loss_bbox_0: 0.3364  loss_rpn_cls: 0.24  loss_rpn_reg: 0.4376  time: 0.1891  last_time: 0.1910  data_time: 0.0050  last_data_time: 0.0091   lr: 5e-05  max_mem: 3029M
[03/05 13:10:05] d2.utils.events INFO:  eta: 1:24:40  iter: 27019  total_loss: 3.343  loss_ce: 0.5051  loss_giou: 0.3751  loss_bbox: 0.3355  loss_ce_0: 0.4726  loss_giou_0: 0.4226  loss_bbox_0: 0.3924  loss_rpn_cls: 0.3027  loss_rpn_reg: 0.4957  time: 0.1891  last_time: 0.2339  data_time: 0.0053  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 13:10:09] d2.utils.events INFO:  eta: 1:24:32  iter: 27039  total_loss: 3.292  loss_ce: 0.4852  loss_giou: 0.3549  loss_bbox: 0.2657  loss_ce_0: 0.4819  loss_giou_0: 0.3906  loss_bbox_0: 0.2956  loss_rpn_cls: 0.2521  loss_rpn_reg: 0.4885  time: 0.1891  last_time: 0.1976  data_time: 0.0056  last_data_time: 0.0083   lr: 5e-05  max_mem: 3029M
[03/05 13:10:13] d2.utils.events INFO:  eta: 1:24:29  iter: 27059  total_loss: 2.88  loss_ce: 0.4406  loss_giou: 0.2776  loss_bbox: 0.2976  loss_ce_0: 0.4739  loss_giou_0: 0.2963  loss_bbox_0: 0.3615  loss_rpn_cls: 0.2248  loss_rpn_reg: 0.4325  time: 0.1891  last_time: 0.1606  data_time: 0.0050  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 13:10:17] d2.utils.events INFO:  eta: 1:24:21  iter: 27079  total_loss: 3.311  loss_ce: 0.4955  loss_giou: 0.4201  loss_bbox: 0.3456  loss_ce_0: 0.5234  loss_giou_0: 0.407  loss_bbox_0: 0.3504  loss_rpn_cls: 0.2645  loss_rpn_reg: 0.5111  time: 0.1891  last_time: 0.1800  data_time: 0.0053  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:10:21] d2.utils.events INFO:  eta: 1:24:20  iter: 27099  total_loss: 3.129  loss_ce: 0.5276  loss_giou: 0.3582  loss_bbox: 0.3358  loss_ce_0: 0.4996  loss_giou_0: 0.4026  loss_bbox_0: 0.3735  loss_rpn_cls: 0.2363  loss_rpn_reg: 0.487  time: 0.1891  last_time: 0.2020  data_time: 0.0047  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:10:25] d2.utils.events INFO:  eta: 1:24:19  iter: 27119  total_loss: 3.252  loss_ce: 0.503  loss_giou: 0.3419  loss_bbox: 0.382  loss_ce_0: 0.4903  loss_giou_0: 0.3792  loss_bbox_0: 0.3907  loss_rpn_cls: 0.2487  loss_rpn_reg: 0.4865  time: 0.1891  last_time: 0.1872  data_time: 0.0050  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 13:10:29] d2.utils.events INFO:  eta: 1:24:25  iter: 27139  total_loss: 3.013  loss_ce: 0.4413  loss_giou: 0.3413  loss_bbox: 0.3104  loss_ce_0: 0.4453  loss_giou_0: 0.3648  loss_bbox_0: 0.3463  loss_rpn_cls: 0.2238  loss_rpn_reg: 0.4758  time: 0.1891  last_time: 0.1888  data_time: 0.0052  last_data_time: 0.0079   lr: 5e-05  max_mem: 3029M
[03/05 13:10:32] d2.utils.events INFO:  eta: 1:24:18  iter: 27159  total_loss: 3.321  loss_ce: 0.4865  loss_giou: 0.3867  loss_bbox: 0.3272  loss_ce_0: 0.5124  loss_giou_0: 0.3835  loss_bbox_0: 0.3638  loss_rpn_cls: 0.2563  loss_rpn_reg: 0.4974  time: 0.1891  last_time: 0.1916  data_time: 0.0044  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:10:36] d2.utils.events INFO:  eta: 1:24:19  iter: 27179  total_loss: 3.172  loss_ce: 0.4713  loss_giou: 0.3126  loss_bbox: 0.3284  loss_ce_0: 0.5009  loss_giou_0: 0.3428  loss_bbox_0: 0.3689  loss_rpn_cls: 0.2302  loss_rpn_reg: 0.4788  time: 0.1891  last_time: 0.2015  data_time: 0.0046  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:10:40] d2.utils.events INFO:  eta: 1:24:14  iter: 27199  total_loss: 3.098  loss_ce: 0.4829  loss_giou: 0.3552  loss_bbox: 0.2731  loss_ce_0: 0.4943  loss_giou_0: 0.3688  loss_bbox_0: 0.2994  loss_rpn_cls: 0.2493  loss_rpn_reg: 0.4889  time: 0.1891  last_time: 0.1642  data_time: 0.0047  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:10:44] d2.utils.events INFO:  eta: 1:24:11  iter: 27219  total_loss: 3.045  loss_ce: 0.3874  loss_giou: 0.297  loss_bbox: 0.3013  loss_ce_0: 0.4123  loss_giou_0: 0.3578  loss_bbox_0: 0.3165  loss_rpn_cls: 0.2322  loss_rpn_reg: 0.4466  time: 0.1891  last_time: 0.1723  data_time: 0.0049  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:10:47] d2.utils.events INFO:  eta: 1:24:08  iter: 27239  total_loss: 3.262  loss_ce: 0.4807  loss_giou: 0.3415  loss_bbox: 0.294  loss_ce_0: 0.535  loss_giou_0: 0.3613  loss_bbox_0: 0.3296  loss_rpn_cls: 0.2429  loss_rpn_reg: 0.4744  time: 0.1891  last_time: 0.2041  data_time: 0.0049  last_data_time: 0.0071   lr: 5e-05  max_mem: 3029M
[03/05 13:10:51] d2.utils.events INFO:  eta: 1:24:04  iter: 27259  total_loss: 2.889  loss_ce: 0.4376  loss_giou: 0.2814  loss_bbox: 0.3046  loss_ce_0: 0.4807  loss_giou_0: 0.3093  loss_bbox_0: 0.3197  loss_rpn_cls: 0.2022  loss_rpn_reg: 0.469  time: 0.1891  last_time: 0.2098  data_time: 0.0057  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:10:55] d2.utils.events INFO:  eta: 1:24:00  iter: 27279  total_loss: 2.95  loss_ce: 0.449  loss_giou: 0.3319  loss_bbox: 0.3203  loss_ce_0: 0.4869  loss_giou_0: 0.3607  loss_bbox_0: 0.3508  loss_rpn_cls: 0.2257  loss_rpn_reg: 0.5112  time: 0.1891  last_time: 0.1871  data_time: 0.0051  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:10:59] d2.utils.events INFO:  eta: 1:23:57  iter: 27299  total_loss: 2.94  loss_ce: 0.4359  loss_giou: 0.3901  loss_bbox: 0.3309  loss_ce_0: 0.4601  loss_giou_0: 0.4157  loss_bbox_0: 0.4017  loss_rpn_cls: 0.267  loss_rpn_reg: 0.5143  time: 0.1891  last_time: 0.1906  data_time: 0.0050  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 13:11:03] d2.utils.events INFO:  eta: 1:23:43  iter: 27319  total_loss: 3.38  loss_ce: 0.5179  loss_giou: 0.3524  loss_bbox: 0.3288  loss_ce_0: 0.5535  loss_giou_0: 0.3819  loss_bbox_0: 0.3789  loss_rpn_cls: 0.2569  loss_rpn_reg: 0.4866  time: 0.1891  last_time: 0.1840  data_time: 0.0054  last_data_time: 0.0086   lr: 5e-05  max_mem: 3029M
[03/05 13:11:06] d2.utils.events INFO:  eta: 1:23:38  iter: 27339  total_loss: 2.837  loss_ce: 0.4654  loss_giou: 0.3324  loss_bbox: 0.2568  loss_ce_0: 0.4788  loss_giou_0: 0.3537  loss_bbox_0: 0.2945  loss_rpn_cls: 0.2221  loss_rpn_reg: 0.4763  time: 0.1891  last_time: 0.1673  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:11:10] d2.utils.events INFO:  eta: 1:23:36  iter: 27359  total_loss: 3.27  loss_ce: 0.4874  loss_giou: 0.4314  loss_bbox: 0.256  loss_ce_0: 0.5304  loss_giou_0: 0.4591  loss_bbox_0: 0.303  loss_rpn_cls: 0.2775  loss_rpn_reg: 0.5192  time: 0.1891  last_time: 0.1846  data_time: 0.0050  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:11:14] d2.utils.events INFO:  eta: 1:23:39  iter: 27379  total_loss: 2.976  loss_ce: 0.4784  loss_giou: 0.382  loss_bbox: 0.2732  loss_ce_0: 0.4761  loss_giou_0: 0.4089  loss_bbox_0: 0.3271  loss_rpn_cls: 0.2469  loss_rpn_reg: 0.5038  time: 0.1891  last_time: 0.1858  data_time: 0.0056  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 13:11:18] d2.utils.events INFO:  eta: 1:23:35  iter: 27399  total_loss: 2.933  loss_ce: 0.4923  loss_giou: 0.3445  loss_bbox: 0.2969  loss_ce_0: 0.5138  loss_giou_0: 0.3739  loss_bbox_0: 0.3352  loss_rpn_cls: 0.214  loss_rpn_reg: 0.4776  time: 0.1891  last_time: 0.2110  data_time: 0.0051  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 13:11:22] d2.utils.events INFO:  eta: 1:23:30  iter: 27419  total_loss: 2.922  loss_ce: 0.448  loss_giou: 0.331  loss_bbox: 0.3012  loss_ce_0: 0.4841  loss_giou_0: 0.3558  loss_bbox_0: 0.3212  loss_rpn_cls: 0.2495  loss_rpn_reg: 0.4805  time: 0.1891  last_time: 0.1965  data_time: 0.0049  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:11:25] d2.utils.events INFO:  eta: 1:23:19  iter: 27439  total_loss: 2.792  loss_ce: 0.4465  loss_giou: 0.3033  loss_bbox: 0.2741  loss_ce_0: 0.5118  loss_giou_0: 0.3413  loss_bbox_0: 0.3414  loss_rpn_cls: 0.2617  loss_rpn_reg: 0.4821  time: 0.1891  last_time: 0.1890  data_time: 0.0047  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:11:29] d2.utils.events INFO:  eta: 1:23:13  iter: 27459  total_loss: 2.995  loss_ce: 0.451  loss_giou: 0.3097  loss_bbox: 0.276  loss_ce_0: 0.5056  loss_giou_0: 0.3642  loss_bbox_0: 0.2937  loss_rpn_cls: 0.2322  loss_rpn_reg: 0.5008  time: 0.1891  last_time: 0.1973  data_time: 0.0048  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:11:33] d2.utils.events INFO:  eta: 1:23:12  iter: 27479  total_loss: 3.138  loss_ce: 0.4777  loss_giou: 0.3391  loss_bbox: 0.3235  loss_ce_0: 0.4666  loss_giou_0: 0.3556  loss_bbox_0: 0.3699  loss_rpn_cls: 0.2345  loss_rpn_reg: 0.4985  time: 0.1891  last_time: 0.1769  data_time: 0.0048  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:11:37] d2.utils.events INFO:  eta: 1:23:07  iter: 27499  total_loss: 2.682  loss_ce: 0.3929  loss_giou: 0.3041  loss_bbox: 0.2564  loss_ce_0: 0.434  loss_giou_0: 0.3406  loss_bbox_0: 0.2944  loss_rpn_cls: 0.2446  loss_rpn_reg: 0.4663  time: 0.1891  last_time: 0.1780  data_time: 0.0050  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 13:11:41] d2.utils.events INFO:  eta: 1:23:01  iter: 27519  total_loss: 3.179  loss_ce: 0.4947  loss_giou: 0.3154  loss_bbox: 0.2946  loss_ce_0: 0.4866  loss_giou_0: 0.3488  loss_bbox_0: 0.2987  loss_rpn_cls: 0.2355  loss_rpn_reg: 0.4788  time: 0.1891  last_time: 0.1524  data_time: 0.0047  last_data_time: 0.0032   lr: 5e-05  max_mem: 3029M
[03/05 13:11:44] d2.utils.events INFO:  eta: 1:22:57  iter: 27539  total_loss: 3.075  loss_ce: 0.4236  loss_giou: 0.3213  loss_bbox: 0.3378  loss_ce_0: 0.4578  loss_giou_0: 0.3441  loss_bbox_0: 0.3849  loss_rpn_cls: 0.2578  loss_rpn_reg: 0.502  time: 0.1891  last_time: 0.1971  data_time: 0.0047  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 13:11:48] d2.utils.events INFO:  eta: 1:22:53  iter: 27559  total_loss: 2.89  loss_ce: 0.4641  loss_giou: 0.2969  loss_bbox: 0.2853  loss_ce_0: 0.4835  loss_giou_0: 0.3222  loss_bbox_0: 0.3292  loss_rpn_cls: 0.242  loss_rpn_reg: 0.4587  time: 0.1891  last_time: 0.1591  data_time: 0.0056  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:11:52] d2.utils.events INFO:  eta: 1:22:51  iter: 27579  total_loss: 3.474  loss_ce: 0.5155  loss_giou: 0.3251  loss_bbox: 0.3288  loss_ce_0: 0.4963  loss_giou_0: 0.3581  loss_bbox_0: 0.3716  loss_rpn_cls: 0.2586  loss_rpn_reg: 0.5026  time: 0.1891  last_time: 0.2112  data_time: 0.0056  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 13:11:56] d2.utils.events INFO:  eta: 1:22:46  iter: 27599  total_loss: 3.028  loss_ce: 0.4674  loss_giou: 0.3465  loss_bbox: 0.3175  loss_ce_0: 0.4791  loss_giou_0: 0.3417  loss_bbox_0: 0.3304  loss_rpn_cls: 0.2311  loss_rpn_reg: 0.459  time: 0.1891  last_time: 0.1619  data_time: 0.0050  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:12:00] d2.utils.events INFO:  eta: 1:22:40  iter: 27619  total_loss: 3.178  loss_ce: 0.4974  loss_giou: 0.3259  loss_bbox: 0.3159  loss_ce_0: 0.5196  loss_giou_0: 0.3474  loss_bbox_0: 0.3836  loss_rpn_cls: 0.2688  loss_rpn_reg: 0.4722  time: 0.1891  last_time: 0.1852  data_time: 0.0048  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:12:03] d2.utils.events INFO:  eta: 1:22:32  iter: 27639  total_loss: 3.23  loss_ce: 0.5023  loss_giou: 0.3869  loss_bbox: 0.2974  loss_ce_0: 0.5079  loss_giou_0: 0.3998  loss_bbox_0: 0.3186  loss_rpn_cls: 0.2663  loss_rpn_reg: 0.5201  time: 0.1891  last_time: 0.1647  data_time: 0.0052  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:12:07] d2.utils.events INFO:  eta: 1:22:26  iter: 27659  total_loss: 3.27  loss_ce: 0.5045  loss_giou: 0.3695  loss_bbox: 0.3311  loss_ce_0: 0.5539  loss_giou_0: 0.386  loss_bbox_0: 0.3612  loss_rpn_cls: 0.2497  loss_rpn_reg: 0.5049  time: 0.1891  last_time: 0.1957  data_time: 0.0049  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:12:11] d2.utils.events INFO:  eta: 1:22:21  iter: 27679  total_loss: 2.913  loss_ce: 0.461  loss_giou: 0.3013  loss_bbox: 0.2693  loss_ce_0: 0.4823  loss_giou_0: 0.327  loss_bbox_0: 0.3119  loss_rpn_cls: 0.2311  loss_rpn_reg: 0.4672  time: 0.1891  last_time: 0.1850  data_time: 0.0042  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:12:15] d2.utils.events INFO:  eta: 1:22:17  iter: 27699  total_loss: 2.826  loss_ce: 0.4593  loss_giou: 0.2969  loss_bbox: 0.3233  loss_ce_0: 0.4823  loss_giou_0: 0.3092  loss_bbox_0: 0.3433  loss_rpn_cls: 0.2414  loss_rpn_reg: 0.4715  time: 0.1891  last_time: 0.1798  data_time: 0.0049  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:12:19] d2.utils.events INFO:  eta: 1:22:12  iter: 27719  total_loss: 3.133  loss_ce: 0.4341  loss_giou: 0.328  loss_bbox: 0.2856  loss_ce_0: 0.5177  loss_giou_0: 0.3399  loss_bbox_0: 0.3176  loss_rpn_cls: 0.2837  loss_rpn_reg: 0.5028  time: 0.1891  last_time: 0.1652  data_time: 0.0053  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:12:22] d2.utils.events INFO:  eta: 1:22:08  iter: 27739  total_loss: 3.024  loss_ce: 0.4673  loss_giou: 0.3614  loss_bbox: 0.3058  loss_ce_0: 0.4945  loss_giou_0: 0.3711  loss_bbox_0: 0.319  loss_rpn_cls: 0.2763  loss_rpn_reg: 0.484  time: 0.1891  last_time: 0.1823  data_time: 0.0052  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:12:26] d2.utils.events INFO:  eta: 1:21:53  iter: 27759  total_loss: 2.963  loss_ce: 0.4689  loss_giou: 0.3528  loss_bbox: 0.2594  loss_ce_0: 0.4776  loss_giou_0: 0.3916  loss_bbox_0: 0.2965  loss_rpn_cls: 0.2494  loss_rpn_reg: 0.4725  time: 0.1891  last_time: 0.1787  data_time: 0.0051  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:12:30] d2.utils.events INFO:  eta: 1:21:50  iter: 27779  total_loss: 3.229  loss_ce: 0.4523  loss_giou: 0.3391  loss_bbox: 0.3325  loss_ce_0: 0.4975  loss_giou_0: 0.3753  loss_bbox_0: 0.366  loss_rpn_cls: 0.243  loss_rpn_reg: 0.5175  time: 0.1891  last_time: 0.2034  data_time: 0.0054  last_data_time: 0.0090   lr: 5e-05  max_mem: 3029M
[03/05 13:12:34] d2.utils.events INFO:  eta: 1:21:43  iter: 27799  total_loss: 3.039  loss_ce: 0.4729  loss_giou: 0.3162  loss_bbox: 0.2715  loss_ce_0: 0.4749  loss_giou_0: 0.343  loss_bbox_0: 0.3129  loss_rpn_cls: 0.255  loss_rpn_reg: 0.4974  time: 0.1890  last_time: 0.1878  data_time: 0.0049  last_data_time: 0.0070   lr: 5e-05  max_mem: 3029M
[03/05 13:12:38] d2.utils.events INFO:  eta: 1:21:38  iter: 27819  total_loss: 3.021  loss_ce: 0.4896  loss_giou: 0.3622  loss_bbox: 0.271  loss_ce_0: 0.5401  loss_giou_0: 0.3652  loss_bbox_0: 0.3214  loss_rpn_cls: 0.2443  loss_rpn_reg: 0.4877  time: 0.1890  last_time: 0.1690  data_time: 0.0048  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 13:12:41] d2.utils.events INFO:  eta: 1:21:34  iter: 27839  total_loss: 3.249  loss_ce: 0.487  loss_giou: 0.3685  loss_bbox: 0.3013  loss_ce_0: 0.5115  loss_giou_0: 0.3721  loss_bbox_0: 0.3216  loss_rpn_cls: 0.27  loss_rpn_reg: 0.4968  time: 0.1890  last_time: 0.1799  data_time: 0.0054  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:12:45] d2.utils.events INFO:  eta: 1:21:33  iter: 27859  total_loss: 2.853  loss_ce: 0.4386  loss_giou: 0.2957  loss_bbox: 0.2545  loss_ce_0: 0.4787  loss_giou_0: 0.2888  loss_bbox_0: 0.2586  loss_rpn_cls: 0.2048  loss_rpn_reg: 0.4436  time: 0.1890  last_time: 0.1601  data_time: 0.0048  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:12:49] d2.utils.events INFO:  eta: 1:21:38  iter: 27879  total_loss: 2.752  loss_ce: 0.3932  loss_giou: 0.3358  loss_bbox: 0.2901  loss_ce_0: 0.4335  loss_giou_0: 0.3348  loss_bbox_0: 0.304  loss_rpn_cls: 0.2372  loss_rpn_reg: 0.4606  time: 0.1890  last_time: 0.1900  data_time: 0.0049  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:12:53] d2.utils.events INFO:  eta: 1:21:25  iter: 27899  total_loss: 3.215  loss_ce: 0.4936  loss_giou: 0.2957  loss_bbox: 0.3247  loss_ce_0: 0.5261  loss_giou_0: 0.3289  loss_bbox_0: 0.3247  loss_rpn_cls: 0.2333  loss_rpn_reg: 0.4673  time: 0.1890  last_time: 0.2071  data_time: 0.0055  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 13:12:57] d2.utils.events INFO:  eta: 1:21:23  iter: 27919  total_loss: 3.205  loss_ce: 0.5221  loss_giou: 0.3871  loss_bbox: 0.3231  loss_ce_0: 0.5223  loss_giou_0: 0.4264  loss_bbox_0: 0.3196  loss_rpn_cls: 0.2655  loss_rpn_reg: 0.5372  time: 0.1890  last_time: 0.1977  data_time: 0.0054  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:13:00] d2.utils.events INFO:  eta: 1:21:17  iter: 27939  total_loss: 3.388  loss_ce: 0.5517  loss_giou: 0.3873  loss_bbox: 0.3217  loss_ce_0: 0.5127  loss_giou_0: 0.4336  loss_bbox_0: 0.3652  loss_rpn_cls: 0.2754  loss_rpn_reg: 0.5374  time: 0.1890  last_time: 0.1869  data_time: 0.0049  last_data_time: 0.0071   lr: 5e-05  max_mem: 3029M
[03/05 13:13:04] d2.utils.events INFO:  eta: 1:21:11  iter: 27959  total_loss: 3.57  loss_ce: 0.516  loss_giou: 0.4012  loss_bbox: 0.2461  loss_ce_0: 0.5308  loss_giou_0: 0.4068  loss_bbox_0: 0.2936  loss_rpn_cls: 0.2946  loss_rpn_reg: 0.4958  time: 0.1890  last_time: 0.1928  data_time: 0.0044  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:13:08] d2.utils.events INFO:  eta: 1:21:07  iter: 27979  total_loss: 2.824  loss_ce: 0.4063  loss_giou: 0.348  loss_bbox: 0.31  loss_ce_0: 0.4507  loss_giou_0: 0.3733  loss_bbox_0: 0.3604  loss_rpn_cls: 0.2333  loss_rpn_reg: 0.4913  time: 0.1890  last_time: 0.1880  data_time: 0.0051  last_data_time: 0.0025   lr: 5e-05  max_mem: 3029M
[03/05 13:13:12] d2.utils.events INFO:  eta: 1:21:04  iter: 27999  total_loss: 3.045  loss_ce: 0.4788  loss_giou: 0.3073  loss_bbox: 0.3151  loss_ce_0: 0.4765  loss_giou_0: 0.3343  loss_bbox_0: 0.3605  loss_rpn_cls: 0.2314  loss_rpn_reg: 0.4802  time: 0.1890  last_time: 0.1798  data_time: 0.0054  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 13:13:16] d2.utils.events INFO:  eta: 1:21:00  iter: 28019  total_loss: 3.137  loss_ce: 0.4446  loss_giou: 0.3164  loss_bbox: 0.3414  loss_ce_0: 0.527  loss_giou_0: 0.3372  loss_bbox_0: 0.3421  loss_rpn_cls: 0.2439  loss_rpn_reg: 0.4896  time: 0.1890  last_time: 0.1818  data_time: 0.0049  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 13:13:20] d2.utils.events INFO:  eta: 1:21:00  iter: 28039  total_loss: 3.037  loss_ce: 0.4226  loss_giou: 0.3681  loss_bbox: 0.34  loss_ce_0: 0.4601  loss_giou_0: 0.3651  loss_bbox_0: 0.3852  loss_rpn_cls: 0.2381  loss_rpn_reg: 0.4779  time: 0.1890  last_time: 0.2094  data_time: 0.0061  last_data_time: 0.0079   lr: 5e-05  max_mem: 3029M
[03/05 13:13:23] d2.utils.events INFO:  eta: 1:20:56  iter: 28059  total_loss: 3.082  loss_ce: 0.4336  loss_giou: 0.3214  loss_bbox: 0.309  loss_ce_0: 0.4699  loss_giou_0: 0.347  loss_bbox_0: 0.3165  loss_rpn_cls: 0.2581  loss_rpn_reg: 0.495  time: 0.1890  last_time: 0.1799  data_time: 0.0050  last_data_time: 0.0078   lr: 5e-05  max_mem: 3029M
[03/05 13:13:27] d2.utils.events INFO:  eta: 1:21:00  iter: 28079  total_loss: 2.787  loss_ce: 0.3928  loss_giou: 0.3406  loss_bbox: 0.2861  loss_ce_0: 0.4697  loss_giou_0: 0.353  loss_bbox_0: 0.3212  loss_rpn_cls: 0.2336  loss_rpn_reg: 0.4949  time: 0.1890  last_time: 0.2062  data_time: 0.0050  last_data_time: 0.0031   lr: 5e-05  max_mem: 3029M
[03/05 13:13:31] d2.utils.events INFO:  eta: 1:20:52  iter: 28099  total_loss: 3.256  loss_ce: 0.5079  loss_giou: 0.4139  loss_bbox: 0.3453  loss_ce_0: 0.5245  loss_giou_0: 0.4087  loss_bbox_0: 0.3972  loss_rpn_cls: 0.2861  loss_rpn_reg: 0.5004  time: 0.1890  last_time: 0.1918  data_time: 0.0052  last_data_time: 0.0093   lr: 5e-05  max_mem: 3029M
[03/05 13:13:35] d2.utils.events INFO:  eta: 1:20:46  iter: 28119  total_loss: 2.733  loss_ce: 0.4563  loss_giou: 0.3422  loss_bbox: 0.2709  loss_ce_0: 0.4897  loss_giou_0: 0.3476  loss_bbox_0: 0.2843  loss_rpn_cls: 0.1972  loss_rpn_reg: 0.5183  time: 0.1890  last_time: 0.1903  data_time: 0.0054  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:13:39] d2.utils.events INFO:  eta: 1:20:36  iter: 28139  total_loss: 3.087  loss_ce: 0.4489  loss_giou: 0.3719  loss_bbox: 0.3165  loss_ce_0: 0.4625  loss_giou_0: 0.4197  loss_bbox_0: 0.3329  loss_rpn_cls: 0.2341  loss_rpn_reg: 0.5132  time: 0.1890  last_time: 0.1921  data_time: 0.0046  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 13:13:42] d2.utils.events INFO:  eta: 1:20:33  iter: 28159  total_loss: 3.029  loss_ce: 0.4332  loss_giou: 0.3387  loss_bbox: 0.3091  loss_ce_0: 0.4884  loss_giou_0: 0.3282  loss_bbox_0: 0.3258  loss_rpn_cls: 0.2353  loss_rpn_reg: 0.4989  time: 0.1890  last_time: 0.1944  data_time: 0.0052  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:13:46] d2.utils.events INFO:  eta: 1:20:28  iter: 28179  total_loss: 3.219  loss_ce: 0.478  loss_giou: 0.4095  loss_bbox: 0.3293  loss_ce_0: 0.4978  loss_giou_0: 0.408  loss_bbox_0: 0.3489  loss_rpn_cls: 0.2453  loss_rpn_reg: 0.499  time: 0.1890  last_time: 0.1663  data_time: 0.0054  last_data_time: 0.0024   lr: 5e-05  max_mem: 3029M
[03/05 13:13:50] d2.utils.events INFO:  eta: 1:20:25  iter: 28199  total_loss: 3.369  loss_ce: 0.5231  loss_giou: 0.3268  loss_bbox: 0.3271  loss_ce_0: 0.5346  loss_giou_0: 0.3792  loss_bbox_0: 0.3903  loss_rpn_cls: 0.2794  loss_rpn_reg: 0.4882  time: 0.1890  last_time: 0.1851  data_time: 0.0049  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 13:13:54] d2.utils.events INFO:  eta: 1:20:22  iter: 28219  total_loss: 3.132  loss_ce: 0.4579  loss_giou: 0.3902  loss_bbox: 0.3066  loss_ce_0: 0.4963  loss_giou_0: 0.3994  loss_bbox_0: 0.3112  loss_rpn_cls: 0.2238  loss_rpn_reg: 0.5342  time: 0.1890  last_time: 0.2251  data_time: 0.0053  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:13:58] d2.utils.events INFO:  eta: 1:20:18  iter: 28239  total_loss: 3.027  loss_ce: 0.4679  loss_giou: 0.3386  loss_bbox: 0.2997  loss_ce_0: 0.4722  loss_giou_0: 0.3792  loss_bbox_0: 0.3649  loss_rpn_cls: 0.252  loss_rpn_reg: 0.4944  time: 0.1890  last_time: 0.2017  data_time: 0.0050  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 13:14:02] d2.utils.events INFO:  eta: 1:20:19  iter: 28259  total_loss: 3.032  loss_ce: 0.4015  loss_giou: 0.3457  loss_bbox: 0.2978  loss_ce_0: 0.4644  loss_giou_0: 0.3812  loss_bbox_0: 0.3498  loss_rpn_cls: 0.2441  loss_rpn_reg: 0.4502  time: 0.1890  last_time: 0.2254  data_time: 0.0051  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 13:14:06] d2.utils.events INFO:  eta: 1:20:16  iter: 28279  total_loss: 3.051  loss_ce: 0.4465  loss_giou: 0.3177  loss_bbox: 0.3282  loss_ce_0: 0.4815  loss_giou_0: 0.3454  loss_bbox_0: 0.3591  loss_rpn_cls: 0.2149  loss_rpn_reg: 0.4564  time: 0.1890  last_time: 0.1886  data_time: 0.0053  last_data_time: 0.0026   lr: 5e-05  max_mem: 3029M
[03/05 13:14:09] d2.utils.events INFO:  eta: 1:20:08  iter: 28299  total_loss: 3.194  loss_ce: 0.4497  loss_giou: 0.4061  loss_bbox: 0.3119  loss_ce_0: 0.454  loss_giou_0: 0.4004  loss_bbox_0: 0.3535  loss_rpn_cls: 0.2673  loss_rpn_reg: 0.4632  time: 0.1890  last_time: 0.1884  data_time: 0.0052  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 13:14:13] d2.utils.events INFO:  eta: 1:20:06  iter: 28319  total_loss: 2.962  loss_ce: 0.4209  loss_giou: 0.3544  loss_bbox: 0.2823  loss_ce_0: 0.4179  loss_giou_0: 0.3758  loss_bbox_0: 0.301  loss_rpn_cls: 0.2066  loss_rpn_reg: 0.5001  time: 0.1890  last_time: 0.1577  data_time: 0.0045  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:14:17] d2.utils.events INFO:  eta: 1:20:00  iter: 28339  total_loss: 3.091  loss_ce: 0.401  loss_giou: 0.3065  loss_bbox: 0.2918  loss_ce_0: 0.4582  loss_giou_0: 0.3132  loss_bbox_0: 0.3519  loss_rpn_cls: 0.1853  loss_rpn_reg: 0.5107  time: 0.1890  last_time: 0.1750  data_time: 0.0046  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:14:21] d2.utils.events INFO:  eta: 1:19:56  iter: 28359  total_loss: 3.179  loss_ce: 0.4789  loss_giou: 0.359  loss_bbox: 0.2953  loss_ce_0: 0.4999  loss_giou_0: 0.3697  loss_bbox_0: 0.3372  loss_rpn_cls: 0.2391  loss_rpn_reg: 0.4851  time: 0.1890  last_time: 0.1686  data_time: 0.0056  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 13:14:24] d2.utils.events INFO:  eta: 1:19:50  iter: 28379  total_loss: 2.734  loss_ce: 0.3893  loss_giou: 0.3387  loss_bbox: 0.2509  loss_ce_0: 0.4515  loss_giou_0: 0.3614  loss_bbox_0: 0.2808  loss_rpn_cls: 0.2123  loss_rpn_reg: 0.4793  time: 0.1890  last_time: 0.1711  data_time: 0.0045  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 13:14:28] d2.utils.events INFO:  eta: 1:19:43  iter: 28399  total_loss: 2.88  loss_ce: 0.4177  loss_giou: 0.347  loss_bbox: 0.2957  loss_ce_0: 0.4801  loss_giou_0: 0.3705  loss_bbox_0: 0.3194  loss_rpn_cls: 0.2485  loss_rpn_reg: 0.4967  time: 0.1890  last_time: 0.1714  data_time: 0.0046  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:14:32] d2.utils.events INFO:  eta: 1:19:33  iter: 28419  total_loss: 3.105  loss_ce: 0.4782  loss_giou: 0.3567  loss_bbox: 0.2931  loss_ce_0: 0.5275  loss_giou_0: 0.3779  loss_bbox_0: 0.3299  loss_rpn_cls: 0.2274  loss_rpn_reg: 0.5187  time: 0.1890  last_time: 0.1976  data_time: 0.0044  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:14:35] d2.utils.events INFO:  eta: 1:19:31  iter: 28439  total_loss: 3.061  loss_ce: 0.4689  loss_giou: 0.3686  loss_bbox: 0.2735  loss_ce_0: 0.486  loss_giou_0: 0.3759  loss_bbox_0: 0.3008  loss_rpn_cls: 0.2513  loss_rpn_reg: 0.5079  time: 0.1890  last_time: 0.1952  data_time: 0.0044  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 13:14:39] d2.utils.events INFO:  eta: 1:19:33  iter: 28459  total_loss: 3.559  loss_ce: 0.4238  loss_giou: 0.418  loss_bbox: 0.3086  loss_ce_0: 0.4671  loss_giou_0: 0.4093  loss_bbox_0: 0.3495  loss_rpn_cls: 0.2768  loss_rpn_reg: 0.517  time: 0.1890  last_time: 0.2124  data_time: 0.0059  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:14:43] d2.utils.events INFO:  eta: 1:19:22  iter: 28479  total_loss: 2.828  loss_ce: 0.4777  loss_giou: 0.315  loss_bbox: 0.2808  loss_ce_0: 0.5149  loss_giou_0: 0.3392  loss_bbox_0: 0.3291  loss_rpn_cls: 0.2266  loss_rpn_reg: 0.4629  time: 0.1890  last_time: 0.1738  data_time: 0.0049  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 13:14:47] d2.utils.events INFO:  eta: 1:19:27  iter: 28499  total_loss: 3.263  loss_ce: 0.4971  loss_giou: 0.3391  loss_bbox: 0.3906  loss_ce_0: 0.5138  loss_giou_0: 0.3396  loss_bbox_0: 0.4222  loss_rpn_cls: 0.2458  loss_rpn_reg: 0.4761  time: 0.1890  last_time: 0.1649  data_time: 0.0056  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:14:51] d2.utils.events INFO:  eta: 1:19:23  iter: 28519  total_loss: 3.112  loss_ce: 0.4476  loss_giou: 0.3818  loss_bbox: 0.3211  loss_ce_0: 0.4463  loss_giou_0: 0.4  loss_bbox_0: 0.3285  loss_rpn_cls: 0.2396  loss_rpn_reg: 0.4741  time: 0.1890  last_time: 0.1955  data_time: 0.0049  last_data_time: 0.0031   lr: 5e-05  max_mem: 3029M
[03/05 13:14:54] d2.utils.events INFO:  eta: 1:19:20  iter: 28539  total_loss: 3.449  loss_ce: 0.5457  loss_giou: 0.4358  loss_bbox: 0.3433  loss_ce_0: 0.5214  loss_giou_0: 0.4474  loss_bbox_0: 0.3813  loss_rpn_cls: 0.2807  loss_rpn_reg: 0.4999  time: 0.1890  last_time: 0.1760  data_time: 0.0051  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:14:58] d2.utils.events INFO:  eta: 1:19:17  iter: 28559  total_loss: 2.917  loss_ce: 0.4598  loss_giou: 0.345  loss_bbox: 0.311  loss_ce_0: 0.5071  loss_giou_0: 0.3566  loss_bbox_0: 0.3405  loss_rpn_cls: 0.2924  loss_rpn_reg: 0.475  time: 0.1890  last_time: 0.1922  data_time: 0.0065  last_data_time: 0.0025   lr: 5e-05  max_mem: 3029M
[03/05 13:15:02] d2.utils.events INFO:  eta: 1:19:08  iter: 28579  total_loss: 3.285  loss_ce: 0.4915  loss_giou: 0.3541  loss_bbox: 0.3495  loss_ce_0: 0.4949  loss_giou_0: 0.376  loss_bbox_0: 0.3588  loss_rpn_cls: 0.2474  loss_rpn_reg: 0.4967  time: 0.1890  last_time: 0.1784  data_time: 0.0048  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 13:15:06] d2.utils.events INFO:  eta: 1:19:07  iter: 28599  total_loss: 3.374  loss_ce: 0.4884  loss_giou: 0.342  loss_bbox: 0.3565  loss_ce_0: 0.5337  loss_giou_0: 0.363  loss_bbox_0: 0.3724  loss_rpn_cls: 0.2756  loss_rpn_reg: 0.4999  time: 0.1890  last_time: 0.1966  data_time: 0.0048  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 13:15:10] d2.utils.events INFO:  eta: 1:19:04  iter: 28619  total_loss: 3.192  loss_ce: 0.4984  loss_giou: 0.3849  loss_bbox: 0.2962  loss_ce_0: 0.4786  loss_giou_0: 0.4367  loss_bbox_0: 0.3132  loss_rpn_cls: 0.2767  loss_rpn_reg: 0.5116  time: 0.1890  last_time: 0.1783  data_time: 0.0054  last_data_time: 0.0030   lr: 5e-05  max_mem: 3029M
[03/05 13:15:14] d2.utils.events INFO:  eta: 1:18:59  iter: 28639  total_loss: 2.997  loss_ce: 0.4447  loss_giou: 0.35  loss_bbox: 0.3132  loss_ce_0: 0.4628  loss_giou_0: 0.3713  loss_bbox_0: 0.3154  loss_rpn_cls: 0.2473  loss_rpn_reg: 0.4825  time: 0.1890  last_time: 0.1815  data_time: 0.0057  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:15:17] d2.utils.events INFO:  eta: 1:18:56  iter: 28659  total_loss: 3.174  loss_ce: 0.4034  loss_giou: 0.4087  loss_bbox: 0.2945  loss_ce_0: 0.4267  loss_giou_0: 0.421  loss_bbox_0: 0.3381  loss_rpn_cls: 0.2418  loss_rpn_reg: 0.4846  time: 0.1890  last_time: 0.2012  data_time: 0.0053  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:15:21] d2.utils.events INFO:  eta: 1:18:52  iter: 28679  total_loss: 3.019  loss_ce: 0.5374  loss_giou: 0.3367  loss_bbox: 0.2673  loss_ce_0: 0.5046  loss_giou_0: 0.366  loss_bbox_0: 0.3054  loss_rpn_cls: 0.2558  loss_rpn_reg: 0.4874  time: 0.1890  last_time: 0.1876  data_time: 0.0058  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:15:25] d2.utils.events INFO:  eta: 1:18:49  iter: 28699  total_loss: 2.805  loss_ce: 0.3946  loss_giou: 0.3609  loss_bbox: 0.3147  loss_ce_0: 0.4291  loss_giou_0: 0.3782  loss_bbox_0: 0.3174  loss_rpn_cls: 0.2221  loss_rpn_reg: 0.4653  time: 0.1890  last_time: 0.1789  data_time: 0.0057  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:15:29] d2.utils.events INFO:  eta: 1:18:45  iter: 28719  total_loss: 3.214  loss_ce: 0.5092  loss_giou: 0.3712  loss_bbox: 0.2975  loss_ce_0: 0.5122  loss_giou_0: 0.4006  loss_bbox_0: 0.3521  loss_rpn_cls: 0.2448  loss_rpn_reg: 0.5048  time: 0.1890  last_time: 0.1763  data_time: 0.0049  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:15:32] d2.utils.events INFO:  eta: 1:18:36  iter: 28739  total_loss: 3.318  loss_ce: 0.5083  loss_giou: 0.3592  loss_bbox: 0.3396  loss_ce_0: 0.5331  loss_giou_0: 0.3777  loss_bbox_0: 0.3579  loss_rpn_cls: 0.2472  loss_rpn_reg: 0.5125  time: 0.1890  last_time: 0.1823  data_time: 0.0048  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:15:36] d2.utils.events INFO:  eta: 1:18:36  iter: 28759  total_loss: 3.104  loss_ce: 0.4527  loss_giou: 0.3607  loss_bbox: 0.315  loss_ce_0: 0.5297  loss_giou_0: 0.3924  loss_bbox_0: 0.3901  loss_rpn_cls: 0.2455  loss_rpn_reg: 0.5177  time: 0.1890  last_time: 0.1716  data_time: 0.0055  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 13:15:40] d2.utils.events INFO:  eta: 1:18:29  iter: 28779  total_loss: 3.468  loss_ce: 0.4468  loss_giou: 0.3981  loss_bbox: 0.322  loss_ce_0: 0.5276  loss_giou_0: 0.3835  loss_bbox_0: 0.3159  loss_rpn_cls: 0.2256  loss_rpn_reg: 0.5481  time: 0.1890  last_time: 0.1853  data_time: 0.0054  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 13:15:44] d2.utils.events INFO:  eta: 1:18:29  iter: 28799  total_loss: 3.07  loss_ce: 0.4527  loss_giou: 0.3262  loss_bbox: 0.293  loss_ce_0: 0.4843  loss_giou_0: 0.3467  loss_bbox_0: 0.3301  loss_rpn_cls: 0.2473  loss_rpn_reg: 0.4946  time: 0.1890  last_time: 0.1657  data_time: 0.0055  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:15:48] d2.utils.events INFO:  eta: 1:18:28  iter: 28819  total_loss: 3.058  loss_ce: 0.4632  loss_giou: 0.3738  loss_bbox: 0.2878  loss_ce_0: 0.5132  loss_giou_0: 0.4083  loss_bbox_0: 0.3083  loss_rpn_cls: 0.2402  loss_rpn_reg: 0.5145  time: 0.1890  last_time: 0.1546  data_time: 0.0050  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:15:51] d2.utils.events INFO:  eta: 1:18:23  iter: 28839  total_loss: 3.209  loss_ce: 0.4941  loss_giou: 0.3462  loss_bbox: 0.3113  loss_ce_0: 0.5632  loss_giou_0: 0.3647  loss_bbox_0: 0.3332  loss_rpn_cls: 0.2643  loss_rpn_reg: 0.4902  time: 0.1890  last_time: 0.1856  data_time: 0.0055  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:15:55] d2.utils.events INFO:  eta: 1:18:19  iter: 28859  total_loss: 3.244  loss_ce: 0.5061  loss_giou: 0.3194  loss_bbox: 0.2823  loss_ce_0: 0.527  loss_giou_0: 0.3312  loss_bbox_0: 0.3436  loss_rpn_cls: 0.2328  loss_rpn_reg: 0.4724  time: 0.1890  last_time: 0.1783  data_time: 0.0054  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 13:15:59] d2.utils.events INFO:  eta: 1:18:16  iter: 28879  total_loss: 3.024  loss_ce: 0.4272  loss_giou: 0.3247  loss_bbox: 0.3216  loss_ce_0: 0.4585  loss_giou_0: 0.3555  loss_bbox_0: 0.3407  loss_rpn_cls: 0.2402  loss_rpn_reg: 0.4969  time: 0.1890  last_time: 0.1831  data_time: 0.0049  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:16:03] d2.utils.events INFO:  eta: 1:18:12  iter: 28899  total_loss: 2.946  loss_ce: 0.4953  loss_giou: 0.292  loss_bbox: 0.2657  loss_ce_0: 0.5459  loss_giou_0: 0.3201  loss_bbox_0: 0.3055  loss_rpn_cls: 0.2628  loss_rpn_reg: 0.4732  time: 0.1890  last_time: 0.2229  data_time: 0.0056  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 13:16:07] d2.utils.events INFO:  eta: 1:18:06  iter: 28919  total_loss: 3.473  loss_ce: 0.5291  loss_giou: 0.356  loss_bbox: 0.382  loss_ce_0: 0.5545  loss_giou_0: 0.3828  loss_bbox_0: 0.4167  loss_rpn_cls: 0.2666  loss_rpn_reg: 0.5218  time: 0.1890  last_time: 0.1808  data_time: 0.0051  last_data_time: 0.0021   lr: 5e-05  max_mem: 3029M
[03/05 13:16:11] d2.utils.events INFO:  eta: 1:18:05  iter: 28939  total_loss: 3.054  loss_ce: 0.46  loss_giou: 0.3482  loss_bbox: 0.285  loss_ce_0: 0.4896  loss_giou_0: 0.3584  loss_bbox_0: 0.3162  loss_rpn_cls: 0.2328  loss_rpn_reg: 0.4952  time: 0.1890  last_time: 0.2083  data_time: 0.0055  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 13:16:15] d2.utils.events INFO:  eta: 1:18:06  iter: 28959  total_loss: 3.276  loss_ce: 0.4932  loss_giou: 0.3814  loss_bbox: 0.3577  loss_ce_0: 0.5137  loss_giou_0: 0.396  loss_bbox_0: 0.3615  loss_rpn_cls: 0.2305  loss_rpn_reg: 0.4818  time: 0.1890  last_time: 0.2024  data_time: 0.0059  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 13:16:19] d2.utils.events INFO:  eta: 1:18:08  iter: 28979  total_loss: 2.941  loss_ce: 0.4592  loss_giou: 0.3756  loss_bbox: 0.2874  loss_ce_0: 0.4734  loss_giou_0: 0.3805  loss_bbox_0: 0.3208  loss_rpn_cls: 0.2149  loss_rpn_reg: 0.4938  time: 0.1890  last_time: 0.1686  data_time: 0.0056  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 13:16:23] d2.utils.events INFO:  eta: 1:18:04  iter: 28999  total_loss: 3.119  loss_ce: 0.4727  loss_giou: 0.3461  loss_bbox: 0.3477  loss_ce_0: 0.5433  loss_giou_0: 0.3765  loss_bbox_0: 0.3601  loss_rpn_cls: 0.2127  loss_rpn_reg: 0.5416  time: 0.1890  last_time: 0.1899  data_time: 0.0052  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 13:16:26] d2.utils.events INFO:  eta: 1:18:00  iter: 29019  total_loss: 2.929  loss_ce: 0.4791  loss_giou: 0.3333  loss_bbox: 0.3049  loss_ce_0: 0.5048  loss_giou_0: 0.366  loss_bbox_0: 0.3493  loss_rpn_cls: 0.2261  loss_rpn_reg: 0.4845  time: 0.1890  last_time: 0.1834  data_time: 0.0048  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:16:30] d2.utils.events INFO:  eta: 1:17:53  iter: 29039  total_loss: 2.834  loss_ce: 0.4153  loss_giou: 0.3265  loss_bbox: 0.2749  loss_ce_0: 0.4249  loss_giou_0: 0.3568  loss_bbox_0: 0.3123  loss_rpn_cls: 0.2376  loss_rpn_reg: 0.4348  time: 0.1890  last_time: 0.1741  data_time: 0.0052  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:16:34] d2.utils.events INFO:  eta: 1:17:47  iter: 29059  total_loss: 2.849  loss_ce: 0.4246  loss_giou: 0.3306  loss_bbox: 0.2843  loss_ce_0: 0.4445  loss_giou_0: 0.3606  loss_bbox_0: 0.2965  loss_rpn_cls: 0.2173  loss_rpn_reg: 0.4717  time: 0.1890  last_time: 0.1730  data_time: 0.0046  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:16:38] d2.utils.events INFO:  eta: 1:17:43  iter: 29079  total_loss: 3.158  loss_ce: 0.4601  loss_giou: 0.3334  loss_bbox: 0.3063  loss_ce_0: 0.482  loss_giou_0: 0.3573  loss_bbox_0: 0.3242  loss_rpn_cls: 0.2592  loss_rpn_reg: 0.5271  time: 0.1890  last_time: 0.1874  data_time: 0.0053  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:16:42] d2.utils.events INFO:  eta: 1:17:38  iter: 29099  total_loss: 2.797  loss_ce: 0.3789  loss_giou: 0.3814  loss_bbox: 0.2773  loss_ce_0: 0.3972  loss_giou_0: 0.4025  loss_bbox_0: 0.2927  loss_rpn_cls: 0.2128  loss_rpn_reg: 0.4853  time: 0.1890  last_time: 0.1978  data_time: 0.0059  last_data_time: 0.0197   lr: 5e-05  max_mem: 3029M
[03/05 13:16:46] d2.utils.events INFO:  eta: 1:17:33  iter: 29119  total_loss: 3.002  loss_ce: 0.4158  loss_giou: 0.309  loss_bbox: 0.286  loss_ce_0: 0.4555  loss_giou_0: 0.33  loss_bbox_0: 0.3052  loss_rpn_cls: 0.2236  loss_rpn_reg: 0.4722  time: 0.1890  last_time: 0.1765  data_time: 0.0053  last_data_time: 0.0032   lr: 5e-05  max_mem: 3029M
[03/05 13:16:49] d2.utils.events INFO:  eta: 1:17:38  iter: 29139  total_loss: 2.827  loss_ce: 0.3659  loss_giou: 0.3132  loss_bbox: 0.2643  loss_ce_0: 0.4343  loss_giou_0: 0.3352  loss_bbox_0: 0.2851  loss_rpn_cls: 0.2303  loss_rpn_reg: 0.4835  time: 0.1890  last_time: 0.1888  data_time: 0.0053  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:16:53] d2.utils.events INFO:  eta: 1:17:34  iter: 29159  total_loss: 3.008  loss_ce: 0.3905  loss_giou: 0.3812  loss_bbox: 0.3243  loss_ce_0: 0.4178  loss_giou_0: 0.4065  loss_bbox_0: 0.345  loss_rpn_cls: 0.247  loss_rpn_reg: 0.4951  time: 0.1890  last_time: 0.1816  data_time: 0.0057  last_data_time: 0.0107   lr: 5e-05  max_mem: 3029M
[03/05 13:16:57] d2.utils.events INFO:  eta: 1:17:32  iter: 29179  total_loss: 2.801  loss_ce: 0.4035  loss_giou: 0.2847  loss_bbox: 0.2549  loss_ce_0: 0.4742  loss_giou_0: 0.3309  loss_bbox_0: 0.2962  loss_rpn_cls: 0.2367  loss_rpn_reg: 0.4711  time: 0.1890  last_time: 0.1576  data_time: 0.0048  last_data_time: 0.0069   lr: 5e-05  max_mem: 3029M
[03/05 13:17:01] d2.utils.events INFO:  eta: 1:17:23  iter: 29199  total_loss: 2.946  loss_ce: 0.3593  loss_giou: 0.348  loss_bbox: 0.2663  loss_ce_0: 0.4161  loss_giou_0: 0.3748  loss_bbox_0: 0.2786  loss_rpn_cls: 0.2418  loss_rpn_reg: 0.4835  time: 0.1890  last_time: 0.1960  data_time: 0.0047  last_data_time: 0.0085   lr: 5e-05  max_mem: 3029M
[03/05 13:17:05] d2.utils.events INFO:  eta: 1:17:21  iter: 29219  total_loss: 3.084  loss_ce: 0.4766  loss_giou: 0.3472  loss_bbox: 0.3155  loss_ce_0: 0.4678  loss_giou_0: 0.3734  loss_bbox_0: 0.3353  loss_rpn_cls: 0.238  loss_rpn_reg: 0.4718  time: 0.1890  last_time: 0.1823  data_time: 0.0057  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:17:08] d2.utils.events INFO:  eta: 1:17:12  iter: 29239  total_loss: 2.727  loss_ce: 0.4392  loss_giou: 0.2951  loss_bbox: 0.2955  loss_ce_0: 0.4701  loss_giou_0: 0.3169  loss_bbox_0: 0.3  loss_rpn_cls: 0.1941  loss_rpn_reg: 0.4452  time: 0.1890  last_time: 0.1905  data_time: 0.0049  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:17:12] d2.utils.events INFO:  eta: 1:17:06  iter: 29259  total_loss: 2.91  loss_ce: 0.3977  loss_giou: 0.3107  loss_bbox: 0.2995  loss_ce_0: 0.435  loss_giou_0: 0.318  loss_bbox_0: 0.3251  loss_rpn_cls: 0.2187  loss_rpn_reg: 0.471  time: 0.1890  last_time: 0.1814  data_time: 0.0055  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:17:16] d2.utils.events INFO:  eta: 1:17:01  iter: 29279  total_loss: 2.775  loss_ce: 0.4253  loss_giou: 0.3361  loss_bbox: 0.2855  loss_ce_0: 0.4434  loss_giou_0: 0.3505  loss_bbox_0: 0.3105  loss_rpn_cls: 0.2456  loss_rpn_reg: 0.489  time: 0.1890  last_time: 0.1716  data_time: 0.0048  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:17:20] d2.utils.events INFO:  eta: 1:16:58  iter: 29299  total_loss: 3.03  loss_ce: 0.4282  loss_giou: 0.3289  loss_bbox: 0.3213  loss_ce_0: 0.5092  loss_giou_0: 0.3124  loss_bbox_0: 0.3671  loss_rpn_cls: 0.2417  loss_rpn_reg: 0.489  time: 0.1890  last_time: 0.2187  data_time: 0.0050  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 13:17:24] d2.utils.events INFO:  eta: 1:16:55  iter: 29319  total_loss: 2.913  loss_ce: 0.4515  loss_giou: 0.2759  loss_bbox: 0.2684  loss_ce_0: 0.4819  loss_giou_0: 0.3145  loss_bbox_0: 0.3171  loss_rpn_cls: 0.2196  loss_rpn_reg: 0.4912  time: 0.1890  last_time: 0.1840  data_time: 0.0056  last_data_time: 0.0025   lr: 5e-05  max_mem: 3029M
[03/05 13:17:28] d2.utils.events INFO:  eta: 1:17:00  iter: 29339  total_loss: 3.01  loss_ce: 0.4395  loss_giou: 0.3639  loss_bbox: 0.2917  loss_ce_0: 0.441  loss_giou_0: 0.3878  loss_bbox_0: 0.3434  loss_rpn_cls: 0.2204  loss_rpn_reg: 0.4849  time: 0.1890  last_time: 0.2001  data_time: 0.0056  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:17:31] d2.utils.events INFO:  eta: 1:16:51  iter: 29359  total_loss: 2.799  loss_ce: 0.3454  loss_giou: 0.3551  loss_bbox: 0.2972  loss_ce_0: 0.4297  loss_giou_0: 0.3433  loss_bbox_0: 0.3383  loss_rpn_cls: 0.2193  loss_rpn_reg: 0.4667  time: 0.1890  last_time: 0.1872  data_time: 0.0047  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:17:35] d2.utils.events INFO:  eta: 1:16:56  iter: 29379  total_loss: 2.653  loss_ce: 0.405  loss_giou: 0.2879  loss_bbox: 0.2555  loss_ce_0: 0.4674  loss_giou_0: 0.3407  loss_bbox_0: 0.322  loss_rpn_cls: 0.2099  loss_rpn_reg: 0.4737  time: 0.1890  last_time: 0.1890  data_time: 0.0054  last_data_time: 0.0075   lr: 5e-05  max_mem: 3029M
[03/05 13:17:39] d2.utils.events INFO:  eta: 1:16:58  iter: 29399  total_loss: 3.008  loss_ce: 0.4142  loss_giou: 0.3251  loss_bbox: 0.3002  loss_ce_0: 0.495  loss_giou_0: 0.3171  loss_bbox_0: 0.3396  loss_rpn_cls: 0.2113  loss_rpn_reg: 0.4899  time: 0.1890  last_time: 0.1667  data_time: 0.0053  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:17:43] d2.utils.events INFO:  eta: 1:17:02  iter: 29419  total_loss: 3.182  loss_ce: 0.4302  loss_giou: 0.3475  loss_bbox: 0.2877  loss_ce_0: 0.458  loss_giou_0: 0.3655  loss_bbox_0: 0.3488  loss_rpn_cls: 0.2448  loss_rpn_reg: 0.4713  time: 0.1890  last_time: 0.1934  data_time: 0.0049  last_data_time: 0.0009   lr: 5e-05  max_mem: 3029M
[03/05 13:17:47] d2.utils.events INFO:  eta: 1:16:54  iter: 29439  total_loss: 2.956  loss_ce: 0.4457  loss_giou: 0.3244  loss_bbox: 0.2765  loss_ce_0: 0.4819  loss_giou_0: 0.3614  loss_bbox_0: 0.316  loss_rpn_cls: 0.2446  loss_rpn_reg: 0.4458  time: 0.1890  last_time: 0.1877  data_time: 0.0053  last_data_time: 0.0023   lr: 5e-05  max_mem: 3029M
[03/05 13:17:51] d2.utils.events INFO:  eta: 1:16:50  iter: 29459  total_loss: 2.788  loss_ce: 0.3902  loss_giou: 0.3012  loss_bbox: 0.261  loss_ce_0: 0.4033  loss_giou_0: 0.3451  loss_bbox_0: 0.3501  loss_rpn_cls: 0.2132  loss_rpn_reg: 0.4815  time: 0.1890  last_time: 0.1929  data_time: 0.0060  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:17:55] d2.utils.events INFO:  eta: 1:16:54  iter: 29479  total_loss: 2.84  loss_ce: 0.4123  loss_giou: 0.3513  loss_bbox: 0.2762  loss_ce_0: 0.4614  loss_giou_0: 0.3754  loss_bbox_0: 0.3067  loss_rpn_cls: 0.2458  loss_rpn_reg: 0.4649  time: 0.1890  last_time: 0.1920  data_time: 0.0066  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:17:58] d2.utils.events INFO:  eta: 1:16:49  iter: 29499  total_loss: 3.085  loss_ce: 0.4397  loss_giou: 0.408  loss_bbox: 0.316  loss_ce_0: 0.441  loss_giou_0: 0.4162  loss_bbox_0: 0.3111  loss_rpn_cls: 0.2555  loss_rpn_reg: 0.4865  time: 0.1890  last_time: 0.1988  data_time: 0.0050  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 13:18:02] d2.utils.events INFO:  eta: 1:16:48  iter: 29519  total_loss: 2.901  loss_ce: 0.3876  loss_giou: 0.3191  loss_bbox: 0.2669  loss_ce_0: 0.4203  loss_giou_0: 0.3408  loss_bbox_0: 0.3107  loss_rpn_cls: 0.2394  loss_rpn_reg: 0.4801  time: 0.1890  last_time: 0.1961  data_time: 0.0048  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:18:06] d2.utils.events INFO:  eta: 1:16:45  iter: 29539  total_loss: 3.091  loss_ce: 0.448  loss_giou: 0.3586  loss_bbox: 0.3146  loss_ce_0: 0.4901  loss_giou_0: 0.3924  loss_bbox_0: 0.329  loss_rpn_cls: 0.2408  loss_rpn_reg: 0.4994  time: 0.1890  last_time: 0.1734  data_time: 0.0052  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:18:10] d2.utils.events INFO:  eta: 1:16:42  iter: 29559  total_loss: 3.061  loss_ce: 0.4229  loss_giou: 0.3395  loss_bbox: 0.3247  loss_ce_0: 0.4788  loss_giou_0: 0.3614  loss_bbox_0: 0.3377  loss_rpn_cls: 0.2367  loss_rpn_reg: 0.4855  time: 0.1890  last_time: 0.1941  data_time: 0.0053  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 13:18:14] d2.utils.events INFO:  eta: 1:16:41  iter: 29579  total_loss: 3.248  loss_ce: 0.4623  loss_giou: 0.3645  loss_bbox: 0.3308  loss_ce_0: 0.4775  loss_giou_0: 0.3825  loss_bbox_0: 0.3744  loss_rpn_cls: 0.2525  loss_rpn_reg: 0.5166  time: 0.1890  last_time: 0.1830  data_time: 0.0054  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 13:18:18] d2.utils.events INFO:  eta: 1:16:36  iter: 29599  total_loss: 3.011  loss_ce: 0.4924  loss_giou: 0.3261  loss_bbox: 0.313  loss_ce_0: 0.5258  loss_giou_0: 0.3267  loss_bbox_0: 0.3264  loss_rpn_cls: 0.2312  loss_rpn_reg: 0.4983  time: 0.1890  last_time: 0.1830  data_time: 0.0053  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 13:18:22] d2.utils.events INFO:  eta: 1:16:33  iter: 29619  total_loss: 3.378  loss_ce: 0.4241  loss_giou: 0.3539  loss_bbox: 0.3499  loss_ce_0: 0.4755  loss_giou_0: 0.3558  loss_bbox_0: 0.358  loss_rpn_cls: 0.2617  loss_rpn_reg: 0.4941  time: 0.1890  last_time: 0.2006  data_time: 0.0060  last_data_time: 0.0072   lr: 5e-05  max_mem: 3029M
[03/05 13:18:25] d2.utils.events INFO:  eta: 1:16:30  iter: 29639  total_loss: 2.909  loss_ce: 0.4396  loss_giou: 0.3248  loss_bbox: 0.2876  loss_ce_0: 0.4593  loss_giou_0: 0.3428  loss_bbox_0: 0.302  loss_rpn_cls: 0.2377  loss_rpn_reg: 0.4897  time: 0.1890  last_time: 0.2056  data_time: 0.0052  last_data_time: 0.0081   lr: 5e-05  max_mem: 3029M
[03/05 13:18:29] d2.utils.events INFO:  eta: 1:16:27  iter: 29659  total_loss: 2.889  loss_ce: 0.3753  loss_giou: 0.3557  loss_bbox: 0.3117  loss_ce_0: 0.444  loss_giou_0: 0.3598  loss_bbox_0: 0.3233  loss_rpn_cls: 0.2186  loss_rpn_reg: 0.4809  time: 0.1890  last_time: 0.1885  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:18:33] d2.utils.events INFO:  eta: 1:16:25  iter: 29679  total_loss: 2.85  loss_ce: 0.4076  loss_giou: 0.361  loss_bbox: 0.2794  loss_ce_0: 0.4588  loss_giou_0: 0.373  loss_bbox_0: 0.3105  loss_rpn_cls: 0.2233  loss_rpn_reg: 0.4545  time: 0.1890  last_time: 0.1960  data_time: 0.0054  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 13:18:37] d2.utils.events INFO:  eta: 1:16:21  iter: 29699  total_loss: 3.171  loss_ce: 0.4777  loss_giou: 0.3833  loss_bbox: 0.3206  loss_ce_0: 0.5138  loss_giou_0: 0.4016  loss_bbox_0: 0.3295  loss_rpn_cls: 0.2465  loss_rpn_reg: 0.4885  time: 0.1890  last_time: 0.1986  data_time: 0.0049  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:18:41] d2.utils.events INFO:  eta: 1:16:17  iter: 29719  total_loss: 2.901  loss_ce: 0.4364  loss_giou: 0.3378  loss_bbox: 0.2861  loss_ce_0: 0.4772  loss_giou_0: 0.3485  loss_bbox_0: 0.3204  loss_rpn_cls: 0.2149  loss_rpn_reg: 0.4844  time: 0.1890  last_time: 0.1847  data_time: 0.0053  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 13:18:44] d2.utils.events INFO:  eta: 1:16:14  iter: 29739  total_loss: 3.31  loss_ce: 0.5322  loss_giou: 0.3272  loss_bbox: 0.3471  loss_ce_0: 0.5354  loss_giou_0: 0.3688  loss_bbox_0: 0.3769  loss_rpn_cls: 0.2642  loss_rpn_reg: 0.4617  time: 0.1890  last_time: 0.1751  data_time: 0.0047  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:18:48] d2.utils.events INFO:  eta: 1:16:08  iter: 29759  total_loss: 2.881  loss_ce: 0.3826  loss_giou: 0.3407  loss_bbox: 0.3193  loss_ce_0: 0.4297  loss_giou_0: 0.3699  loss_bbox_0: 0.3518  loss_rpn_cls: 0.2301  loss_rpn_reg: 0.4883  time: 0.1890  last_time: 0.1739  data_time: 0.0053  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:18:52] d2.utils.events INFO:  eta: 1:16:06  iter: 29779  total_loss: 3.176  loss_ce: 0.4223  loss_giou: 0.3612  loss_bbox: 0.2487  loss_ce_0: 0.4543  loss_giou_0: 0.4053  loss_bbox_0: 0.291  loss_rpn_cls: 0.2287  loss_rpn_reg: 0.5108  time: 0.1890  last_time: 0.1774  data_time: 0.0046  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 13:18:56] d2.utils.events INFO:  eta: 1:16:01  iter: 29799  total_loss: 2.542  loss_ce: 0.3756  loss_giou: 0.2769  loss_bbox: 0.3072  loss_ce_0: 0.3745  loss_giou_0: 0.3028  loss_bbox_0: 0.341  loss_rpn_cls: 0.2183  loss_rpn_reg: 0.4537  time: 0.1890  last_time: 0.1949  data_time: 0.0051  last_data_time: 0.0088   lr: 5e-05  max_mem: 3029M
[03/05 13:19:00] d2.utils.events INFO:  eta: 1:15:56  iter: 29819  total_loss: 2.899  loss_ce: 0.4159  loss_giou: 0.3512  loss_bbox: 0.2533  loss_ce_0: 0.4277  loss_giou_0: 0.391  loss_bbox_0: 0.2949  loss_rpn_cls: 0.226  loss_rpn_reg: 0.5172  time: 0.1890  last_time: 0.1678  data_time: 0.0051  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:19:03] d2.utils.events INFO:  eta: 1:15:53  iter: 29839  total_loss: 2.866  loss_ce: 0.4774  loss_giou: 0.3206  loss_bbox: 0.2732  loss_ce_0: 0.5026  loss_giou_0: 0.3636  loss_bbox_0: 0.3081  loss_rpn_cls: 0.2507  loss_rpn_reg: 0.458  time: 0.1890  last_time: 0.1682  data_time: 0.0052  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:19:07] d2.utils.events INFO:  eta: 1:15:51  iter: 29859  total_loss: 2.789  loss_ce: 0.4125  loss_giou: 0.3677  loss_bbox: 0.2302  loss_ce_0: 0.411  loss_giou_0: 0.3592  loss_bbox_0: 0.2496  loss_rpn_cls: 0.2225  loss_rpn_reg: 0.4879  time: 0.1890  last_time: 0.2092  data_time: 0.0057  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:19:11] d2.utils.events INFO:  eta: 1:15:53  iter: 29879  total_loss: 2.924  loss_ce: 0.514  loss_giou: 0.3652  loss_bbox: 0.3202  loss_ce_0: 0.4993  loss_giou_0: 0.3992  loss_bbox_0: 0.3461  loss_rpn_cls: 0.291  loss_rpn_reg: 0.4867  time: 0.1890  last_time: 0.2233  data_time: 0.0055  last_data_time: 0.0081   lr: 5e-05  max_mem: 3029M
[03/05 13:19:15] d2.utils.events INFO:  eta: 1:15:49  iter: 29899  total_loss: 3.178  loss_ce: 0.4579  loss_giou: 0.2829  loss_bbox: 0.3457  loss_ce_0: 0.4773  loss_giou_0: 0.3007  loss_bbox_0: 0.3551  loss_rpn_cls: 0.2437  loss_rpn_reg: 0.4927  time: 0.1890  last_time: 0.1979  data_time: 0.0050  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 13:19:19] d2.utils.events INFO:  eta: 1:15:47  iter: 29919  total_loss: 3.042  loss_ce: 0.4749  loss_giou: 0.311  loss_bbox: 0.3074  loss_ce_0: 0.5193  loss_giou_0: 0.3311  loss_bbox_0: 0.3397  loss_rpn_cls: 0.2475  loss_rpn_reg: 0.4876  time: 0.1890  last_time: 0.1740  data_time: 0.0046  last_data_time: 0.0028   lr: 5e-05  max_mem: 3029M
[03/05 13:19:23] d2.utils.events INFO:  eta: 1:15:44  iter: 29939  total_loss: 2.853  loss_ce: 0.427  loss_giou: 0.3418  loss_bbox: 0.2575  loss_ce_0: 0.4379  loss_giou_0: 0.3588  loss_bbox_0: 0.2788  loss_rpn_cls: 0.2441  loss_rpn_reg: 0.4668  time: 0.1890  last_time: 0.1784  data_time: 0.0060  last_data_time: 0.0075   lr: 5e-05  max_mem: 3029M
[03/05 13:19:27] d2.utils.events INFO:  eta: 1:15:38  iter: 29959  total_loss: 3.148  loss_ce: 0.437  loss_giou: 0.3279  loss_bbox: 0.2742  loss_ce_0: 0.5083  loss_giou_0: 0.3535  loss_bbox_0: 0.3021  loss_rpn_cls: 0.2455  loss_rpn_reg: 0.467  time: 0.1890  last_time: 0.2006  data_time: 0.0054  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 13:19:31] d2.utils.events INFO:  eta: 1:15:31  iter: 29979  total_loss: 2.76  loss_ce: 0.3815  loss_giou: 0.3161  loss_bbox: 0.2257  loss_ce_0: 0.4037  loss_giou_0: 0.3345  loss_bbox_0: 0.2873  loss_rpn_cls: 0.2326  loss_rpn_reg: 0.42  time: 0.1890  last_time: 0.2164  data_time: 0.0056  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:19:35] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/t1/model_0029999.pth
[03/05 13:19:36] d2.utils.events INFO:  eta: 1:15:29  iter: 29999  total_loss: 2.716  loss_ce: 0.3542  loss_giou: 0.2856  loss_bbox: 0.2818  loss_ce_0: 0.4595  loss_giou_0: 0.3012  loss_bbox_0: 0.3115  loss_rpn_cls: 0.2285  loss_rpn_reg: 0.4359  time: 0.1890  last_time: 0.1999  data_time: 0.0049  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 13:19:40] d2.utils.events INFO:  eta: 1:15:25  iter: 30019  total_loss: 3.249  loss_ce: 0.4268  loss_giou: 0.3601  loss_bbox: 0.3365  loss_ce_0: 0.4959  loss_giou_0: 0.4011  loss_bbox_0: 0.3569  loss_rpn_cls: 0.2942  loss_rpn_reg: 0.5173  time: 0.1890  last_time: 0.1750  data_time: 0.0050  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:19:43] d2.utils.events INFO:  eta: 1:15:17  iter: 30039  total_loss: 3.057  loss_ce: 0.4823  loss_giou: 0.3421  loss_bbox: 0.2835  loss_ce_0: 0.5123  loss_giou_0: 0.3677  loss_bbox_0: 0.3433  loss_rpn_cls: 0.2524  loss_rpn_reg: 0.4958  time: 0.1890  last_time: 0.2220  data_time: 0.0051  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:19:47] d2.utils.events INFO:  eta: 1:15:11  iter: 30059  total_loss: 3.097  loss_ce: 0.4679  loss_giou: 0.349  loss_bbox: 0.2948  loss_ce_0: 0.4968  loss_giou_0: 0.3323  loss_bbox_0: 0.3269  loss_rpn_cls: 0.2457  loss_rpn_reg: 0.4614  time: 0.1890  last_time: 0.1753  data_time: 0.0048  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:19:51] d2.utils.events INFO:  eta: 1:15:05  iter: 30079  total_loss: 3.176  loss_ce: 0.4817  loss_giou: 0.3134  loss_bbox: 0.3577  loss_ce_0: 0.4799  loss_giou_0: 0.3367  loss_bbox_0: 0.3835  loss_rpn_cls: 0.2542  loss_rpn_reg: 0.472  time: 0.1890  last_time: 0.1925  data_time: 0.0063  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:19:55] d2.utils.events INFO:  eta: 1:15:01  iter: 30099  total_loss: 3.031  loss_ce: 0.4999  loss_giou: 0.2835  loss_bbox: 0.2784  loss_ce_0: 0.5102  loss_giou_0: 0.3223  loss_bbox_0: 0.2975  loss_rpn_cls: 0.2462  loss_rpn_reg: 0.4817  time: 0.1890  last_time: 0.1845  data_time: 0.0050  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:19:58] d2.utils.events INFO:  eta: 1:14:59  iter: 30119  total_loss: 2.805  loss_ce: 0.4531  loss_giou: 0.3202  loss_bbox: 0.2872  loss_ce_0: 0.5105  loss_giou_0: 0.3326  loss_bbox_0: 0.3255  loss_rpn_cls: 0.2455  loss_rpn_reg: 0.4672  time: 0.1890  last_time: 0.1849  data_time: 0.0056  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:20:02] d2.utils.events INFO:  eta: 1:14:53  iter: 30139  total_loss: 2.972  loss_ce: 0.4291  loss_giou: 0.3218  loss_bbox: 0.2885  loss_ce_0: 0.4992  loss_giou_0: 0.3266  loss_bbox_0: 0.3294  loss_rpn_cls: 0.2392  loss_rpn_reg: 0.5047  time: 0.1890  last_time: 0.1825  data_time: 0.0054  last_data_time: 0.0028   lr: 5e-05  max_mem: 3029M
[03/05 13:20:06] d2.utils.events INFO:  eta: 1:14:47  iter: 30159  total_loss: 3.283  loss_ce: 0.5398  loss_giou: 0.3774  loss_bbox: 0.3611  loss_ce_0: 0.5848  loss_giou_0: 0.385  loss_bbox_0: 0.4144  loss_rpn_cls: 0.286  loss_rpn_reg: 0.4924  time: 0.1890  last_time: 0.2037  data_time: 0.0051  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:20:10] d2.utils.events INFO:  eta: 1:14:44  iter: 30179  total_loss: 3.133  loss_ce: 0.4279  loss_giou: 0.3531  loss_bbox: 0.271  loss_ce_0: 0.4943  loss_giou_0: 0.362  loss_bbox_0: 0.2844  loss_rpn_cls: 0.2533  loss_rpn_reg: 0.491  time: 0.1890  last_time: 0.1832  data_time: 0.0055  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:20:14] d2.utils.events INFO:  eta: 1:14:43  iter: 30199  total_loss: 3.07  loss_ce: 0.3752  loss_giou: 0.3789  loss_bbox: 0.3313  loss_ce_0: 0.4304  loss_giou_0: 0.3903  loss_bbox_0: 0.2935  loss_rpn_cls: 0.2461  loss_rpn_reg: 0.4868  time: 0.1890  last_time: 0.2575  data_time: 0.0053  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 13:20:18] d2.utils.events INFO:  eta: 1:14:38  iter: 30219  total_loss: 2.932  loss_ce: 0.4982  loss_giou: 0.3257  loss_bbox: 0.2887  loss_ce_0: 0.4764  loss_giou_0: 0.3417  loss_bbox_0: 0.3394  loss_rpn_cls: 0.2668  loss_rpn_reg: 0.4765  time: 0.1890  last_time: 0.1789  data_time: 0.0056  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 13:20:22] d2.utils.events INFO:  eta: 1:14:37  iter: 30239  total_loss: 3.332  loss_ce: 0.5024  loss_giou: 0.4184  loss_bbox: 0.325  loss_ce_0: 0.5217  loss_giou_0: 0.4432  loss_bbox_0: 0.3251  loss_rpn_cls: 0.2697  loss_rpn_reg: 0.5174  time: 0.1890  last_time: 0.1919  data_time: 0.0047  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:20:26] d2.utils.events INFO:  eta: 1:14:33  iter: 30259  total_loss: 3.033  loss_ce: 0.4323  loss_giou: 0.3336  loss_bbox: 0.3117  loss_ce_0: 0.449  loss_giou_0: 0.338  loss_bbox_0: 0.3304  loss_rpn_cls: 0.2419  loss_rpn_reg: 0.4736  time: 0.1890  last_time: 0.1764  data_time: 0.0051  last_data_time: 0.0030   lr: 5e-05  max_mem: 3029M
[03/05 13:20:29] d2.utils.events INFO:  eta: 1:14:29  iter: 30279  total_loss: 3.192  loss_ce: 0.47  loss_giou: 0.362  loss_bbox: 0.3597  loss_ce_0: 0.5335  loss_giou_0: 0.3862  loss_bbox_0: 0.4043  loss_rpn_cls: 0.2691  loss_rpn_reg: 0.5007  time: 0.1890  last_time: 0.2030  data_time: 0.0052  last_data_time: 0.0079   lr: 5e-05  max_mem: 3029M
[03/05 13:20:33] d2.utils.events INFO:  eta: 1:14:27  iter: 30299  total_loss: 3.152  loss_ce: 0.4504  loss_giou: 0.3709  loss_bbox: 0.2804  loss_ce_0: 0.4986  loss_giou_0: 0.3882  loss_bbox_0: 0.3421  loss_rpn_cls: 0.2472  loss_rpn_reg: 0.4973  time: 0.1890  last_time: 0.1718  data_time: 0.0053  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:20:37] d2.utils.events INFO:  eta: 1:14:23  iter: 30319  total_loss: 3.206  loss_ce: 0.4222  loss_giou: 0.354  loss_bbox: 0.2945  loss_ce_0: 0.494  loss_giou_0: 0.3854  loss_bbox_0: 0.3484  loss_rpn_cls: 0.2196  loss_rpn_reg: 0.4803  time: 0.1890  last_time: 0.1735  data_time: 0.0055  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:20:41] d2.utils.events INFO:  eta: 1:14:16  iter: 30339  total_loss: 3.034  loss_ce: 0.4574  loss_giou: 0.3137  loss_bbox: 0.3262  loss_ce_0: 0.4637  loss_giou_0: 0.3191  loss_bbox_0: 0.3072  loss_rpn_cls: 0.2098  loss_rpn_reg: 0.4905  time: 0.1890  last_time: 0.1717  data_time: 0.0058  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 13:20:45] d2.utils.events INFO:  eta: 1:14:13  iter: 30359  total_loss: 2.773  loss_ce: 0.4113  loss_giou: 0.3546  loss_bbox: 0.2468  loss_ce_0: 0.4455  loss_giou_0: 0.3626  loss_bbox_0: 0.2954  loss_rpn_cls: 0.2584  loss_rpn_reg: 0.4837  time: 0.1890  last_time: 0.1801  data_time: 0.0057  last_data_time: 0.0070   lr: 5e-05  max_mem: 3029M
[03/05 13:20:49] d2.utils.events INFO:  eta: 1:14:10  iter: 30379  total_loss: 3.1  loss_ce: 0.4339  loss_giou: 0.3574  loss_bbox: 0.2742  loss_ce_0: 0.4871  loss_giou_0: 0.3879  loss_bbox_0: 0.3065  loss_rpn_cls: 0.2808  loss_rpn_reg: 0.5062  time: 0.1890  last_time: 0.1833  data_time: 0.0051  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:20:52] d2.utils.events INFO:  eta: 1:14:05  iter: 30399  total_loss: 2.878  loss_ce: 0.4125  loss_giou: 0.3656  loss_bbox: 0.3216  loss_ce_0: 0.4454  loss_giou_0: 0.3653  loss_bbox_0: 0.3682  loss_rpn_cls: 0.2376  loss_rpn_reg: 0.4422  time: 0.1890  last_time: 0.1821  data_time: 0.0047  last_data_time: 0.0023   lr: 5e-05  max_mem: 3029M
[03/05 13:20:56] d2.utils.events INFO:  eta: 1:14:03  iter: 30419  total_loss: 2.933  loss_ce: 0.4099  loss_giou: 0.3759  loss_bbox: 0.2662  loss_ce_0: 0.4607  loss_giou_0: 0.4053  loss_bbox_0: 0.2735  loss_rpn_cls: 0.2316  loss_rpn_reg: 0.4904  time: 0.1890  last_time: 0.1981  data_time: 0.0055  last_data_time: 0.0101   lr: 5e-05  max_mem: 3029M
[03/05 13:21:00] d2.utils.events INFO:  eta: 1:14:02  iter: 30439  total_loss: 3.164  loss_ce: 0.506  loss_giou: 0.3334  loss_bbox: 0.2899  loss_ce_0: 0.5483  loss_giou_0: 0.369  loss_bbox_0: 0.3289  loss_rpn_cls: 0.2817  loss_rpn_reg: 0.5142  time: 0.1890  last_time: 0.2044  data_time: 0.0056  last_data_time: 0.0034   lr: 5e-05  max_mem: 3029M
[03/05 13:21:04] d2.utils.events INFO:  eta: 1:14:00  iter: 30459  total_loss: 2.92  loss_ce: 0.4395  loss_giou: 0.3433  loss_bbox: 0.302  loss_ce_0: 0.4781  loss_giou_0: 0.3763  loss_bbox_0: 0.2839  loss_rpn_cls: 0.257  loss_rpn_reg: 0.482  time: 0.1890  last_time: 0.1940  data_time: 0.0061  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 13:21:08] d2.utils.events INFO:  eta: 1:13:54  iter: 30479  total_loss: 2.917  loss_ce: 0.4307  loss_giou: 0.3271  loss_bbox: 0.2785  loss_ce_0: 0.4678  loss_giou_0: 0.335  loss_bbox_0: 0.2753  loss_rpn_cls: 0.2025  loss_rpn_reg: 0.5017  time: 0.1890  last_time: 0.2043  data_time: 0.0059  last_data_time: 0.0029   lr: 5e-05  max_mem: 3029M
[03/05 13:21:12] d2.utils.events INFO:  eta: 1:13:51  iter: 30499  total_loss: 2.858  loss_ce: 0.4059  loss_giou: 0.2851  loss_bbox: 0.3177  loss_ce_0: 0.4729  loss_giou_0: 0.3157  loss_bbox_0: 0.3388  loss_rpn_cls: 0.2438  loss_rpn_reg: 0.4751  time: 0.1890  last_time: 0.1841  data_time: 0.0048  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 13:21:16] d2.utils.events INFO:  eta: 1:13:53  iter: 30519  total_loss: 2.862  loss_ce: 0.3849  loss_giou: 0.2875  loss_bbox: 0.3241  loss_ce_0: 0.4054  loss_giou_0: 0.315  loss_bbox_0: 0.3231  loss_rpn_cls: 0.2461  loss_rpn_reg: 0.4648  time: 0.1890  last_time: 0.2098  data_time: 0.0054  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 13:21:20] d2.utils.events INFO:  eta: 1:13:56  iter: 30539  total_loss: 2.843  loss_ce: 0.416  loss_giou: 0.3548  loss_bbox: 0.2958  loss_ce_0: 0.4156  loss_giou_0: 0.3855  loss_bbox_0: 0.3275  loss_rpn_cls: 0.2123  loss_rpn_reg: 0.4993  time: 0.1890  last_time: 0.2225  data_time: 0.0063  last_data_time: 0.0100   lr: 5e-05  max_mem: 3029M
[03/05 13:21:24] d2.utils.events INFO:  eta: 1:13:47  iter: 30559  total_loss: 3.099  loss_ce: 0.4525  loss_giou: 0.4037  loss_bbox: 0.3364  loss_ce_0: 0.4836  loss_giou_0: 0.4436  loss_bbox_0: 0.3633  loss_rpn_cls: 0.2355  loss_rpn_reg: 0.517  time: 0.1890  last_time: 0.1751  data_time: 0.0056  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:21:28] d2.utils.events INFO:  eta: 1:13:43  iter: 30579  total_loss: 3.373  loss_ce: 0.4458  loss_giou: 0.3476  loss_bbox: 0.3553  loss_ce_0: 0.4781  loss_giou_0: 0.3836  loss_bbox_0: 0.3634  loss_rpn_cls: 0.2475  loss_rpn_reg: 0.5086  time: 0.1890  last_time: 0.1884  data_time: 0.0059  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 13:21:32] d2.utils.events INFO:  eta: 1:13:44  iter: 30599  total_loss: 3.007  loss_ce: 0.4565  loss_giou: 0.3397  loss_bbox: 0.2553  loss_ce_0: 0.4839  loss_giou_0: 0.3639  loss_bbox_0: 0.3287  loss_rpn_cls: 0.2637  loss_rpn_reg: 0.4739  time: 0.1890  last_time: 0.2049  data_time: 0.0050  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 13:21:36] d2.utils.events INFO:  eta: 1:13:46  iter: 30619  total_loss: 2.656  loss_ce: 0.38  loss_giou: 0.3112  loss_bbox: 0.264  loss_ce_0: 0.4151  loss_giou_0: 0.3256  loss_bbox_0: 0.2756  loss_rpn_cls: 0.2018  loss_rpn_reg: 0.4506  time: 0.1890  last_time: 0.1975  data_time: 0.0053  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:21:40] d2.utils.events INFO:  eta: 1:13:43  iter: 30639  total_loss: 3.054  loss_ce: 0.4437  loss_giou: 0.3774  loss_bbox: 0.2718  loss_ce_0: 0.4726  loss_giou_0: 0.3836  loss_bbox_0: 0.2985  loss_rpn_cls: 0.2416  loss_rpn_reg: 0.4972  time: 0.1890  last_time: 0.1928  data_time: 0.0050  last_data_time: 0.0064   lr: 5e-05  max_mem: 3029M
[03/05 13:21:43] d2.utils.events INFO:  eta: 1:13:49  iter: 30659  total_loss: 3.145  loss_ce: 0.4545  loss_giou: 0.3433  loss_bbox: 0.3401  loss_ce_0: 0.4982  loss_giou_0: 0.3611  loss_bbox_0: 0.3465  loss_rpn_cls: 0.2452  loss_rpn_reg: 0.4892  time: 0.1890  last_time: 0.1775  data_time: 0.0053  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 13:21:47] d2.utils.events INFO:  eta: 1:13:46  iter: 30679  total_loss: 3.111  loss_ce: 0.4424  loss_giou: 0.3521  loss_bbox: 0.2733  loss_ce_0: 0.4989  loss_giou_0: 0.3598  loss_bbox_0: 0.2886  loss_rpn_cls: 0.2561  loss_rpn_reg: 0.5117  time: 0.1890  last_time: 0.1683  data_time: 0.0048  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 13:21:52] d2.utils.events INFO:  eta: 1:13:43  iter: 30699  total_loss: 2.948  loss_ce: 0.4389  loss_giou: 0.3151  loss_bbox: 0.2748  loss_ce_0: 0.4505  loss_giou_0: 0.3597  loss_bbox_0: 0.3065  loss_rpn_cls: 0.2212  loss_rpn_reg: 0.4633  time: 0.1890  last_time: 0.2024  data_time: 0.0054  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 13:21:55] d2.utils.events INFO:  eta: 1:13:38  iter: 30719  total_loss: 2.896  loss_ce: 0.4341  loss_giou: 0.3414  loss_bbox: 0.249  loss_ce_0: 0.4722  loss_giou_0: 0.3502  loss_bbox_0: 0.2844  loss_rpn_cls: 0.2372  loss_rpn_reg: 0.4655  time: 0.1890  last_time: 0.1789  data_time: 0.0049  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:21:59] d2.utils.events INFO:  eta: 1:13:34  iter: 30739  total_loss: 3.152  loss_ce: 0.4952  loss_giou: 0.3491  loss_bbox: 0.3192  loss_ce_0: 0.4877  loss_giou_0: 0.3802  loss_bbox_0: 0.3848  loss_rpn_cls: 0.2317  loss_rpn_reg: 0.4937  time: 0.1890  last_time: 0.1801  data_time: 0.0047  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 13:22:03] d2.utils.events INFO:  eta: 1:13:32  iter: 30759  total_loss: 2.766  loss_ce: 0.3879  loss_giou: 0.3545  loss_bbox: 0.2951  loss_ce_0: 0.4148  loss_giou_0: 0.3673  loss_bbox_0: 0.3145  loss_rpn_cls: 0.2187  loss_rpn_reg: 0.4672  time: 0.1890  last_time: 0.1775  data_time: 0.0063  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:22:07] d2.utils.events INFO:  eta: 1:13:29  iter: 30779  total_loss: 3.089  loss_ce: 0.4001  loss_giou: 0.303  loss_bbox: 0.3114  loss_ce_0: 0.4412  loss_giou_0: 0.34  loss_bbox_0: 0.383  loss_rpn_cls: 0.2536  loss_rpn_reg: 0.4854  time: 0.1890  last_time: 0.1932  data_time: 0.0068  last_data_time: 0.0077   lr: 5e-05  max_mem: 3029M
[03/05 13:22:11] d2.utils.events INFO:  eta: 1:13:23  iter: 30799  total_loss: 2.864  loss_ce: 0.41  loss_giou: 0.28  loss_bbox: 0.2844  loss_ce_0: 0.4431  loss_giou_0: 0.3229  loss_bbox_0: 0.3218  loss_rpn_cls: 0.2337  loss_rpn_reg: 0.4483  time: 0.1890  last_time: 0.1773  data_time: 0.0048  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 13:22:14] d2.utils.events INFO:  eta: 1:13:19  iter: 30819  total_loss: 3.022  loss_ce: 0.4893  loss_giou: 0.3348  loss_bbox: 0.292  loss_ce_0: 0.49  loss_giou_0: 0.3595  loss_bbox_0: 0.3033  loss_rpn_cls: 0.2478  loss_rpn_reg: 0.472  time: 0.1890  last_time: 0.1784  data_time: 0.0056  last_data_time: 0.0070   lr: 5e-05  max_mem: 3029M
[03/05 13:22:18] d2.utils.events INFO:  eta: 1:13:19  iter: 30839  total_loss: 3.024  loss_ce: 0.4944  loss_giou: 0.2959  loss_bbox: 0.2892  loss_ce_0: 0.4871  loss_giou_0: 0.3294  loss_bbox_0: 0.3433  loss_rpn_cls: 0.2277  loss_rpn_reg: 0.4445  time: 0.1890  last_time: 0.2102  data_time: 0.0050  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 13:22:22] d2.utils.events INFO:  eta: 1:13:10  iter: 30859  total_loss: 2.876  loss_ce: 0.4429  loss_giou: 0.3409  loss_bbox: 0.2859  loss_ce_0: 0.4718  loss_giou_0: 0.3732  loss_bbox_0: 0.3224  loss_rpn_cls: 0.244  loss_rpn_reg: 0.4828  time: 0.1890  last_time: 0.1836  data_time: 0.0047  last_data_time: 0.0024   lr: 5e-05  max_mem: 3029M
[03/05 13:22:26] d2.utils.events INFO:  eta: 1:13:02  iter: 30879  total_loss: 3.226  loss_ce: 0.514  loss_giou: 0.3742  loss_bbox: 0.2877  loss_ce_0: 0.528  loss_giou_0: 0.3858  loss_bbox_0: 0.3224  loss_rpn_cls: 0.2628  loss_rpn_reg: 0.5169  time: 0.1890  last_time: 0.1988  data_time: 0.0053  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:22:30] d2.utils.events INFO:  eta: 1:12:58  iter: 30899  total_loss: 3.329  loss_ce: 0.4329  loss_giou: 0.4065  loss_bbox: 0.351  loss_ce_0: 0.4636  loss_giou_0: 0.4545  loss_bbox_0: 0.387  loss_rpn_cls: 0.2397  loss_rpn_reg: 0.5217  time: 0.1890  last_time: 0.2069  data_time: 0.0057  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:22:34] d2.utils.events INFO:  eta: 1:12:51  iter: 30919  total_loss: 3.046  loss_ce: 0.4119  loss_giou: 0.3248  loss_bbox: 0.3126  loss_ce_0: 0.4741  loss_giou_0: 0.3663  loss_bbox_0: 0.355  loss_rpn_cls: 0.2612  loss_rpn_reg: 0.5101  time: 0.1890  last_time: 0.2062  data_time: 0.0052  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 13:22:38] d2.utils.events INFO:  eta: 1:12:44  iter: 30939  total_loss: 2.982  loss_ce: 0.4103  loss_giou: 0.3365  loss_bbox: 0.3114  loss_ce_0: 0.4657  loss_giou_0: 0.3644  loss_bbox_0: 0.3448  loss_rpn_cls: 0.2286  loss_rpn_reg: 0.4868  time: 0.1890  last_time: 0.1981  data_time: 0.0055  last_data_time: 0.0022   lr: 5e-05  max_mem: 3029M
[03/05 13:22:41] d2.utils.events INFO:  eta: 1:12:41  iter: 30959  total_loss: 3.126  loss_ce: 0.4865  loss_giou: 0.4031  loss_bbox: 0.3348  loss_ce_0: 0.5014  loss_giou_0: 0.4131  loss_bbox_0: 0.3437  loss_rpn_cls: 0.2274  loss_rpn_reg: 0.5209  time: 0.1890  last_time: 0.1946  data_time: 0.0050  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 13:22:45] d2.utils.events INFO:  eta: 1:12:34  iter: 30979  total_loss: 3.044  loss_ce: 0.5114  loss_giou: 0.3354  loss_bbox: 0.3157  loss_ce_0: 0.5671  loss_giou_0: 0.377  loss_bbox_0: 0.3195  loss_rpn_cls: 0.2369  loss_rpn_reg: 0.4937  time: 0.1890  last_time: 0.1968  data_time: 0.0046  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 13:22:49] d2.utils.events INFO:  eta: 1:12:26  iter: 30999  total_loss: 2.892  loss_ce: 0.3719  loss_giou: 0.3689  loss_bbox: 0.2897  loss_ce_0: 0.4287  loss_giou_0: 0.3873  loss_bbox_0: 0.3036  loss_rpn_cls: 0.2252  loss_rpn_reg: 0.4746  time: 0.1890  last_time: 0.1815  data_time: 0.0047  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 13:22:53] d2.utils.events INFO:  eta: 1:12:25  iter: 31019  total_loss: 3.057  loss_ce: 0.4514  loss_giou: 0.3837  loss_bbox: 0.314  loss_ce_0: 0.4654  loss_giou_0: 0.3809  loss_bbox_0: 0.3456  loss_rpn_cls: 0.2594  loss_rpn_reg: 0.4814  time: 0.1890  last_time: 0.1914  data_time: 0.0052  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 13:22:56] d2.utils.events INFO:  eta: 1:12:25  iter: 31039  total_loss: 3.047  loss_ce: 0.4584  loss_giou: 0.3263  loss_bbox: 0.3005  loss_ce_0: 0.4953  loss_giou_0: 0.3518  loss_bbox_0: 0.3261  loss_rpn_cls: 0.2453  loss_rpn_reg: 0.4715  time: 0.1890  last_time: 0.1995  data_time: 0.0052  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:23:00] d2.utils.events INFO:  eta: 1:12:28  iter: 31059  total_loss: 3.098  loss_ce: 0.4169  loss_giou: 0.4319  loss_bbox: 0.2728  loss_ce_0: 0.4678  loss_giou_0: 0.4491  loss_bbox_0: 0.281  loss_rpn_cls: 0.2518  loss_rpn_reg: 0.5504  time: 0.1890  last_time: 0.1923  data_time: 0.0047  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:23:04] d2.utils.events INFO:  eta: 1:12:28  iter: 31079  total_loss: 2.757  loss_ce: 0.4478  loss_giou: 0.3545  loss_bbox: 0.2972  loss_ce_0: 0.4801  loss_giou_0: 0.3663  loss_bbox_0: 0.3219  loss_rpn_cls: 0.2204  loss_rpn_reg: 0.4707  time: 0.1890  last_time: 0.1830  data_time: 0.0048  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:23:08] d2.utils.events INFO:  eta: 1:12:24  iter: 31099  total_loss: 2.902  loss_ce: 0.4067  loss_giou: 0.3331  loss_bbox: 0.2779  loss_ce_0: 0.4393  loss_giou_0: 0.3676  loss_bbox_0: 0.2964  loss_rpn_cls: 0.2682  loss_rpn_reg: 0.4705  time: 0.1890  last_time: 0.1835  data_time: 0.0049  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 13:23:12] d2.utils.events INFO:  eta: 1:12:21  iter: 31119  total_loss: 3.254  loss_ce: 0.5087  loss_giou: 0.341  loss_bbox: 0.3219  loss_ce_0: 0.5434  loss_giou_0: 0.3713  loss_bbox_0: 0.3404  loss_rpn_cls: 0.2526  loss_rpn_reg: 0.5141  time: 0.1890  last_time: 0.1921  data_time: 0.0050  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 13:23:15] d2.utils.events INFO:  eta: 1:12:17  iter: 31139  total_loss: 3.222  loss_ce: 0.4553  loss_giou: 0.322  loss_bbox: 0.3584  loss_ce_0: 0.4696  loss_giou_0: 0.3739  loss_bbox_0: 0.3984  loss_rpn_cls: 0.2589  loss_rpn_reg: 0.4777  time: 0.1890  last_time: 0.1797  data_time: 0.0052  last_data_time: 0.0074   lr: 5e-05  max_mem: 3029M
[03/05 13:23:19] d2.utils.events INFO:  eta: 1:12:14  iter: 31159  total_loss: 3.048  loss_ce: 0.3976  loss_giou: 0.3372  loss_bbox: 0.2788  loss_ce_0: 0.4467  loss_giou_0: 0.3737  loss_bbox_0: 0.3009  loss_rpn_cls: 0.252  loss_rpn_reg: 0.4732  time: 0.1890  last_time: 0.2073  data_time: 0.0054  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 13:23:23] d2.utils.events INFO:  eta: 1:12:10  iter: 31179  total_loss: 2.919  loss_ce: 0.456  loss_giou: 0.3307  loss_bbox: 0.2653  loss_ce_0: 0.4535  loss_giou_0: 0.3689  loss_bbox_0: 0.3  loss_rpn_cls: 0.232  loss_rpn_reg: 0.5165  time: 0.1890  last_time: 0.1841  data_time: 0.0054  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:23:27] d2.utils.events INFO:  eta: 1:12:07  iter: 31199  total_loss: 3.084  loss_ce: 0.451  loss_giou: 0.3397  loss_bbox: 0.2703  loss_ce_0: 0.4677  loss_giou_0: 0.3764  loss_bbox_0: 0.2951  loss_rpn_cls: 0.2456  loss_rpn_reg: 0.4986  time: 0.1890  last_time: 0.1545  data_time: 0.0070  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 13:23:31] d2.utils.events INFO:  eta: 1:12:03  iter: 31219  total_loss: 3.285  loss_ce: 0.4877  loss_giou: 0.3368  loss_bbox: 0.3167  loss_ce_0: 0.4894  loss_giou_0: 0.3652  loss_bbox_0: 0.3614  loss_rpn_cls: 0.2519  loss_rpn_reg: 0.4736  time: 0.1890  last_time: 0.1720  data_time: 0.0053  last_data_time: 0.0073   lr: 5e-05  max_mem: 3029M
[03/05 13:23:35] d2.utils.events INFO:  eta: 1:11:58  iter: 31239  total_loss: 2.571  loss_ce: 0.3705  loss_giou: 0.289  loss_bbox: 0.2739  loss_ce_0: 0.4296  loss_giou_0: 0.3102  loss_bbox_0: 0.3022  loss_rpn_cls: 0.2005  loss_rpn_reg: 0.4775  time: 0.1890  last_time: 0.1944  data_time: 0.0052  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 13:23:38] d2.utils.events INFO:  eta: 1:11:55  iter: 31259  total_loss: 2.679  loss_ce: 0.3875  loss_giou: 0.3057  loss_bbox: 0.2509  loss_ce_0: 0.4254  loss_giou_0: 0.3218  loss_bbox_0: 0.2643  loss_rpn_cls: 0.2163  loss_rpn_reg: 0.4582  time: 0.1890  last_time: 0.1720  data_time: 0.0051  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 13:23:42] d2.utils.events INFO:  eta: 1:11:51  iter: 31279  total_loss: 3.003  loss_ce: 0.4446  loss_giou: 0.3627  loss_bbox: 0.2987  loss_ce_0: 0.4739  loss_giou_0: 0.3819  loss_bbox_0: 0.3372  loss_rpn_cls: 0.2341  loss_rpn_reg: 0.5151  time: 0.1890  last_time: 0.1773  data_time: 0.0055  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:23:46] d2.utils.events INFO:  eta: 1:11:47  iter: 31299  total_loss: 2.978  loss_ce: 0.4252  loss_giou: 0.3684  loss_bbox: 0.3125  loss_ce_0: 0.4458  loss_giou_0: 0.4012  loss_bbox_0: 0.3541  loss_rpn_cls: 0.2421  loss_rpn_reg: 0.4964  time: 0.1890  last_time: 0.2015  data_time: 0.0051  last_data_time: 0.0086   lr: 5e-05  max_mem: 3029M
[03/05 13:23:50] d2.utils.events INFO:  eta: 1:11:49  iter: 31319  total_loss: 2.908  loss_ce: 0.4415  loss_giou: 0.3427  loss_bbox: 0.2752  loss_ce_0: 0.4566  loss_giou_0: 0.3552  loss_bbox_0: 0.2773  loss_rpn_cls: 0.2189  loss_rpn_reg: 0.4827  time: 0.1890  last_time: 0.1774  data_time: 0.0054  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:23:54] d2.utils.events INFO:  eta: 1:11:48  iter: 31339  total_loss: 2.861  loss_ce: 0.4294  loss_giou: 0.3075  loss_bbox: 0.2892  loss_ce_0: 0.4439  loss_giou_0: 0.3384  loss_bbox_0: 0.3525  loss_rpn_cls: 0.2406  loss_rpn_reg: 0.4614  time: 0.1890  last_time: 0.1912  data_time: 0.0056  last_data_time: 0.0077   lr: 5e-05  max_mem: 3029M
[03/05 13:23:58] d2.utils.events INFO:  eta: 1:11:45  iter: 31359  total_loss: 2.729  loss_ce: 0.43  loss_giou: 0.3127  loss_bbox: 0.2365  loss_ce_0: 0.4317  loss_giou_0: 0.3312  loss_bbox_0: 0.2919  loss_rpn_cls: 0.2152  loss_rpn_reg: 0.4745  time: 0.1890  last_time: 0.1860  data_time: 0.0048  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:24:02] d2.utils.events INFO:  eta: 1:11:35  iter: 31379  total_loss: 3.423  loss_ce: 0.5616  loss_giou: 0.4297  loss_bbox: 0.3383  loss_ce_0: 0.556  loss_giou_0: 0.4719  loss_bbox_0: 0.3845  loss_rpn_cls: 0.3009  loss_rpn_reg: 0.4923  time: 0.1890  last_time: 0.1839  data_time: 0.0055  last_data_time: 0.0025   lr: 5e-05  max_mem: 3029M
[03/05 13:24:05] d2.utils.events INFO:  eta: 1:11:31  iter: 31399  total_loss: 2.863  loss_ce: 0.4634  loss_giou: 0.3041  loss_bbox: 0.2923  loss_ce_0: 0.4778  loss_giou_0: 0.3144  loss_bbox_0: 0.3161  loss_rpn_cls: 0.2429  loss_rpn_reg: 0.4811  time: 0.1890  last_time: 0.1639  data_time: 0.0049  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 13:24:09] d2.utils.events INFO:  eta: 1:11:27  iter: 31419  total_loss: 3.1  loss_ce: 0.4972  loss_giou: 0.3291  loss_bbox: 0.3151  loss_ce_0: 0.4952  loss_giou_0: 0.3557  loss_bbox_0: 0.3618  loss_rpn_cls: 0.257  loss_rpn_reg: 0.4828  time: 0.1890  last_time: 0.1978  data_time: 0.0054  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:24:13] d2.utils.events INFO:  eta: 1:11:22  iter: 31439  total_loss: 3.251  loss_ce: 0.4817  loss_giou: 0.3521  loss_bbox: 0.2875  loss_ce_0: 0.468  loss_giou_0: 0.3847  loss_bbox_0: 0.3664  loss_rpn_cls: 0.2294  loss_rpn_reg: 0.4828  time: 0.1890  last_time: 0.2052  data_time: 0.0056  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 13:24:17] d2.utils.events INFO:  eta: 1:11:18  iter: 31459  total_loss: 3.248  loss_ce: 0.4848  loss_giou: 0.3901  loss_bbox: 0.3746  loss_ce_0: 0.4806  loss_giou_0: 0.4316  loss_bbox_0: 0.409  loss_rpn_cls: 0.25  loss_rpn_reg: 0.5152  time: 0.1890  last_time: 0.1740  data_time: 0.0052  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:24:21] d2.utils.events INFO:  eta: 1:11:15  iter: 31479  total_loss: 2.812  loss_ce: 0.4012  loss_giou: 0.3098  loss_bbox: 0.2816  loss_ce_0: 0.4712  loss_giou_0: 0.3312  loss_bbox_0: 0.3183  loss_rpn_cls: 0.2565  loss_rpn_reg: 0.4368  time: 0.1890  last_time: 0.2126  data_time: 0.0064  last_data_time: 0.0077   lr: 5e-05  max_mem: 3029M
[03/05 13:24:25] d2.utils.events INFO:  eta: 1:11:10  iter: 31499  total_loss: 3.007  loss_ce: 0.4115  loss_giou: 0.3659  loss_bbox: 0.3018  loss_ce_0: 0.4265  loss_giou_0: 0.386  loss_bbox_0: 0.3447  loss_rpn_cls: 0.2109  loss_rpn_reg: 0.4921  time: 0.1890  last_time: 0.1838  data_time: 0.0049  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 13:24:28] d2.utils.events INFO:  eta: 1:11:03  iter: 31519  total_loss: 2.87  loss_ce: 0.4191  loss_giou: 0.3157  loss_bbox: 0.3193  loss_ce_0: 0.4266  loss_giou_0: 0.3453  loss_bbox_0: 0.3368  loss_rpn_cls: 0.2112  loss_rpn_reg: 0.4569  time: 0.1890  last_time: 0.1879  data_time: 0.0056  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:24:32] d2.utils.events INFO:  eta: 1:10:58  iter: 31539  total_loss: 3.119  loss_ce: 0.5046  loss_giou: 0.3215  loss_bbox: 0.3089  loss_ce_0: 0.543  loss_giou_0: 0.3589  loss_bbox_0: 0.3508  loss_rpn_cls: 0.2528  loss_rpn_reg: 0.5022  time: 0.1890  last_time: 0.2103  data_time: 0.0063  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 13:24:37] d2.utils.events INFO:  eta: 1:10:58  iter: 31559  total_loss: 3.146  loss_ce: 0.5073  loss_giou: 0.3216  loss_bbox: 0.2687  loss_ce_0: 0.5399  loss_giou_0: 0.346  loss_bbox_0: 0.3174  loss_rpn_cls: 0.2087  loss_rpn_reg: 0.4959  time: 0.1890  last_time: 0.1916  data_time: 0.0049  last_data_time: 0.0094   lr: 5e-05  max_mem: 3029M
[03/05 13:24:41] d2.utils.events INFO:  eta: 1:10:57  iter: 31579  total_loss: 3.074  loss_ce: 0.466  loss_giou: 0.2986  loss_bbox: 0.3209  loss_ce_0: 0.4883  loss_giou_0: 0.352  loss_bbox_0: 0.3702  loss_rpn_cls: 0.2484  loss_rpn_reg: 0.4694  time: 0.1890  last_time: 0.2139  data_time: 0.0055  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:24:45] d2.utils.events INFO:  eta: 1:10:59  iter: 31599  total_loss: 3.308  loss_ce: 0.4898  loss_giou: 0.4126  loss_bbox: 0.3481  loss_ce_0: 0.484  loss_giou_0: 0.4152  loss_bbox_0: 0.3815  loss_rpn_cls: 0.2631  loss_rpn_reg: 0.5239  time: 0.1890  last_time: 0.2111  data_time: 0.0054  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:24:48] d2.utils.events INFO:  eta: 1:10:46  iter: 31619  total_loss: 3.143  loss_ce: 0.461  loss_giou: 0.3732  loss_bbox: 0.3217  loss_ce_0: 0.4995  loss_giou_0: 0.4  loss_bbox_0: 0.3501  loss_rpn_cls: 0.2405  loss_rpn_reg: 0.4813  time: 0.1890  last_time: 0.1831  data_time: 0.0054  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:24:52] d2.utils.events INFO:  eta: 1:10:45  iter: 31639  total_loss: 3.085  loss_ce: 0.4759  loss_giou: 0.3473  loss_bbox: 0.2717  loss_ce_0: 0.4915  loss_giou_0: 0.3701  loss_bbox_0: 0.3205  loss_rpn_cls: 0.2525  loss_rpn_reg: 0.4647  time: 0.1890  last_time: 0.1971  data_time: 0.0053  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 13:24:56] d2.utils.events INFO:  eta: 1:10:42  iter: 31659  total_loss: 2.677  loss_ce: 0.438  loss_giou: 0.3053  loss_bbox: 0.2731  loss_ce_0: 0.4518  loss_giou_0: 0.3053  loss_bbox_0: 0.3032  loss_rpn_cls: 0.2291  loss_rpn_reg: 0.4793  time: 0.1890  last_time: 0.1909  data_time: 0.0054  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 13:25:00] d2.utils.events INFO:  eta: 1:10:44  iter: 31679  total_loss: 2.991  loss_ce: 0.4199  loss_giou: 0.3108  loss_bbox: 0.2881  loss_ce_0: 0.457  loss_giou_0: 0.3595  loss_bbox_0: 0.3195  loss_rpn_cls: 0.2091  loss_rpn_reg: 0.4829  time: 0.1891  last_time: 0.1765  data_time: 0.0048  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 13:25:04] d2.utils.events INFO:  eta: 1:10:31  iter: 31699  total_loss: 3.272  loss_ce: 0.4955  loss_giou: 0.3446  loss_bbox: 0.3027  loss_ce_0: 0.5492  loss_giou_0: 0.3687  loss_bbox_0: 0.3429  loss_rpn_cls: 0.2467  loss_rpn_reg: 0.4861  time: 0.1890  last_time: 0.1994  data_time: 0.0052  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:25:08] d2.utils.events INFO:  eta: 1:10:30  iter: 31719  total_loss: 2.863  loss_ce: 0.421  loss_giou: 0.3393  loss_bbox: 0.2995  loss_ce_0: 0.4598  loss_giou_0: 0.3732  loss_bbox_0: 0.3683  loss_rpn_cls: 0.2109  loss_rpn_reg: 0.4812  time: 0.1890  last_time: 0.1837  data_time: 0.0054  last_data_time: 0.0019   lr: 5e-05  max_mem: 3029M
[03/05 13:25:12] d2.utils.events INFO:  eta: 1:10:33  iter: 31739  total_loss: 3.246  loss_ce: 0.4362  loss_giou: 0.346  loss_bbox: 0.338  loss_ce_0: 0.4101  loss_giou_0: 0.3799  loss_bbox_0: 0.3953  loss_rpn_cls: 0.2662  loss_rpn_reg: 0.4956  time: 0.1891  last_time: 0.1990  data_time: 0.0061  last_data_time: 0.0111   lr: 5e-05  max_mem: 3029M
[03/05 13:25:16] d2.utils.events INFO:  eta: 1:10:31  iter: 31759  total_loss: 3.094  loss_ce: 0.3926  loss_giou: 0.3475  loss_bbox: 0.3343  loss_ce_0: 0.44  loss_giou_0: 0.3534  loss_bbox_0: 0.3704  loss_rpn_cls: 0.2157  loss_rpn_reg: 0.5256  time: 0.1891  last_time: 0.2046  data_time: 0.0046  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:25:20] d2.utils.events INFO:  eta: 1:10:25  iter: 31779  total_loss: 3.079  loss_ce: 0.4851  loss_giou: 0.3799  loss_bbox: 0.3107  loss_ce_0: 0.4836  loss_giou_0: 0.4108  loss_bbox_0: 0.3286  loss_rpn_cls: 0.2359  loss_rpn_reg: 0.5035  time: 0.1891  last_time: 0.1858  data_time: 0.0057  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 13:25:23] d2.utils.events INFO:  eta: 1:10:26  iter: 31799  total_loss: 3.108  loss_ce: 0.5098  loss_giou: 0.3892  loss_bbox: 0.2991  loss_ce_0: 0.538  loss_giou_0: 0.4233  loss_bbox_0: 0.3443  loss_rpn_cls: 0.2829  loss_rpn_reg: 0.5005  time: 0.1891  last_time: 0.1972  data_time: 0.0053  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 13:25:27] d2.utils.events INFO:  eta: 1:10:21  iter: 31819  total_loss: 2.618  loss_ce: 0.361  loss_giou: 0.3264  loss_bbox: 0.2757  loss_ce_0: 0.3764  loss_giou_0: 0.3339  loss_bbox_0: 0.3005  loss_rpn_cls: 0.211  loss_rpn_reg: 0.453  time: 0.1891  last_time: 0.1902  data_time: 0.0054  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 13:25:31] d2.utils.events INFO:  eta: 1:10:16  iter: 31839  total_loss: 2.902  loss_ce: 0.3945  loss_giou: 0.3341  loss_bbox: 0.3063  loss_ce_0: 0.4133  loss_giou_0: 0.3743  loss_bbox_0: 0.3463  loss_rpn_cls: 0.2154  loss_rpn_reg: 0.4794  time: 0.1891  last_time: 0.1886  data_time: 0.0050  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:25:35] d2.utils.events INFO:  eta: 1:10:18  iter: 31859  total_loss: 2.815  loss_ce: 0.4193  loss_giou: 0.3468  loss_bbox: 0.2722  loss_ce_0: 0.476  loss_giou_0: 0.3517  loss_bbox_0: 0.3327  loss_rpn_cls: 0.2455  loss_rpn_reg: 0.4807  time: 0.1891  last_time: 0.1709  data_time: 0.0053  last_data_time: 0.0021   lr: 5e-05  max_mem: 3029M
[03/05 13:25:39] d2.utils.events INFO:  eta: 1:10:15  iter: 31879  total_loss: 2.912  loss_ce: 0.4414  loss_giou: 0.3741  loss_bbox: 0.2239  loss_ce_0: 0.4702  loss_giou_0: 0.3779  loss_bbox_0: 0.2913  loss_rpn_cls: 0.2259  loss_rpn_reg: 0.4671  time: 0.1891  last_time: 0.1974  data_time: 0.0057  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 13:25:43] d2.utils.events INFO:  eta: 1:10:11  iter: 31899  total_loss: 2.928  loss_ce: 0.4547  loss_giou: 0.2874  loss_bbox: 0.2511  loss_ce_0: 0.4779  loss_giou_0: 0.3579  loss_bbox_0: 0.2995  loss_rpn_cls: 0.247  loss_rpn_reg: 0.4486  time: 0.1891  last_time: 0.2072  data_time: 0.0057  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 13:25:47] d2.utils.events INFO:  eta: 1:10:09  iter: 31919  total_loss: 3.19  loss_ce: 0.4605  loss_giou: 0.3867  loss_bbox: 0.2616  loss_ce_0: 0.475  loss_giou_0: 0.4546  loss_bbox_0: 0.2988  loss_rpn_cls: 0.28  loss_rpn_reg: 0.5358  time: 0.1891  last_time: 0.1999  data_time: 0.0051  last_data_time: 0.0097   lr: 5e-05  max_mem: 3029M
[03/05 13:25:51] d2.utils.events INFO:  eta: 1:10:07  iter: 31939  total_loss: 3.091  loss_ce: 0.3974  loss_giou: 0.32  loss_bbox: 0.3271  loss_ce_0: 0.44  loss_giou_0: 0.3539  loss_bbox_0: 0.3629  loss_rpn_cls: 0.2222  loss_rpn_reg: 0.4697  time: 0.1891  last_time: 0.2199  data_time: 0.0060  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:25:55] d2.utils.events INFO:  eta: 1:10:03  iter: 31959  total_loss: 2.919  loss_ce: 0.4  loss_giou: 0.3626  loss_bbox: 0.2721  loss_ce_0: 0.4429  loss_giou_0: 0.3741  loss_bbox_0: 0.303  loss_rpn_cls: 0.2484  loss_rpn_reg: 0.527  time: 0.1891  last_time: 0.2039  data_time: 0.0057  last_data_time: 0.0059   lr: 5e-05  max_mem: 3029M
[03/05 13:25:59] d2.utils.events INFO:  eta: 1:10:00  iter: 31979  total_loss: 3.024  loss_ce: 0.384  loss_giou: 0.34  loss_bbox: 0.2912  loss_ce_0: 0.4557  loss_giou_0: 0.3657  loss_bbox_0: 0.3136  loss_rpn_cls: 0.2302  loss_rpn_reg: 0.4655  time: 0.1891  last_time: 0.2442  data_time: 0.0051  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:26:03] d2.utils.events INFO:  eta: 1:10:01  iter: 31999  total_loss: 3.001  loss_ce: 0.4794  loss_giou: 0.3776  loss_bbox: 0.2972  loss_ce_0: 0.523  loss_giou_0: 0.4039  loss_bbox_0: 0.3239  loss_rpn_cls: 0.2329  loss_rpn_reg: 0.4894  time: 0.1891  last_time: 0.1978  data_time: 0.0045  last_data_time: 0.0029   lr: 5e-05  max_mem: 3029M
[03/05 13:26:07] d2.utils.events INFO:  eta: 1:09:58  iter: 32019  total_loss: 3.184  loss_ce: 0.4194  loss_giou: 0.3631  loss_bbox: 0.2586  loss_ce_0: 0.4238  loss_giou_0: 0.4007  loss_bbox_0: 0.3003  loss_rpn_cls: 0.2338  loss_rpn_reg: 0.4866  time: 0.1891  last_time: 0.1896  data_time: 0.0056  last_data_time: 0.0021   lr: 5e-05  max_mem: 3029M
[03/05 13:26:11] d2.utils.events INFO:  eta: 1:09:56  iter: 32039  total_loss: 3.423  loss_ce: 0.4539  loss_giou: 0.3848  loss_bbox: 0.4066  loss_ce_0: 0.4978  loss_giou_0: 0.3934  loss_bbox_0: 0.3761  loss_rpn_cls: 0.2585  loss_rpn_reg: 0.4964  time: 0.1891  last_time: 0.2147  data_time: 0.0044  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:26:15] d2.utils.events INFO:  eta: 1:09:53  iter: 32059  total_loss: 2.899  loss_ce: 0.3793  loss_giou: 0.3234  loss_bbox: 0.2555  loss_ce_0: 0.4727  loss_giou_0: 0.3308  loss_bbox_0: 0.2696  loss_rpn_cls: 0.2174  loss_rpn_reg: 0.4791  time: 0.1891  last_time: 0.1696  data_time: 0.0047  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:26:18] d2.utils.events INFO:  eta: 1:09:48  iter: 32079  total_loss: 3.133  loss_ce: 0.4611  loss_giou: 0.3923  loss_bbox: 0.3139  loss_ce_0: 0.4663  loss_giou_0: 0.398  loss_bbox_0: 0.3162  loss_rpn_cls: 0.2439  loss_rpn_reg: 0.4794  time: 0.1891  last_time: 0.1911  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:26:22] d2.utils.events INFO:  eta: 1:09:45  iter: 32099  total_loss: 3.265  loss_ce: 0.4706  loss_giou: 0.4235  loss_bbox: 0.3255  loss_ce_0: 0.4953  loss_giou_0: 0.4015  loss_bbox_0: 0.3313  loss_rpn_cls: 0.2605  loss_rpn_reg: 0.4889  time: 0.1891  last_time: 0.1824  data_time: 0.0051  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:26:26] d2.utils.events INFO:  eta: 1:09:41  iter: 32119  total_loss: 3.071  loss_ce: 0.4486  loss_giou: 0.3404  loss_bbox: 0.3088  loss_ce_0: 0.4818  loss_giou_0: 0.3713  loss_bbox_0: 0.3304  loss_rpn_cls: 0.2281  loss_rpn_reg: 0.48  time: 0.1891  last_time: 0.1475  data_time: 0.0051  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:26:30] d2.utils.events INFO:  eta: 1:09:41  iter: 32139  total_loss: 3.166  loss_ce: 0.4133  loss_giou: 0.3827  loss_bbox: 0.3229  loss_ce_0: 0.4414  loss_giou_0: 0.4098  loss_bbox_0: 0.3303  loss_rpn_cls: 0.2277  loss_rpn_reg: 0.5015  time: 0.1891  last_time: 0.2265  data_time: 0.0053  last_data_time: 0.0090   lr: 5e-05  max_mem: 3029M
[03/05 13:26:34] d2.utils.events INFO:  eta: 1:09:43  iter: 32159  total_loss: 3.151  loss_ce: 0.4834  loss_giou: 0.3576  loss_bbox: 0.3169  loss_ce_0: 0.5061  loss_giou_0: 0.374  loss_bbox_0: 0.3339  loss_rpn_cls: 0.2568  loss_rpn_reg: 0.5021  time: 0.1891  last_time: 0.1980  data_time: 0.0055  last_data_time: 0.0029   lr: 5e-05  max_mem: 3029M
[03/05 13:26:38] d2.utils.events INFO:  eta: 1:09:37  iter: 32179  total_loss: 2.769  loss_ce: 0.3422  loss_giou: 0.3329  loss_bbox: 0.2832  loss_ce_0: 0.4058  loss_giou_0: 0.324  loss_bbox_0: 0.3163  loss_rpn_cls: 0.2235  loss_rpn_reg: 0.497  time: 0.1891  last_time: 0.1869  data_time: 0.0055  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:26:42] d2.utils.events INFO:  eta: 1:09:35  iter: 32199  total_loss: 3.106  loss_ce: 0.4166  loss_giou: 0.3667  loss_bbox: 0.3057  loss_ce_0: 0.4386  loss_giou_0: 0.3896  loss_bbox_0: 0.3167  loss_rpn_cls: 0.2586  loss_rpn_reg: 0.5169  time: 0.1891  last_time: 0.1826  data_time: 0.0048  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:26:46] d2.utils.events INFO:  eta: 1:09:32  iter: 32219  total_loss: 2.787  loss_ce: 0.3727  loss_giou: 0.2978  loss_bbox: 0.2837  loss_ce_0: 0.3998  loss_giou_0: 0.3186  loss_bbox_0: 0.3241  loss_rpn_cls: 0.2245  loss_rpn_reg: 0.4402  time: 0.1891  last_time: 0.1655  data_time: 0.0055  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:26:50] d2.utils.events INFO:  eta: 1:09:29  iter: 32239  total_loss: 3.292  loss_ce: 0.4672  loss_giou: 0.3401  loss_bbox: 0.2724  loss_ce_0: 0.5303  loss_giou_0: 0.3687  loss_bbox_0: 0.3458  loss_rpn_cls: 0.2479  loss_rpn_reg: 0.4969  time: 0.1891  last_time: 0.1695  data_time: 0.0052  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 13:26:54] d2.utils.events INFO:  eta: 1:09:21  iter: 32259  total_loss: 2.917  loss_ce: 0.3775  loss_giou: 0.3117  loss_bbox: 0.3389  loss_ce_0: 0.4568  loss_giou_0: 0.322  loss_bbox_0: 0.3547  loss_rpn_cls: 0.2126  loss_rpn_reg: 0.4743  time: 0.1891  last_time: 0.2056  data_time: 0.0046  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 13:26:57] d2.utils.events INFO:  eta: 1:09:18  iter: 32279  total_loss: 2.608  loss_ce: 0.3142  loss_giou: 0.3337  loss_bbox: 0.2792  loss_ce_0: 0.3671  loss_giou_0: 0.3426  loss_bbox_0: 0.3026  loss_rpn_cls: 0.2159  loss_rpn_reg: 0.4691  time: 0.1891  last_time: 0.2032  data_time: 0.0054  last_data_time: 0.0064   lr: 5e-05  max_mem: 3029M
[03/05 13:27:01] d2.utils.events INFO:  eta: 1:09:17  iter: 32299  total_loss: 3.019  loss_ce: 0.4163  loss_giou: 0.3514  loss_bbox: 0.3398  loss_ce_0: 0.4849  loss_giou_0: 0.3906  loss_bbox_0: 0.3431  loss_rpn_cls: 0.2568  loss_rpn_reg: 0.4742  time: 0.1891  last_time: 0.2043  data_time: 0.0064  last_data_time: 0.0206   lr: 5e-05  max_mem: 3029M
[03/05 13:27:05] d2.utils.events INFO:  eta: 1:09:09  iter: 32319  total_loss: 2.782  loss_ce: 0.3724  loss_giou: 0.3763  loss_bbox: 0.2698  loss_ce_0: 0.4374  loss_giou_0: 0.401  loss_bbox_0: 0.2923  loss_rpn_cls: 0.2288  loss_rpn_reg: 0.4668  time: 0.1891  last_time: 0.1910  data_time: 0.0048  last_data_time: 0.0024   lr: 5e-05  max_mem: 3029M
[03/05 13:27:09] d2.utils.events INFO:  eta: 1:09:05  iter: 32339  total_loss: 3.004  loss_ce: 0.4575  loss_giou: 0.3211  loss_bbox: 0.3031  loss_ce_0: 0.4954  loss_giou_0: 0.3412  loss_bbox_0: 0.3329  loss_rpn_cls: 0.2378  loss_rpn_reg: 0.4926  time: 0.1891  last_time: 0.1990  data_time: 0.0059  last_data_time: 0.0029   lr: 5e-05  max_mem: 3029M
[03/05 13:27:13] d2.utils.events INFO:  eta: 1:09:02  iter: 32359  total_loss: 3.096  loss_ce: 0.418  loss_giou: 0.3373  loss_bbox: 0.2481  loss_ce_0: 0.4854  loss_giou_0: 0.3819  loss_bbox_0: 0.2857  loss_rpn_cls: 0.2424  loss_rpn_reg: 0.4804  time: 0.1891  last_time: 0.1768  data_time: 0.0071  last_data_time: 0.0028   lr: 5e-05  max_mem: 3029M
[03/05 13:27:17] d2.utils.events INFO:  eta: 1:09:01  iter: 32379  total_loss: 2.896  loss_ce: 0.4631  loss_giou: 0.3099  loss_bbox: 0.2946  loss_ce_0: 0.4809  loss_giou_0: 0.3225  loss_bbox_0: 0.332  loss_rpn_cls: 0.2427  loss_rpn_reg: 0.4744  time: 0.1891  last_time: 0.1582  data_time: 0.0054  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:27:21] d2.utils.events INFO:  eta: 1:08:59  iter: 32399  total_loss: 2.899  loss_ce: 0.4434  loss_giou: 0.3349  loss_bbox: 0.2589  loss_ce_0: 0.4686  loss_giou_0: 0.3678  loss_bbox_0: 0.3003  loss_rpn_cls: 0.2458  loss_rpn_reg: 0.5019  time: 0.1891  last_time: 0.1915  data_time: 0.0051  last_data_time: 0.0103   lr: 5e-05  max_mem: 3029M
[03/05 13:27:25] d2.utils.events INFO:  eta: 1:08:55  iter: 32419  total_loss: 2.873  loss_ce: 0.4178  loss_giou: 0.3639  loss_bbox: 0.282  loss_ce_0: 0.4008  loss_giou_0: 0.4105  loss_bbox_0: 0.2883  loss_rpn_cls: 0.2352  loss_rpn_reg: 0.4668  time: 0.1891  last_time: 0.1894  data_time: 0.0051  last_data_time: 0.0030   lr: 5e-05  max_mem: 3029M
[03/05 13:27:28] d2.utils.events INFO:  eta: 1:08:51  iter: 32439  total_loss: 3.259  loss_ce: 0.4437  loss_giou: 0.3442  loss_bbox: 0.3733  loss_ce_0: 0.4886  loss_giou_0: 0.3781  loss_bbox_0: 0.3525  loss_rpn_cls: 0.2385  loss_rpn_reg: 0.4913  time: 0.1891  last_time: 0.1964  data_time: 0.0051  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:27:32] d2.utils.events INFO:  eta: 1:08:48  iter: 32459  total_loss: 3.13  loss_ce: 0.4212  loss_giou: 0.3921  loss_bbox: 0.3073  loss_ce_0: 0.4741  loss_giou_0: 0.4099  loss_bbox_0: 0.3315  loss_rpn_cls: 0.2711  loss_rpn_reg: 0.4625  time: 0.1891  last_time: 0.2023  data_time: 0.0049  last_data_time: 0.0070   lr: 5e-05  max_mem: 3029M
[03/05 13:27:36] d2.utils.events INFO:  eta: 1:08:40  iter: 32479  total_loss: 2.83  loss_ce: 0.3958  loss_giou: 0.3108  loss_bbox: 0.289  loss_ce_0: 0.4403  loss_giou_0: 0.3246  loss_bbox_0: 0.2941  loss_rpn_cls: 0.2212  loss_rpn_reg: 0.4704  time: 0.1891  last_time: 0.1718  data_time: 0.0051  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:27:40] d2.utils.events INFO:  eta: 1:08:43  iter: 32499  total_loss: 2.95  loss_ce: 0.442  loss_giou: 0.3646  loss_bbox: 0.2568  loss_ce_0: 0.4502  loss_giou_0: 0.3887  loss_bbox_0: 0.3053  loss_rpn_cls: 0.2228  loss_rpn_reg: 0.4628  time: 0.1891  last_time: 0.2068  data_time: 0.0061  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:27:44] d2.utils.events INFO:  eta: 1:08:40  iter: 32519  total_loss: 3.165  loss_ce: 0.4664  loss_giou: 0.3427  loss_bbox: 0.2975  loss_ce_0: 0.5281  loss_giou_0: 0.3735  loss_bbox_0: 0.3329  loss_rpn_cls: 0.2614  loss_rpn_reg: 0.5111  time: 0.1891  last_time: 0.1754  data_time: 0.0051  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:27:48] d2.utils.events INFO:  eta: 1:08:34  iter: 32539  total_loss: 2.707  loss_ce: 0.4493  loss_giou: 0.2826  loss_bbox: 0.27  loss_ce_0: 0.5114  loss_giou_0: 0.3196  loss_bbox_0: 0.2867  loss_rpn_cls: 0.2079  loss_rpn_reg: 0.5143  time: 0.1891  last_time: 0.1819  data_time: 0.0052  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:27:52] d2.utils.events INFO:  eta: 1:08:25  iter: 32559  total_loss: 2.98  loss_ce: 0.4126  loss_giou: 0.325  loss_bbox: 0.3444  loss_ce_0: 0.434  loss_giou_0: 0.343  loss_bbox_0: 0.3744  loss_rpn_cls: 0.2239  loss_rpn_reg: 0.4829  time: 0.1891  last_time: 0.1814  data_time: 0.0049  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:27:56] d2.utils.events INFO:  eta: 1:08:17  iter: 32579  total_loss: 3.025  loss_ce: 0.4561  loss_giou: 0.3404  loss_bbox: 0.2838  loss_ce_0: 0.4728  loss_giou_0: 0.3603  loss_bbox_0: 0.3117  loss_rpn_cls: 0.2428  loss_rpn_reg: 0.509  time: 0.1891  last_time: 0.2090  data_time: 0.0050  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:27:59] d2.utils.events INFO:  eta: 1:08:11  iter: 32599  total_loss: 2.961  loss_ce: 0.444  loss_giou: 0.3324  loss_bbox: 0.268  loss_ce_0: 0.4858  loss_giou_0: 0.3339  loss_bbox_0: 0.2741  loss_rpn_cls: 0.2385  loss_rpn_reg: 0.4874  time: 0.1891  last_time: 0.1845  data_time: 0.0053  last_data_time: 0.0064   lr: 5e-05  max_mem: 3029M
[03/05 13:28:03] d2.utils.events INFO:  eta: 1:08:08  iter: 32619  total_loss: 2.939  loss_ce: 0.3797  loss_giou: 0.3552  loss_bbox: 0.2557  loss_ce_0: 0.4234  loss_giou_0: 0.3827  loss_bbox_0: 0.2802  loss_rpn_cls: 0.2458  loss_rpn_reg: 0.4712  time: 0.1891  last_time: 0.1954  data_time: 0.0058  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 13:28:07] d2.utils.events INFO:  eta: 1:08:04  iter: 32639  total_loss: 3.135  loss_ce: 0.4086  loss_giou: 0.331  loss_bbox: 0.2775  loss_ce_0: 0.4312  loss_giou_0: 0.3401  loss_bbox_0: 0.3026  loss_rpn_cls: 0.2478  loss_rpn_reg: 0.4905  time: 0.1891  last_time: 0.2046  data_time: 0.0050  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:28:11] d2.utils.events INFO:  eta: 1:08:01  iter: 32659  total_loss: 3.104  loss_ce: 0.5099  loss_giou: 0.3509  loss_bbox: 0.2827  loss_ce_0: 0.5438  loss_giou_0: 0.3735  loss_bbox_0: 0.3333  loss_rpn_cls: 0.2872  loss_rpn_reg: 0.4945  time: 0.1891  last_time: 0.1884  data_time: 0.0050  last_data_time: 0.0079   lr: 5e-05  max_mem: 3029M
[03/05 13:28:15] d2.utils.events INFO:  eta: 1:07:54  iter: 32679  total_loss: 3.017  loss_ce: 0.4585  loss_giou: 0.3513  loss_bbox: 0.2469  loss_ce_0: 0.485  loss_giou_0: 0.3521  loss_bbox_0: 0.2618  loss_rpn_cls: 0.2428  loss_rpn_reg: 0.4784  time: 0.1891  last_time: 0.1931  data_time: 0.0057  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:28:19] d2.utils.events INFO:  eta: 1:07:54  iter: 32699  total_loss: 2.918  loss_ce: 0.4648  loss_giou: 0.3695  loss_bbox: 0.2754  loss_ce_0: 0.4934  loss_giou_0: 0.3958  loss_bbox_0: 0.294  loss_rpn_cls: 0.2415  loss_rpn_reg: 0.4875  time: 0.1891  last_time: 0.1770  data_time: 0.0062  last_data_time: 0.0094   lr: 5e-05  max_mem: 3029M
[03/05 13:28:23] d2.utils.events INFO:  eta: 1:07:51  iter: 32719  total_loss: 3.187  loss_ce: 0.5328  loss_giou: 0.3415  loss_bbox: 0.2833  loss_ce_0: 0.5072  loss_giou_0: 0.3872  loss_bbox_0: 0.3282  loss_rpn_cls: 0.241  loss_rpn_reg: 0.4799  time: 0.1891  last_time: 0.1860  data_time: 0.0057  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:28:27] d2.utils.events INFO:  eta: 1:07:45  iter: 32739  total_loss: 3.257  loss_ce: 0.4842  loss_giou: 0.3278  loss_bbox: 0.36  loss_ce_0: 0.5008  loss_giou_0: 0.39  loss_bbox_0: 0.3938  loss_rpn_cls: 0.2559  loss_rpn_reg: 0.5083  time: 0.1891  last_time: 0.1866  data_time: 0.0057  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 13:28:31] d2.utils.events INFO:  eta: 1:07:41  iter: 32759  total_loss: 3.09  loss_ce: 0.3997  loss_giou: 0.3574  loss_bbox: 0.332  loss_ce_0: 0.4432  loss_giou_0: 0.3843  loss_bbox_0: 0.3605  loss_rpn_cls: 0.2247  loss_rpn_reg: 0.5131  time: 0.1891  last_time: 0.1914  data_time: 0.0056  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:28:35] d2.utils.events INFO:  eta: 1:07:37  iter: 32779  total_loss: 3.022  loss_ce: 0.5473  loss_giou: 0.3086  loss_bbox: 0.2813  loss_ce_0: 0.5039  loss_giou_0: 0.3453  loss_bbox_0: 0.3647  loss_rpn_cls: 0.2396  loss_rpn_reg: 0.4987  time: 0.1891  last_time: 0.2068  data_time: 0.0049  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:28:38] d2.utils.events INFO:  eta: 1:07:33  iter: 32799  total_loss: 2.963  loss_ce: 0.4759  loss_giou: 0.3251  loss_bbox: 0.3093  loss_ce_0: 0.5002  loss_giou_0: 0.3354  loss_bbox_0: 0.3279  loss_rpn_cls: 0.2097  loss_rpn_reg: 0.4371  time: 0.1891  last_time: 0.1662  data_time: 0.0058  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:28:42] d2.utils.events INFO:  eta: 1:07:30  iter: 32819  total_loss: 3.095  loss_ce: 0.4636  loss_giou: 0.3416  loss_bbox: 0.3289  loss_ce_0: 0.4903  loss_giou_0: 0.3745  loss_bbox_0: 0.3727  loss_rpn_cls: 0.2425  loss_rpn_reg: 0.4889  time: 0.1891  last_time: 0.1893  data_time: 0.0047  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:28:46] d2.utils.events INFO:  eta: 1:07:27  iter: 32839  total_loss: 3.085  loss_ce: 0.4781  loss_giou: 0.3695  loss_bbox: 0.3395  loss_ce_0: 0.4684  loss_giou_0: 0.3957  loss_bbox_0: 0.3533  loss_rpn_cls: 0.2497  loss_rpn_reg: 0.5352  time: 0.1891  last_time: 0.1818  data_time: 0.0055  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:28:50] d2.utils.events INFO:  eta: 1:07:22  iter: 32859  total_loss: 2.97  loss_ce: 0.4448  loss_giou: 0.3257  loss_bbox: 0.3066  loss_ce_0: 0.4757  loss_giou_0: 0.3736  loss_bbox_0: 0.3332  loss_rpn_cls: 0.1979  loss_rpn_reg: 0.5162  time: 0.1891  last_time: 0.2076  data_time: 0.0052  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 13:28:54] d2.utils.events INFO:  eta: 1:07:18  iter: 32879  total_loss: 2.93  loss_ce: 0.4324  loss_giou: 0.3339  loss_bbox: 0.2639  loss_ce_0: 0.4543  loss_giou_0: 0.3578  loss_bbox_0: 0.3088  loss_rpn_cls: 0.2231  loss_rpn_reg: 0.4524  time: 0.1891  last_time: 0.1756  data_time: 0.0051  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 13:28:58] d2.utils.events INFO:  eta: 1:07:13  iter: 32899  total_loss: 3.098  loss_ce: 0.4563  loss_giou: 0.344  loss_bbox: 0.339  loss_ce_0: 0.5032  loss_giou_0: 0.3697  loss_bbox_0: 0.3734  loss_rpn_cls: 0.2501  loss_rpn_reg: 0.5143  time: 0.1891  last_time: 0.1932  data_time: 0.0049  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 13:29:02] d2.utils.events INFO:  eta: 1:07:09  iter: 32919  total_loss: 2.968  loss_ce: 0.4261  loss_giou: 0.3536  loss_bbox: 0.2789  loss_ce_0: 0.4543  loss_giou_0: 0.3809  loss_bbox_0: 0.2895  loss_rpn_cls: 0.2236  loss_rpn_reg: 0.5019  time: 0.1891  last_time: 0.2010  data_time: 0.0053  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 13:29:06] d2.utils.events INFO:  eta: 1:07:04  iter: 32939  total_loss: 2.897  loss_ce: 0.4338  loss_giou: 0.3572  loss_bbox: 0.2662  loss_ce_0: 0.4637  loss_giou_0: 0.4187  loss_bbox_0: 0.2835  loss_rpn_cls: 0.2069  loss_rpn_reg: 0.5102  time: 0.1891  last_time: 0.2067  data_time: 0.0061  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:29:09] d2.utils.events INFO:  eta: 1:06:58  iter: 32959  total_loss: 3.135  loss_ce: 0.4802  loss_giou: 0.3749  loss_bbox: 0.32  loss_ce_0: 0.4713  loss_giou_0: 0.3997  loss_bbox_0: 0.3412  loss_rpn_cls: 0.2588  loss_rpn_reg: 0.4856  time: 0.1891  last_time: 0.1974  data_time: 0.0059  last_data_time: 0.0071   lr: 5e-05  max_mem: 3029M
[03/05 13:29:13] d2.utils.events INFO:  eta: 1:06:56  iter: 32979  total_loss: 3.178  loss_ce: 0.5399  loss_giou: 0.3501  loss_bbox: 0.2814  loss_ce_0: 0.5625  loss_giou_0: 0.4077  loss_bbox_0: 0.3827  loss_rpn_cls: 0.2436  loss_rpn_reg: 0.4765  time: 0.1891  last_time: 0.2077  data_time: 0.0054  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 13:29:17] d2.utils.events INFO:  eta: 1:06:52  iter: 32999  total_loss: 3.298  loss_ce: 0.4303  loss_giou: 0.4059  loss_bbox: 0.3173  loss_ce_0: 0.4538  loss_giou_0: 0.4342  loss_bbox_0: 0.3721  loss_rpn_cls: 0.2687  loss_rpn_reg: 0.4912  time: 0.1891  last_time: 0.2095  data_time: 0.0050  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:29:21] d2.utils.events INFO:  eta: 1:06:44  iter: 33019  total_loss: 3.12  loss_ce: 0.3892  loss_giou: 0.3717  loss_bbox: 0.2675  loss_ce_0: 0.4158  loss_giou_0: 0.3708  loss_bbox_0: 0.2924  loss_rpn_cls: 0.2397  loss_rpn_reg: 0.4783  time: 0.1892  last_time: 0.1868  data_time: 0.0050  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:29:25] d2.utils.events INFO:  eta: 1:06:40  iter: 33039  total_loss: 2.902  loss_ce: 0.4194  loss_giou: 0.3398  loss_bbox: 0.3229  loss_ce_0: 0.447  loss_giou_0: 0.3369  loss_bbox_0: 0.3813  loss_rpn_cls: 0.2199  loss_rpn_reg: 0.4712  time: 0.1892  last_time: 0.2231  data_time: 0.0056  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:29:29] d2.utils.events INFO:  eta: 1:06:41  iter: 33059  total_loss: 3.092  loss_ce: 0.4815  loss_giou: 0.3118  loss_bbox: 0.2886  loss_ce_0: 0.461  loss_giou_0: 0.3609  loss_bbox_0: 0.3265  loss_rpn_cls: 0.2255  loss_rpn_reg: 0.4677  time: 0.1892  last_time: 0.2036  data_time: 0.0049  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 13:29:33] d2.utils.events INFO:  eta: 1:06:38  iter: 33079  total_loss: 2.908  loss_ce: 0.3923  loss_giou: 0.3447  loss_bbox: 0.3027  loss_ce_0: 0.4344  loss_giou_0: 0.3777  loss_bbox_0: 0.3424  loss_rpn_cls: 0.234  loss_rpn_reg: 0.4819  time: 0.1892  last_time: 0.2093  data_time: 0.0054  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 13:29:37] d2.utils.events INFO:  eta: 1:06:35  iter: 33099  total_loss: 2.954  loss_ce: 0.3837  loss_giou: 0.3041  loss_bbox: 0.3044  loss_ce_0: 0.4755  loss_giou_0: 0.3146  loss_bbox_0: 0.3399  loss_rpn_cls: 0.24  loss_rpn_reg: 0.4639  time: 0.1892  last_time: 0.1889  data_time: 0.0050  last_data_time: 0.0011   lr: 5e-05  max_mem: 3029M
[03/05 13:29:41] d2.utils.events INFO:  eta: 1:06:31  iter: 33119  total_loss: 2.962  loss_ce: 0.3982  loss_giou: 0.2876  loss_bbox: 0.3148  loss_ce_0: 0.4351  loss_giou_0: 0.328  loss_bbox_0: 0.411  loss_rpn_cls: 0.241  loss_rpn_reg: 0.4831  time: 0.1892  last_time: 0.1868  data_time: 0.0052  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 13:29:45] d2.utils.events INFO:  eta: 1:06:26  iter: 33139  total_loss: 2.928  loss_ce: 0.3659  loss_giou: 0.3827  loss_bbox: 0.2672  loss_ce_0: 0.3932  loss_giou_0: 0.4108  loss_bbox_0: 0.2947  loss_rpn_cls: 0.2213  loss_rpn_reg: 0.483  time: 0.1892  last_time: 0.2372  data_time: 0.0052  last_data_time: 0.0064   lr: 5e-05  max_mem: 3029M
[03/05 13:29:49] d2.utils.events INFO:  eta: 1:06:19  iter: 33159  total_loss: 2.9  loss_ce: 0.4088  loss_giou: 0.301  loss_bbox: 0.3162  loss_ce_0: 0.4397  loss_giou_0: 0.3485  loss_bbox_0: 0.3325  loss_rpn_cls: 0.225  loss_rpn_reg: 0.4536  time: 0.1892  last_time: 0.1962  data_time: 0.0058  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:29:53] d2.utils.events INFO:  eta: 1:06:15  iter: 33179  total_loss: 2.828  loss_ce: 0.3909  loss_giou: 0.3069  loss_bbox: 0.2854  loss_ce_0: 0.4427  loss_giou_0: 0.3353  loss_bbox_0: 0.2848  loss_rpn_cls: 0.2014  loss_rpn_reg: 0.4741  time: 0.1892  last_time: 0.1764  data_time: 0.0055  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:29:56] d2.utils.events INFO:  eta: 1:06:09  iter: 33199  total_loss: 2.735  loss_ce: 0.3506  loss_giou: 0.3328  loss_bbox: 0.2633  loss_ce_0: 0.4015  loss_giou_0: 0.3549  loss_bbox_0: 0.2856  loss_rpn_cls: 0.2233  loss_rpn_reg: 0.4634  time: 0.1892  last_time: 0.1781  data_time: 0.0062  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:30:00] d2.utils.events INFO:  eta: 1:06:02  iter: 33219  total_loss: 2.816  loss_ce: 0.4513  loss_giou: 0.3282  loss_bbox: 0.2614  loss_ce_0: 0.4519  loss_giou_0: 0.3642  loss_bbox_0: 0.2976  loss_rpn_cls: 0.2286  loss_rpn_reg: 0.4573  time: 0.1892  last_time: 0.1816  data_time: 0.0050  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:30:04] d2.utils.events INFO:  eta: 1:05:54  iter: 33239  total_loss: 2.923  loss_ce: 0.4045  loss_giou: 0.3042  loss_bbox: 0.3011  loss_ce_0: 0.4408  loss_giou_0: 0.3204  loss_bbox_0: 0.3309  loss_rpn_cls: 0.2163  loss_rpn_reg: 0.464  time: 0.1892  last_time: 0.2061  data_time: 0.0054  last_data_time: 0.0076   lr: 5e-05  max_mem: 3029M
[03/05 13:30:08] d2.utils.events INFO:  eta: 1:05:55  iter: 33259  total_loss: 3.094  loss_ce: 0.4989  loss_giou: 0.3732  loss_bbox: 0.3767  loss_ce_0: 0.5101  loss_giou_0: 0.3774  loss_bbox_0: 0.3824  loss_rpn_cls: 0.251  loss_rpn_reg: 0.5104  time: 0.1892  last_time: 0.1997  data_time: 0.0057  last_data_time: 0.0067   lr: 5e-05  max_mem: 3029M
[03/05 13:30:12] d2.utils.events INFO:  eta: 1:05:51  iter: 33279  total_loss: 3.072  loss_ce: 0.4958  loss_giou: 0.3207  loss_bbox: 0.2815  loss_ce_0: 0.5068  loss_giou_0: 0.3476  loss_bbox_0: 0.3319  loss_rpn_cls: 0.2502  loss_rpn_reg: 0.479  time: 0.1892  last_time: 0.1970  data_time: 0.0048  last_data_time: 0.0025   lr: 5e-05  max_mem: 3029M
[03/05 13:30:16] d2.utils.events INFO:  eta: 1:05:43  iter: 33299  total_loss: 2.898  loss_ce: 0.4269  loss_giou: 0.3636  loss_bbox: 0.2846  loss_ce_0: 0.4443  loss_giou_0: 0.3744  loss_bbox_0: 0.3009  loss_rpn_cls: 0.2233  loss_rpn_reg: 0.4607  time: 0.1892  last_time: 0.1697  data_time: 0.0051  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:30:19] d2.utils.events INFO:  eta: 1:05:39  iter: 33319  total_loss: 2.958  loss_ce: 0.4474  loss_giou: 0.3511  loss_bbox: 0.2978  loss_ce_0: 0.4715  loss_giou_0: 0.3744  loss_bbox_0: 0.3096  loss_rpn_cls: 0.2126  loss_rpn_reg: 0.4518  time: 0.1892  last_time: 0.1825  data_time: 0.0047  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:30:23] d2.utils.events INFO:  eta: 1:05:37  iter: 33339  total_loss: 2.985  loss_ce: 0.4356  loss_giou: 0.3596  loss_bbox: 0.3326  loss_ce_0: 0.4709  loss_giou_0: 0.3611  loss_bbox_0: 0.3447  loss_rpn_cls: 0.2323  loss_rpn_reg: 0.4699  time: 0.1892  last_time: 0.2047  data_time: 0.0049  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 13:30:27] d2.utils.events INFO:  eta: 1:05:32  iter: 33359  total_loss: 2.98  loss_ce: 0.4847  loss_giou: 0.2991  loss_bbox: 0.2856  loss_ce_0: 0.5035  loss_giou_0: 0.3292  loss_bbox_0: 0.3441  loss_rpn_cls: 0.2441  loss_rpn_reg: 0.4744  time: 0.1892  last_time: 0.1863  data_time: 0.0056  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 13:30:31] d2.utils.events INFO:  eta: 1:05:26  iter: 33379  total_loss: 3.139  loss_ce: 0.5047  loss_giou: 0.3437  loss_bbox: 0.3559  loss_ce_0: 0.5387  loss_giou_0: 0.3719  loss_bbox_0: 0.4081  loss_rpn_cls: 0.2465  loss_rpn_reg: 0.4422  time: 0.1892  last_time: 0.1899  data_time: 0.0048  last_data_time: 0.0026   lr: 5e-05  max_mem: 3029M
[03/05 13:30:35] d2.utils.events INFO:  eta: 1:05:18  iter: 33399  total_loss: 2.845  loss_ce: 0.3949  loss_giou: 0.3347  loss_bbox: 0.3113  loss_ce_0: 0.4477  loss_giou_0: 0.3537  loss_bbox_0: 0.3553  loss_rpn_cls: 0.2152  loss_rpn_reg: 0.4501  time: 0.1892  last_time: 0.1661  data_time: 0.0050  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:30:38] d2.utils.events INFO:  eta: 1:05:13  iter: 33419  total_loss: 3.056  loss_ce: 0.4776  loss_giou: 0.3367  loss_bbox: 0.2885  loss_ce_0: 0.5081  loss_giou_0: 0.3532  loss_bbox_0: 0.3502  loss_rpn_cls: 0.2653  loss_rpn_reg: 0.495  time: 0.1892  last_time: 0.1900  data_time: 0.0053  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:30:42] d2.utils.events INFO:  eta: 1:05:09  iter: 33439  total_loss: 3.113  loss_ce: 0.4729  loss_giou: 0.2863  loss_bbox: 0.2852  loss_ce_0: 0.5646  loss_giou_0: 0.2983  loss_bbox_0: 0.3068  loss_rpn_cls: 0.2573  loss_rpn_reg: 0.5048  time: 0.1892  last_time: 0.1807  data_time: 0.0049  last_data_time: 0.0054   lr: 5e-05  max_mem: 3029M
[03/05 13:30:46] d2.utils.events INFO:  eta: 1:05:02  iter: 33459  total_loss: 2.847  loss_ce: 0.3828  loss_giou: 0.3532  loss_bbox: 0.3054  loss_ce_0: 0.3986  loss_giou_0: 0.3777  loss_bbox_0: 0.3472  loss_rpn_cls: 0.2055  loss_rpn_reg: 0.4703  time: 0.1892  last_time: 0.1685  data_time: 0.0047  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 13:30:50] d2.utils.events INFO:  eta: 1:04:57  iter: 33479  total_loss: 2.857  loss_ce: 0.4325  loss_giou: 0.3179  loss_bbox: 0.3387  loss_ce_0: 0.4564  loss_giou_0: 0.3298  loss_bbox_0: 0.338  loss_rpn_cls: 0.2054  loss_rpn_reg: 0.4886  time: 0.1892  last_time: 0.1849  data_time: 0.0052  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:30:54] d2.utils.events INFO:  eta: 1:04:49  iter: 33499  total_loss: 2.749  loss_ce: 0.3647  loss_giou: 0.3038  loss_bbox: 0.2983  loss_ce_0: 0.4256  loss_giou_0: 0.3227  loss_bbox_0: 0.3224  loss_rpn_cls: 0.2264  loss_rpn_reg: 0.5024  time: 0.1892  last_time: 0.2079  data_time: 0.0055  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:30:58] d2.utils.events INFO:  eta: 1:04:48  iter: 33519  total_loss: 2.935  loss_ce: 0.4418  loss_giou: 0.3485  loss_bbox: 0.3062  loss_ce_0: 0.4591  loss_giou_0: 0.3744  loss_bbox_0: 0.3258  loss_rpn_cls: 0.2237  loss_rpn_reg: 0.5213  time: 0.1892  last_time: 0.2161  data_time: 0.0054  last_data_time: 0.0074   lr: 5e-05  max_mem: 3029M
[03/05 13:31:02] d2.utils.events INFO:  eta: 1:04:39  iter: 33539  total_loss: 2.759  loss_ce: 0.3223  loss_giou: 0.347  loss_bbox: 0.2841  loss_ce_0: 0.4128  loss_giou_0: 0.3404  loss_bbox_0: 0.2946  loss_rpn_cls: 0.2326  loss_rpn_reg: 0.4743  time: 0.1892  last_time: 0.1826  data_time: 0.0056  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 13:31:06] d2.utils.events INFO:  eta: 1:04:33  iter: 33559  total_loss: 3.027  loss_ce: 0.3973  loss_giou: 0.3964  loss_bbox: 0.3111  loss_ce_0: 0.4414  loss_giou_0: 0.4024  loss_bbox_0: 0.3367  loss_rpn_cls: 0.2498  loss_rpn_reg: 0.4587  time: 0.1892  last_time: 0.2164  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:31:09] d2.utils.events INFO:  eta: 1:04:29  iter: 33579  total_loss: 2.833  loss_ce: 0.3877  loss_giou: 0.3054  loss_bbox: 0.2538  loss_ce_0: 0.4707  loss_giou_0: 0.3091  loss_bbox_0: 0.3005  loss_rpn_cls: 0.2603  loss_rpn_reg: 0.4631  time: 0.1892  last_time: 0.1942  data_time: 0.0052  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 13:31:13] d2.utils.events INFO:  eta: 1:04:30  iter: 33599  total_loss: 2.815  loss_ce: 0.4291  loss_giou: 0.3278  loss_bbox: 0.2382  loss_ce_0: 0.5011  loss_giou_0: 0.3671  loss_bbox_0: 0.2535  loss_rpn_cls: 0.2337  loss_rpn_reg: 0.4542  time: 0.1892  last_time: 0.1854  data_time: 0.0052  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:31:17] d2.utils.events INFO:  eta: 1:04:28  iter: 33619  total_loss: 2.914  loss_ce: 0.3851  loss_giou: 0.3292  loss_bbox: 0.2888  loss_ce_0: 0.4388  loss_giou_0: 0.3599  loss_bbox_0: 0.3495  loss_rpn_cls: 0.2484  loss_rpn_reg: 0.4892  time: 0.1892  last_time: 0.1744  data_time: 0.0054  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:31:21] d2.utils.events INFO:  eta: 1:04:20  iter: 33639  total_loss: 2.794  loss_ce: 0.3804  loss_giou: 0.3373  loss_bbox: 0.2948  loss_ce_0: 0.4404  loss_giou_0: 0.3327  loss_bbox_0: 0.3477  loss_rpn_cls: 0.2344  loss_rpn_reg: 0.4691  time: 0.1892  last_time: 0.1886  data_time: 0.0059  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:31:25] d2.utils.events INFO:  eta: 1:04:14  iter: 33659  total_loss: 2.767  loss_ce: 0.394  loss_giou: 0.3097  loss_bbox: 0.2659  loss_ce_0: 0.4383  loss_giou_0: 0.3387  loss_bbox_0: 0.2848  loss_rpn_cls: 0.2321  loss_rpn_reg: 0.4679  time: 0.1892  last_time: 0.2148  data_time: 0.0043  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 13:31:29] d2.utils.events INFO:  eta: 1:04:08  iter: 33679  total_loss: 3.255  loss_ce: 0.4841  loss_giou: 0.3609  loss_bbox: 0.288  loss_ce_0: 0.5326  loss_giou_0: 0.3745  loss_bbox_0: 0.3139  loss_rpn_cls: 0.2756  loss_rpn_reg: 0.5204  time: 0.1892  last_time: 0.1950  data_time: 0.0055  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:31:32] d2.utils.events INFO:  eta: 1:04:02  iter: 33699  total_loss: 2.993  loss_ce: 0.494  loss_giou: 0.3258  loss_bbox: 0.2481  loss_ce_0: 0.4859  loss_giou_0: 0.3578  loss_bbox_0: 0.2873  loss_rpn_cls: 0.269  loss_rpn_reg: 0.4686  time: 0.1892  last_time: 0.1962  data_time: 0.0054  last_data_time: 0.0078   lr: 5e-05  max_mem: 3029M
[03/05 13:31:36] d2.utils.events INFO:  eta: 1:03:58  iter: 33719  total_loss: 2.724  loss_ce: 0.3551  loss_giou: 0.3094  loss_bbox: 0.271  loss_ce_0: 0.3859  loss_giou_0: 0.335  loss_bbox_0: 0.3509  loss_rpn_cls: 0.193  loss_rpn_reg: 0.4607  time: 0.1892  last_time: 0.1744  data_time: 0.0051  last_data_time: 0.0025   lr: 5e-05  max_mem: 3029M
[03/05 13:31:40] d2.utils.events INFO:  eta: 1:03:51  iter: 33739  total_loss: 2.67  loss_ce: 0.34  loss_giou: 0.2914  loss_bbox: 0.2952  loss_ce_0: 0.3973  loss_giou_0: 0.3189  loss_bbox_0: 0.3359  loss_rpn_cls: 0.2147  loss_rpn_reg: 0.4396  time: 0.1892  last_time: 0.1896  data_time: 0.0055  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:31:44] d2.utils.events INFO:  eta: 1:03:46  iter: 33759  total_loss: 2.94  loss_ce: 0.4508  loss_giou: 0.3513  loss_bbox: 0.2837  loss_ce_0: 0.4802  loss_giou_0: 0.3839  loss_bbox_0: 0.316  loss_rpn_cls: 0.2385  loss_rpn_reg: 0.5124  time: 0.1892  last_time: 0.1826  data_time: 0.0055  last_data_time: 0.0028   lr: 5e-05  max_mem: 3029M
[03/05 13:31:48] d2.utils.events INFO:  eta: 1:03:42  iter: 33779  total_loss: 2.963  loss_ce: 0.4568  loss_giou: 0.3485  loss_bbox: 0.2869  loss_ce_0: 0.4611  loss_giou_0: 0.3792  loss_bbox_0: 0.3382  loss_rpn_cls: 0.2466  loss_rpn_reg: 0.4935  time: 0.1892  last_time: 0.2088  data_time: 0.0047  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 13:31:52] d2.utils.events INFO:  eta: 1:03:39  iter: 33799  total_loss: 2.802  loss_ce: 0.3589  loss_giou: 0.3972  loss_bbox: 0.2532  loss_ce_0: 0.4004  loss_giou_0: 0.3962  loss_bbox_0: 0.2795  loss_rpn_cls: 0.2264  loss_rpn_reg: 0.4944  time: 0.1892  last_time: 0.1867  data_time: 0.0050  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:31:55] d2.utils.events INFO:  eta: 1:03:37  iter: 33819  total_loss: 2.672  loss_ce: 0.3739  loss_giou: 0.3308  loss_bbox: 0.263  loss_ce_0: 0.4  loss_giou_0: 0.3551  loss_bbox_0: 0.2993  loss_rpn_cls: 0.1879  loss_rpn_reg: 0.4893  time: 0.1892  last_time: 0.1928  data_time: 0.0055  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:31:59] d2.utils.events INFO:  eta: 1:03:34  iter: 33839  total_loss: 2.899  loss_ce: 0.3816  loss_giou: 0.385  loss_bbox: 0.2809  loss_ce_0: 0.4076  loss_giou_0: 0.4043  loss_bbox_0: 0.2823  loss_rpn_cls: 0.2334  loss_rpn_reg: 0.4988  time: 0.1892  last_time: 0.1841  data_time: 0.0047  last_data_time: 0.0077   lr: 5e-05  max_mem: 3029M
[03/05 13:32:03] d2.utils.events INFO:  eta: 1:03:32  iter: 33859  total_loss: 2.684  loss_ce: 0.324  loss_giou: 0.3256  loss_bbox: 0.294  loss_ce_0: 0.3581  loss_giou_0: 0.3447  loss_bbox_0: 0.3255  loss_rpn_cls: 0.2124  loss_rpn_reg: 0.4747  time: 0.1892  last_time: 0.2042  data_time: 0.0060  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:32:07] d2.utils.events INFO:  eta: 1:03:25  iter: 33879  total_loss: 2.882  loss_ce: 0.4053  loss_giou: 0.3606  loss_bbox: 0.3184  loss_ce_0: 0.4215  loss_giou_0: 0.3622  loss_bbox_0: 0.3104  loss_rpn_cls: 0.2066  loss_rpn_reg: 0.473  time: 0.1892  last_time: 0.1891  data_time: 0.0047  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:32:11] d2.utils.events INFO:  eta: 1:03:25  iter: 33899  total_loss: 2.842  loss_ce: 0.4129  loss_giou: 0.3094  loss_bbox: 0.2777  loss_ce_0: 0.4393  loss_giou_0: 0.3501  loss_bbox_0: 0.3229  loss_rpn_cls: 0.2321  loss_rpn_reg: 0.4721  time: 0.1892  last_time: 0.2141  data_time: 0.0053  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:32:15] d2.utils.events INFO:  eta: 1:03:19  iter: 33919  total_loss: 2.863  loss_ce: 0.505  loss_giou: 0.3018  loss_bbox: 0.259  loss_ce_0: 0.5605  loss_giou_0: 0.333  loss_bbox_0: 0.2786  loss_rpn_cls: 0.2127  loss_rpn_reg: 0.467  time: 0.1892  last_time: 0.2004  data_time: 0.0052  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:32:19] d2.utils.events INFO:  eta: 1:03:17  iter: 33939  total_loss: 3.212  loss_ce: 0.4503  loss_giou: 0.3707  loss_bbox: 0.3259  loss_ce_0: 0.4721  loss_giou_0: 0.4107  loss_bbox_0: 0.346  loss_rpn_cls: 0.2553  loss_rpn_reg: 0.5036  time: 0.1892  last_time: 0.2296  data_time: 0.0050  last_data_time: 0.0073   lr: 5e-05  max_mem: 3029M
[03/05 13:32:23] d2.utils.events INFO:  eta: 1:03:13  iter: 33959  total_loss: 2.897  loss_ce: 0.3859  loss_giou: 0.352  loss_bbox: 0.2804  loss_ce_0: 0.3946  loss_giou_0: 0.4009  loss_bbox_0: 0.3077  loss_rpn_cls: 0.224  loss_rpn_reg: 0.493  time: 0.1892  last_time: 0.1873  data_time: 0.0060  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:32:27] d2.utils.events INFO:  eta: 1:03:09  iter: 33979  total_loss: 3.026  loss_ce: 0.4422  loss_giou: 0.3548  loss_bbox: 0.2887  loss_ce_0: 0.4857  loss_giou_0: 0.3821  loss_bbox_0: 0.3289  loss_rpn_cls: 0.2563  loss_rpn_reg: 0.4667  time: 0.1892  last_time: 0.1908  data_time: 0.0054  last_data_time: 0.0096   lr: 5e-05  max_mem: 3029M
[03/05 13:32:30] d2.utils.events INFO:  eta: 1:03:04  iter: 33999  total_loss: 3.024  loss_ce: 0.4444  loss_giou: 0.3391  loss_bbox: 0.3176  loss_ce_0: 0.4788  loss_giou_0: 0.3547  loss_bbox_0: 0.3274  loss_rpn_cls: 0.2359  loss_rpn_reg: 0.4772  time: 0.1892  last_time: 0.1930  data_time: 0.0055  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:32:34] d2.utils.events INFO:  eta: 1:03:00  iter: 34019  total_loss: 3.239  loss_ce: 0.4407  loss_giou: 0.3496  loss_bbox: 0.3338  loss_ce_0: 0.5158  loss_giou_0: 0.3571  loss_bbox_0: 0.3356  loss_rpn_cls: 0.2559  loss_rpn_reg: 0.4896  time: 0.1892  last_time: 0.1905  data_time: 0.0054  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:32:38] d2.utils.events INFO:  eta: 1:02:55  iter: 34039  total_loss: 2.638  loss_ce: 0.3467  loss_giou: 0.3144  loss_bbox: 0.2656  loss_ce_0: 0.3981  loss_giou_0: 0.3261  loss_bbox_0: 0.2853  loss_rpn_cls: 0.197  loss_rpn_reg: 0.4778  time: 0.1892  last_time: 0.1889  data_time: 0.0054  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:32:42] d2.utils.events INFO:  eta: 1:02:49  iter: 34059  total_loss: 2.743  loss_ce: 0.3608  loss_giou: 0.3117  loss_bbox: 0.2514  loss_ce_0: 0.4351  loss_giou_0: 0.3328  loss_bbox_0: 0.2907  loss_rpn_cls: 0.2168  loss_rpn_reg: 0.4649  time: 0.1892  last_time: 0.1766  data_time: 0.0062  last_data_time: 0.0094   lr: 5e-05  max_mem: 3029M
[03/05 13:32:46] d2.utils.events INFO:  eta: 1:02:45  iter: 34079  total_loss: 3.07  loss_ce: 0.4347  loss_giou: 0.3352  loss_bbox: 0.2686  loss_ce_0: 0.4766  loss_giou_0: 0.3704  loss_bbox_0: 0.2943  loss_rpn_cls: 0.2603  loss_rpn_reg: 0.5024  time: 0.1892  last_time: 0.1921  data_time: 0.0058  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 13:32:50] d2.utils.events INFO:  eta: 1:02:39  iter: 34099  total_loss: 3.006  loss_ce: 0.4217  loss_giou: 0.2951  loss_bbox: 0.2532  loss_ce_0: 0.5008  loss_giou_0: 0.3341  loss_bbox_0: 0.3261  loss_rpn_cls: 0.249  loss_rpn_reg: 0.4842  time: 0.1892  last_time: 0.1558  data_time: 0.0049  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:32:54] d2.utils.events INFO:  eta: 1:02:38  iter: 34119  total_loss: 3.017  loss_ce: 0.4364  loss_giou: 0.2731  loss_bbox: 0.3141  loss_ce_0: 0.4436  loss_giou_0: 0.311  loss_bbox_0: 0.3621  loss_rpn_cls: 0.2422  loss_rpn_reg: 0.4731  time: 0.1892  last_time: 0.1932  data_time: 0.0059  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:32:58] d2.utils.events INFO:  eta: 1:02:35  iter: 34139  total_loss: 2.751  loss_ce: 0.407  loss_giou: 0.3223  loss_bbox: 0.2889  loss_ce_0: 0.3808  loss_giou_0: 0.3532  loss_bbox_0: 0.3407  loss_rpn_cls: 0.2242  loss_rpn_reg: 0.469  time: 0.1892  last_time: 0.1945  data_time: 0.0060  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:33:02] d2.utils.events INFO:  eta: 1:02:32  iter: 34159  total_loss: 2.926  loss_ce: 0.386  loss_giou: 0.3416  loss_bbox: 0.2776  loss_ce_0: 0.4609  loss_giou_0: 0.3467  loss_bbox_0: 0.3103  loss_rpn_cls: 0.2272  loss_rpn_reg: 0.4622  time: 0.1892  last_time: 0.2026  data_time: 0.0048  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:33:05] d2.utils.events INFO:  eta: 1:02:30  iter: 34179  total_loss: 2.628  loss_ce: 0.3591  loss_giou: 0.3449  loss_bbox: 0.2906  loss_ce_0: 0.3602  loss_giou_0: 0.3758  loss_bbox_0: 0.329  loss_rpn_cls: 0.1934  loss_rpn_reg: 0.4819  time: 0.1892  last_time: 0.2037  data_time: 0.0052  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:33:09] d2.utils.events INFO:  eta: 1:02:24  iter: 34199  total_loss: 2.642  loss_ce: 0.3759  loss_giou: 0.2953  loss_bbox: 0.2683  loss_ce_0: 0.3938  loss_giou_0: 0.3273  loss_bbox_0: 0.2774  loss_rpn_cls: 0.2293  loss_rpn_reg: 0.4557  time: 0.1892  last_time: 0.1662  data_time: 0.0048  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:33:13] d2.utils.events INFO:  eta: 1:02:23  iter: 34219  total_loss: 2.583  loss_ce: 0.3579  loss_giou: 0.3075  loss_bbox: 0.2705  loss_ce_0: 0.3727  loss_giou_0: 0.3618  loss_bbox_0: 0.3143  loss_rpn_cls: 0.2091  loss_rpn_reg: 0.491  time: 0.1892  last_time: 0.1678  data_time: 0.0054  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 13:33:17] d2.utils.events INFO:  eta: 1:02:20  iter: 34239  total_loss: 2.86  loss_ce: 0.411  loss_giou: 0.3413  loss_bbox: 0.2617  loss_ce_0: 0.4167  loss_giou_0: 0.3552  loss_bbox_0: 0.2849  loss_rpn_cls: 0.2334  loss_rpn_reg: 0.4633  time: 0.1892  last_time: 0.1694  data_time: 0.0055  last_data_time: 0.0023   lr: 5e-05  max_mem: 3029M
[03/05 13:33:21] d2.utils.events INFO:  eta: 1:02:16  iter: 34259  total_loss: 2.619  loss_ce: 0.35  loss_giou: 0.33  loss_bbox: 0.282  loss_ce_0: 0.4126  loss_giou_0: 0.3456  loss_bbox_0: 0.3086  loss_rpn_cls: 0.2169  loss_rpn_reg: 0.4776  time: 0.1892  last_time: 0.2032  data_time: 0.0051  last_data_time: 0.0050   lr: 5e-05  max_mem: 3029M
[03/05 13:33:24] d2.utils.events INFO:  eta: 1:02:09  iter: 34279  total_loss: 3.028  loss_ce: 0.4195  loss_giou: 0.3524  loss_bbox: 0.3154  loss_ce_0: 0.4653  loss_giou_0: 0.3702  loss_bbox_0: 0.2979  loss_rpn_cls: 0.2454  loss_rpn_reg: 0.4785  time: 0.1892  last_time: 0.1833  data_time: 0.0061  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:33:28] d2.utils.events INFO:  eta: 1:02:07  iter: 34299  total_loss: 2.843  loss_ce: 0.3767  loss_giou: 0.3158  loss_bbox: 0.2882  loss_ce_0: 0.4371  loss_giou_0: 0.344  loss_bbox_0: 0.3091  loss_rpn_cls: 0.217  loss_rpn_reg: 0.467  time: 0.1892  last_time: 0.1908  data_time: 0.0053  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:33:32] d2.utils.events INFO:  eta: 1:02:02  iter: 34319  total_loss: 2.91  loss_ce: 0.3785  loss_giou: 0.3066  loss_bbox: 0.2774  loss_ce_0: 0.4121  loss_giou_0: 0.319  loss_bbox_0: 0.3187  loss_rpn_cls: 0.2195  loss_rpn_reg: 0.4588  time: 0.1892  last_time: 0.1735  data_time: 0.0049  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 13:33:36] d2.utils.events INFO:  eta: 1:01:58  iter: 34339  total_loss: 2.845  loss_ce: 0.403  loss_giou: 0.3726  loss_bbox: 0.2507  loss_ce_0: 0.4149  loss_giou_0: 0.3923  loss_bbox_0: 0.289  loss_rpn_cls: 0.2108  loss_rpn_reg: 0.5178  time: 0.1892  last_time: 0.1749  data_time: 0.0056  last_data_time: 0.0031   lr: 5e-05  max_mem: 3029M
[03/05 13:33:40] d2.utils.events INFO:  eta: 1:01:54  iter: 34359  total_loss: 2.675  loss_ce: 0.3443  loss_giou: 0.3357  loss_bbox: 0.2932  loss_ce_0: 0.403  loss_giou_0: 0.3491  loss_bbox_0: 0.3226  loss_rpn_cls: 0.2236  loss_rpn_reg: 0.4937  time: 0.1892  last_time: 0.1928  data_time: 0.0052  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:33:44] d2.utils.events INFO:  eta: 1:01:52  iter: 34379  total_loss: 2.961  loss_ce: 0.361  loss_giou: 0.3407  loss_bbox: 0.3225  loss_ce_0: 0.4136  loss_giou_0: 0.3643  loss_bbox_0: 0.3474  loss_rpn_cls: 0.2337  loss_rpn_reg: 0.4744  time: 0.1892  last_time: 0.1998  data_time: 0.0055  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 13:33:48] d2.utils.events INFO:  eta: 1:01:52  iter: 34399  total_loss: 3.011  loss_ce: 0.4281  loss_giou: 0.3357  loss_bbox: 0.3008  loss_ce_0: 0.4673  loss_giou_0: 0.3519  loss_bbox_0: 0.3325  loss_rpn_cls: 0.2519  loss_rpn_reg: 0.4846  time: 0.1892  last_time: 0.2017  data_time: 0.0056  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 13:33:51] d2.utils.events INFO:  eta: 1:01:46  iter: 34419  total_loss: 2.856  loss_ce: 0.4203  loss_giou: 0.334  loss_bbox: 0.296  loss_ce_0: 0.4348  loss_giou_0: 0.36  loss_bbox_0: 0.3055  loss_rpn_cls: 0.2411  loss_rpn_reg: 0.4803  time: 0.1892  last_time: 0.1881  data_time: 0.0051  last_data_time: 0.0055   lr: 5e-05  max_mem: 3029M
[03/05 13:33:55] d2.utils.events INFO:  eta: 1:01:41  iter: 34439  total_loss: 2.697  loss_ce: 0.4279  loss_giou: 0.3308  loss_bbox: 0.2394  loss_ce_0: 0.4341  loss_giou_0: 0.3619  loss_bbox_0: 0.2605  loss_rpn_cls: 0.2309  loss_rpn_reg: 0.4446  time: 0.1892  last_time: 0.1917  data_time: 0.0055  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:33:59] d2.utils.events INFO:  eta: 1:01:41  iter: 34459  total_loss: 2.728  loss_ce: 0.369  loss_giou: 0.3284  loss_bbox: 0.3128  loss_ce_0: 0.4015  loss_giou_0: 0.345  loss_bbox_0: 0.3357  loss_rpn_cls: 0.2245  loss_rpn_reg: 0.469  time: 0.1892  last_time: 0.1816  data_time: 0.0053  last_data_time: 0.0095   lr: 5e-05  max_mem: 3029M
[03/05 13:34:03] d2.utils.events INFO:  eta: 1:01:39  iter: 34479  total_loss: 2.94  loss_ce: 0.4497  loss_giou: 0.3104  loss_bbox: 0.3262  loss_ce_0: 0.4894  loss_giou_0: 0.3264  loss_bbox_0: 0.3467  loss_rpn_cls: 0.26  loss_rpn_reg: 0.4611  time: 0.1892  last_time: 0.2009  data_time: 0.0057  last_data_time: 0.0020   lr: 5e-05  max_mem: 3029M
[03/05 13:34:07] d2.utils.events INFO:  eta: 1:01:33  iter: 34499  total_loss: 2.805  loss_ce: 0.364  loss_giou: 0.3152  loss_bbox: 0.2833  loss_ce_0: 0.4015  loss_giou_0: 0.3501  loss_bbox_0: 0.3401  loss_rpn_cls: 0.2161  loss_rpn_reg: 0.4823  time: 0.1892  last_time: 0.1901  data_time: 0.0048  last_data_time: 0.0035   lr: 5e-05  max_mem: 3029M
[03/05 13:34:11] d2.utils.events INFO:  eta: 1:01:29  iter: 34519  total_loss: 2.692  loss_ce: 0.4422  loss_giou: 0.2864  loss_bbox: 0.262  loss_ce_0: 0.4842  loss_giou_0: 0.2919  loss_bbox_0: 0.2883  loss_rpn_cls: 0.2253  loss_rpn_reg: 0.4422  time: 0.1892  last_time: 0.1930  data_time: 0.0058  last_data_time: 0.0073   lr: 5e-05  max_mem: 3029M
[03/05 13:34:15] d2.utils.events INFO:  eta: 1:01:26  iter: 34539  total_loss: 3.097  loss_ce: 0.4381  loss_giou: 0.3397  loss_bbox: 0.3131  loss_ce_0: 0.4725  loss_giou_0: 0.339  loss_bbox_0: 0.3526  loss_rpn_cls: 0.251  loss_rpn_reg: 0.4681  time: 0.1892  last_time: 0.2068  data_time: 0.0047  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 13:34:19] d2.utils.events INFO:  eta: 1:01:22  iter: 34559  total_loss: 2.935  loss_ce: 0.4012  loss_giou: 0.3215  loss_bbox: 0.2851  loss_ce_0: 0.4764  loss_giou_0: 0.3422  loss_bbox_0: 0.3324  loss_rpn_cls: 0.2084  loss_rpn_reg: 0.4826  time: 0.1892  last_time: 0.1875  data_time: 0.0055  last_data_time: 0.0099   lr: 5e-05  max_mem: 3029M
[03/05 13:34:23] d2.utils.events INFO:  eta: 1:01:22  iter: 34579  total_loss: 2.63  loss_ce: 0.3925  loss_giou: 0.325  loss_bbox: 0.2433  loss_ce_0: 0.3901  loss_giou_0: 0.3621  loss_bbox_0: 0.2767  loss_rpn_cls: 0.2417  loss_rpn_reg: 0.4526  time: 0.1892  last_time: 0.1773  data_time: 0.0048  last_data_time: 0.0066   lr: 5e-05  max_mem: 3029M
[03/05 13:34:26] d2.utils.events INFO:  eta: 1:01:16  iter: 34599  total_loss: 2.967  loss_ce: 0.4354  loss_giou: 0.3554  loss_bbox: 0.2829  loss_ce_0: 0.4188  loss_giou_0: 0.3811  loss_bbox_0: 0.3412  loss_rpn_cls: 0.2371  loss_rpn_reg: 0.4924  time: 0.1892  last_time: 0.1880  data_time: 0.0048  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:34:30] d2.utils.events INFO:  eta: 1:01:11  iter: 34619  total_loss: 2.978  loss_ce: 0.4141  loss_giou: 0.3732  loss_bbox: 0.3112  loss_ce_0: 0.46  loss_giou_0: 0.3903  loss_bbox_0: 0.3303  loss_rpn_cls: 0.233  loss_rpn_reg: 0.5108  time: 0.1892  last_time: 0.1646  data_time: 0.0047  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:34:34] d2.utils.events INFO:  eta: 1:01:07  iter: 34639  total_loss: 2.999  loss_ce: 0.3485  loss_giou: 0.3505  loss_bbox: 0.286  loss_ce_0: 0.3776  loss_giou_0: 0.3695  loss_bbox_0: 0.3365  loss_rpn_cls: 0.2417  loss_rpn_reg: 0.4969  time: 0.1892  last_time: 0.1678  data_time: 0.0051  last_data_time: 0.0060   lr: 5e-05  max_mem: 3029M
[03/05 13:34:38] d2.utils.events INFO:  eta: 1:01:07  iter: 34659  total_loss: 2.93  loss_ce: 0.4504  loss_giou: 0.3208  loss_bbox: 0.277  loss_ce_0: 0.4241  loss_giou_0: 0.3289  loss_bbox_0: 0.2969  loss_rpn_cls: 0.2373  loss_rpn_reg: 0.4582  time: 0.1892  last_time: 0.2254  data_time: 0.0053  last_data_time: 0.0081   lr: 5e-05  max_mem: 3029M
[03/05 13:34:42] d2.utils.events INFO:  eta: 1:01:03  iter: 34679  total_loss: 3.292  loss_ce: 0.4794  loss_giou: 0.372  loss_bbox: 0.3168  loss_ce_0: 0.5079  loss_giou_0: 0.384  loss_bbox_0: 0.3309  loss_rpn_cls: 0.25  loss_rpn_reg: 0.4999  time: 0.1892  last_time: 0.1920  data_time: 0.0065  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 13:34:45] d2.utils.events INFO:  eta: 1:00:59  iter: 34699  total_loss: 2.871  loss_ce: 0.4572  loss_giou: 0.2845  loss_bbox: 0.2941  loss_ce_0: 0.4545  loss_giou_0: 0.3193  loss_bbox_0: 0.3335  loss_rpn_cls: 0.2611  loss_rpn_reg: 0.4485  time: 0.1892  last_time: 0.2011  data_time: 0.0057  last_data_time: 0.0053   lr: 5e-05  max_mem: 3029M
[03/05 13:34:49] d2.utils.events INFO:  eta: 1:00:59  iter: 34719  total_loss: 2.945  loss_ce: 0.4652  loss_giou: 0.3538  loss_bbox: 0.2817  loss_ce_0: 0.5016  loss_giou_0: 0.3696  loss_bbox_0: 0.3126  loss_rpn_cls: 0.2263  loss_rpn_reg: 0.4963  time: 0.1892  last_time: 0.2069  data_time: 0.0049  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:34:53] d2.utils.events INFO:  eta: 1:00:57  iter: 34739  total_loss: 2.751  loss_ce: 0.3993  loss_giou: 0.3118  loss_bbox: 0.2556  loss_ce_0: 0.4104  loss_giou_0: 0.3287  loss_bbox_0: 0.3078  loss_rpn_cls: 0.1987  loss_rpn_reg: 0.4534  time: 0.1892  last_time: 0.1873  data_time: 0.0051  last_data_time: 0.0074   lr: 5e-05  max_mem: 3029M
[03/05 13:34:57] d2.utils.events INFO:  eta: 1:00:57  iter: 34759  total_loss: 3.029  loss_ce: 0.4733  loss_giou: 0.3478  loss_bbox: 0.3126  loss_ce_0: 0.521  loss_giou_0: 0.3719  loss_bbox_0: 0.3327  loss_rpn_cls: 0.2284  loss_rpn_reg: 0.4897  time: 0.1892  last_time: 0.1845  data_time: 0.0054  last_data_time: 0.0072   lr: 5e-05  max_mem: 3029M
[03/05 13:35:01] d2.utils.events INFO:  eta: 1:00:52  iter: 34779  total_loss: 2.752  loss_ce: 0.3665  loss_giou: 0.3082  loss_bbox: 0.2753  loss_ce_0: 0.3952  loss_giou_0: 0.3425  loss_bbox_0: 0.3082  loss_rpn_cls: 0.2423  loss_rpn_reg: 0.4803  time: 0.1892  last_time: 0.1964  data_time: 0.0048  last_data_time: 0.0092   lr: 5e-05  max_mem: 3029M
[03/05 13:35:05] d2.utils.events INFO:  eta: 1:00:46  iter: 34799  total_loss: 2.909  loss_ce: 0.4228  loss_giou: 0.361  loss_bbox: 0.294  loss_ce_0: 0.4638  loss_giou_0: 0.3638  loss_bbox_0: 0.3103  loss_rpn_cls: 0.2313  loss_rpn_reg: 0.4763  time: 0.1892  last_time: 0.1866  data_time: 0.0058  last_data_time: 0.0065   lr: 5e-05  max_mem: 3029M
[03/05 13:35:09] d2.utils.events INFO:  eta: 1:00:41  iter: 34819  total_loss: 2.843  loss_ce: 0.4104  loss_giou: 0.3046  loss_bbox: 0.3018  loss_ce_0: 0.4363  loss_giou_0: 0.3359  loss_bbox_0: 0.3126  loss_rpn_cls: 0.2155  loss_rpn_reg: 0.4754  time: 0.1892  last_time: 0.1796  data_time: 0.0048  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:35:13] d2.utils.events INFO:  eta: 1:00:38  iter: 34839  total_loss: 2.879  loss_ce: 0.3761  loss_giou: 0.3521  loss_bbox: 0.2944  loss_ce_0: 0.4002  loss_giou_0: 0.3853  loss_bbox_0: 0.3027  loss_rpn_cls: 0.229  loss_rpn_reg: 0.4936  time: 0.1892  last_time: 0.2030  data_time: 0.0047  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 13:35:16] d2.utils.events INFO:  eta: 1:00:30  iter: 34859  total_loss: 2.89  loss_ce: 0.442  loss_giou: 0.3438  loss_bbox: 0.276  loss_ce_0: 0.4864  loss_giou_0: 0.3678  loss_bbox_0: 0.2859  loss_rpn_cls: 0.2274  loss_rpn_reg: 0.4755  time: 0.1892  last_time: 0.1594  data_time: 0.0049  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:35:20] d2.utils.events INFO:  eta: 1:00:25  iter: 34879  total_loss: 2.91  loss_ce: 0.438  loss_giou: 0.3352  loss_bbox: 0.2931  loss_ce_0: 0.4453  loss_giou_0: 0.3776  loss_bbox_0: 0.3437  loss_rpn_cls: 0.2104  loss_rpn_reg: 0.4969  time: 0.1892  last_time: 0.1792  data_time: 0.0051  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:35:24] d2.utils.events INFO:  eta: 1:00:20  iter: 34899  total_loss: 2.92  loss_ce: 0.444  loss_giou: 0.3262  loss_bbox: 0.2847  loss_ce_0: 0.4619  loss_giou_0: 0.3537  loss_bbox_0: 0.3112  loss_rpn_cls: 0.2069  loss_rpn_reg: 0.5143  time: 0.1892  last_time: 0.1863  data_time: 0.0053  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:35:28] d2.utils.events INFO:  eta: 1:00:17  iter: 34919  total_loss: 2.982  loss_ce: 0.4207  loss_giou: 0.3682  loss_bbox: 0.2884  loss_ce_0: 0.4489  loss_giou_0: 0.3986  loss_bbox_0: 0.3123  loss_rpn_cls: 0.2521  loss_rpn_reg: 0.5224  time: 0.1892  last_time: 0.1558  data_time: 0.0047  last_data_time: 0.0033   lr: 5e-05  max_mem: 3029M
[03/05 13:35:32] d2.utils.events INFO:  eta: 1:00:13  iter: 34939  total_loss: 3.099  loss_ce: 0.4809  loss_giou: 0.3315  loss_bbox: 0.355  loss_ce_0: 0.5152  loss_giou_0: 0.3446  loss_bbox_0: 0.3915  loss_rpn_cls: 0.2279  loss_rpn_reg: 0.4878  time: 0.1892  last_time: 0.1675  data_time: 0.0052  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:35:35] d2.utils.events INFO:  eta: 1:00:07  iter: 34959  total_loss: 2.928  loss_ce: 0.4175  loss_giou: 0.3675  loss_bbox: 0.2914  loss_ce_0: 0.4522  loss_giou_0: 0.3651  loss_bbox_0: 0.325  loss_rpn_cls: 0.2542  loss_rpn_reg: 0.4601  time: 0.1892  last_time: 0.1731  data_time: 0.0050  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:35:39] d2.utils.events INFO:  eta: 1:00:05  iter: 34979  total_loss: 2.841  loss_ce: 0.4489  loss_giou: 0.3103  loss_bbox: 0.2639  loss_ce_0: 0.4749  loss_giou_0: 0.3418  loss_bbox_0: 0.3403  loss_rpn_cls: 0.2292  loss_rpn_reg: 0.4598  time: 0.1892  last_time: 0.1905  data_time: 0.0053  last_data_time: 0.0091   lr: 5e-05  max_mem: 3029M
[03/05 13:35:43] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/t1/model_0034999.pth
[03/05 13:35:44] d2.utils.events INFO:  eta: 1:00:00  iter: 34999  total_loss: 2.653  loss_ce: 0.376  loss_giou: 0.2923  loss_bbox: 0.2556  loss_ce_0: 0.4117  loss_giou_0: 0.3257  loss_bbox_0: 0.2779  loss_rpn_cls: 0.2239  loss_rpn_reg: 0.4596  time: 0.1892  last_time: 0.1896  data_time: 0.0050  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:35:48] d2.utils.events INFO:  eta: 0:59:55  iter: 35019  total_loss: 2.753  loss_ce: 0.3707  loss_giou: 0.312  loss_bbox: 0.3101  loss_ce_0: 0.4171  loss_giou_0: 0.3327  loss_bbox_0: 0.3288  loss_rpn_cls: 0.2195  loss_rpn_reg: 0.4492  time: 0.1892  last_time: 0.1925  data_time: 0.0056  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:35:52] d2.utils.events INFO:  eta: 0:59:51  iter: 35039  total_loss: 3.065  loss_ce: 0.4063  loss_giou: 0.3711  loss_bbox: 0.2914  loss_ce_0: 0.4157  loss_giou_0: 0.3815  loss_bbox_0: 0.3186  loss_rpn_cls: 0.2329  loss_rpn_reg: 0.5063  time: 0.1892  last_time: 0.2059  data_time: 0.0046  last_data_time: 0.0020   lr: 5e-05  max_mem: 3029M
[03/05 13:35:56] d2.utils.events INFO:  eta: 0:59:51  iter: 35059  total_loss: 2.748  loss_ce: 0.3146  loss_giou: 0.3095  loss_bbox: 0.2468  loss_ce_0: 0.3318  loss_giou_0: 0.3474  loss_bbox_0: 0.3067  loss_rpn_cls: 0.1976  loss_rpn_reg: 0.5143  time: 0.1892  last_time: 0.1906  data_time: 0.0057  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 13:36:00] d2.utils.events INFO:  eta: 0:59:45  iter: 35079  total_loss: 2.992  loss_ce: 0.3979  loss_giou: 0.4029  loss_bbox: 0.2404  loss_ce_0: 0.4455  loss_giou_0: 0.4229  loss_bbox_0: 0.288  loss_rpn_cls: 0.2487  loss_rpn_reg: 0.4932  time: 0.1892  last_time: 0.1877  data_time: 0.0053  last_data_time: 0.0057   lr: 5e-05  max_mem: 3029M
[03/05 13:36:04] d2.utils.events INFO:  eta: 0:59:43  iter: 35099  total_loss: 2.968  loss_ce: 0.4241  loss_giou: 0.3249  loss_bbox: 0.2361  loss_ce_0: 0.4949  loss_giou_0: 0.3573  loss_bbox_0: 0.2811  loss_rpn_cls: 0.2648  loss_rpn_reg: 0.4547  time: 0.1892  last_time: 0.1989  data_time: 0.0053  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:36:08] d2.utils.events INFO:  eta: 0:59:40  iter: 35119  total_loss: 3.195  loss_ce: 0.5074  loss_giou: 0.3291  loss_bbox: 0.2735  loss_ce_0: 0.4998  loss_giou_0: 0.3887  loss_bbox_0: 0.3252  loss_rpn_cls: 0.2392  loss_rpn_reg: 0.4908  time: 0.1892  last_time: 0.2022  data_time: 0.0053  last_data_time: 0.0045   lr: 5e-05  max_mem: 3029M
[03/05 13:36:11] d2.utils.events INFO:  eta: 0:59:35  iter: 35139  total_loss: 2.938  loss_ce: 0.4225  loss_giou: 0.3526  loss_bbox: 0.2685  loss_ce_0: 0.4228  loss_giou_0: 0.3798  loss_bbox_0: 0.2723  loss_rpn_cls: 0.2296  loss_rpn_reg: 0.496  time: 0.1892  last_time: 0.1837  data_time: 0.0048  last_data_time: 0.0072   lr: 5e-05  max_mem: 3029M
[03/05 13:36:15] d2.utils.events INFO:  eta: 0:59:30  iter: 35159  total_loss: 2.768  loss_ce: 0.3961  loss_giou: 0.3624  loss_bbox: 0.2916  loss_ce_0: 0.4008  loss_giou_0: 0.3649  loss_bbox_0: 0.2867  loss_rpn_cls: 0.2402  loss_rpn_reg: 0.4704  time: 0.1892  last_time: 0.1930  data_time: 0.0054  last_data_time: 0.0022   lr: 5e-05  max_mem: 3029M
[03/05 13:36:19] d2.utils.events INFO:  eta: 0:59:27  iter: 35179  total_loss: 2.715  loss_ce: 0.4158  loss_giou: 0.3371  loss_bbox: 0.2674  loss_ce_0: 0.3994  loss_giou_0: 0.3629  loss_bbox_0: 0.3033  loss_rpn_cls: 0.2225  loss_rpn_reg: 0.4624  time: 0.1892  last_time: 0.2003  data_time: 0.0055  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:36:23] d2.utils.events INFO:  eta: 0:59:24  iter: 35199  total_loss: 2.819  loss_ce: 0.3804  loss_giou: 0.3287  loss_bbox: 0.2493  loss_ce_0: 0.4162  loss_giou_0: 0.3485  loss_bbox_0: 0.2707  loss_rpn_cls: 0.2087  loss_rpn_reg: 0.4844  time: 0.1892  last_time: 0.1769  data_time: 0.0060  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:36:27] d2.utils.events INFO:  eta: 0:59:17  iter: 35219  total_loss: 2.867  loss_ce: 0.388  loss_giou: 0.3367  loss_bbox: 0.2962  loss_ce_0: 0.4212  loss_giou_0: 0.3487  loss_bbox_0: 0.3682  loss_rpn_cls: 0.2238  loss_rpn_reg: 0.4987  time: 0.1892  last_time: 0.1662  data_time: 0.0050  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 13:36:31] d2.utils.events INFO:  eta: 0:59:13  iter: 35239  total_loss: 2.718  loss_ce: 0.3643  loss_giou: 0.2879  loss_bbox: 0.318  loss_ce_0: 0.4056  loss_giou_0: 0.3238  loss_bbox_0: 0.3538  loss_rpn_cls: 0.2053  loss_rpn_reg: 0.4552  time: 0.1892  last_time: 0.2037  data_time: 0.0049  last_data_time: 0.0048   lr: 5e-05  max_mem: 3029M
[03/05 13:36:34] d2.utils.events INFO:  eta: 0:59:07  iter: 35259  total_loss: 2.737  loss_ce: 0.4137  loss_giou: 0.3195  loss_bbox: 0.2969  loss_ce_0: 0.4381  loss_giou_0: 0.3446  loss_bbox_0: 0.3295  loss_rpn_cls: 0.2441  loss_rpn_reg: 0.4506  time: 0.1892  last_time: 0.2152  data_time: 0.0053  last_data_time: 0.0071   lr: 5e-05  max_mem: 3029M
[03/05 13:36:38] d2.utils.events INFO:  eta: 0:59:06  iter: 35279  total_loss: 2.766  loss_ce: 0.384  loss_giou: 0.3622  loss_bbox: 0.2422  loss_ce_0: 0.3839  loss_giou_0: 0.3894  loss_bbox_0: 0.2779  loss_rpn_cls: 0.2195  loss_rpn_reg: 0.4968  time: 0.1892  last_time: 0.2127  data_time: 0.0053  last_data_time: 0.0063   lr: 5e-05  max_mem: 3029M
[03/05 13:36:42] d2.utils.events INFO:  eta: 0:59:02  iter: 35299  total_loss: 3.073  loss_ce: 0.426  loss_giou: 0.3589  loss_bbox: 0.2743  loss_ce_0: 0.4836  loss_giou_0: 0.3824  loss_bbox_0: 0.3416  loss_rpn_cls: 0.2451  loss_rpn_reg: 0.4769  time: 0.1892  last_time: 0.2002  data_time: 0.0052  last_data_time: 0.0084   lr: 5e-05  max_mem: 3029M
[03/05 13:36:46] d2.utils.events INFO:  eta: 0:58:58  iter: 35319  total_loss: 2.823  loss_ce: 0.4371  loss_giou: 0.2997  loss_bbox: 0.2813  loss_ce_0: 0.4426  loss_giou_0: 0.3161  loss_bbox_0: 0.2989  loss_rpn_cls: 0.224  loss_rpn_reg: 0.4525  time: 0.1892  last_time: 0.1793  data_time: 0.0049  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:36:50] d2.utils.events INFO:  eta: 0:58:54  iter: 35339  total_loss: 2.95  loss_ce: 0.4488  loss_giou: 0.3744  loss_bbox: 0.2673  loss_ce_0: 0.4532  loss_giou_0: 0.3646  loss_bbox_0: 0.3079  loss_rpn_cls: 0.2472  loss_rpn_reg: 0.5012  time: 0.1892  last_time: 0.2271  data_time: 0.0048  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 13:36:54] d2.utils.events INFO:  eta: 0:58:51  iter: 35359  total_loss: 3.004  loss_ce: 0.4297  loss_giou: 0.3496  loss_bbox: 0.3188  loss_ce_0: 0.466  loss_giou_0: 0.3702  loss_bbox_0: 0.3539  loss_rpn_cls: 0.2409  loss_rpn_reg: 0.4909  time: 0.1892  last_time: 0.2081  data_time: 0.0051  last_data_time: 0.0062   lr: 5e-05  max_mem: 3029M
[03/05 13:36:58] d2.utils.events INFO:  eta: 0:58:47  iter: 35379  total_loss: 2.929  loss_ce: 0.4725  loss_giou: 0.3853  loss_bbox: 0.2918  loss_ce_0: 0.4441  loss_giou_0: 0.3977  loss_bbox_0: 0.3538  loss_rpn_cls: 0.2402  loss_rpn_reg: 0.4951  time: 0.1892  last_time: 0.1903  data_time: 0.0051  last_data_time: 0.0036   lr: 5e-05  max_mem: 3029M
[03/05 13:37:01] d2.utils.events INFO:  eta: 0:58:42  iter: 35399  total_loss: 3.12  loss_ce: 0.4297  loss_giou: 0.3858  loss_bbox: 0.2577  loss_ce_0: 0.4647  loss_giou_0: 0.4152  loss_bbox_0: 0.3052  loss_rpn_cls: 0.2771  loss_rpn_reg: 0.4951  time: 0.1892  last_time: 0.1925  data_time: 0.0051  last_data_time: 0.0097   lr: 5e-05  max_mem: 3029M
[03/05 13:37:05] d2.utils.events INFO:  eta: 0:58:39  iter: 35419  total_loss: 2.765  loss_ce: 0.413  loss_giou: 0.3225  loss_bbox: 0.2831  loss_ce_0: 0.4195  loss_giou_0: 0.3566  loss_bbox_0: 0.3396  loss_rpn_cls: 0.2575  loss_rpn_reg: 0.4937  time: 0.1892  last_time: 0.1953  data_time: 0.0050  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:37:09] d2.utils.events INFO:  eta: 0:58:36  iter: 35439  total_loss: 2.943  loss_ce: 0.3747  loss_giou: 0.3293  loss_bbox: 0.3112  loss_ce_0: 0.4261  loss_giou_0: 0.3732  loss_bbox_0: 0.3633  loss_rpn_cls: 0.2062  loss_rpn_reg: 0.4734  time: 0.1892  last_time: 0.1856  data_time: 0.0051  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:37:13] d2.utils.events INFO:  eta: 0:58:31  iter: 35459  total_loss: 2.966  loss_ce: 0.4422  loss_giou: 0.306  loss_bbox: 0.3037  loss_ce_0: 0.4614  loss_giou_0: 0.3448  loss_bbox_0: 0.3434  loss_rpn_cls: 0.226  loss_rpn_reg: 0.4547  time: 0.1892  last_time: 0.1934  data_time: 0.0050  last_data_time: 0.0043   lr: 5e-05  max_mem: 3029M
[03/05 13:37:17] d2.utils.events INFO:  eta: 0:58:26  iter: 35479  total_loss: 3.049  loss_ce: 0.3814  loss_giou: 0.3595  loss_bbox: 0.3164  loss_ce_0: 0.4514  loss_giou_0: 0.3935  loss_bbox_0: 0.3642  loss_rpn_cls: 0.2624  loss_rpn_reg: 0.4998  time: 0.1892  last_time: 0.1896  data_time: 0.0050  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:37:21] d2.utils.events INFO:  eta: 0:58:22  iter: 35499  total_loss: 3.002  loss_ce: 0.3935  loss_giou: 0.3363  loss_bbox: 0.2721  loss_ce_0: 0.4877  loss_giou_0: 0.3663  loss_bbox_0: 0.3319  loss_rpn_cls: 0.2574  loss_rpn_reg: 0.4783  time: 0.1892  last_time: 0.1793  data_time: 0.0051  last_data_time: 0.0052   lr: 5e-05  max_mem: 3029M
[03/05 13:37:25] d2.utils.events INFO:  eta: 0:58:18  iter: 35519  total_loss: 2.61  loss_ce: 0.3776  loss_giou: 0.2995  loss_bbox: 0.2597  loss_ce_0: 0.4574  loss_giou_0: 0.3161  loss_bbox_0: 0.2844  loss_rpn_cls: 0.2415  loss_rpn_reg: 0.4697  time: 0.1892  last_time: 0.1995  data_time: 0.0056  last_data_time: 0.0040   lr: 5e-05  max_mem: 3029M
[03/05 13:37:28] d2.utils.events INFO:  eta: 0:58:15  iter: 35539  total_loss: 3.233  loss_ce: 0.4663  loss_giou: 0.3643  loss_bbox: 0.3185  loss_ce_0: 0.4831  loss_giou_0: 0.3863  loss_bbox_0: 0.3529  loss_rpn_cls: 0.2519  loss_rpn_reg: 0.5125  time: 0.1892  last_time: 0.2299  data_time: 0.0046  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 13:37:32] d2.utils.events INFO:  eta: 0:58:13  iter: 35559  total_loss: 2.812  loss_ce: 0.3523  loss_giou: 0.3058  loss_bbox: 0.2907  loss_ce_0: 0.4265  loss_giou_0: 0.3379  loss_bbox_0: 0.3167  loss_rpn_cls: 0.2388  loss_rpn_reg: 0.4689  time: 0.1892  last_time: 0.1813  data_time: 0.0050  last_data_time: 0.0068   lr: 5e-05  max_mem: 3029M
[03/05 13:37:36] d2.utils.events INFO:  eta: 0:58:05  iter: 35579  total_loss: 3.031  loss_ce: 0.4452  loss_giou: 0.3182  loss_bbox: 0.284  loss_ce_0: 0.4568  loss_giou_0: 0.3396  loss_bbox_0: 0.3005  loss_rpn_cls: 0.1985  loss_rpn_reg: 0.4768  time: 0.1892  last_time: 0.1807  data_time: 0.0053  last_data_time: 0.0077   lr: 5e-05  max_mem: 3029M
[03/05 13:37:40] d2.utils.events INFO:  eta: 0:57:58  iter: 35599  total_loss: 2.87  loss_ce: 0.4618  loss_giou: 0.311  loss_bbox: 0.2669  loss_ce_0: 0.4766  loss_giou_0: 0.3323  loss_bbox_0: 0.3222  loss_rpn_cls: 0.2163  loss_rpn_reg: 0.4762  time: 0.1892  last_time: 0.1731  data_time: 0.0048  last_data_time: 0.0056   lr: 5e-05  max_mem: 3029M
[03/05 13:37:43] d2.utils.events INFO:  eta: 0:57:49  iter: 35619  total_loss: 2.765  loss_ce: 0.4226  loss_giou: 0.3398  loss_bbox: 0.2739  loss_ce_0: 0.4331  loss_giou_0: 0.356  loss_bbox_0: 0.2796  loss_rpn_cls: 0.2118  loss_rpn_reg: 0.4591  time: 0.1892  last_time: 0.1712  data_time: 0.0048  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:37:48] d2.utils.events INFO:  eta: 0:57:45  iter: 35639  total_loss: 2.695  loss_ce: 0.4259  loss_giou: 0.2792  loss_bbox: 0.257  loss_ce_0: 0.4415  loss_giou_0: 0.3043  loss_bbox_0: 0.2823  loss_rpn_cls: 0.1953  loss_rpn_reg: 0.4363  time: 0.1892  last_time: 0.2240  data_time: 0.0052  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 13:37:51] d2.utils.events INFO:  eta: 0:57:40  iter: 35659  total_loss: 2.732  loss_ce: 0.4046  loss_giou: 0.3017  loss_bbox: 0.2526  loss_ce_0: 0.4031  loss_giou_0: 0.3323  loss_bbox_0: 0.2926  loss_rpn_cls: 0.226  loss_rpn_reg: 0.466  time: 0.1892  last_time: 0.1697  data_time: 0.0060  last_data_time: 0.0041   lr: 5e-05  max_mem: 3029M
[03/05 13:37:55] d2.utils.events INFO:  eta: 0:57:38  iter: 35679  total_loss: 2.935  loss_ce: 0.4158  loss_giou: 0.3059  loss_bbox: 0.3002  loss_ce_0: 0.4796  loss_giou_0: 0.3695  loss_bbox_0: 0.3869  loss_rpn_cls: 0.2144  loss_rpn_reg: 0.4863  time: 0.1892  last_time: 0.1994  data_time: 0.0046  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:37:59] d2.utils.events INFO:  eta: 0:57:34  iter: 35699  total_loss: 2.669  loss_ce: 0.4792  loss_giou: 0.2646  loss_bbox: 0.2403  loss_ce_0: 0.4733  loss_giou_0: 0.2894  loss_bbox_0: 0.2636  loss_rpn_cls: 0.2075  loss_rpn_reg: 0.4798  time: 0.1892  last_time: 0.1979  data_time: 0.0058  last_data_time: 0.0087   lr: 5e-05  max_mem: 3029M
[03/05 13:38:03] d2.utils.events INFO:  eta: 0:57:29  iter: 35719  total_loss: 3.24  loss_ce: 0.5022  loss_giou: 0.3107  loss_bbox: 0.3237  loss_ce_0: 0.5329  loss_giou_0: 0.3558  loss_bbox_0: 0.3405  loss_rpn_cls: 0.2656  loss_rpn_reg: 0.5242  time: 0.1892  last_time: 0.1987  data_time: 0.0049  last_data_time: 0.0042   lr: 5e-05  max_mem: 3029M
[03/05 13:38:07] d2.utils.events INFO:  eta: 0:57:24  iter: 35739  total_loss: 3.051  loss_ce: 0.4388  loss_giou: 0.3378  loss_bbox: 0.2913  loss_ce_0: 0.4072  loss_giou_0: 0.345  loss_bbox_0: 0.3184  loss_rpn_cls: 0.2142  loss_rpn_reg: 0.4932  time: 0.1892  last_time: 0.1907  data_time: 0.0049  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:38:11] d2.utils.events INFO:  eta: 0:57:19  iter: 35759  total_loss: 2.935  loss_ce: 0.4363  loss_giou: 0.3993  loss_bbox: 0.2678  loss_ce_0: 0.4456  loss_giou_0: 0.3994  loss_bbox_0: 0.3184  loss_rpn_cls: 0.2393  loss_rpn_reg: 0.4822  time: 0.1892  last_time: 0.1969  data_time: 0.0046  last_data_time: 0.0047   lr: 5e-05  max_mem: 3029M
[03/05 13:38:14] d2.utils.events INFO:  eta: 0:57:16  iter: 35779  total_loss: 2.993  loss_ce: 0.5024  loss_giou: 0.3783  loss_bbox: 0.2974  loss_ce_0: 0.517  loss_giou_0: 0.3931  loss_bbox_0: 0.3609  loss_rpn_cls: 0.2399  loss_rpn_reg: 0.5338  time: 0.1892  last_time: 0.1962  data_time: 0.0049  last_data_time: 0.0046   lr: 5e-05  max_mem: 3029M
[03/05 13:38:18] d2.utils.events INFO:  eta: 0:57:09  iter: 35799  total_loss: 2.733  loss_ce: 0.3979  loss_giou: 0.3632  loss_bbox: 0.2634  loss_ce_0: 0.468  loss_giou_0: 0.3813  loss_bbox_0: 0.2892  loss_rpn_cls: 0.2251  loss_rpn_reg: 0.4854  time: 0.1892  last_time: 0.1975  data_time: 0.0052  last_data_time: 0.0038   lr: 5e-05  max_mem: 3029M
[03/05 13:38:22] d2.utils.events INFO:  eta: 0:57:05  iter: 35819  total_loss: 2.684  loss_ce: 0.4105  loss_giou: 0.2991  loss_bbox: 0.3004  loss_ce_0: 0.4229  loss_giou_0: 0.3287  loss_bbox_0: 0.3151  loss_rpn_cls: 0.2025  loss_rpn_reg: 0.4721  time: 0.1892  last_time: 0.1827  data_time: 0.0056  last_data_time: 0.0061   lr: 5e-05  max_mem: 3029M
[03/05 13:38:26] d2.utils.events INFO:  eta: 0:57:02  iter: 35839  total_loss: 2.764  loss_ce: 0.409  loss_giou: 0.3316  loss_bbox: 0.2468  loss_ce_0: 0.4192  loss_giou_0: 0.3539  loss_bbox_0: 0.2524  loss_rpn_cls: 0.182  loss_rpn_reg: 0.4682  time: 0.1892  last_time: 0.1982  data_time: 0.0051  last_data_time: 0.0049   lr: 5e-05  max_mem: 3029M
[03/05 13:38:30] d2.utils.events INFO:  eta: 0:57:00  iter: 35859  total_loss: 2.683  loss_ce: 0.4239  loss_giou: 0.265  loss_bbox: 0.2601  loss_ce_0: 0.4585  loss_giou_0: 0.3062  loss_bbox_0: 0.3107  loss_rpn_cls: 0.198  loss_rpn_reg: 0.4733  time: 0.1892  last_time: 0.1830  data_time: 0.0061  last_data_time: 0.0129   lr: 5e-05  max_mem: 3029M
[03/05 13:38:33] d2.utils.events INFO:  eta: 0:57:00  iter: 35879  total_loss: 2.918  loss_ce: 0.454  loss_giou: 0.3126  loss_bbox: 0.2711  loss_ce_0: 0.4945  loss_giou_0: 0.3559  loss_bbox_0: 0.2919  loss_rpn_cls: 0.2352  loss_rpn_reg: 0.4754  time: 0.1892  last_time: 0.1786  data_time: 0.0048  last_data_time: 0.0044   lr: 5e-05  max_mem: 3029M
[03/05 13:38:37] d2.utils.events INFO:  eta: 0:56:56  iter: 35899  total_loss: 2.897  loss_ce: 0.5083  loss_giou: 0.3113  loss_bbox: 0.2686  loss_ce_0: 0.5346  loss_giou_0: 0.35  loss_bbox_0: 0.3041  loss_rpn_cls: 0.2191  loss_rpn_reg: 0.471  time: 0.1892  last_time: 0.1777  data_time: 0.0051  last_data_time: 0.0051   lr: 5e-05  max_mem: 3029M
[03/05 13:38:41] d2.utils.events INFO:  eta: 0:56:53  iter: 35919  total_loss: 2.64  loss_ce: 0.358  loss_giou: 0.291  loss_bbox: 0.2404  loss_ce_0: 0.4398  loss_giou_0: 0.3043  loss_bbox_0: 0.256  loss_rpn_cls: 0.2024  loss_rpn_reg: 0.422  time: 0.1892  last_time: 0.1750  data_time: 0.0054  last_data_time: 0.0037   lr: 5e-05  max_mem: 3029M
[03/05 13:38:45] d2.utils.events INFO:  eta: 0:56:47  iter: 35939  total_loss: 2.793  loss_ce: 0.3591  loss_giou: 0.3416  loss_bbox: 0.2621  loss_ce_0: 0.4088  loss_giou_0: 0.384  loss_bbox_0: 0.336  loss_rpn_cls: 0.2198  loss_rpn_reg: 0.4592  time: 0.1892  last_time: 0.2004  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:38:49] d2.utils.events INFO:  eta: 0:56:39  iter: 35959  total_loss: 3.156  loss_ce: 0.5187  loss_giou: 0.3384  loss_bbox: 0.2602  loss_ce_0: 0.5118  loss_giou_0: 0.3586  loss_bbox_0: 0.3283  loss_rpn_cls: 0.2366  loss_rpn_reg: 0.4958  time: 0.1892  last_time: 0.1680  data_time: 0.0052  last_data_time: 0.0039   lr: 5e-05  max_mem: 3029M
[03/05 13:38:52] d2.utils.events INFO:  eta: 0:56:32  iter: 35979  total_loss: 2.974  loss_ce: 0.4771  loss_giou: 0.3767  loss_bbox: 0.2302  loss_ce_0: 0.4577  loss_giou_0: 0.415  loss_bbox_0: 0.2683  loss_rpn_cls: 0.2202  loss_rpn_reg: 0.475  time: 0.1892  last_time: 0.1804  data_time: 0.0049  last_data_time: 0.0076   lr: 5e-05  max_mem: 3029M
[03/05 13:38:56] d2.utils.events INFO:  eta: 0:56:30  iter: 35999  total_loss: 3.054  loss_ce: 0.4147  loss_giou: 0.3278  loss_bbox: 0.2655  loss_ce_0: 0.4655  loss_giou_0: 0.3628  loss_bbox_0: 0.3174  loss_rpn_cls: 0.2461  loss_rpn_reg: 0.4974  time: 0.1892  last_time: 0.1848  data_time: 0.0047  last_data_time: 0.0058   lr: 5e-05  max_mem: 3029M
[03/05 13:39:00] d2.utils.events INFO:  eta: 0:56:28  iter: 36019  total_loss: 3.04  loss_ce: 0.4691  loss_giou: 0.3058  loss_bbox: 0.2834  loss_ce_0: 0.5215  loss_giou_0: 0.3211  loss_bbox_0: 0.3006  loss_rpn_cls: 0.2339  loss_rpn_reg: 0.4644  time: 0.1892  last_time: 0.1829  data_time: 0.0054  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 13:39:04] d2.utils.events INFO:  eta: 0:56:26  iter: 36039  total_loss: 3.137  loss_ce: 0.4112  loss_giou: 0.3381  loss_bbox: 0.3078  loss_ce_0: 0.4811  loss_giou_0: 0.3477  loss_bbox_0: 0.3587  loss_rpn_cls: 0.2381  loss_rpn_reg: 0.4875  time: 0.1892  last_time: 0.1937  data_time: 0.0049  last_data_time: 0.0035   lr: 5e-06  max_mem: 3029M
[03/05 13:39:08] d2.utils.events INFO:  eta: 0:56:19  iter: 36059  total_loss: 2.704  loss_ce: 0.3842  loss_giou: 0.3239  loss_bbox: 0.234  loss_ce_0: 0.4432  loss_giou_0: 0.3411  loss_bbox_0: 0.2625  loss_rpn_cls: 0.226  loss_rpn_reg: 0.4807  time: 0.1892  last_time: 0.1938  data_time: 0.0047  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 13:39:11] d2.utils.events INFO:  eta: 0:56:14  iter: 36079  total_loss: 2.442  loss_ce: 0.3039  loss_giou: 0.2698  loss_bbox: 0.2575  loss_ce_0: 0.3478  loss_giou_0: 0.2799  loss_bbox_0: 0.2884  loss_rpn_cls: 0.1874  loss_rpn_reg: 0.4393  time: 0.1892  last_time: 0.1674  data_time: 0.0049  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 13:39:15] d2.utils.events INFO:  eta: 0:56:07  iter: 36099  total_loss: 2.706  loss_ce: 0.3669  loss_giou: 0.3118  loss_bbox: 0.2754  loss_ce_0: 0.4374  loss_giou_0: 0.3443  loss_bbox_0: 0.3312  loss_rpn_cls: 0.2084  loss_rpn_reg: 0.475  time: 0.1892  last_time: 0.1984  data_time: 0.0050  last_data_time: 0.0066   lr: 5e-06  max_mem: 3029M
[03/05 13:39:19] d2.utils.events INFO:  eta: 0:56:02  iter: 36119  total_loss: 2.699  loss_ce: 0.3679  loss_giou: 0.3179  loss_bbox: 0.2898  loss_ce_0: 0.4334  loss_giou_0: 0.3572  loss_bbox_0: 0.3279  loss_rpn_cls: 0.2175  loss_rpn_reg: 0.5072  time: 0.1892  last_time: 0.1731  data_time: 0.0048  last_data_time: 0.0027   lr: 5e-06  max_mem: 3029M
[03/05 13:39:23] d2.utils.events INFO:  eta: 0:55:57  iter: 36139  total_loss: 2.652  loss_ce: 0.3417  loss_giou: 0.3336  loss_bbox: 0.2798  loss_ce_0: 0.3843  loss_giou_0: 0.3315  loss_bbox_0: 0.2823  loss_rpn_cls: 0.2034  loss_rpn_reg: 0.4244  time: 0.1892  last_time: 0.1997  data_time: 0.0052  last_data_time: 0.0059   lr: 5e-06  max_mem: 3029M
[03/05 13:39:27] d2.utils.events INFO:  eta: 0:55:49  iter: 36159  total_loss: 2.62  loss_ce: 0.3399  loss_giou: 0.3014  loss_bbox: 0.2595  loss_ce_0: 0.3749  loss_giou_0: 0.3143  loss_bbox_0: 0.2839  loss_rpn_cls: 0.2128  loss_rpn_reg: 0.4517  time: 0.1892  last_time: 0.1855  data_time: 0.0045  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 13:39:30] d2.utils.events INFO:  eta: 0:55:44  iter: 36179  total_loss: 2.912  loss_ce: 0.4447  loss_giou: 0.3746  loss_bbox: 0.3074  loss_ce_0: 0.4671  loss_giou_0: 0.4153  loss_bbox_0: 0.3198  loss_rpn_cls: 0.2136  loss_rpn_reg: 0.4774  time: 0.1892  last_time: 0.1871  data_time: 0.0050  last_data_time: 0.0046   lr: 5e-06  max_mem: 3029M
[03/05 13:39:34] d2.utils.events INFO:  eta: 0:55:40  iter: 36199  total_loss: 2.684  loss_ce: 0.4343  loss_giou: 0.3282  loss_bbox: 0.2576  loss_ce_0: 0.4171  loss_giou_0: 0.3296  loss_bbox_0: 0.2891  loss_rpn_cls: 0.2458  loss_rpn_reg: 0.4418  time: 0.1892  last_time: 0.1859  data_time: 0.0050  last_data_time: 0.0060   lr: 5e-06  max_mem: 3029M
[03/05 13:39:38] d2.utils.events INFO:  eta: 0:55:38  iter: 36219  total_loss: 2.731  loss_ce: 0.4035  loss_giou: 0.3663  loss_bbox: 0.2438  loss_ce_0: 0.4093  loss_giou_0: 0.3814  loss_bbox_0: 0.2975  loss_rpn_cls: 0.234  loss_rpn_reg: 0.478  time: 0.1892  last_time: 0.2058  data_time: 0.0047  last_data_time: 0.0051   lr: 5e-06  max_mem: 3029M
[03/05 13:39:42] d2.utils.events INFO:  eta: 0:55:34  iter: 36239  total_loss: 2.666  loss_ce: 0.3389  loss_giou: 0.3372  loss_bbox: 0.2631  loss_ce_0: 0.3884  loss_giou_0: 0.3198  loss_bbox_0: 0.3075  loss_rpn_cls: 0.216  loss_rpn_reg: 0.4748  time: 0.1892  last_time: 0.1830  data_time: 0.0044  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 13:39:45] d2.utils.events INFO:  eta: 0:55:29  iter: 36259  total_loss: 2.742  loss_ce: 0.31  loss_giou: 0.334  loss_bbox: 0.3095  loss_ce_0: 0.3361  loss_giou_0: 0.3537  loss_bbox_0: 0.3263  loss_rpn_cls: 0.2006  loss_rpn_reg: 0.4284  time: 0.1892  last_time: 0.1802  data_time: 0.0046  last_data_time: 0.0032   lr: 5e-06  max_mem: 3029M
[03/05 13:39:49] d2.utils.events INFO:  eta: 0:55:23  iter: 36279  total_loss: 2.655  loss_ce: 0.369  loss_giou: 0.3111  loss_bbox: 0.2586  loss_ce_0: 0.3969  loss_giou_0: 0.3531  loss_bbox_0: 0.2907  loss_rpn_cls: 0.2348  loss_rpn_reg: 0.4666  time: 0.1892  last_time: 0.1919  data_time: 0.0045  last_data_time: 0.0046   lr: 5e-06  max_mem: 3029M
[03/05 13:39:53] d2.utils.events INFO:  eta: 0:55:20  iter: 36299  total_loss: 2.439  loss_ce: 0.3467  loss_giou: 0.2857  loss_bbox: 0.2138  loss_ce_0: 0.3839  loss_giou_0: 0.3049  loss_bbox_0: 0.2382  loss_rpn_cls: 0.2065  loss_rpn_reg: 0.4604  time: 0.1892  last_time: 0.1860  data_time: 0.0046  last_data_time: 0.0056   lr: 5e-06  max_mem: 3029M
[03/05 13:39:57] d2.utils.events INFO:  eta: 0:55:18  iter: 36319  total_loss: 2.552  loss_ce: 0.3357  loss_giou: 0.3244  loss_bbox: 0.2526  loss_ce_0: 0.3688  loss_giou_0: 0.3462  loss_bbox_0: 0.2579  loss_rpn_cls: 0.1903  loss_rpn_reg: 0.4188  time: 0.1892  last_time: 0.2076  data_time: 0.0045  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 13:40:01] d2.utils.events INFO:  eta: 0:55:14  iter: 36339  total_loss: 2.577  loss_ce: 0.33  loss_giou: 0.2903  loss_bbox: 0.2482  loss_ce_0: 0.3462  loss_giou_0: 0.3009  loss_bbox_0: 0.2849  loss_rpn_cls: 0.1819  loss_rpn_reg: 0.4418  time: 0.1892  last_time: 0.1848  data_time: 0.0050  last_data_time: 0.0045   lr: 5e-06  max_mem: 3029M
[03/05 13:40:04] d2.utils.events INFO:  eta: 0:55:06  iter: 36359  total_loss: 2.499  loss_ce: 0.3127  loss_giou: 0.3206  loss_bbox: 0.2485  loss_ce_0: 0.3793  loss_giou_0: 0.3527  loss_bbox_0: 0.2898  loss_rpn_cls: 0.1881  loss_rpn_reg: 0.4618  time: 0.1892  last_time: 0.1964  data_time: 0.0044  last_data_time: 0.0031   lr: 5e-06  max_mem: 3029M
[03/05 13:40:08] d2.utils.events INFO:  eta: 0:54:59  iter: 36379  total_loss: 2.452  loss_ce: 0.3487  loss_giou: 0.3207  loss_bbox: 0.2282  loss_ce_0: 0.3816  loss_giou_0: 0.3306  loss_bbox_0: 0.2558  loss_rpn_cls: 0.2182  loss_rpn_reg: 0.4325  time: 0.1892  last_time: 0.1988  data_time: 0.0043  last_data_time: 0.0048   lr: 5e-06  max_mem: 3029M
[03/05 13:40:12] d2.utils.events INFO:  eta: 0:54:53  iter: 36399  total_loss: 2.59  loss_ce: 0.3778  loss_giou: 0.2952  loss_bbox: 0.2264  loss_ce_0: 0.3807  loss_giou_0: 0.3422  loss_bbox_0: 0.2567  loss_rpn_cls: 0.2069  loss_rpn_reg: 0.4509  time: 0.1892  last_time: 0.1678  data_time: 0.0046  last_data_time: 0.0045   lr: 5e-06  max_mem: 3029M
[03/05 13:40:16] d2.utils.events INFO:  eta: 0:54:50  iter: 36419  total_loss: 2.603  loss_ce: 0.365  loss_giou: 0.3418  loss_bbox: 0.215  loss_ce_0: 0.438  loss_giou_0: 0.3704  loss_bbox_0: 0.2432  loss_rpn_cls: 0.2267  loss_rpn_reg: 0.4421  time: 0.1892  last_time: 0.1893  data_time: 0.0047  last_data_time: 0.0046   lr: 5e-06  max_mem: 3029M
[03/05 13:40:19] d2.utils.events INFO:  eta: 0:54:43  iter: 36439  total_loss: 2.707  loss_ce: 0.357  loss_giou: 0.3262  loss_bbox: 0.2787  loss_ce_0: 0.4622  loss_giou_0: 0.3223  loss_bbox_0: 0.2769  loss_rpn_cls: 0.2195  loss_rpn_reg: 0.4492  time: 0.1891  last_time: 0.1547  data_time: 0.0045  last_data_time: 0.0031   lr: 5e-06  max_mem: 3029M
[03/05 13:40:23] d2.utils.events INFO:  eta: 0:54:38  iter: 36459  total_loss: 2.685  loss_ce: 0.3845  loss_giou: 0.3099  loss_bbox: 0.2939  loss_ce_0: 0.4393  loss_giou_0: 0.345  loss_bbox_0: 0.3226  loss_rpn_cls: 0.2255  loss_rpn_reg: 0.4683  time: 0.1891  last_time: 0.1662  data_time: 0.0049  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 13:40:27] d2.utils.events INFO:  eta: 0:54:32  iter: 36479  total_loss: 2.599  loss_ce: 0.3475  loss_giou: 0.3259  loss_bbox: 0.2489  loss_ce_0: 0.4173  loss_giou_0: 0.3352  loss_bbox_0: 0.2758  loss_rpn_cls: 0.2188  loss_rpn_reg: 0.4361  time: 0.1891  last_time: 0.1895  data_time: 0.0044  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 13:40:31] d2.utils.events INFO:  eta: 0:54:29  iter: 36499  total_loss: 2.477  loss_ce: 0.3198  loss_giou: 0.266  loss_bbox: 0.2547  loss_ce_0: 0.3619  loss_giou_0: 0.2784  loss_bbox_0: 0.2534  loss_rpn_cls: 0.2016  loss_rpn_reg: 0.4316  time: 0.1891  last_time: 0.1876  data_time: 0.0048  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 13:40:34] d2.utils.events INFO:  eta: 0:54:21  iter: 36519  total_loss: 2.583  loss_ce: 0.3649  loss_giou: 0.2866  loss_bbox: 0.2656  loss_ce_0: 0.4054  loss_giou_0: 0.2982  loss_bbox_0: 0.2767  loss_rpn_cls: 0.1786  loss_rpn_reg: 0.4528  time: 0.1891  last_time: 0.1819  data_time: 0.0052  last_data_time: 0.0055   lr: 5e-06  max_mem: 3029M
[03/05 13:40:38] d2.utils.events INFO:  eta: 0:54:15  iter: 36539  total_loss: 2.661  loss_ce: 0.3921  loss_giou: 0.3083  loss_bbox: 0.2373  loss_ce_0: 0.4315  loss_giou_0: 0.3112  loss_bbox_0: 0.2508  loss_rpn_cls: 0.218  loss_rpn_reg: 0.4461  time: 0.1891  last_time: 0.1755  data_time: 0.0051  last_data_time: 0.0061   lr: 5e-06  max_mem: 3029M
[03/05 13:40:42] d2.utils.events INFO:  eta: 0:54:07  iter: 36559  total_loss: 2.375  loss_ce: 0.3751  loss_giou: 0.3114  loss_bbox: 0.219  loss_ce_0: 0.4226  loss_giou_0: 0.313  loss_bbox_0: 0.2515  loss_rpn_cls: 0.1934  loss_rpn_reg: 0.4314  time: 0.1891  last_time: 0.1641  data_time: 0.0057  last_data_time: 0.0059   lr: 5e-06  max_mem: 3029M
[03/05 13:40:46] d2.utils.events INFO:  eta: 0:54:05  iter: 36579  total_loss: 2.525  loss_ce: 0.3512  loss_giou: 0.2763  loss_bbox: 0.2612  loss_ce_0: 0.3699  loss_giou_0: 0.3086  loss_bbox_0: 0.2882  loss_rpn_cls: 0.2025  loss_rpn_reg: 0.4382  time: 0.1891  last_time: 0.2155  data_time: 0.0049  last_data_time: 0.0046   lr: 5e-06  max_mem: 3029M
[03/05 13:40:49] d2.utils.events INFO:  eta: 0:54:02  iter: 36599  total_loss: 2.595  loss_ce: 0.3925  loss_giou: 0.3247  loss_bbox: 0.2228  loss_ce_0: 0.4288  loss_giou_0: 0.3341  loss_bbox_0: 0.2374  loss_rpn_cls: 0.2204  loss_rpn_reg: 0.4704  time: 0.1891  last_time: 0.1949  data_time: 0.0048  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 13:40:53] d2.utils.events INFO:  eta: 0:54:03  iter: 36619  total_loss: 2.49  loss_ce: 0.3261  loss_giou: 0.2999  loss_bbox: 0.225  loss_ce_0: 0.3643  loss_giou_0: 0.3204  loss_bbox_0: 0.2466  loss_rpn_cls: 0.2016  loss_rpn_reg: 0.4297  time: 0.1891  last_time: 0.1735  data_time: 0.0048  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 13:40:57] d2.utils.events INFO:  eta: 0:53:56  iter: 36639  total_loss: 2.211  loss_ce: 0.3205  loss_giou: 0.237  loss_bbox: 0.1999  loss_ce_0: 0.3859  loss_giou_0: 0.2546  loss_bbox_0: 0.2157  loss_rpn_cls: 0.1912  loss_rpn_reg: 0.446  time: 0.1891  last_time: 0.1960  data_time: 0.0044  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 13:41:01] d2.utils.events INFO:  eta: 0:53:51  iter: 36659  total_loss: 2.768  loss_ce: 0.3287  loss_giou: 0.3598  loss_bbox: 0.2635  loss_ce_0: 0.3677  loss_giou_0: 0.378  loss_bbox_0: 0.2789  loss_rpn_cls: 0.1932  loss_rpn_reg: 0.4183  time: 0.1891  last_time: 0.1827  data_time: 0.0050  last_data_time: 0.0057   lr: 5e-06  max_mem: 3029M
[03/05 13:41:04] d2.utils.events INFO:  eta: 0:53:47  iter: 36679  total_loss: 2.654  loss_ce: 0.337  loss_giou: 0.3062  loss_bbox: 0.2366  loss_ce_0: 0.363  loss_giou_0: 0.3263  loss_bbox_0: 0.2795  loss_rpn_cls: 0.1925  loss_rpn_reg: 0.4507  time: 0.1891  last_time: 0.1771  data_time: 0.0047  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 13:41:08] d2.utils.events INFO:  eta: 0:53:43  iter: 36699  total_loss: 2.626  loss_ce: 0.32  loss_giou: 0.3179  loss_bbox: 0.2502  loss_ce_0: 0.3726  loss_giou_0: 0.3367  loss_bbox_0: 0.2671  loss_rpn_cls: 0.1903  loss_rpn_reg: 0.454  time: 0.1891  last_time: 0.1660  data_time: 0.0046  last_data_time: 0.0050   lr: 5e-06  max_mem: 3029M
[03/05 13:41:12] d2.utils.events INFO:  eta: 0:53:36  iter: 36719  total_loss: 2.691  loss_ce: 0.364  loss_giou: 0.2744  loss_bbox: 0.2877  loss_ce_0: 0.3985  loss_giou_0: 0.287  loss_bbox_0: 0.3223  loss_rpn_cls: 0.2112  loss_rpn_reg: 0.4547  time: 0.1891  last_time: 0.2025  data_time: 0.0046  last_data_time: 0.0057   lr: 5e-06  max_mem: 3029M
[03/05 13:41:16] d2.utils.events INFO:  eta: 0:53:35  iter: 36739  total_loss: 2.776  loss_ce: 0.3816  loss_giou: 0.3308  loss_bbox: 0.2576  loss_ce_0: 0.4259  loss_giou_0: 0.3378  loss_bbox_0: 0.2917  loss_rpn_cls: 0.208  loss_rpn_reg: 0.4581  time: 0.1891  last_time: 0.1780  data_time: 0.0047  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 13:41:20] d2.utils.events INFO:  eta: 0:53:31  iter: 36759  total_loss: 2.411  loss_ce: 0.3506  loss_giou: 0.286  loss_bbox: 0.2059  loss_ce_0: 0.3982  loss_giou_0: 0.3038  loss_bbox_0: 0.2506  loss_rpn_cls: 0.2266  loss_rpn_reg: 0.4435  time: 0.1891  last_time: 0.1977  data_time: 0.0044  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 13:41:23] d2.utils.events INFO:  eta: 0:53:26  iter: 36779  total_loss: 2.578  loss_ce: 0.3339  loss_giou: 0.2934  loss_bbox: 0.2608  loss_ce_0: 0.3715  loss_giou_0: 0.2975  loss_bbox_0: 0.2774  loss_rpn_cls: 0.2061  loss_rpn_reg: 0.4477  time: 0.1891  last_time: 0.1705  data_time: 0.0047  last_data_time: 0.0046   lr: 5e-06  max_mem: 3029M
[03/05 13:41:27] d2.utils.events INFO:  eta: 0:53:23  iter: 36799  total_loss: 2.594  loss_ce: 0.3356  loss_giou: 0.303  loss_bbox: 0.2498  loss_ce_0: 0.4213  loss_giou_0: 0.3125  loss_bbox_0: 0.2826  loss_rpn_cls: 0.2314  loss_rpn_reg: 0.4265  time: 0.1891  last_time: 0.1887  data_time: 0.0045  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 13:41:31] d2.utils.events INFO:  eta: 0:53:20  iter: 36819  total_loss: 2.55  loss_ce: 0.3932  loss_giou: 0.2869  loss_bbox: 0.2324  loss_ce_0: 0.4827  loss_giou_0: 0.3132  loss_bbox_0: 0.2719  loss_rpn_cls: 0.2344  loss_rpn_reg: 0.44  time: 0.1891  last_time: 0.2106  data_time: 0.0049  last_data_time: 0.0073   lr: 5e-06  max_mem: 3029M
[03/05 13:41:35] d2.utils.events INFO:  eta: 0:53:17  iter: 36839  total_loss: 2.353  loss_ce: 0.3748  loss_giou: 0.2826  loss_bbox: 0.2277  loss_ce_0: 0.3959  loss_giou_0: 0.3086  loss_bbox_0: 0.2704  loss_rpn_cls: 0.1878  loss_rpn_reg: 0.4363  time: 0.1891  last_time: 0.1686  data_time: 0.0043  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 13:41:38] d2.utils.events INFO:  eta: 0:53:11  iter: 36859  total_loss: 2.649  loss_ce: 0.3331  loss_giou: 0.3362  loss_bbox: 0.2619  loss_ce_0: 0.3441  loss_giou_0: 0.3598  loss_bbox_0: 0.2869  loss_rpn_cls: 0.226  loss_rpn_reg: 0.4386  time: 0.1891  last_time: 0.2029  data_time: 0.0048  last_data_time: 0.0079   lr: 5e-06  max_mem: 3029M
[03/05 13:41:42] d2.utils.events INFO:  eta: 0:53:06  iter: 36879  total_loss: 2.524  loss_ce: 0.3233  loss_giou: 0.3086  loss_bbox: 0.2405  loss_ce_0: 0.3588  loss_giou_0: 0.3469  loss_bbox_0: 0.2737  loss_rpn_cls: 0.1942  loss_rpn_reg: 0.4386  time: 0.1891  last_time: 0.2220  data_time: 0.0046  last_data_time: 0.0055   lr: 5e-06  max_mem: 3029M
[03/05 13:41:46] d2.utils.events INFO:  eta: 0:52:59  iter: 36899  total_loss: 2.588  loss_ce: 0.312  loss_giou: 0.2692  loss_bbox: 0.3122  loss_ce_0: 0.3747  loss_giou_0: 0.2945  loss_bbox_0: 0.3484  loss_rpn_cls: 0.202  loss_rpn_reg: 0.4323  time: 0.1891  last_time: 0.1919  data_time: 0.0047  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 13:41:50] d2.utils.events INFO:  eta: 0:52:54  iter: 36919  total_loss: 2.503  loss_ce: 0.3546  loss_giou: 0.2883  loss_bbox: 0.2498  loss_ce_0: 0.3632  loss_giou_0: 0.3012  loss_bbox_0: 0.2673  loss_rpn_cls: 0.2109  loss_rpn_reg: 0.4266  time: 0.1891  last_time: 0.1736  data_time: 0.0046  last_data_time: 0.0049   lr: 5e-06  max_mem: 3029M
[03/05 13:41:53] d2.utils.events INFO:  eta: 0:52:49  iter: 36939  total_loss: 2.383  loss_ce: 0.3075  loss_giou: 0.301  loss_bbox: 0.2571  loss_ce_0: 0.341  loss_giou_0: 0.3204  loss_bbox_0: 0.27  loss_rpn_cls: 0.1987  loss_rpn_reg: 0.4305  time: 0.1891  last_time: 0.2306  data_time: 0.0046  last_data_time: 0.0067   lr: 5e-06  max_mem: 3029M
[03/05 13:41:57] d2.utils.events INFO:  eta: 0:52:47  iter: 36959  total_loss: 2.656  loss_ce: 0.4118  loss_giou: 0.3044  loss_bbox: 0.2343  loss_ce_0: 0.463  loss_giou_0: 0.337  loss_bbox_0: 0.2561  loss_rpn_cls: 0.2247  loss_rpn_reg: 0.4482  time: 0.1891  last_time: 0.1819  data_time: 0.0047  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 13:42:01] d2.utils.events INFO:  eta: 0:52:42  iter: 36979  total_loss: 2.447  loss_ce: 0.3834  loss_giou: 0.2365  loss_bbox: 0.2083  loss_ce_0: 0.4032  loss_giou_0: 0.2753  loss_bbox_0: 0.2449  loss_rpn_cls: 0.1732  loss_rpn_reg: 0.4281  time: 0.1891  last_time: 0.1816  data_time: 0.0050  last_data_time: 0.0065   lr: 5e-06  max_mem: 3029M
[03/05 13:42:05] d2.utils.events INFO:  eta: 0:52:40  iter: 36999  total_loss: 2.399  loss_ce: 0.3287  loss_giou: 0.3275  loss_bbox: 0.2464  loss_ce_0: 0.3395  loss_giou_0: 0.3454  loss_bbox_0: 0.2865  loss_rpn_cls: 0.1852  loss_rpn_reg: 0.4826  time: 0.1891  last_time: 0.1978  data_time: 0.0063  last_data_time: 0.0082   lr: 5e-06  max_mem: 3029M
[03/05 13:42:09] d2.utils.events INFO:  eta: 0:52:36  iter: 37019  total_loss: 2.665  loss_ce: 0.3176  loss_giou: 0.3262  loss_bbox: 0.256  loss_ce_0: 0.3646  loss_giou_0: 0.3479  loss_bbox_0: 0.279  loss_rpn_cls: 0.1998  loss_rpn_reg: 0.4453  time: 0.1891  last_time: 0.1962  data_time: 0.0048  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 13:42:13] d2.utils.events INFO:  eta: 0:52:32  iter: 37039  total_loss: 2.546  loss_ce: 0.339  loss_giou: 0.262  loss_bbox: 0.229  loss_ce_0: 0.3858  loss_giou_0: 0.2824  loss_bbox_0: 0.2759  loss_rpn_cls: 0.2094  loss_rpn_reg: 0.3998  time: 0.1891  last_time: 0.1987  data_time: 0.0047  last_data_time: 0.0049   lr: 5e-06  max_mem: 3029M
[03/05 13:42:16] d2.utils.events INFO:  eta: 0:52:29  iter: 37059  total_loss: 2.872  loss_ce: 0.3651  loss_giou: 0.3292  loss_bbox: 0.2418  loss_ce_0: 0.3834  loss_giou_0: 0.3586  loss_bbox_0: 0.2735  loss_rpn_cls: 0.2118  loss_rpn_reg: 0.4647  time: 0.1891  last_time: 0.2011  data_time: 0.0050  last_data_time: 0.0027   lr: 5e-06  max_mem: 3029M
[03/05 13:42:20] d2.utils.events INFO:  eta: 0:52:25  iter: 37079  total_loss: 2.794  loss_ce: 0.4028  loss_giou: 0.3973  loss_bbox: 0.2643  loss_ce_0: 0.4114  loss_giou_0: 0.4079  loss_bbox_0: 0.3164  loss_rpn_cls: 0.209  loss_rpn_reg: 0.4431  time: 0.1891  last_time: 0.2058  data_time: 0.0049  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 13:42:24] d2.utils.events INFO:  eta: 0:52:21  iter: 37099  total_loss: 2.396  loss_ce: 0.3396  loss_giou: 0.2737  loss_bbox: 0.2358  loss_ce_0: 0.3688  loss_giou_0: 0.3001  loss_bbox_0: 0.2624  loss_rpn_cls: 0.1894  loss_rpn_reg: 0.4408  time: 0.1891  last_time: 0.2121  data_time: 0.0045  last_data_time: 0.0033   lr: 5e-06  max_mem: 3029M
[03/05 13:42:28] d2.utils.events INFO:  eta: 0:52:17  iter: 37119  total_loss: 2.373  loss_ce: 0.3098  loss_giou: 0.2679  loss_bbox: 0.2615  loss_ce_0: 0.3589  loss_giou_0: 0.2872  loss_bbox_0: 0.2589  loss_rpn_cls: 0.2133  loss_rpn_reg: 0.3806  time: 0.1891  last_time: 0.1754  data_time: 0.0046  last_data_time: 0.0032   lr: 5e-06  max_mem: 3029M
[03/05 13:42:31] d2.utils.events INFO:  eta: 0:52:13  iter: 37139  total_loss: 2.447  loss_ce: 0.277  loss_giou: 0.2896  loss_bbox: 0.2173  loss_ce_0: 0.3283  loss_giou_0: 0.3033  loss_bbox_0: 0.2524  loss_rpn_cls: 0.1938  loss_rpn_reg: 0.4227  time: 0.1891  last_time: 0.1947  data_time: 0.0047  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 13:42:35] d2.utils.events INFO:  eta: 0:52:09  iter: 37159  total_loss: 2.845  loss_ce: 0.4117  loss_giou: 0.316  loss_bbox: 0.2582  loss_ce_0: 0.4244  loss_giou_0: 0.3083  loss_bbox_0: 0.2688  loss_rpn_cls: 0.243  loss_rpn_reg: 0.4657  time: 0.1891  last_time: 0.1744  data_time: 0.0047  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 13:42:39] d2.utils.events INFO:  eta: 0:52:06  iter: 37179  total_loss: 2.868  loss_ce: 0.3566  loss_giou: 0.3494  loss_bbox: 0.3234  loss_ce_0: 0.3693  loss_giou_0: 0.3693  loss_bbox_0: 0.2776  loss_rpn_cls: 0.2091  loss_rpn_reg: 0.4573  time: 0.1891  last_time: 0.1825  data_time: 0.0048  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 13:42:43] d2.utils.events INFO:  eta: 0:52:03  iter: 37199  total_loss: 2.388  loss_ce: 0.3066  loss_giou: 0.3043  loss_bbox: 0.2617  loss_ce_0: 0.3682  loss_giou_0: 0.3149  loss_bbox_0: 0.2765  loss_rpn_cls: 0.2057  loss_rpn_reg: 0.4128  time: 0.1891  last_time: 0.1529  data_time: 0.0045  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 13:42:47] d2.utils.events INFO:  eta: 0:52:01  iter: 37219  total_loss: 2.857  loss_ce: 0.3497  loss_giou: 0.3201  loss_bbox: 0.301  loss_ce_0: 0.4006  loss_giou_0: 0.322  loss_bbox_0: 0.3466  loss_rpn_cls: 0.2211  loss_rpn_reg: 0.4875  time: 0.1891  last_time: 0.1800  data_time: 0.0048  last_data_time: 0.0047   lr: 5e-06  max_mem: 3029M
[03/05 13:42:50] d2.utils.events INFO:  eta: 0:51:58  iter: 37239  total_loss: 2.622  loss_ce: 0.3171  loss_giou: 0.2553  loss_bbox: 0.2716  loss_ce_0: 0.3794  loss_giou_0: 0.3113  loss_bbox_0: 0.3082  loss_rpn_cls: 0.2085  loss_rpn_reg: 0.4579  time: 0.1891  last_time: 0.1781  data_time: 0.0045  last_data_time: 0.0059   lr: 5e-06  max_mem: 3029M
[03/05 13:42:54] d2.utils.events INFO:  eta: 0:51:54  iter: 37259  total_loss: 2.69  loss_ce: 0.3029  loss_giou: 0.3399  loss_bbox: 0.2405  loss_ce_0: 0.344  loss_giou_0: 0.3565  loss_bbox_0: 0.2721  loss_rpn_cls: 0.2019  loss_rpn_reg: 0.4351  time: 0.1891  last_time: 0.1920  data_time: 0.0044  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 13:42:58] d2.utils.events INFO:  eta: 0:51:50  iter: 37279  total_loss: 2.677  loss_ce: 0.3703  loss_giou: 0.281  loss_bbox: 0.2311  loss_ce_0: 0.4213  loss_giou_0: 0.305  loss_bbox_0: 0.2754  loss_rpn_cls: 0.209  loss_rpn_reg: 0.4325  time: 0.1891  last_time: 0.1797  data_time: 0.0055  last_data_time: 0.0033   lr: 5e-06  max_mem: 3029M
[03/05 13:43:02] d2.utils.events INFO:  eta: 0:51:47  iter: 37299  total_loss: 2.524  loss_ce: 0.3427  loss_giou: 0.3246  loss_bbox: 0.2217  loss_ce_0: 0.3798  loss_giou_0: 0.3519  loss_bbox_0: 0.2583  loss_rpn_cls: 0.1967  loss_rpn_reg: 0.4641  time: 0.1891  last_time: 0.1839  data_time: 0.0053  last_data_time: 0.0045   lr: 5e-06  max_mem: 3029M
[03/05 13:43:06] d2.utils.events INFO:  eta: 0:51:43  iter: 37319  total_loss: 2.374  loss_ce: 0.2895  loss_giou: 0.2767  loss_bbox: 0.2012  loss_ce_0: 0.3228  loss_giou_0: 0.2984  loss_bbox_0: 0.223  loss_rpn_cls: 0.2164  loss_rpn_reg: 0.4636  time: 0.1891  last_time: 0.1646  data_time: 0.0058  last_data_time: 0.0033   lr: 5e-06  max_mem: 3029M
[03/05 13:43:10] d2.utils.events INFO:  eta: 0:51:39  iter: 37339  total_loss: 2.432  loss_ce: 0.2974  loss_giou: 0.3099  loss_bbox: 0.2547  loss_ce_0: 0.3524  loss_giou_0: 0.3096  loss_bbox_0: 0.2657  loss_rpn_cls: 0.188  loss_rpn_reg: 0.4267  time: 0.1891  last_time: 0.1637  data_time: 0.0044  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 13:43:13] d2.utils.events INFO:  eta: 0:51:36  iter: 37359  total_loss: 2.291  loss_ce: 0.2413  loss_giou: 0.2953  loss_bbox: 0.2115  loss_ce_0: 0.2647  loss_giou_0: 0.302  loss_bbox_0: 0.2486  loss_rpn_cls: 0.1932  loss_rpn_reg: 0.4257  time: 0.1891  last_time: 0.1744  data_time: 0.0048  last_data_time: 0.0055   lr: 5e-06  max_mem: 3029M
[03/05 13:43:17] d2.utils.events INFO:  eta: 0:51:32  iter: 37379  total_loss: 2.246  loss_ce: 0.2407  loss_giou: 0.275  loss_bbox: 0.2348  loss_ce_0: 0.3323  loss_giou_0: 0.2696  loss_bbox_0: 0.2511  loss_rpn_cls: 0.1932  loss_rpn_reg: 0.4217  time: 0.1891  last_time: 0.1855  data_time: 0.0058  last_data_time: 0.0062   lr: 5e-06  max_mem: 3029M
[03/05 13:43:21] d2.utils.events INFO:  eta: 0:51:30  iter: 37399  total_loss: 2.558  loss_ce: 0.3472  loss_giou: 0.3534  loss_bbox: 0.2251  loss_ce_0: 0.3799  loss_giou_0: 0.3538  loss_bbox_0: 0.2441  loss_rpn_cls: 0.2192  loss_rpn_reg: 0.4531  time: 0.1891  last_time: 0.1888  data_time: 0.0045  last_data_time: 0.0061   lr: 5e-06  max_mem: 3029M
[03/05 13:43:25] d2.utils.events INFO:  eta: 0:51:26  iter: 37419  total_loss: 2.419  loss_ce: 0.2999  loss_giou: 0.3184  loss_bbox: 0.2594  loss_ce_0: 0.3996  loss_giou_0: 0.3367  loss_bbox_0: 0.2743  loss_rpn_cls: 0.2012  loss_rpn_reg: 0.4472  time: 0.1891  last_time: 0.1612  data_time: 0.0052  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 13:43:28] d2.utils.events INFO:  eta: 0:51:24  iter: 37439  total_loss: 2.457  loss_ce: 0.3727  loss_giou: 0.3141  loss_bbox: 0.2417  loss_ce_0: 0.4079  loss_giou_0: 0.3429  loss_bbox_0: 0.2765  loss_rpn_cls: 0.2111  loss_rpn_reg: 0.4476  time: 0.1891  last_time: 0.1826  data_time: 0.0050  last_data_time: 0.0058   lr: 5e-06  max_mem: 3029M
[03/05 13:43:32] d2.utils.events INFO:  eta: 0:51:20  iter: 37459  total_loss: 2.494  loss_ce: 0.3659  loss_giou: 0.287  loss_bbox: 0.231  loss_ce_0: 0.3811  loss_giou_0: 0.3158  loss_bbox_0: 0.2749  loss_rpn_cls: 0.2058  loss_rpn_reg: 0.4527  time: 0.1891  last_time: 0.1831  data_time: 0.0051  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 13:43:36] d2.utils.events INFO:  eta: 0:51:16  iter: 37479  total_loss: 2.626  loss_ce: 0.3511  loss_giou: 0.2583  loss_bbox: 0.272  loss_ce_0: 0.3991  loss_giou_0: 0.272  loss_bbox_0: 0.2942  loss_rpn_cls: 0.2157  loss_rpn_reg: 0.4108  time: 0.1891  last_time: 0.2031  data_time: 0.0045  last_data_time: 0.0062   lr: 5e-06  max_mem: 3029M
[03/05 13:43:40] d2.utils.events INFO:  eta: 0:51:12  iter: 37499  total_loss: 2.533  loss_ce: 0.3545  loss_giou: 0.3571  loss_bbox: 0.219  loss_ce_0: 0.3788  loss_giou_0: 0.3698  loss_bbox_0: 0.2401  loss_rpn_cls: 0.2103  loss_rpn_reg: 0.45  time: 0.1891  last_time: 0.1858  data_time: 0.0054  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 13:43:44] d2.utils.events INFO:  eta: 0:51:10  iter: 37519  total_loss: 2.525  loss_ce: 0.3556  loss_giou: 0.3089  loss_bbox: 0.1991  loss_ce_0: 0.3928  loss_giou_0: 0.315  loss_bbox_0: 0.2409  loss_rpn_cls: 0.2018  loss_rpn_reg: 0.444  time: 0.1891  last_time: 0.1721  data_time: 0.0048  last_data_time: 0.0058   lr: 5e-06  max_mem: 3029M
[03/05 13:43:47] d2.utils.events INFO:  eta: 0:51:06  iter: 37539  total_loss: 2.351  loss_ce: 0.2902  loss_giou: 0.2622  loss_bbox: 0.2216  loss_ce_0: 0.3306  loss_giou_0: 0.3009  loss_bbox_0: 0.2391  loss_rpn_cls: 0.1914  loss_rpn_reg: 0.4193  time: 0.1891  last_time: 0.1714  data_time: 0.0052  last_data_time: 0.0048   lr: 5e-06  max_mem: 3029M
[03/05 13:43:51] d2.utils.events INFO:  eta: 0:51:03  iter: 37559  total_loss: 2.621  loss_ce: 0.3062  loss_giou: 0.2801  loss_bbox: 0.2408  loss_ce_0: 0.3579  loss_giou_0: 0.302  loss_bbox_0: 0.2728  loss_rpn_cls: 0.1958  loss_rpn_reg: 0.4028  time: 0.1891  last_time: 0.1694  data_time: 0.0047  last_data_time: 0.0062   lr: 5e-06  max_mem: 3029M
[03/05 13:43:55] d2.utils.events INFO:  eta: 0:50:58  iter: 37579  total_loss: 2.579  loss_ce: 0.2962  loss_giou: 0.3045  loss_bbox: 0.2434  loss_ce_0: 0.3317  loss_giou_0: 0.3152  loss_bbox_0: 0.2609  loss_rpn_cls: 0.2093  loss_rpn_reg: 0.4316  time: 0.1891  last_time: 0.1684  data_time: 0.0051  last_data_time: 0.0060   lr: 5e-06  max_mem: 3029M
[03/05 13:43:59] d2.utils.events INFO:  eta: 0:50:56  iter: 37599  total_loss: 2.547  loss_ce: 0.3247  loss_giou: 0.2894  loss_bbox: 0.2661  loss_ce_0: 0.3698  loss_giou_0: 0.2988  loss_bbox_0: 0.2846  loss_rpn_cls: 0.2076  loss_rpn_reg: 0.4375  time: 0.1891  last_time: 0.1996  data_time: 0.0051  last_data_time: 0.0051   lr: 5e-06  max_mem: 3029M
[03/05 13:44:03] d2.utils.events INFO:  eta: 0:50:54  iter: 37619  total_loss: 2.454  loss_ce: 0.3875  loss_giou: 0.2694  loss_bbox: 0.2416  loss_ce_0: 0.3847  loss_giou_0: 0.2772  loss_bbox_0: 0.2675  loss_rpn_cls: 0.2117  loss_rpn_reg: 0.4208  time: 0.1891  last_time: 0.2032  data_time: 0.0046  last_data_time: 0.0049   lr: 5e-06  max_mem: 3029M
[03/05 13:44:06] d2.utils.events INFO:  eta: 0:50:50  iter: 37639  total_loss: 2.428  loss_ce: 0.3063  loss_giou: 0.2715  loss_bbox: 0.2531  loss_ce_0: 0.3769  loss_giou_0: 0.3101  loss_bbox_0: 0.2678  loss_rpn_cls: 0.1943  loss_rpn_reg: 0.4407  time: 0.1891  last_time: 0.1941  data_time: 0.0054  last_data_time: 0.0100   lr: 5e-06  max_mem: 3029M
[03/05 13:44:10] d2.utils.events INFO:  eta: 0:50:47  iter: 37659  total_loss: 2.292  loss_ce: 0.2685  loss_giou: 0.2747  loss_bbox: 0.2075  loss_ce_0: 0.3134  loss_giou_0: 0.3022  loss_bbox_0: 0.2434  loss_rpn_cls: 0.1721  loss_rpn_reg: 0.443  time: 0.1891  last_time: 0.1762  data_time: 0.0046  last_data_time: 0.0020   lr: 5e-06  max_mem: 3029M
[03/05 13:44:14] d2.utils.events INFO:  eta: 0:50:44  iter: 37679  total_loss: 2.566  loss_ce: 0.3908  loss_giou: 0.2638  loss_bbox: 0.2745  loss_ce_0: 0.399  loss_giou_0: 0.2825  loss_bbox_0: 0.3212  loss_rpn_cls: 0.2129  loss_rpn_reg: 0.4569  time: 0.1891  last_time: 0.1656  data_time: 0.0050  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 13:44:18] d2.utils.events INFO:  eta: 0:50:40  iter: 37699  total_loss: 2.831  loss_ce: 0.3416  loss_giou: 0.3226  loss_bbox: 0.2264  loss_ce_0: 0.3934  loss_giou_0: 0.3497  loss_bbox_0: 0.2645  loss_rpn_cls: 0.2179  loss_rpn_reg: 0.4747  time: 0.1891  last_time: 0.1764  data_time: 0.0047  last_data_time: 0.0045   lr: 5e-06  max_mem: 3029M
[03/05 13:44:22] d2.utils.events INFO:  eta: 0:50:40  iter: 37719  total_loss: 2.301  loss_ce: 0.3377  loss_giou: 0.2596  loss_bbox: 0.2206  loss_ce_0: 0.365  loss_giou_0: 0.2826  loss_bbox_0: 0.2607  loss_rpn_cls: 0.1947  loss_rpn_reg: 0.4147  time: 0.1891  last_time: 0.1996  data_time: 0.0048  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 13:44:26] d2.utils.events INFO:  eta: 0:50:35  iter: 37739  total_loss: 2.326  loss_ce: 0.28  loss_giou: 0.2933  loss_bbox: 0.2064  loss_ce_0: 0.299  loss_giou_0: 0.3052  loss_bbox_0: 0.2423  loss_rpn_cls: 0.1879  loss_rpn_reg: 0.3855  time: 0.1891  last_time: 0.1878  data_time: 0.0049  last_data_time: 0.0047   lr: 5e-06  max_mem: 3029M
[03/05 13:44:29] d2.utils.events INFO:  eta: 0:50:31  iter: 37759  total_loss: 2.339  loss_ce: 0.3162  loss_giou: 0.2937  loss_bbox: 0.2517  loss_ce_0: 0.337  loss_giou_0: 0.3105  loss_bbox_0: 0.2464  loss_rpn_cls: 0.1846  loss_rpn_reg: 0.3925  time: 0.1891  last_time: 0.1969  data_time: 0.0045  last_data_time: 0.0029   lr: 5e-06  max_mem: 3029M
[03/05 13:44:33] d2.utils.events INFO:  eta: 0:50:28  iter: 37779  total_loss: 2.341  loss_ce: 0.261  loss_giou: 0.2831  loss_bbox: 0.2451  loss_ce_0: 0.3619  loss_giou_0: 0.2951  loss_bbox_0: 0.2418  loss_rpn_cls: 0.1973  loss_rpn_reg: 0.4258  time: 0.1891  last_time: 0.2090  data_time: 0.0047  last_data_time: 0.0053   lr: 5e-06  max_mem: 3029M
[03/05 13:44:37] d2.utils.events INFO:  eta: 0:50:30  iter: 37799  total_loss: 2.119  loss_ce: 0.2644  loss_giou: 0.2881  loss_bbox: 0.217  loss_ce_0: 0.3095  loss_giou_0: 0.3041  loss_bbox_0: 0.2476  loss_rpn_cls: 0.1921  loss_rpn_reg: 0.413  time: 0.1891  last_time: 0.1865  data_time: 0.0048  last_data_time: 0.0035   lr: 5e-06  max_mem: 3029M
[03/05 13:44:41] d2.utils.events INFO:  eta: 0:50:27  iter: 37819  total_loss: 2.597  loss_ce: 0.3279  loss_giou: 0.3485  loss_bbox: 0.251  loss_ce_0: 0.3522  loss_giou_0: 0.3547  loss_bbox_0: 0.2834  loss_rpn_cls: 0.187  loss_rpn_reg: 0.4816  time: 0.1891  last_time: 0.1852  data_time: 0.0050  last_data_time: 0.0051   lr: 5e-06  max_mem: 3029M
[03/05 13:44:45] d2.utils.events INFO:  eta: 0:50:17  iter: 37839  total_loss: 2.711  loss_ce: 0.3611  loss_giou: 0.3354  loss_bbox: 0.2882  loss_ce_0: 0.414  loss_giou_0: 0.3272  loss_bbox_0: 0.293  loss_rpn_cls: 0.2182  loss_rpn_reg: 0.4421  time: 0.1891  last_time: 0.1589  data_time: 0.0060  last_data_time: 0.0058   lr: 5e-06  max_mem: 3029M
[03/05 13:44:49] d2.utils.events INFO:  eta: 0:50:21  iter: 37859  total_loss: 2.518  loss_ce: 0.3377  loss_giou: 0.2936  loss_bbox: 0.2493  loss_ce_0: 0.4105  loss_giou_0: 0.2954  loss_bbox_0: 0.2597  loss_rpn_cls: 0.2104  loss_rpn_reg: 0.4512  time: 0.1891  last_time: 0.1889  data_time: 0.0053  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 13:44:53] d2.utils.events INFO:  eta: 0:50:22  iter: 37879  total_loss: 2.4  loss_ce: 0.3034  loss_giou: 0.2636  loss_bbox: 0.2126  loss_ce_0: 0.3679  loss_giou_0: 0.293  loss_bbox_0: 0.2411  loss_rpn_cls: 0.2018  loss_rpn_reg: 0.4339  time: 0.1891  last_time: 0.1829  data_time: 0.0048  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 13:44:56] d2.utils.events INFO:  eta: 0:50:23  iter: 37899  total_loss: 2.184  loss_ce: 0.2785  loss_giou: 0.2195  loss_bbox: 0.2328  loss_ce_0: 0.2959  loss_giou_0: 0.2467  loss_bbox_0: 0.2485  loss_rpn_cls: 0.1777  loss_rpn_reg: 0.3651  time: 0.1891  last_time: 0.1654  data_time: 0.0055  last_data_time: 0.0035   lr: 5e-06  max_mem: 3029M
[03/05 13:45:00] d2.utils.events INFO:  eta: 0:50:19  iter: 37919  total_loss: 2.668  loss_ce: 0.3716  loss_giou: 0.3298  loss_bbox: 0.2691  loss_ce_0: 0.4106  loss_giou_0: 0.3427  loss_bbox_0: 0.2875  loss_rpn_cls: 0.2165  loss_rpn_reg: 0.4617  time: 0.1891  last_time: 0.1911  data_time: 0.0047  last_data_time: 0.0045   lr: 5e-06  max_mem: 3029M
[03/05 13:45:04] d2.utils.events INFO:  eta: 0:50:17  iter: 37939  total_loss: 2.336  loss_ce: 0.3049  loss_giou: 0.2835  loss_bbox: 0.2031  loss_ce_0: 0.3408  loss_giou_0: 0.307  loss_bbox_0: 0.2424  loss_rpn_cls: 0.1739  loss_rpn_reg: 0.4502  time: 0.1891  last_time: 0.2083  data_time: 0.0053  last_data_time: 0.0059   lr: 5e-06  max_mem: 3029M
[03/05 13:45:08] d2.utils.events INFO:  eta: 0:50:11  iter: 37959  total_loss: 2.591  loss_ce: 0.2961  loss_giou: 0.315  loss_bbox: 0.2539  loss_ce_0: 0.3341  loss_giou_0: 0.3184  loss_bbox_0: 0.2611  loss_rpn_cls: 0.1989  loss_rpn_reg: 0.4368  time: 0.1891  last_time: 0.2041  data_time: 0.0045  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 13:45:11] d2.utils.events INFO:  eta: 0:50:11  iter: 37979  total_loss: 2.409  loss_ce: 0.2911  loss_giou: 0.2938  loss_bbox: 0.2015  loss_ce_0: 0.3338  loss_giou_0: 0.3255  loss_bbox_0: 0.2246  loss_rpn_cls: 0.2069  loss_rpn_reg: 0.3918  time: 0.1891  last_time: 0.1694  data_time: 0.0047  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 13:45:15] d2.utils.events INFO:  eta: 0:50:04  iter: 37999  total_loss: 2.348  loss_ce: 0.2432  loss_giou: 0.3047  loss_bbox: 0.1929  loss_ce_0: 0.3036  loss_giou_0: 0.3216  loss_bbox_0: 0.2446  loss_rpn_cls: 0.1829  loss_rpn_reg: 0.4308  time: 0.1891  last_time: 0.1866  data_time: 0.0050  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 13:45:19] d2.utils.events INFO:  eta: 0:50:01  iter: 38019  total_loss: 2.425  loss_ce: 0.3184  loss_giou: 0.2656  loss_bbox: 0.2176  loss_ce_0: 0.3556  loss_giou_0: 0.2788  loss_bbox_0: 0.2557  loss_rpn_cls: 0.1888  loss_rpn_reg: 0.4301  time: 0.1891  last_time: 0.1973  data_time: 0.0052  last_data_time: 0.0063   lr: 5e-06  max_mem: 3029M
[03/05 13:45:23] d2.utils.events INFO:  eta: 0:50:00  iter: 38039  total_loss: 2.435  loss_ce: 0.3124  loss_giou: 0.3059  loss_bbox: 0.2505  loss_ce_0: 0.3326  loss_giou_0: 0.315  loss_bbox_0: 0.2496  loss_rpn_cls: 0.1974  loss_rpn_reg: 0.4302  time: 0.1891  last_time: 0.1967  data_time: 0.0050  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 13:45:27] d2.utils.events INFO:  eta: 0:49:56  iter: 38059  total_loss: 2.514  loss_ce: 0.3261  loss_giou: 0.2981  loss_bbox: 0.2132  loss_ce_0: 0.3517  loss_giou_0: 0.321  loss_bbox_0: 0.2433  loss_rpn_cls: 0.1963  loss_rpn_reg: 0.4376  time: 0.1891  last_time: 0.2014  data_time: 0.0050  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 13:45:31] d2.utils.events INFO:  eta: 0:49:53  iter: 38079  total_loss: 2.27  loss_ce: 0.248  loss_giou: 0.2781  loss_bbox: 0.2143  loss_ce_0: 0.3308  loss_giou_0: 0.2947  loss_bbox_0: 0.2544  loss_rpn_cls: 0.1906  loss_rpn_reg: 0.4325  time: 0.1891  last_time: 0.1818  data_time: 0.0048  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 13:45:35] d2.utils.events INFO:  eta: 0:49:48  iter: 38099  total_loss: 2.398  loss_ce: 0.3023  loss_giou: 0.2789  loss_bbox: 0.2235  loss_ce_0: 0.3242  loss_giou_0: 0.2889  loss_bbox_0: 0.2518  loss_rpn_cls: 0.1883  loss_rpn_reg: 0.4259  time: 0.1891  last_time: 0.1784  data_time: 0.0049  last_data_time: 0.0051   lr: 5e-06  max_mem: 3029M
[03/05 13:45:38] d2.utils.events INFO:  eta: 0:49:45  iter: 38119  total_loss: 2.391  loss_ce: 0.3172  loss_giou: 0.2819  loss_bbox: 0.2241  loss_ce_0: 0.3539  loss_giou_0: 0.2946  loss_bbox_0: 0.2277  loss_rpn_cls: 0.188  loss_rpn_reg: 0.4321  time: 0.1891  last_time: 0.1925  data_time: 0.0052  last_data_time: 0.0053   lr: 5e-06  max_mem: 3029M
[03/05 13:45:42] d2.utils.events INFO:  eta: 0:49:42  iter: 38139  total_loss: 2.752  loss_ce: 0.3218  loss_giou: 0.3403  loss_bbox: 0.2488  loss_ce_0: 0.3521  loss_giou_0: 0.364  loss_bbox_0: 0.2604  loss_rpn_cls: 0.2068  loss_rpn_reg: 0.4518  time: 0.1891  last_time: 0.1761  data_time: 0.0048  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 13:45:46] d2.utils.events INFO:  eta: 0:49:39  iter: 38159  total_loss: 2.187  loss_ce: 0.2988  loss_giou: 0.274  loss_bbox: 0.2302  loss_ce_0: 0.3567  loss_giou_0: 0.291  loss_bbox_0: 0.2449  loss_rpn_cls: 0.1832  loss_rpn_reg: 0.4572  time: 0.1891  last_time: 0.1979  data_time: 0.0052  last_data_time: 0.0056   lr: 5e-06  max_mem: 3029M
[03/05 13:45:50] d2.utils.events INFO:  eta: 0:49:34  iter: 38179  total_loss: 2.353  loss_ce: 0.2916  loss_giou: 0.2736  loss_bbox: 0.2678  loss_ce_0: 0.3376  loss_giou_0: 0.289  loss_bbox_0: 0.286  loss_rpn_cls: 0.2184  loss_rpn_reg: 0.396  time: 0.1891  last_time: 0.1765  data_time: 0.0052  last_data_time: 0.0063   lr: 5e-06  max_mem: 3029M
[03/05 13:45:54] d2.utils.events INFO:  eta: 0:49:31  iter: 38199  total_loss: 2.243  loss_ce: 0.2689  loss_giou: 0.2809  loss_bbox: 0.2214  loss_ce_0: 0.3186  loss_giou_0: 0.3059  loss_bbox_0: 0.24  loss_rpn_cls: 0.1646  loss_rpn_reg: 0.4086  time: 0.1891  last_time: 0.1857  data_time: 0.0053  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 13:45:57] d2.utils.events INFO:  eta: 0:49:26  iter: 38219  total_loss: 2.418  loss_ce: 0.3117  loss_giou: 0.2582  loss_bbox: 0.2336  loss_ce_0: 0.355  loss_giou_0: 0.2699  loss_bbox_0: 0.2677  loss_rpn_cls: 0.1821  loss_rpn_reg: 0.4021  time: 0.1891  last_time: 0.1779  data_time: 0.0050  last_data_time: 0.0059   lr: 5e-06  max_mem: 3029M
[03/05 13:46:01] d2.utils.events INFO:  eta: 0:49:20  iter: 38239  total_loss: 2.452  loss_ce: 0.3388  loss_giou: 0.2913  loss_bbox: 0.259  loss_ce_0: 0.3541  loss_giou_0: 0.3179  loss_bbox_0: 0.2731  loss_rpn_cls: 0.197  loss_rpn_reg: 0.4533  time: 0.1890  last_time: 0.1735  data_time: 0.0045  last_data_time: 0.0049   lr: 5e-06  max_mem: 3029M
[03/05 13:46:05] d2.utils.events INFO:  eta: 0:49:20  iter: 38259  total_loss: 2.526  loss_ce: 0.3489  loss_giou: 0.2757  loss_bbox: 0.2322  loss_ce_0: 0.3693  loss_giou_0: 0.3093  loss_bbox_0: 0.292  loss_rpn_cls: 0.1954  loss_rpn_reg: 0.4427  time: 0.1890  last_time: 0.1744  data_time: 0.0056  last_data_time: 0.0075   lr: 5e-06  max_mem: 3029M
[03/05 13:46:09] d2.utils.events INFO:  eta: 0:49:16  iter: 38279  total_loss: 2.376  loss_ce: 0.3203  loss_giou: 0.291  loss_bbox: 0.2475  loss_ce_0: 0.3719  loss_giou_0: 0.3153  loss_bbox_0: 0.2837  loss_rpn_cls: 0.1992  loss_rpn_reg: 0.4079  time: 0.1891  last_time: 0.1887  data_time: 0.0048  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 13:46:13] d2.utils.events INFO:  eta: 0:49:12  iter: 38299  total_loss: 2.642  loss_ce: 0.3446  loss_giou: 0.3046  loss_bbox: 0.2589  loss_ce_0: 0.4036  loss_giou_0: 0.3092  loss_bbox_0: 0.2952  loss_rpn_cls: 0.2297  loss_rpn_reg: 0.4779  time: 0.1891  last_time: 0.1921  data_time: 0.0049  last_data_time: 0.0024   lr: 5e-06  max_mem: 3029M
[03/05 13:46:17] d2.utils.events INFO:  eta: 0:49:07  iter: 38319  total_loss: 2.524  loss_ce: 0.2947  loss_giou: 0.3219  loss_bbox: 0.2633  loss_ce_0: 0.3893  loss_giou_0: 0.3458  loss_bbox_0: 0.2869  loss_rpn_cls: 0.1993  loss_rpn_reg: 0.423  time: 0.1891  last_time: 0.1766  data_time: 0.0052  last_data_time: 0.0051   lr: 5e-06  max_mem: 3029M
[03/05 13:46:21] d2.utils.events INFO:  eta: 0:49:05  iter: 38339  total_loss: 2.254  loss_ce: 0.3002  loss_giou: 0.2828  loss_bbox: 0.2116  loss_ce_0: 0.3565  loss_giou_0: 0.3226  loss_bbox_0: 0.2636  loss_rpn_cls: 0.1795  loss_rpn_reg: 0.41  time: 0.1891  last_time: 0.2044  data_time: 0.0050  last_data_time: 0.0060   lr: 5e-06  max_mem: 3029M
[03/05 13:46:25] d2.utils.events INFO:  eta: 0:49:03  iter: 38359  total_loss: 2.177  loss_ce: 0.2904  loss_giou: 0.273  loss_bbox: 0.1936  loss_ce_0: 0.309  loss_giou_0: 0.2916  loss_bbox_0: 0.2171  loss_rpn_cls: 0.1763  loss_rpn_reg: 0.4148  time: 0.1891  last_time: 0.1887  data_time: 0.0047  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 13:46:28] d2.utils.events INFO:  eta: 0:49:02  iter: 38379  total_loss: 2.36  loss_ce: 0.2981  loss_giou: 0.2773  loss_bbox: 0.2039  loss_ce_0: 0.3435  loss_giou_0: 0.2732  loss_bbox_0: 0.2255  loss_rpn_cls: 0.2252  loss_rpn_reg: 0.4265  time: 0.1891  last_time: 0.1813  data_time: 0.0052  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 13:46:32] d2.utils.events INFO:  eta: 0:49:00  iter: 38399  total_loss: 2.264  loss_ce: 0.278  loss_giou: 0.2613  loss_bbox: 0.2339  loss_ce_0: 0.3179  loss_giou_0: 0.289  loss_bbox_0: 0.2722  loss_rpn_cls: 0.1653  loss_rpn_reg: 0.4232  time: 0.1891  last_time: 0.1895  data_time: 0.0049  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 13:46:36] d2.utils.events INFO:  eta: 0:48:57  iter: 38419  total_loss: 2.352  loss_ce: 0.3419  loss_giou: 0.3142  loss_bbox: 0.1904  loss_ce_0: 0.379  loss_giou_0: 0.3287  loss_bbox_0: 0.2249  loss_rpn_cls: 0.2137  loss_rpn_reg: 0.4344  time: 0.1891  last_time: 0.1916  data_time: 0.0049  last_data_time: 0.0134   lr: 5e-06  max_mem: 3029M
[03/05 13:46:40] d2.utils.events INFO:  eta: 0:48:53  iter: 38439  total_loss: 2.576  loss_ce: 0.4207  loss_giou: 0.3121  loss_bbox: 0.2591  loss_ce_0: 0.4317  loss_giou_0: 0.3179  loss_bbox_0: 0.2841  loss_rpn_cls: 0.2108  loss_rpn_reg: 0.4345  time: 0.1891  last_time: 0.1570  data_time: 0.0057  last_data_time: 0.0076   lr: 5e-06  max_mem: 3029M
[03/05 13:46:44] d2.utils.events INFO:  eta: 0:48:50  iter: 38459  total_loss: 2.529  loss_ce: 0.2833  loss_giou: 0.334  loss_bbox: 0.2713  loss_ce_0: 0.3001  loss_giou_0: 0.3436  loss_bbox_0: 0.3018  loss_rpn_cls: 0.1938  loss_rpn_reg: 0.4529  time: 0.1891  last_time: 0.1652  data_time: 0.0050  last_data_time: 0.0034   lr: 5e-06  max_mem: 3029M
[03/05 13:46:47] d2.utils.events INFO:  eta: 0:48:48  iter: 38479  total_loss: 2.37  loss_ce: 0.301  loss_giou: 0.3025  loss_bbox: 0.2547  loss_ce_0: 0.3509  loss_giou_0: 0.3185  loss_bbox_0: 0.2592  loss_rpn_cls: 0.181  loss_rpn_reg: 0.4596  time: 0.1891  last_time: 0.1933  data_time: 0.0053  last_data_time: 0.0023   lr: 5e-06  max_mem: 3029M
[03/05 13:46:51] d2.utils.events INFO:  eta: 0:48:45  iter: 38499  total_loss: 2.538  loss_ce: 0.3319  loss_giou: 0.2795  loss_bbox: 0.2449  loss_ce_0: 0.3698  loss_giou_0: 0.3099  loss_bbox_0: 0.2892  loss_rpn_cls: 0.2122  loss_rpn_reg: 0.4505  time: 0.1891  last_time: 0.1808  data_time: 0.0051  last_data_time: 0.0050   lr: 5e-06  max_mem: 3029M
[03/05 13:46:55] d2.utils.events INFO:  eta: 0:48:42  iter: 38519  total_loss: 2.208  loss_ce: 0.2955  loss_giou: 0.2818  loss_bbox: 0.223  loss_ce_0: 0.3312  loss_giou_0: 0.3205  loss_bbox_0: 0.2571  loss_rpn_cls: 0.1969  loss_rpn_reg: 0.3955  time: 0.1891  last_time: 0.1903  data_time: 0.0053  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 13:46:59] d2.utils.events INFO:  eta: 0:48:40  iter: 38539  total_loss: 2.144  loss_ce: 0.2686  loss_giou: 0.2757  loss_bbox: 0.2279  loss_ce_0: 0.2675  loss_giou_0: 0.2978  loss_bbox_0: 0.2412  loss_rpn_cls: 0.1711  loss_rpn_reg: 0.3986  time: 0.1891  last_time: 0.2108  data_time: 0.0049  last_data_time: 0.0058   lr: 5e-06  max_mem: 3029M
[03/05 13:47:03] d2.utils.events INFO:  eta: 0:48:38  iter: 38559  total_loss: 2.504  loss_ce: 0.2919  loss_giou: 0.3036  loss_bbox: 0.2463  loss_ce_0: 0.3244  loss_giou_0: 0.3336  loss_bbox_0: 0.2611  loss_rpn_cls: 0.1856  loss_rpn_reg: 0.4449  time: 0.1891  last_time: 0.1918  data_time: 0.0054  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 13:47:06] d2.utils.events INFO:  eta: 0:48:33  iter: 38579  total_loss: 2.603  loss_ce: 0.3652  loss_giou: 0.3459  loss_bbox: 0.2435  loss_ce_0: 0.3978  loss_giou_0: 0.3563  loss_bbox_0: 0.2679  loss_rpn_cls: 0.2089  loss_rpn_reg: 0.4555  time: 0.1890  last_time: 0.1750  data_time: 0.0046  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 13:47:10] d2.utils.events INFO:  eta: 0:48:29  iter: 38599  total_loss: 2.21  loss_ce: 0.2795  loss_giou: 0.2544  loss_bbox: 0.2416  loss_ce_0: 0.3494  loss_giou_0: 0.2751  loss_bbox_0: 0.2641  loss_rpn_cls: 0.1839  loss_rpn_reg: 0.4358  time: 0.1890  last_time: 0.1952  data_time: 0.0052  last_data_time: 0.0092   lr: 5e-06  max_mem: 3029M
[03/05 13:47:14] d2.utils.events INFO:  eta: 0:48:25  iter: 38619  total_loss: 2.444  loss_ce: 0.3612  loss_giou: 0.2619  loss_bbox: 0.2399  loss_ce_0: 0.4125  loss_giou_0: 0.2593  loss_bbox_0: 0.2322  loss_rpn_cls: 0.2024  loss_rpn_reg: 0.4261  time: 0.1890  last_time: 0.1861  data_time: 0.0046  last_data_time: 0.0048   lr: 5e-06  max_mem: 3029M
[03/05 13:47:18] d2.utils.events INFO:  eta: 0:48:21  iter: 38639  total_loss: 2.68  loss_ce: 0.3273  loss_giou: 0.2802  loss_bbox: 0.2433  loss_ce_0: 0.377  loss_giou_0: 0.3225  loss_bbox_0: 0.2836  loss_rpn_cls: 0.2214  loss_rpn_reg: 0.431  time: 0.1890  last_time: 0.1897  data_time: 0.0049  last_data_time: 0.0072   lr: 5e-06  max_mem: 3029M
[03/05 13:47:22] d2.utils.events INFO:  eta: 0:48:15  iter: 38659  total_loss: 2.049  loss_ce: 0.2936  loss_giou: 0.2464  loss_bbox: 0.2261  loss_ce_0: 0.3514  loss_giou_0: 0.2589  loss_bbox_0: 0.2359  loss_rpn_cls: 0.1768  loss_rpn_reg: 0.4062  time: 0.1890  last_time: 0.1546  data_time: 0.0047  last_data_time: 0.0047   lr: 5e-06  max_mem: 3029M
[03/05 13:47:26] d2.utils.events INFO:  eta: 0:48:12  iter: 38679  total_loss: 2.403  loss_ce: 0.3705  loss_giou: 0.3266  loss_bbox: 0.1838  loss_ce_0: 0.4155  loss_giou_0: 0.3406  loss_bbox_0: 0.1998  loss_rpn_cls: 0.1876  loss_rpn_reg: 0.4415  time: 0.1890  last_time: 0.2035  data_time: 0.0060  last_data_time: 0.0069   lr: 5e-06  max_mem: 3029M
[03/05 13:47:29] d2.utils.events INFO:  eta: 0:48:10  iter: 38699  total_loss: 2.354  loss_ce: 0.3794  loss_giou: 0.2405  loss_bbox: 0.2003  loss_ce_0: 0.468  loss_giou_0: 0.2624  loss_bbox_0: 0.242  loss_rpn_cls: 0.1625  loss_rpn_reg: 0.4207  time: 0.1890  last_time: 0.2085  data_time: 0.0048  last_data_time: 0.0032   lr: 5e-06  max_mem: 3029M
[03/05 13:47:33] d2.utils.events INFO:  eta: 0:48:04  iter: 38719  total_loss: 2.603  loss_ce: 0.363  loss_giou: 0.2562  loss_bbox: 0.2225  loss_ce_0: 0.4019  loss_giou_0: 0.267  loss_bbox_0: 0.2694  loss_rpn_cls: 0.1926  loss_rpn_reg: 0.443  time: 0.1890  last_time: 0.2133  data_time: 0.0052  last_data_time: 0.0068   lr: 5e-06  max_mem: 3029M
[03/05 13:47:37] d2.utils.events INFO:  eta: 0:48:01  iter: 38739  total_loss: 2.57  loss_ce: 0.3358  loss_giou: 0.2671  loss_bbox: 0.2604  loss_ce_0: 0.3861  loss_giou_0: 0.2931  loss_bbox_0: 0.2754  loss_rpn_cls: 0.2025  loss_rpn_reg: 0.4024  time: 0.1890  last_time: 0.1723  data_time: 0.0059  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 13:47:41] d2.utils.events INFO:  eta: 0:47:59  iter: 38759  total_loss: 2.262  loss_ce: 0.33  loss_giou: 0.2612  loss_bbox: 0.1994  loss_ce_0: 0.3346  loss_giou_0: 0.2846  loss_bbox_0: 0.2164  loss_rpn_cls: 0.1951  loss_rpn_reg: 0.4266  time: 0.1891  last_time: 0.1785  data_time: 0.0059  last_data_time: 0.0033   lr: 5e-06  max_mem: 3029M
[03/05 13:47:45] d2.utils.events INFO:  eta: 0:47:57  iter: 38779  total_loss: 2.475  loss_ce: 0.2595  loss_giou: 0.2907  loss_bbox: 0.2643  loss_ce_0: 0.3308  loss_giou_0: 0.3181  loss_bbox_0: 0.2902  loss_rpn_cls: 0.1782  loss_rpn_reg: 0.4318  time: 0.1890  last_time: 0.1773  data_time: 0.0051  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 13:47:49] d2.utils.events INFO:  eta: 0:47:51  iter: 38799  total_loss: 2.704  loss_ce: 0.3463  loss_giou: 0.3207  loss_bbox: 0.2836  loss_ce_0: 0.3692  loss_giou_0: 0.3605  loss_bbox_0: 0.255  loss_rpn_cls: 0.1985  loss_rpn_reg: 0.438  time: 0.1890  last_time: 0.1837  data_time: 0.0053  last_data_time: 0.0072   lr: 5e-06  max_mem: 3029M
[03/05 13:47:52] d2.utils.events INFO:  eta: 0:47:45  iter: 38819  total_loss: 2.474  loss_ce: 0.3332  loss_giou: 0.2911  loss_bbox: 0.2343  loss_ce_0: 0.3529  loss_giou_0: 0.3065  loss_bbox_0: 0.2624  loss_rpn_cls: 0.1682  loss_rpn_reg: 0.4702  time: 0.1890  last_time: 0.1852  data_time: 0.0053  last_data_time: 0.0035   lr: 5e-06  max_mem: 3029M
[03/05 13:47:56] d2.utils.events INFO:  eta: 0:47:42  iter: 38839  total_loss: 2.364  loss_ce: 0.2906  loss_giou: 0.2683  loss_bbox: 0.2101  loss_ce_0: 0.3453  loss_giou_0: 0.2927  loss_bbox_0: 0.2484  loss_rpn_cls: 0.1974  loss_rpn_reg: 0.4276  time: 0.1890  last_time: 0.1909  data_time: 0.0052  last_data_time: 0.0061   lr: 5e-06  max_mem: 3029M
[03/05 13:48:00] d2.utils.events INFO:  eta: 0:47:36  iter: 38859  total_loss: 2.408  loss_ce: 0.3017  loss_giou: 0.2937  loss_bbox: 0.2348  loss_ce_0: 0.3721  loss_giou_0: 0.3104  loss_bbox_0: 0.2769  loss_rpn_cls: 0.2007  loss_rpn_reg: 0.4246  time: 0.1890  last_time: 0.1857  data_time: 0.0047  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 13:48:04] d2.utils.events INFO:  eta: 0:47:28  iter: 38879  total_loss: 2.41  loss_ce: 0.3341  loss_giou: 0.2814  loss_bbox: 0.2427  loss_ce_0: 0.3784  loss_giou_0: 0.3034  loss_bbox_0: 0.2788  loss_rpn_cls: 0.2053  loss_rpn_reg: 0.432  time: 0.1890  last_time: 0.1845  data_time: 0.0053  last_data_time: 0.0055   lr: 5e-06  max_mem: 3029M
[03/05 13:48:08] d2.utils.events INFO:  eta: 0:47:23  iter: 38899  total_loss: 2.459  loss_ce: 0.3149  loss_giou: 0.2695  loss_bbox: 0.2256  loss_ce_0: 0.3173  loss_giou_0: 0.2799  loss_bbox_0: 0.2585  loss_rpn_cls: 0.1962  loss_rpn_reg: 0.47  time: 0.1890  last_time: 0.1982  data_time: 0.0053  last_data_time: 0.0073   lr: 5e-06  max_mem: 3029M
[03/05 13:48:11] d2.utils.events INFO:  eta: 0:47:19  iter: 38919  total_loss: 2.455  loss_ce: 0.2668  loss_giou: 0.3067  loss_bbox: 0.2165  loss_ce_0: 0.2972  loss_giou_0: 0.3385  loss_bbox_0: 0.2444  loss_rpn_cls: 0.1856  loss_rpn_reg: 0.4242  time: 0.1890  last_time: 0.1699  data_time: 0.0050  last_data_time: 0.0056   lr: 5e-06  max_mem: 3029M
[03/05 13:48:15] d2.utils.events INFO:  eta: 0:47:15  iter: 38939  total_loss: 2.2  loss_ce: 0.2694  loss_giou: 0.2436  loss_bbox: 0.2307  loss_ce_0: 0.336  loss_giou_0: 0.2729  loss_bbox_0: 0.2236  loss_rpn_cls: 0.1761  loss_rpn_reg: 0.4181  time: 0.1890  last_time: 0.2124  data_time: 0.0053  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 13:48:19] d2.utils.events INFO:  eta: 0:47:11  iter: 38959  total_loss: 2.392  loss_ce: 0.3022  loss_giou: 0.2926  loss_bbox: 0.2164  loss_ce_0: 0.3453  loss_giou_0: 0.3255  loss_bbox_0: 0.2515  loss_rpn_cls: 0.1913  loss_rpn_reg: 0.431  time: 0.1890  last_time: 0.1867  data_time: 0.0047  last_data_time: 0.0048   lr: 5e-06  max_mem: 3029M
[03/05 13:48:23] d2.utils.events INFO:  eta: 0:47:06  iter: 38979  total_loss: 2.627  loss_ce: 0.3666  loss_giou: 0.2783  loss_bbox: 0.2489  loss_ce_0: 0.3855  loss_giou_0: 0.3101  loss_bbox_0: 0.2762  loss_rpn_cls: 0.2052  loss_rpn_reg: 0.4379  time: 0.1890  last_time: 0.2019  data_time: 0.0049  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 13:48:27] d2.utils.events INFO:  eta: 0:47:04  iter: 38999  total_loss: 2.347  loss_ce: 0.2842  loss_giou: 0.2876  loss_bbox: 0.2024  loss_ce_0: 0.3107  loss_giou_0: 0.3163  loss_bbox_0: 0.2373  loss_rpn_cls: 0.1938  loss_rpn_reg: 0.4105  time: 0.1890  last_time: 0.1903  data_time: 0.0053  last_data_time: 0.0031   lr: 5e-06  max_mem: 3029M
[03/05 13:48:30] d2.utils.events INFO:  eta: 0:46:58  iter: 39019  total_loss: 2.585  loss_ce: 0.3298  loss_giou: 0.2906  loss_bbox: 0.2356  loss_ce_0: 0.3894  loss_giou_0: 0.2944  loss_bbox_0: 0.2587  loss_rpn_cls: 0.2134  loss_rpn_reg: 0.4471  time: 0.1890  last_time: 0.1604  data_time: 0.0051  last_data_time: 0.0034   lr: 5e-06  max_mem: 3029M
[03/05 13:48:34] d2.utils.events INFO:  eta: 0:46:53  iter: 39039  total_loss: 2.553  loss_ce: 0.3267  loss_giou: 0.2764  loss_bbox: 0.2816  loss_ce_0: 0.3681  loss_giou_0: 0.2939  loss_bbox_0: 0.2726  loss_rpn_cls: 0.2364  loss_rpn_reg: 0.422  time: 0.1890  last_time: 0.1655  data_time: 0.0053  last_data_time: 0.0061   lr: 5e-06  max_mem: 3029M
[03/05 13:48:38] d2.utils.events INFO:  eta: 0:46:49  iter: 39059  total_loss: 2.357  loss_ce: 0.3179  loss_giou: 0.308  loss_bbox: 0.2434  loss_ce_0: 0.3472  loss_giou_0: 0.3281  loss_bbox_0: 0.2604  loss_rpn_cls: 0.1955  loss_rpn_reg: 0.4258  time: 0.1890  last_time: 0.2221  data_time: 0.0048  last_data_time: 0.0060   lr: 5e-06  max_mem: 3029M
[03/05 13:48:42] d2.utils.events INFO:  eta: 0:46:43  iter: 39079  total_loss: 2.434  loss_ce: 0.3005  loss_giou: 0.3091  loss_bbox: 0.2338  loss_ce_0: 0.3378  loss_giou_0: 0.3297  loss_bbox_0: 0.2705  loss_rpn_cls: 0.1922  loss_rpn_reg: 0.442  time: 0.1890  last_time: 0.2177  data_time: 0.0048  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 13:48:46] d2.utils.events INFO:  eta: 0:46:42  iter: 39099  total_loss: 2.272  loss_ce: 0.2749  loss_giou: 0.2682  loss_bbox: 0.2224  loss_ce_0: 0.334  loss_giou_0: 0.291  loss_bbox_0: 0.262  loss_rpn_cls: 0.1868  loss_rpn_reg: 0.419  time: 0.1890  last_time: 0.1984  data_time: 0.0056  last_data_time: 0.0034   lr: 5e-06  max_mem: 3029M
[03/05 13:48:49] d2.utils.events INFO:  eta: 0:46:37  iter: 39119  total_loss: 2.426  loss_ce: 0.3112  loss_giou: 0.3034  loss_bbox: 0.2167  loss_ce_0: 0.3732  loss_giou_0: 0.3291  loss_bbox_0: 0.242  loss_rpn_cls: 0.1818  loss_rpn_reg: 0.441  time: 0.1890  last_time: 0.1950  data_time: 0.0050  last_data_time: 0.0045   lr: 5e-06  max_mem: 3029M
[03/05 13:48:53] d2.utils.events INFO:  eta: 0:46:32  iter: 39139  total_loss: 2.303  loss_ce: 0.2802  loss_giou: 0.2877  loss_bbox: 0.2213  loss_ce_0: 0.3465  loss_giou_0: 0.3214  loss_bbox_0: 0.2753  loss_rpn_cls: 0.1773  loss_rpn_reg: 0.4379  time: 0.1890  last_time: 0.2123  data_time: 0.0047  last_data_time: 0.0045   lr: 5e-06  max_mem: 3029M
[03/05 13:48:57] d2.utils.events INFO:  eta: 0:46:28  iter: 39159  total_loss: 2.681  loss_ce: 0.3572  loss_giou: 0.2963  loss_bbox: 0.2678  loss_ce_0: 0.3704  loss_giou_0: 0.3082  loss_bbox_0: 0.2427  loss_rpn_cls: 0.1951  loss_rpn_reg: 0.4181  time: 0.1890  last_time: 0.1917  data_time: 0.0046  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 13:49:01] d2.utils.events INFO:  eta: 0:46:25  iter: 39179  total_loss: 2.228  loss_ce: 0.2809  loss_giou: 0.2777  loss_bbox: 0.1955  loss_ce_0: 0.3646  loss_giou_0: 0.2959  loss_bbox_0: 0.2273  loss_rpn_cls: 0.1937  loss_rpn_reg: 0.4231  time: 0.1890  last_time: 0.2046  data_time: 0.0052  last_data_time: 0.0132   lr: 5e-06  max_mem: 3029M
[03/05 13:49:05] d2.utils.events INFO:  eta: 0:46:23  iter: 39199  total_loss: 2.471  loss_ce: 0.2793  loss_giou: 0.2822  loss_bbox: 0.2372  loss_ce_0: 0.3371  loss_giou_0: 0.298  loss_bbox_0: 0.2429  loss_rpn_cls: 0.1845  loss_rpn_reg: 0.416  time: 0.1890  last_time: 0.1924  data_time: 0.0049  last_data_time: 0.0088   lr: 5e-06  max_mem: 3029M
[03/05 13:49:09] d2.utils.events INFO:  eta: 0:46:21  iter: 39219  total_loss: 2.353  loss_ce: 0.2705  loss_giou: 0.258  loss_bbox: 0.2215  loss_ce_0: 0.2925  loss_giou_0: 0.2783  loss_bbox_0: 0.2477  loss_rpn_cls: 0.1895  loss_rpn_reg: 0.3914  time: 0.1890  last_time: 0.1899  data_time: 0.0050  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 13:49:12] d2.utils.events INFO:  eta: 0:46:18  iter: 39239  total_loss: 2.567  loss_ce: 0.3214  loss_giou: 0.3045  loss_bbox: 0.2337  loss_ce_0: 0.3822  loss_giou_0: 0.3814  loss_bbox_0: 0.2613  loss_rpn_cls: 0.2361  loss_rpn_reg: 0.4593  time: 0.1890  last_time: 0.1907  data_time: 0.0052  last_data_time: 0.0053   lr: 5e-06  max_mem: 3029M
[03/05 13:49:16] d2.utils.events INFO:  eta: 0:46:13  iter: 39259  total_loss: 2.232  loss_ce: 0.2454  loss_giou: 0.2806  loss_bbox: 0.2133  loss_ce_0: 0.329  loss_giou_0: 0.3047  loss_bbox_0: 0.2324  loss_rpn_cls: 0.183  loss_rpn_reg: 0.4093  time: 0.1890  last_time: 0.2055  data_time: 0.0052  last_data_time: 0.0099   lr: 5e-06  max_mem: 3029M
[03/05 13:49:20] d2.utils.events INFO:  eta: 0:46:10  iter: 39279  total_loss: 2.555  loss_ce: 0.333  loss_giou: 0.2977  loss_bbox: 0.2395  loss_ce_0: 0.3679  loss_giou_0: 0.3283  loss_bbox_0: 0.2645  loss_rpn_cls: 0.2162  loss_rpn_reg: 0.4712  time: 0.1890  last_time: 0.2030  data_time: 0.0046  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 13:49:24] d2.utils.events INFO:  eta: 0:46:03  iter: 39299  total_loss: 2.399  loss_ce: 0.3307  loss_giou: 0.2663  loss_bbox: 0.2255  loss_ce_0: 0.3939  loss_giou_0: 0.2845  loss_bbox_0: 0.2551  loss_rpn_cls: 0.1988  loss_rpn_reg: 0.3998  time: 0.1890  last_time: 0.1872  data_time: 0.0050  last_data_time: 0.0057   lr: 5e-06  max_mem: 3029M
[03/05 13:49:28] d2.utils.events INFO:  eta: 0:46:00  iter: 39319  total_loss: 2.608  loss_ce: 0.3146  loss_giou: 0.3025  loss_bbox: 0.2523  loss_ce_0: 0.377  loss_giou_0: 0.3089  loss_bbox_0: 0.2735  loss_rpn_cls: 0.2004  loss_rpn_reg: 0.4607  time: 0.1890  last_time: 0.2135  data_time: 0.0048  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 13:49:32] d2.utils.events INFO:  eta: 0:45:56  iter: 39339  total_loss: 2.244  loss_ce: 0.298  loss_giou: 0.2739  loss_bbox: 0.2456  loss_ce_0: 0.319  loss_giou_0: 0.2739  loss_bbox_0: 0.2764  loss_rpn_cls: 0.2145  loss_rpn_reg: 0.4108  time: 0.1890  last_time: 0.1807  data_time: 0.0051  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 13:49:36] d2.utils.events INFO:  eta: 0:45:50  iter: 39359  total_loss: 2.28  loss_ce: 0.2806  loss_giou: 0.3141  loss_bbox: 0.2239  loss_ce_0: 0.3149  loss_giou_0: 0.3241  loss_bbox_0: 0.2356  loss_rpn_cls: 0.1917  loss_rpn_reg: 0.4045  time: 0.1890  last_time: 0.1962  data_time: 0.0046  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 13:49:40] d2.utils.events INFO:  eta: 0:45:46  iter: 39379  total_loss: 2.352  loss_ce: 0.2991  loss_giou: 0.3154  loss_bbox: 0.2536  loss_ce_0: 0.3526  loss_giou_0: 0.3288  loss_bbox_0: 0.2743  loss_rpn_cls: 0.187  loss_rpn_reg: 0.4624  time: 0.1890  last_time: 0.1833  data_time: 0.0048  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 13:49:43] d2.utils.events INFO:  eta: 0:45:42  iter: 39399  total_loss: 2.712  loss_ce: 0.3083  loss_giou: 0.3221  loss_bbox: 0.2998  loss_ce_0: 0.3555  loss_giou_0: 0.3345  loss_bbox_0: 0.3059  loss_rpn_cls: 0.2147  loss_rpn_reg: 0.4685  time: 0.1890  last_time: 0.2050  data_time: 0.0057  last_data_time: 0.0075   lr: 5e-06  max_mem: 3029M
[03/05 13:49:47] d2.utils.events INFO:  eta: 0:45:38  iter: 39419  total_loss: 2.583  loss_ce: 0.3088  loss_giou: 0.3217  loss_bbox: 0.2706  loss_ce_0: 0.3375  loss_giou_0: 0.3368  loss_bbox_0: 0.2917  loss_rpn_cls: 0.2031  loss_rpn_reg: 0.4348  time: 0.1890  last_time: 0.1864  data_time: 0.0050  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 13:49:51] d2.utils.events INFO:  eta: 0:45:34  iter: 39439  total_loss: 2.394  loss_ce: 0.2508  loss_giou: 0.2906  loss_bbox: 0.2422  loss_ce_0: 0.3075  loss_giou_0: 0.3114  loss_bbox_0: 0.2733  loss_rpn_cls: 0.1688  loss_rpn_reg: 0.4024  time: 0.1890  last_time: 0.1933  data_time: 0.0049  last_data_time: 0.0056   lr: 5e-06  max_mem: 3029M
[03/05 13:49:55] d2.utils.events INFO:  eta: 0:45:32  iter: 39459  total_loss: 2.435  loss_ce: 0.3469  loss_giou: 0.2584  loss_bbox: 0.2799  loss_ce_0: 0.4135  loss_giou_0: 0.2922  loss_bbox_0: 0.2917  loss_rpn_cls: 0.197  loss_rpn_reg: 0.4589  time: 0.1890  last_time: 0.1927  data_time: 0.0055  last_data_time: 0.0055   lr: 5e-06  max_mem: 3029M
[03/05 13:49:59] d2.utils.events INFO:  eta: 0:45:26  iter: 39479  total_loss: 2.341  loss_ce: 0.3205  loss_giou: 0.323  loss_bbox: 0.2472  loss_ce_0: 0.3504  loss_giou_0: 0.3342  loss_bbox_0: 0.2542  loss_rpn_cls: 0.1931  loss_rpn_reg: 0.433  time: 0.1890  last_time: 0.1892  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 13:50:03] d2.utils.events INFO:  eta: 0:45:22  iter: 39499  total_loss: 2.473  loss_ce: 0.3185  loss_giou: 0.314  loss_bbox: 0.2007  loss_ce_0: 0.3303  loss_giou_0: 0.326  loss_bbox_0: 0.2179  loss_rpn_cls: 0.2084  loss_rpn_reg: 0.411  time: 0.1890  last_time: 0.1721  data_time: 0.0048  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 13:50:06] d2.utils.events INFO:  eta: 0:45:16  iter: 39519  total_loss: 2.311  loss_ce: 0.2693  loss_giou: 0.277  loss_bbox: 0.218  loss_ce_0: 0.3065  loss_giou_0: 0.3037  loss_bbox_0: 0.2445  loss_rpn_cls: 0.171  loss_rpn_reg: 0.4117  time: 0.1890  last_time: 0.1867  data_time: 0.0049  last_data_time: 0.0049   lr: 5e-06  max_mem: 3029M
[03/05 13:50:10] d2.utils.events INFO:  eta: 0:45:13  iter: 39539  total_loss: 2.662  loss_ce: 0.3444  loss_giou: 0.2453  loss_bbox: 0.2262  loss_ce_0: 0.3827  loss_giou_0: 0.287  loss_bbox_0: 0.2667  loss_rpn_cls: 0.161  loss_rpn_reg: 0.4555  time: 0.1890  last_time: 0.1588  data_time: 0.0054  last_data_time: 0.0028   lr: 5e-06  max_mem: 3029M
[03/05 13:50:14] d2.utils.events INFO:  eta: 0:45:10  iter: 39559  total_loss: 2.354  loss_ce: 0.3382  loss_giou: 0.2872  loss_bbox: 0.2236  loss_ce_0: 0.3624  loss_giou_0: 0.3244  loss_bbox_0: 0.2537  loss_rpn_cls: 0.1884  loss_rpn_reg: 0.4319  time: 0.1890  last_time: 0.1850  data_time: 0.0051  last_data_time: 0.0059   lr: 5e-06  max_mem: 3029M
[03/05 13:50:18] d2.utils.events INFO:  eta: 0:45:06  iter: 39579  total_loss: 2.371  loss_ce: 0.3245  loss_giou: 0.2444  loss_bbox: 0.2298  loss_ce_0: 0.3499  loss_giou_0: 0.2871  loss_bbox_0: 0.2637  loss_rpn_cls: 0.2059  loss_rpn_reg: 0.4273  time: 0.1890  last_time: 0.1969  data_time: 0.0049  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 13:50:22] d2.utils.events INFO:  eta: 0:45:01  iter: 39599  total_loss: 2.532  loss_ce: 0.299  loss_giou: 0.2923  loss_bbox: 0.2438  loss_ce_0: 0.3219  loss_giou_0: 0.315  loss_bbox_0: 0.2764  loss_rpn_cls: 0.181  loss_rpn_reg: 0.4416  time: 0.1890  last_time: 0.1784  data_time: 0.0043  last_data_time: 0.0053   lr: 5e-06  max_mem: 3029M
[03/05 13:50:25] d2.utils.events INFO:  eta: 0:44:57  iter: 39619  total_loss: 2.376  loss_ce: 0.3053  loss_giou: 0.2468  loss_bbox: 0.2362  loss_ce_0: 0.3605  loss_giou_0: 0.2585  loss_bbox_0: 0.2546  loss_rpn_cls: 0.209  loss_rpn_reg: 0.4199  time: 0.1890  last_time: 0.1594  data_time: 0.0049  last_data_time: 0.0066   lr: 5e-06  max_mem: 3029M
[03/05 13:50:29] d2.utils.events INFO:  eta: 0:44:52  iter: 39639  total_loss: 2.579  loss_ce: 0.2981  loss_giou: 0.2996  loss_bbox: 0.236  loss_ce_0: 0.3321  loss_giou_0: 0.3177  loss_bbox_0: 0.2333  loss_rpn_cls: 0.1873  loss_rpn_reg: 0.4427  time: 0.1890  last_time: 0.1938  data_time: 0.0047  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 13:50:33] d2.utils.events INFO:  eta: 0:44:48  iter: 39659  total_loss: 2.298  loss_ce: 0.311  loss_giou: 0.2643  loss_bbox: 0.2408  loss_ce_0: 0.3873  loss_giou_0: 0.2775  loss_bbox_0: 0.2539  loss_rpn_cls: 0.199  loss_rpn_reg: 0.4039  time: 0.1890  last_time: 0.1913  data_time: 0.0048  last_data_time: 0.0101   lr: 5e-06  max_mem: 3029M
[03/05 13:50:37] d2.utils.events INFO:  eta: 0:44:45  iter: 39679  total_loss: 2.509  loss_ce: 0.3588  loss_giou: 0.3039  loss_bbox: 0.2576  loss_ce_0: 0.3654  loss_giou_0: 0.3301  loss_bbox_0: 0.2817  loss_rpn_cls: 0.2039  loss_rpn_reg: 0.4169  time: 0.1890  last_time: 0.2032  data_time: 0.0053  last_data_time: 0.0035   lr: 5e-06  max_mem: 3029M
[03/05 13:50:40] d2.utils.events INFO:  eta: 0:44:38  iter: 39699  total_loss: 2.348  loss_ce: 0.33  loss_giou: 0.2659  loss_bbox: 0.2817  loss_ce_0: 0.3451  loss_giou_0: 0.2927  loss_bbox_0: 0.2855  loss_rpn_cls: 0.1776  loss_rpn_reg: 0.4161  time: 0.1890  last_time: 0.1937  data_time: 0.0048  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 13:50:44] d2.utils.events INFO:  eta: 0:44:36  iter: 39719  total_loss: 2.404  loss_ce: 0.2677  loss_giou: 0.3174  loss_bbox: 0.2725  loss_ce_0: 0.3038  loss_giou_0: 0.3242  loss_bbox_0: 0.2794  loss_rpn_cls: 0.1701  loss_rpn_reg: 0.4415  time: 0.1890  last_time: 0.1896  data_time: 0.0054  last_data_time: 0.0048   lr: 5e-06  max_mem: 3029M
[03/05 13:50:48] d2.utils.events INFO:  eta: 0:44:32  iter: 39739  total_loss: 2.044  loss_ce: 0.2558  loss_giou: 0.293  loss_bbox: 0.2192  loss_ce_0: 0.2776  loss_giou_0: 0.3034  loss_bbox_0: 0.2538  loss_rpn_cls: 0.1819  loss_rpn_reg: 0.4106  time: 0.1890  last_time: 0.1956  data_time: 0.0052  last_data_time: 0.0059   lr: 5e-06  max_mem: 3029M
[03/05 13:50:52] d2.utils.events INFO:  eta: 0:44:28  iter: 39759  total_loss: 2.148  loss_ce: 0.2188  loss_giou: 0.2722  loss_bbox: 0.1975  loss_ce_0: 0.2551  loss_giou_0: 0.2993  loss_bbox_0: 0.2131  loss_rpn_cls: 0.1609  loss_rpn_reg: 0.4193  time: 0.1890  last_time: 0.1843  data_time: 0.0051  last_data_time: 0.0079   lr: 5e-06  max_mem: 3029M
[03/05 13:50:56] d2.utils.events INFO:  eta: 0:44:24  iter: 39779  total_loss: 2.3  loss_ce: 0.2906  loss_giou: 0.2472  loss_bbox: 0.2209  loss_ce_0: 0.3427  loss_giou_0: 0.2644  loss_bbox_0: 0.2498  loss_rpn_cls: 0.1861  loss_rpn_reg: 0.4344  time: 0.1890  last_time: 0.1893  data_time: 0.0048  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 13:51:00] d2.utils.events INFO:  eta: 0:44:21  iter: 39799  total_loss: 2.491  loss_ce: 0.3401  loss_giou: 0.3081  loss_bbox: 0.2299  loss_ce_0: 0.3922  loss_giou_0: 0.3216  loss_bbox_0: 0.2569  loss_rpn_cls: 0.2125  loss_rpn_reg: 0.4547  time: 0.1890  last_time: 0.1988  data_time: 0.0051  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 13:51:04] d2.utils.events INFO:  eta: 0:44:18  iter: 39819  total_loss: 2.123  loss_ce: 0.2852  loss_giou: 0.2477  loss_bbox: 0.2284  loss_ce_0: 0.3181  loss_giou_0: 0.2544  loss_bbox_0: 0.2343  loss_rpn_cls: 0.1749  loss_rpn_reg: 0.3996  time: 0.1890  last_time: 0.1605  data_time: 0.0047  last_data_time: 0.0048   lr: 5e-06  max_mem: 3029M
[03/05 13:51:07] d2.utils.events INFO:  eta: 0:44:16  iter: 39839  total_loss: 2.563  loss_ce: 0.3154  loss_giou: 0.3042  loss_bbox: 0.2317  loss_ce_0: 0.3626  loss_giou_0: 0.3078  loss_bbox_0: 0.2638  loss_rpn_cls: 0.211  loss_rpn_reg: 0.4358  time: 0.1890  last_time: 0.2008  data_time: 0.0057  last_data_time: 0.0053   lr: 5e-06  max_mem: 3029M
[03/05 13:51:11] d2.utils.events INFO:  eta: 0:44:12  iter: 39859  total_loss: 2.259  loss_ce: 0.3071  loss_giou: 0.2553  loss_bbox: 0.1785  loss_ce_0: 0.3377  loss_giou_0: 0.2842  loss_bbox_0: 0.228  loss_rpn_cls: 0.1834  loss_rpn_reg: 0.4226  time: 0.1890  last_time: 0.1827  data_time: 0.0052  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 13:51:15] d2.utils.events INFO:  eta: 0:44:08  iter: 39879  total_loss: 2.401  loss_ce: 0.3353  loss_giou: 0.2493  loss_bbox: 0.1894  loss_ce_0: 0.3965  loss_giou_0: 0.2822  loss_bbox_0: 0.2494  loss_rpn_cls: 0.2053  loss_rpn_reg: 0.451  time: 0.1890  last_time: 0.2003  data_time: 0.0050  last_data_time: 0.0045   lr: 5e-06  max_mem: 3029M
[03/05 13:51:19] d2.utils.events INFO:  eta: 0:44:06  iter: 39899  total_loss: 2.471  loss_ce: 0.3006  loss_giou: 0.3428  loss_bbox: 0.2247  loss_ce_0: 0.3659  loss_giou_0: 0.3467  loss_bbox_0: 0.2418  loss_rpn_cls: 0.1976  loss_rpn_reg: 0.4256  time: 0.1890  last_time: 0.2059  data_time: 0.0048  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 13:51:23] d2.utils.events INFO:  eta: 0:44:02  iter: 39919  total_loss: 2.357  loss_ce: 0.3218  loss_giou: 0.2287  loss_bbox: 0.2254  loss_ce_0: 0.3663  loss_giou_0: 0.258  loss_bbox_0: 0.2501  loss_rpn_cls: 0.2075  loss_rpn_reg: 0.4106  time: 0.1890  last_time: 0.2085  data_time: 0.0051  last_data_time: 0.0065   lr: 5e-06  max_mem: 3029M
[03/05 13:51:27] d2.utils.events INFO:  eta: 0:43:59  iter: 39939  total_loss: 2.345  loss_ce: 0.2718  loss_giou: 0.3061  loss_bbox: 0.2289  loss_ce_0: 0.3055  loss_giou_0: 0.3273  loss_bbox_0: 0.2414  loss_rpn_cls: 0.179  loss_rpn_reg: 0.4494  time: 0.1890  last_time: 0.1820  data_time: 0.0055  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 13:51:31] d2.utils.events INFO:  eta: 0:43:58  iter: 39959  total_loss: 2.476  loss_ce: 0.3046  loss_giou: 0.2971  loss_bbox: 0.2347  loss_ce_0: 0.3197  loss_giou_0: 0.2888  loss_bbox_0: 0.2578  loss_rpn_cls: 0.1957  loss_rpn_reg: 0.4393  time: 0.1890  last_time: 0.2005  data_time: 0.0052  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 13:51:34] d2.utils.events INFO:  eta: 0:43:56  iter: 39979  total_loss: 2.587  loss_ce: 0.3387  loss_giou: 0.319  loss_bbox: 0.2402  loss_ce_0: 0.339  loss_giou_0: 0.3408  loss_bbox_0: 0.2716  loss_rpn_cls: 0.2257  loss_rpn_reg: 0.4456  time: 0.1890  last_time: 0.2043  data_time: 0.0046  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 13:51:38] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/t1/model_0039999.pth
[03/05 13:51:40] d2.utils.events INFO:  eta: 0:43:52  iter: 39999  total_loss: 2.579  loss_ce: 0.3443  loss_giou: 0.2854  loss_bbox: 0.255  loss_ce_0: 0.3474  loss_giou_0: 0.3023  loss_bbox_0: 0.2599  loss_rpn_cls: 0.1793  loss_rpn_reg: 0.4277  time: 0.1890  last_time: 0.2041  data_time: 0.0058  last_data_time: 0.0030   lr: 5e-06  max_mem: 3029M
[03/05 13:51:44] d2.utils.events INFO:  eta: 0:43:53  iter: 40019  total_loss: 2.543  loss_ce: 0.3811  loss_giou: 0.2826  loss_bbox: 0.2585  loss_ce_0: 0.3784  loss_giou_0: 0.2926  loss_bbox_0: 0.2721  loss_rpn_cls: 0.205  loss_rpn_reg: 0.4322  time: 0.1890  last_time: 0.1938  data_time: 0.0053  last_data_time: 0.0068   lr: 5e-06  max_mem: 3029M
[03/05 13:51:48] d2.utils.events INFO:  eta: 0:43:50  iter: 40039  total_loss: 2.513  loss_ce: 0.3437  loss_giou: 0.2802  loss_bbox: 0.283  loss_ce_0: 0.3341  loss_giou_0: 0.2917  loss_bbox_0: 0.285  loss_rpn_cls: 0.1899  loss_rpn_reg: 0.4422  time: 0.1890  last_time: 0.2064  data_time: 0.0051  last_data_time: 0.0083   lr: 5e-06  max_mem: 3029M
[03/05 13:51:52] d2.utils.events INFO:  eta: 0:43:46  iter: 40059  total_loss: 2.456  loss_ce: 0.3338  loss_giou: 0.2691  loss_bbox: 0.2334  loss_ce_0: 0.4133  loss_giou_0: 0.3088  loss_bbox_0: 0.2684  loss_rpn_cls: 0.1688  loss_rpn_reg: 0.4151  time: 0.1890  last_time: 0.1897  data_time: 0.0048  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 13:51:55] d2.utils.events INFO:  eta: 0:43:42  iter: 40079  total_loss: 2.039  loss_ce: 0.201  loss_giou: 0.2728  loss_bbox: 0.2055  loss_ce_0: 0.2522  loss_giou_0: 0.2909  loss_bbox_0: 0.2444  loss_rpn_cls: 0.1591  loss_rpn_reg: 0.3867  time: 0.1890  last_time: 0.2372  data_time: 0.0050  last_data_time: 0.0078   lr: 5e-06  max_mem: 3029M
[03/05 13:51:59] d2.utils.events INFO:  eta: 0:43:40  iter: 40099  total_loss: 2.157  loss_ce: 0.2553  loss_giou: 0.2262  loss_bbox: 0.2186  loss_ce_0: 0.2856  loss_giou_0: 0.2481  loss_bbox_0: 0.226  loss_rpn_cls: 0.1835  loss_rpn_reg: 0.4026  time: 0.1890  last_time: 0.1971  data_time: 0.0052  last_data_time: 0.0065   lr: 5e-06  max_mem: 3029M
[03/05 13:52:03] d2.utils.events INFO:  eta: 0:43:37  iter: 40119  total_loss: 2.594  loss_ce: 0.3554  loss_giou: 0.3282  loss_bbox: 0.2445  loss_ce_0: 0.386  loss_giou_0: 0.3435  loss_bbox_0: 0.2598  loss_rpn_cls: 0.2374  loss_rpn_reg: 0.4407  time: 0.1890  last_time: 0.2031  data_time: 0.0051  last_data_time: 0.0058   lr: 5e-06  max_mem: 3029M
[03/05 13:52:07] d2.utils.events INFO:  eta: 0:43:33  iter: 40139  total_loss: 2.147  loss_ce: 0.2905  loss_giou: 0.2331  loss_bbox: 0.2159  loss_ce_0: 0.3179  loss_giou_0: 0.2613  loss_bbox_0: 0.2573  loss_rpn_cls: 0.1777  loss_rpn_reg: 0.3976  time: 0.1890  last_time: 0.1776  data_time: 0.0053  last_data_time: 0.0086   lr: 5e-06  max_mem: 3029M
[03/05 13:52:11] d2.utils.events INFO:  eta: 0:43:30  iter: 40159  total_loss: 2.47  loss_ce: 0.2616  loss_giou: 0.3198  loss_bbox: 0.257  loss_ce_0: 0.3499  loss_giou_0: 0.3435  loss_bbox_0: 0.2536  loss_rpn_cls: 0.1696  loss_rpn_reg: 0.4538  time: 0.1890  last_time: 0.1945  data_time: 0.0051  last_data_time: 0.0056   lr: 5e-06  max_mem: 3029M
[03/05 13:52:15] d2.utils.events INFO:  eta: 0:43:27  iter: 40179  total_loss: 2.482  loss_ce: 0.2744  loss_giou: 0.3311  loss_bbox: 0.2167  loss_ce_0: 0.3211  loss_giou_0: 0.3585  loss_bbox_0: 0.2467  loss_rpn_cls: 0.2007  loss_rpn_reg: 0.4509  time: 0.1890  last_time: 0.1813  data_time: 0.0046  last_data_time: 0.0050   lr: 5e-06  max_mem: 3029M
[03/05 13:52:19] d2.utils.events INFO:  eta: 0:43:22  iter: 40199  total_loss: 2.43  loss_ce: 0.2849  loss_giou: 0.3145  loss_bbox: 0.223  loss_ce_0: 0.338  loss_giou_0: 0.3574  loss_bbox_0: 0.256  loss_rpn_cls: 0.2389  loss_rpn_reg: 0.4355  time: 0.1890  last_time: 0.1783  data_time: 0.0049  last_data_time: 0.0033   lr: 5e-06  max_mem: 3029M
[03/05 13:52:22] d2.utils.events INFO:  eta: 0:43:16  iter: 40219  total_loss: 2.395  loss_ce: 0.3017  loss_giou: 0.3224  loss_bbox: 0.2689  loss_ce_0: 0.3183  loss_giou_0: 0.3355  loss_bbox_0: 0.2818  loss_rpn_cls: 0.2028  loss_rpn_reg: 0.4467  time: 0.1890  last_time: 0.1758  data_time: 0.0050  last_data_time: 0.0077   lr: 5e-06  max_mem: 3029M
[03/05 13:52:26] d2.utils.events INFO:  eta: 0:43:13  iter: 40239  total_loss: 2.32  loss_ce: 0.3129  loss_giou: 0.2696  loss_bbox: 0.189  loss_ce_0: 0.3689  loss_giou_0: 0.2843  loss_bbox_0: 0.244  loss_rpn_cls: 0.1887  loss_rpn_reg: 0.4206  time: 0.1890  last_time: 0.2004  data_time: 0.0050  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 13:52:30] d2.utils.events INFO:  eta: 0:43:09  iter: 40259  total_loss: 2.483  loss_ce: 0.3177  loss_giou: 0.2865  loss_bbox: 0.2507  loss_ce_0: 0.3268  loss_giou_0: 0.2903  loss_bbox_0: 0.2843  loss_rpn_cls: 0.1891  loss_rpn_reg: 0.439  time: 0.1890  last_time: 0.1880  data_time: 0.0047  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 13:52:34] d2.utils.events INFO:  eta: 0:43:05  iter: 40279  total_loss: 2.341  loss_ce: 0.292  loss_giou: 0.3067  loss_bbox: 0.2483  loss_ce_0: 0.3213  loss_giou_0: 0.3417  loss_bbox_0: 0.2768  loss_rpn_cls: 0.1869  loss_rpn_reg: 0.4487  time: 0.1890  last_time: 0.1632  data_time: 0.0046  last_data_time: 0.0048   lr: 5e-06  max_mem: 3029M
[03/05 13:52:38] d2.utils.events INFO:  eta: 0:43:01  iter: 40299  total_loss: 2.425  loss_ce: 0.3432  loss_giou: 0.2995  loss_bbox: 0.2167  loss_ce_0: 0.3687  loss_giou_0: 0.3017  loss_bbox_0: 0.2898  loss_rpn_cls: 0.1939  loss_rpn_reg: 0.4146  time: 0.1890  last_time: 0.1818  data_time: 0.0049  last_data_time: 0.0047   lr: 5e-06  max_mem: 3029M
[03/05 13:52:41] d2.utils.events INFO:  eta: 0:42:58  iter: 40319  total_loss: 2.267  loss_ce: 0.2548  loss_giou: 0.2972  loss_bbox: 0.2064  loss_ce_0: 0.3346  loss_giou_0: 0.3118  loss_bbox_0: 0.2411  loss_rpn_cls: 0.1868  loss_rpn_reg: 0.4158  time: 0.1890  last_time: 0.1865  data_time: 0.0056  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 13:52:45] d2.utils.events INFO:  eta: 0:42:54  iter: 40339  total_loss: 2.115  loss_ce: 0.2633  loss_giou: 0.2725  loss_bbox: 0.1917  loss_ce_0: 0.2817  loss_giou_0: 0.2722  loss_bbox_0: 0.2262  loss_rpn_cls: 0.1706  loss_rpn_reg: 0.4069  time: 0.1890  last_time: 0.2069  data_time: 0.0051  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 13:52:49] d2.utils.events INFO:  eta: 0:42:50  iter: 40359  total_loss: 2.485  loss_ce: 0.3479  loss_giou: 0.2648  loss_bbox: 0.2518  loss_ce_0: 0.3467  loss_giou_0: 0.3227  loss_bbox_0: 0.2694  loss_rpn_cls: 0.2149  loss_rpn_reg: 0.4081  time: 0.1890  last_time: 0.1982  data_time: 0.0050  last_data_time: 0.0068   lr: 5e-06  max_mem: 3029M
[03/05 13:52:53] d2.utils.events INFO:  eta: 0:42:46  iter: 40379  total_loss: 2.526  loss_ce: 0.3388  loss_giou: 0.3296  loss_bbox: 0.2113  loss_ce_0: 0.3528  loss_giou_0: 0.3588  loss_bbox_0: 0.2095  loss_rpn_cls: 0.2149  loss_rpn_reg: 0.4554  time: 0.1890  last_time: 0.1914  data_time: 0.0054  last_data_time: 0.0071   lr: 5e-06  max_mem: 3029M
[03/05 13:52:57] d2.utils.events INFO:  eta: 0:42:42  iter: 40399  total_loss: 2.33  loss_ce: 0.2406  loss_giou: 0.2758  loss_bbox: 0.2365  loss_ce_0: 0.2699  loss_giou_0: 0.3137  loss_bbox_0: 0.2761  loss_rpn_cls: 0.1413  loss_rpn_reg: 0.4152  time: 0.1890  last_time: 0.1862  data_time: 0.0049  last_data_time: 0.0030   lr: 5e-06  max_mem: 3029M
[03/05 13:53:01] d2.utils.events INFO:  eta: 0:42:39  iter: 40419  total_loss: 2.47  loss_ce: 0.3206  loss_giou: 0.3166  loss_bbox: 0.2508  loss_ce_0: 0.341  loss_giou_0: 0.3364  loss_bbox_0: 0.2592  loss_rpn_cls: 0.2101  loss_rpn_reg: 0.4408  time: 0.1890  last_time: 0.1708  data_time: 0.0057  last_data_time: 0.0139   lr: 5e-06  max_mem: 3029M
[03/05 13:53:05] d2.utils.events INFO:  eta: 0:42:37  iter: 40439  total_loss: 2.024  loss_ce: 0.2238  loss_giou: 0.2509  loss_bbox: 0.2555  loss_ce_0: 0.2541  loss_giou_0: 0.2773  loss_bbox_0: 0.2725  loss_rpn_cls: 0.1864  loss_rpn_reg: 0.4072  time: 0.1890  last_time: 0.1893  data_time: 0.0055  last_data_time: 0.0056   lr: 5e-06  max_mem: 3029M
[03/05 13:53:09] d2.utils.events INFO:  eta: 0:42:34  iter: 40459  total_loss: 2.392  loss_ce: 0.3238  loss_giou: 0.2941  loss_bbox: 0.2115  loss_ce_0: 0.3413  loss_giou_0: 0.3374  loss_bbox_0: 0.2444  loss_rpn_cls: 0.2088  loss_rpn_reg: 0.451  time: 0.1890  last_time: 0.2077  data_time: 0.0047  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 13:53:12] d2.utils.events INFO:  eta: 0:42:31  iter: 40479  total_loss: 2.299  loss_ce: 0.2588  loss_giou: 0.3086  loss_bbox: 0.2168  loss_ce_0: 0.3572  loss_giou_0: 0.3071  loss_bbox_0: 0.2176  loss_rpn_cls: 0.2076  loss_rpn_reg: 0.3823  time: 0.1890  last_time: 0.1671  data_time: 0.0045  last_data_time: 0.0023   lr: 5e-06  max_mem: 3029M
[03/05 13:53:16] d2.utils.events INFO:  eta: 0:42:26  iter: 40499  total_loss: 2.481  loss_ce: 0.3279  loss_giou: 0.3039  loss_bbox: 0.207  loss_ce_0: 0.3463  loss_giou_0: 0.3175  loss_bbox_0: 0.2483  loss_rpn_cls: 0.2086  loss_rpn_reg: 0.4344  time: 0.1890  last_time: 0.1618  data_time: 0.0045  last_data_time: 0.0046   lr: 5e-06  max_mem: 3029M
[03/05 13:53:20] d2.utils.events INFO:  eta: 0:42:27  iter: 40519  total_loss: 2.51  loss_ce: 0.3422  loss_giou: 0.2761  loss_bbox: 0.2328  loss_ce_0: 0.373  loss_giou_0: 0.2912  loss_bbox_0: 0.2858  loss_rpn_cls: 0.2202  loss_rpn_reg: 0.4329  time: 0.1890  last_time: 0.2036  data_time: 0.0047  last_data_time: 0.0026   lr: 5e-06  max_mem: 3029M
[03/05 13:53:24] d2.utils.events INFO:  eta: 0:42:23  iter: 40539  total_loss: 2.529  loss_ce: 0.3333  loss_giou: 0.2744  loss_bbox: 0.2839  loss_ce_0: 0.3478  loss_giou_0: 0.3008  loss_bbox_0: 0.298  loss_rpn_cls: 0.2056  loss_rpn_reg: 0.4167  time: 0.1890  last_time: 0.2347  data_time: 0.0054  last_data_time: 0.0112   lr: 5e-06  max_mem: 3029M
[03/05 13:53:28] d2.utils.events INFO:  eta: 0:42:17  iter: 40559  total_loss: 2.24  loss_ce: 0.2348  loss_giou: 0.3194  loss_bbox: 0.2016  loss_ce_0: 0.2992  loss_giou_0: 0.3414  loss_bbox_0: 0.2217  loss_rpn_cls: 0.1726  loss_rpn_reg: 0.4425  time: 0.1890  last_time: 0.2008  data_time: 0.0062  last_data_time: 0.0070   lr: 5e-06  max_mem: 3029M
[03/05 13:53:32] d2.utils.events INFO:  eta: 0:42:19  iter: 40579  total_loss: 2.039  loss_ce: 0.2921  loss_giou: 0.2214  loss_bbox: 0.1852  loss_ce_0: 0.3074  loss_giou_0: 0.2511  loss_bbox_0: 0.2161  loss_rpn_cls: 0.161  loss_rpn_reg: 0.3873  time: 0.1891  last_time: 0.2082  data_time: 0.0058  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 13:53:36] d2.utils.events INFO:  eta: 0:42:18  iter: 40599  total_loss: 2.248  loss_ce: 0.3049  loss_giou: 0.303  loss_bbox: 0.2155  loss_ce_0: 0.3393  loss_giou_0: 0.3178  loss_bbox_0: 0.2342  loss_rpn_cls: 0.1959  loss_rpn_reg: 0.4374  time: 0.1891  last_time: 0.2105  data_time: 0.0052  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 13:53:40] d2.utils.events INFO:  eta: 0:42:15  iter: 40619  total_loss: 2.511  loss_ce: 0.3035  loss_giou: 0.2948  loss_bbox: 0.2128  loss_ce_0: 0.369  loss_giou_0: 0.3101  loss_bbox_0: 0.2281  loss_rpn_cls: 0.2257  loss_rpn_reg: 0.4552  time: 0.1891  last_time: 0.1739  data_time: 0.0051  last_data_time: 0.0067   lr: 5e-06  max_mem: 3029M
[03/05 13:53:44] d2.utils.events INFO:  eta: 0:42:12  iter: 40639  total_loss: 2.366  loss_ce: 0.3133  loss_giou: 0.2626  loss_bbox: 0.2075  loss_ce_0: 0.3515  loss_giou_0: 0.2637  loss_bbox_0: 0.237  loss_rpn_cls: 0.2112  loss_rpn_reg: 0.4173  time: 0.1891  last_time: 0.1875  data_time: 0.0063  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 13:53:48] d2.utils.events INFO:  eta: 0:42:11  iter: 40659  total_loss: 2.182  loss_ce: 0.2615  loss_giou: 0.2837  loss_bbox: 0.1858  loss_ce_0: 0.3379  loss_giou_0: 0.2949  loss_bbox_0: 0.2254  loss_rpn_cls: 0.2014  loss_rpn_reg: 0.4196  time: 0.1891  last_time: 0.1956  data_time: 0.0063  last_data_time: 0.0051   lr: 5e-06  max_mem: 3029M
[03/05 13:53:52] d2.utils.events INFO:  eta: 0:42:08  iter: 40679  total_loss: 2.293  loss_ce: 0.3003  loss_giou: 0.2561  loss_bbox: 0.21  loss_ce_0: 0.3531  loss_giou_0: 0.2669  loss_bbox_0: 0.2264  loss_rpn_cls: 0.2014  loss_rpn_reg: 0.4506  time: 0.1891  last_time: 0.1829  data_time: 0.0052  last_data_time: 0.0028   lr: 5e-06  max_mem: 3029M
[03/05 13:53:56] d2.utils.events INFO:  eta: 0:42:07  iter: 40699  total_loss: 2.213  loss_ce: 0.2948  loss_giou: 0.2902  loss_bbox: 0.2525  loss_ce_0: 0.3168  loss_giou_0: 0.3087  loss_bbox_0: 0.2765  loss_rpn_cls: 0.141  loss_rpn_reg: 0.4306  time: 0.1891  last_time: 0.1864  data_time: 0.0051  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 13:54:00] d2.utils.events INFO:  eta: 0:42:04  iter: 40719  total_loss: 2.4  loss_ce: 0.3229  loss_giou: 0.2931  loss_bbox: 0.2422  loss_ce_0: 0.3848  loss_giou_0: 0.3116  loss_bbox_0: 0.2424  loss_rpn_cls: 0.2067  loss_rpn_reg: 0.4449  time: 0.1891  last_time: 0.1853  data_time: 0.0058  last_data_time: 0.0084   lr: 5e-06  max_mem: 3029M
[03/05 13:54:04] d2.utils.events INFO:  eta: 0:41:59  iter: 40739  total_loss: 2.369  loss_ce: 0.2505  loss_giou: 0.2949  loss_bbox: 0.2979  loss_ce_0: 0.3176  loss_giou_0: 0.2861  loss_bbox_0: 0.3082  loss_rpn_cls: 0.186  loss_rpn_reg: 0.407  time: 0.1891  last_time: 0.1805  data_time: 0.0053  last_data_time: 0.0062   lr: 5e-06  max_mem: 3029M
[03/05 13:54:08] d2.utils.events INFO:  eta: 0:41:53  iter: 40759  total_loss: 2.336  loss_ce: 0.3069  loss_giou: 0.2786  loss_bbox: 0.2234  loss_ce_0: 0.3446  loss_giou_0: 0.277  loss_bbox_0: 0.2606  loss_rpn_cls: 0.1848  loss_rpn_reg: 0.4149  time: 0.1891  last_time: 0.1955  data_time: 0.0046  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 13:54:11] d2.utils.events INFO:  eta: 0:41:49  iter: 40779  total_loss: 2.524  loss_ce: 0.279  loss_giou: 0.288  loss_bbox: 0.2573  loss_ce_0: 0.3041  loss_giou_0: 0.3201  loss_bbox_0: 0.2892  loss_rpn_cls: 0.1666  loss_rpn_reg: 0.4388  time: 0.1891  last_time: 0.1770  data_time: 0.0048  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 13:54:15] d2.utils.events INFO:  eta: 0:41:45  iter: 40799  total_loss: 2.269  loss_ce: 0.2732  loss_giou: 0.3322  loss_bbox: 0.2169  loss_ce_0: 0.2656  loss_giou_0: 0.3444  loss_bbox_0: 0.2432  loss_rpn_cls: 0.1897  loss_rpn_reg: 0.397  time: 0.1891  last_time: 0.2026  data_time: 0.0050  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 13:54:19] d2.utils.events INFO:  eta: 0:41:42  iter: 40819  total_loss: 2.324  loss_ce: 0.2832  loss_giou: 0.3056  loss_bbox: 0.2526  loss_ce_0: 0.3436  loss_giou_0: 0.301  loss_bbox_0: 0.2628  loss_rpn_cls: 0.2149  loss_rpn_reg: 0.4123  time: 0.1891  last_time: 0.1824  data_time: 0.0057  last_data_time: 0.0064   lr: 5e-06  max_mem: 3029M
[03/05 13:54:23] d2.utils.events INFO:  eta: 0:41:38  iter: 40839  total_loss: 2.363  loss_ce: 0.2977  loss_giou: 0.3189  loss_bbox: 0.2255  loss_ce_0: 0.3517  loss_giou_0: 0.3279  loss_bbox_0: 0.258  loss_rpn_cls: 0.1994  loss_rpn_reg: 0.4186  time: 0.1891  last_time: 0.1741  data_time: 0.0051  last_data_time: 0.0032   lr: 5e-06  max_mem: 3029M
[03/05 13:54:27] d2.utils.events INFO:  eta: 0:41:35  iter: 40859  total_loss: 2.606  loss_ce: 0.3076  loss_giou: 0.3447  loss_bbox: 0.277  loss_ce_0: 0.3355  loss_giou_0: 0.3557  loss_bbox_0: 0.309  loss_rpn_cls: 0.216  loss_rpn_reg: 0.4256  time: 0.1891  last_time: 0.2036  data_time: 0.0065  last_data_time: 0.0172   lr: 5e-06  max_mem: 3029M
[03/05 13:54:31] d2.utils.events INFO:  eta: 0:41:32  iter: 40879  total_loss: 2.205  loss_ce: 0.2304  loss_giou: 0.2762  loss_bbox: 0.235  loss_ce_0: 0.2815  loss_giou_0: 0.2866  loss_bbox_0: 0.2392  loss_rpn_cls: 0.1864  loss_rpn_reg: 0.4093  time: 0.1891  last_time: 0.2005  data_time: 0.0050  last_data_time: 0.0032   lr: 5e-06  max_mem: 3029M
[03/05 13:54:35] d2.utils.events INFO:  eta: 0:41:28  iter: 40899  total_loss: 2.405  loss_ce: 0.3267  loss_giou: 0.2366  loss_bbox: 0.2085  loss_ce_0: 0.3802  loss_giou_0: 0.257  loss_bbox_0: 0.2298  loss_rpn_cls: 0.1929  loss_rpn_reg: 0.4177  time: 0.1891  last_time: 0.1682  data_time: 0.0051  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 13:54:39] d2.utils.events INFO:  eta: 0:41:25  iter: 40919  total_loss: 2.345  loss_ce: 0.3178  loss_giou: 0.2693  loss_bbox: 0.2149  loss_ce_0: 0.3315  loss_giou_0: 0.286  loss_bbox_0: 0.2457  loss_rpn_cls: 0.1797  loss_rpn_reg: 0.4149  time: 0.1891  last_time: 0.1868  data_time: 0.0046  last_data_time: 0.0049   lr: 5e-06  max_mem: 3029M
[03/05 13:54:42] d2.utils.events INFO:  eta: 0:41:21  iter: 40939  total_loss: 2.18  loss_ce: 0.2628  loss_giou: 0.2786  loss_bbox: 0.2091  loss_ce_0: 0.2893  loss_giou_0: 0.3091  loss_bbox_0: 0.2432  loss_rpn_cls: 0.1586  loss_rpn_reg: 0.4029  time: 0.1891  last_time: 0.1855  data_time: 0.0051  last_data_time: 0.0051   lr: 5e-06  max_mem: 3029M
[03/05 13:54:46] d2.utils.events INFO:  eta: 0:41:17  iter: 40959  total_loss: 2.117  loss_ce: 0.2418  loss_giou: 0.2741  loss_bbox: 0.2132  loss_ce_0: 0.2937  loss_giou_0: 0.288  loss_bbox_0: 0.2344  loss_rpn_cls: 0.1942  loss_rpn_reg: 0.3976  time: 0.1891  last_time: 0.1932  data_time: 0.0048  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 13:54:50] d2.utils.events INFO:  eta: 0:41:13  iter: 40979  total_loss: 2.227  loss_ce: 0.2823  loss_giou: 0.2914  loss_bbox: 0.2133  loss_ce_0: 0.3574  loss_giou_0: 0.2877  loss_bbox_0: 0.2685  loss_rpn_cls: 0.1713  loss_rpn_reg: 0.3851  time: 0.1891  last_time: 0.2041  data_time: 0.0053  last_data_time: 0.0061   lr: 5e-06  max_mem: 3029M
[03/05 13:54:54] d2.utils.events INFO:  eta: 0:41:07  iter: 40999  total_loss: 2.056  loss_ce: 0.2421  loss_giou: 0.2386  loss_bbox: 0.2161  loss_ce_0: 0.2306  loss_giou_0: 0.2602  loss_bbox_0: 0.2432  loss_rpn_cls: 0.1437  loss_rpn_reg: 0.3895  time: 0.1891  last_time: 0.1999  data_time: 0.0050  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 13:54:58] d2.utils.events INFO:  eta: 0:41:02  iter: 41019  total_loss: 2.275  loss_ce: 0.2439  loss_giou: 0.2859  loss_bbox: 0.1978  loss_ce_0: 0.3024  loss_giou_0: 0.3182  loss_bbox_0: 0.2151  loss_rpn_cls: 0.1738  loss_rpn_reg: 0.4349  time: 0.1891  last_time: 0.1947  data_time: 0.0053  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 13:55:01] d2.utils.events INFO:  eta: 0:40:57  iter: 41039  total_loss: 2.295  loss_ce: 0.256  loss_giou: 0.2708  loss_bbox: 0.221  loss_ce_0: 0.3073  loss_giou_0: 0.2909  loss_bbox_0: 0.242  loss_rpn_cls: 0.1808  loss_rpn_reg: 0.4128  time: 0.1891  last_time: 0.1804  data_time: 0.0049  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 13:55:05] d2.utils.events INFO:  eta: 0:40:54  iter: 41059  total_loss: 2.561  loss_ce: 0.321  loss_giou: 0.323  loss_bbox: 0.2652  loss_ce_0: 0.3754  loss_giou_0: 0.3296  loss_bbox_0: 0.2594  loss_rpn_cls: 0.2049  loss_rpn_reg: 0.4505  time: 0.1891  last_time: 0.1779  data_time: 0.0057  last_data_time: 0.0034   lr: 5e-06  max_mem: 3029M
[03/05 13:55:09] d2.utils.events INFO:  eta: 0:40:51  iter: 41079  total_loss: 2.417  loss_ce: 0.3021  loss_giou: 0.2642  loss_bbox: 0.2311  loss_ce_0: 0.3405  loss_giou_0: 0.2816  loss_bbox_0: 0.248  loss_rpn_cls: 0.1883  loss_rpn_reg: 0.4079  time: 0.1891  last_time: 0.2215  data_time: 0.0045  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 13:55:13] d2.utils.events INFO:  eta: 0:40:46  iter: 41099  total_loss: 2.162  loss_ce: 0.2836  loss_giou: 0.2341  loss_bbox: 0.2437  loss_ce_0: 0.318  loss_giou_0: 0.2467  loss_bbox_0: 0.2532  loss_rpn_cls: 0.1672  loss_rpn_reg: 0.4006  time: 0.1891  last_time: 0.1976  data_time: 0.0053  last_data_time: 0.0058   lr: 5e-06  max_mem: 3029M
[03/05 13:55:17] d2.utils.events INFO:  eta: 0:40:43  iter: 41119  total_loss: 2.383  loss_ce: 0.2874  loss_giou: 0.3108  loss_bbox: 0.2344  loss_ce_0: 0.3737  loss_giou_0: 0.3179  loss_bbox_0: 0.2483  loss_rpn_cls: 0.2029  loss_rpn_reg: 0.4325  time: 0.1891  last_time: 0.1897  data_time: 0.0053  last_data_time: 0.0064   lr: 5e-06  max_mem: 3029M
[03/05 13:55:21] d2.utils.events INFO:  eta: 0:40:43  iter: 41139  total_loss: 2.367  loss_ce: 0.3046  loss_giou: 0.3137  loss_bbox: 0.2432  loss_ce_0: 0.3406  loss_giou_0: 0.3273  loss_bbox_0: 0.2783  loss_rpn_cls: 0.2035  loss_rpn_reg: 0.451  time: 0.1891  last_time: 0.2094  data_time: 0.0054  last_data_time: 0.0034   lr: 5e-06  max_mem: 3029M
[03/05 13:55:25] d2.utils.events INFO:  eta: 0:40:42  iter: 41159  total_loss: 2.287  loss_ce: 0.2718  loss_giou: 0.2829  loss_bbox: 0.2677  loss_ce_0: 0.3351  loss_giou_0: 0.3069  loss_bbox_0: 0.2818  loss_rpn_cls: 0.1991  loss_rpn_reg: 0.429  time: 0.1891  last_time: 0.1779  data_time: 0.0057  last_data_time: 0.0061   lr: 5e-06  max_mem: 3029M
[03/05 13:55:29] d2.utils.events INFO:  eta: 0:40:36  iter: 41179  total_loss: 2.38  loss_ce: 0.3455  loss_giou: 0.2999  loss_bbox: 0.2415  loss_ce_0: 0.3691  loss_giou_0: 0.3086  loss_bbox_0: 0.2573  loss_rpn_cls: 0.1822  loss_rpn_reg: 0.4223  time: 0.1891  last_time: 0.2151  data_time: 0.0054  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 13:55:32] d2.utils.events INFO:  eta: 0:40:34  iter: 41199  total_loss: 2.439  loss_ce: 0.3175  loss_giou: 0.3105  loss_bbox: 0.2184  loss_ce_0: 0.3597  loss_giou_0: 0.3176  loss_bbox_0: 0.2521  loss_rpn_cls: 0.2131  loss_rpn_reg: 0.4563  time: 0.1891  last_time: 0.1729  data_time: 0.0053  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 13:55:36] d2.utils.events INFO:  eta: 0:40:32  iter: 41219  total_loss: 2.452  loss_ce: 0.2882  loss_giou: 0.2865  loss_bbox: 0.2404  loss_ce_0: 0.3644  loss_giou_0: 0.2932  loss_bbox_0: 0.2758  loss_rpn_cls: 0.2019  loss_rpn_reg: 0.4394  time: 0.1891  last_time: 0.1735  data_time: 0.0046  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 13:55:40] d2.utils.events INFO:  eta: 0:40:28  iter: 41239  total_loss: 2.335  loss_ce: 0.2714  loss_giou: 0.3465  loss_bbox: 0.168  loss_ce_0: 0.2859  loss_giou_0: 0.3594  loss_bbox_0: 0.2088  loss_rpn_cls: 0.1745  loss_rpn_reg: 0.4393  time: 0.1891  last_time: 0.1932  data_time: 0.0059  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 13:55:44] d2.utils.events INFO:  eta: 0:40:21  iter: 41259  total_loss: 2.338  loss_ce: 0.2805  loss_giou: 0.2994  loss_bbox: 0.2716  loss_ce_0: 0.3257  loss_giou_0: 0.3211  loss_bbox_0: 0.3065  loss_rpn_cls: 0.1779  loss_rpn_reg: 0.4286  time: 0.1891  last_time: 0.1894  data_time: 0.0051  last_data_time: 0.0096   lr: 5e-06  max_mem: 3029M
[03/05 13:55:48] d2.utils.events INFO:  eta: 0:40:18  iter: 41279  total_loss: 2.657  loss_ce: 0.3516  loss_giou: 0.3344  loss_bbox: 0.2854  loss_ce_0: 0.363  loss_giou_0: 0.3293  loss_bbox_0: 0.2735  loss_rpn_cls: 0.2001  loss_rpn_reg: 0.4352  time: 0.1891  last_time: 0.2087  data_time: 0.0047  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 13:55:51] d2.utils.events INFO:  eta: 0:40:16  iter: 41299  total_loss: 2.452  loss_ce: 0.2893  loss_giou: 0.3244  loss_bbox: 0.2672  loss_ce_0: 0.371  loss_giou_0: 0.3379  loss_bbox_0: 0.3112  loss_rpn_cls: 0.1756  loss_rpn_reg: 0.4585  time: 0.1891  last_time: 0.2325  data_time: 0.0051  last_data_time: 0.0075   lr: 5e-06  max_mem: 3029M
[03/05 13:55:55] d2.utils.events INFO:  eta: 0:40:12  iter: 41319  total_loss: 2.084  loss_ce: 0.2437  loss_giou: 0.2626  loss_bbox: 0.2456  loss_ce_0: 0.29  loss_giou_0: 0.2609  loss_bbox_0: 0.2564  loss_rpn_cls: 0.1738  loss_rpn_reg: 0.3861  time: 0.1891  last_time: 0.1935  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 13:55:59] d2.utils.events INFO:  eta: 0:40:08  iter: 41339  total_loss: 2.624  loss_ce: 0.3192  loss_giou: 0.3008  loss_bbox: 0.2373  loss_ce_0: 0.3495  loss_giou_0: 0.3008  loss_bbox_0: 0.2757  loss_rpn_cls: 0.1869  loss_rpn_reg: 0.442  time: 0.1891  last_time: 0.1844  data_time: 0.0048  last_data_time: 0.0055   lr: 5e-06  max_mem: 3029M
[03/05 13:56:03] d2.utils.events INFO:  eta: 0:40:05  iter: 41359  total_loss: 2.131  loss_ce: 0.2478  loss_giou: 0.2579  loss_bbox: 0.2064  loss_ce_0: 0.3201  loss_giou_0: 0.2585  loss_bbox_0: 0.2116  loss_rpn_cls: 0.1799  loss_rpn_reg: 0.4153  time: 0.1891  last_time: 0.1933  data_time: 0.0053  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 13:56:07] d2.utils.events INFO:  eta: 0:40:00  iter: 41379  total_loss: 2.328  loss_ce: 0.2873  loss_giou: 0.2908  loss_bbox: 0.2139  loss_ce_0: 0.3454  loss_giou_0: 0.2886  loss_bbox_0: 0.2107  loss_rpn_cls: 0.1924  loss_rpn_reg: 0.4281  time: 0.1891  last_time: 0.2075  data_time: 0.0053  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 13:56:11] d2.utils.events INFO:  eta: 0:39:57  iter: 41399  total_loss: 2.246  loss_ce: 0.3063  loss_giou: 0.3052  loss_bbox: 0.2073  loss_ce_0: 0.333  loss_giou_0: 0.3087  loss_bbox_0: 0.2266  loss_rpn_cls: 0.1907  loss_rpn_reg: 0.457  time: 0.1891  last_time: 0.1998  data_time: 0.0052  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 13:56:14] d2.utils.events INFO:  eta: 0:39:53  iter: 41419  total_loss: 2.103  loss_ce: 0.2547  loss_giou: 0.2135  loss_bbox: 0.2006  loss_ce_0: 0.2927  loss_giou_0: 0.2489  loss_bbox_0: 0.225  loss_rpn_cls: 0.1617  loss_rpn_reg: 0.418  time: 0.1891  last_time: 0.1805  data_time: 0.0048  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 13:56:18] d2.utils.events INFO:  eta: 0:39:49  iter: 41439  total_loss: 2.114  loss_ce: 0.2399  loss_giou: 0.2749  loss_bbox: 0.2181  loss_ce_0: 0.3291  loss_giou_0: 0.2781  loss_bbox_0: 0.2397  loss_rpn_cls: 0.2088  loss_rpn_reg: 0.3964  time: 0.1891  last_time: 0.1919  data_time: 0.0049  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 13:56:22] d2.utils.events INFO:  eta: 0:39:45  iter: 41459  total_loss: 2.391  loss_ce: 0.2568  loss_giou: 0.2696  loss_bbox: 0.2248  loss_ce_0: 0.3117  loss_giou_0: 0.2891  loss_bbox_0: 0.2515  loss_rpn_cls: 0.2143  loss_rpn_reg: 0.4146  time: 0.1891  last_time: 0.1872  data_time: 0.0049  last_data_time: 0.0068   lr: 5e-06  max_mem: 3029M
[03/05 13:56:26] d2.utils.events INFO:  eta: 0:39:42  iter: 41479  total_loss: 2.307  loss_ce: 0.2752  loss_giou: 0.2651  loss_bbox: 0.239  loss_ce_0: 0.285  loss_giou_0: 0.2774  loss_bbox_0: 0.2792  loss_rpn_cls: 0.1787  loss_rpn_reg: 0.4034  time: 0.1891  last_time: 0.1678  data_time: 0.0048  last_data_time: 0.0020   lr: 5e-06  max_mem: 3029M
[03/05 13:56:30] d2.utils.events INFO:  eta: 0:39:39  iter: 41499  total_loss: 2.245  loss_ce: 0.2754  loss_giou: 0.2314  loss_bbox: 0.2611  loss_ce_0: 0.3031  loss_giou_0: 0.2473  loss_bbox_0: 0.2773  loss_rpn_cls: 0.1682  loss_rpn_reg: 0.3998  time: 0.1891  last_time: 0.2079  data_time: 0.0050  last_data_time: 0.0050   lr: 5e-06  max_mem: 3029M
[03/05 13:56:34] d2.utils.events INFO:  eta: 0:39:35  iter: 41519  total_loss: 2.272  loss_ce: 0.2103  loss_giou: 0.2982  loss_bbox: 0.2395  loss_ce_0: 0.2319  loss_giou_0: 0.3311  loss_bbox_0: 0.2281  loss_rpn_cls: 0.1815  loss_rpn_reg: 0.4236  time: 0.1891  last_time: 0.2317  data_time: 0.0058  last_data_time: 0.0062   lr: 5e-06  max_mem: 3029M
[03/05 13:56:38] d2.utils.events INFO:  eta: 0:39:34  iter: 41539  total_loss: 2.153  loss_ce: 0.2624  loss_giou: 0.2709  loss_bbox: 0.1952  loss_ce_0: 0.3363  loss_giou_0: 0.2874  loss_bbox_0: 0.228  loss_rpn_cls: 0.1944  loss_rpn_reg: 0.3914  time: 0.1891  last_time: 0.1929  data_time: 0.0051  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 13:56:42] d2.utils.events INFO:  eta: 0:39:31  iter: 41559  total_loss: 2.514  loss_ce: 0.3026  loss_giou: 0.2762  loss_bbox: 0.248  loss_ce_0: 0.3538  loss_giou_0: 0.2864  loss_bbox_0: 0.2894  loss_rpn_cls: 0.182  loss_rpn_reg: 0.4314  time: 0.1891  last_time: 0.2179  data_time: 0.0054  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 13:56:45] d2.utils.events INFO:  eta: 0:39:26  iter: 41579  total_loss: 2.333  loss_ce: 0.2941  loss_giou: 0.2862  loss_bbox: 0.2489  loss_ce_0: 0.3874  loss_giou_0: 0.2878  loss_bbox_0: 0.2799  loss_rpn_cls: 0.1926  loss_rpn_reg: 0.4  time: 0.1891  last_time: 0.1924  data_time: 0.0053  last_data_time: 0.0051   lr: 5e-06  max_mem: 3029M
[03/05 13:56:49] d2.utils.events INFO:  eta: 0:39:22  iter: 41599  total_loss: 2.13  loss_ce: 0.2214  loss_giou: 0.2914  loss_bbox: 0.2146  loss_ce_0: 0.2478  loss_giou_0: 0.3032  loss_bbox_0: 0.2425  loss_rpn_cls: 0.1805  loss_rpn_reg: 0.4068  time: 0.1891  last_time: 0.1973  data_time: 0.0048  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 13:56:53] d2.utils.events INFO:  eta: 0:39:19  iter: 41619  total_loss: 2.254  loss_ce: 0.2967  loss_giou: 0.2924  loss_bbox: 0.2011  loss_ce_0: 0.314  loss_giou_0: 0.3101  loss_bbox_0: 0.2216  loss_rpn_cls: 0.1965  loss_rpn_reg: 0.4298  time: 0.1891  last_time: 0.1970  data_time: 0.0056  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 13:56:57] d2.utils.events INFO:  eta: 0:39:17  iter: 41639  total_loss: 2.346  loss_ce: 0.3249  loss_giou: 0.273  loss_bbox: 0.2305  loss_ce_0: 0.3834  loss_giou_0: 0.2989  loss_bbox_0: 0.2519  loss_rpn_cls: 0.1984  loss_rpn_reg: 0.4341  time: 0.1891  last_time: 0.2000  data_time: 0.0056  last_data_time: 0.0103   lr: 5e-06  max_mem: 3029M
[03/05 13:57:01] d2.utils.events INFO:  eta: 0:39:10  iter: 41659  total_loss: 2.113  loss_ce: 0.2894  loss_giou: 0.2539  loss_bbox: 0.2475  loss_ce_0: 0.3311  loss_giou_0: 0.2737  loss_bbox_0: 0.257  loss_rpn_cls: 0.1704  loss_rpn_reg: 0.4131  time: 0.1891  last_time: 0.1772  data_time: 0.0053  last_data_time: 0.0045   lr: 5e-06  max_mem: 3029M
[03/05 13:57:05] d2.utils.events INFO:  eta: 0:39:06  iter: 41679  total_loss: 2.321  loss_ce: 0.3055  loss_giou: 0.3157  loss_bbox: 0.248  loss_ce_0: 0.3341  loss_giou_0: 0.325  loss_bbox_0: 0.2527  loss_rpn_cls: 0.1907  loss_rpn_reg: 0.419  time: 0.1891  last_time: 0.1756  data_time: 0.0050  last_data_time: 0.0029   lr: 5e-06  max_mem: 3029M
[03/05 13:57:09] d2.utils.events INFO:  eta: 0:39:00  iter: 41699  total_loss: 2.096  loss_ce: 0.2576  loss_giou: 0.2838  loss_bbox: 0.195  loss_ce_0: 0.2927  loss_giou_0: 0.2827  loss_bbox_0: 0.2132  loss_rpn_cls: 0.1952  loss_rpn_reg: 0.4154  time: 0.1891  last_time: 0.1846  data_time: 0.0052  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 13:57:13] d2.utils.events INFO:  eta: 0:38:56  iter: 41719  total_loss: 2.254  loss_ce: 0.2932  loss_giou: 0.3253  loss_bbox: 0.2347  loss_ce_0: 0.2968  loss_giou_0: 0.3361  loss_bbox_0: 0.2701  loss_rpn_cls: 0.1916  loss_rpn_reg: 0.4019  time: 0.1891  last_time: 0.2039  data_time: 0.0056  last_data_time: 0.0056   lr: 5e-06  max_mem: 3029M
[03/05 13:57:17] d2.utils.events INFO:  eta: 0:38:54  iter: 41739  total_loss: 2.49  loss_ce: 0.279  loss_giou: 0.3425  loss_bbox: 0.2525  loss_ce_0: 0.3306  loss_giou_0: 0.3653  loss_bbox_0: 0.2476  loss_rpn_cls: 0.1855  loss_rpn_reg: 0.4528  time: 0.1891  last_time: 0.2239  data_time: 0.0051  last_data_time: 0.0050   lr: 5e-06  max_mem: 3029M
[03/05 13:57:21] d2.utils.events INFO:  eta: 0:38:52  iter: 41759  total_loss: 2.091  loss_ce: 0.2879  loss_giou: 0.2433  loss_bbox: 0.1956  loss_ce_0: 0.3387  loss_giou_0: 0.2274  loss_bbox_0: 0.226  loss_rpn_cls: 0.1807  loss_rpn_reg: 0.3628  time: 0.1891  last_time: 0.2000  data_time: 0.0052  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 13:57:25] d2.utils.events INFO:  eta: 0:38:51  iter: 41779  total_loss: 2.39  loss_ce: 0.2718  loss_giou: 0.319  loss_bbox: 0.276  loss_ce_0: 0.3258  loss_giou_0: 0.3262  loss_bbox_0: 0.2751  loss_rpn_cls: 0.18  loss_rpn_reg: 0.4334  time: 0.1891  last_time: 0.1791  data_time: 0.0056  last_data_time: 0.0062   lr: 5e-06  max_mem: 3029M
[03/05 13:57:29] d2.utils.events INFO:  eta: 0:38:47  iter: 41799  total_loss: 2.442  loss_ce: 0.3341  loss_giou: 0.2966  loss_bbox: 0.2287  loss_ce_0: 0.3448  loss_giou_0: 0.3099  loss_bbox_0: 0.2461  loss_rpn_cls: 0.1817  loss_rpn_reg: 0.4522  time: 0.1891  last_time: 0.2159  data_time: 0.0049  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 13:57:33] d2.utils.events INFO:  eta: 0:38:42  iter: 41819  total_loss: 2.286  loss_ce: 0.363  loss_giou: 0.2549  loss_bbox: 0.2133  loss_ce_0: 0.403  loss_giou_0: 0.2734  loss_bbox_0: 0.2325  loss_rpn_cls: 0.1901  loss_rpn_reg: 0.4108  time: 0.1891  last_time: 0.2182  data_time: 0.0051  last_data_time: 0.0048   lr: 5e-06  max_mem: 3029M
[03/05 13:57:37] d2.utils.events INFO:  eta: 0:38:40  iter: 41839  total_loss: 2.478  loss_ce: 0.3103  loss_giou: 0.3325  loss_bbox: 0.2229  loss_ce_0: 0.3487  loss_giou_0: 0.3439  loss_bbox_0: 0.2625  loss_rpn_cls: 0.2073  loss_rpn_reg: 0.4568  time: 0.1891  last_time: 0.2128  data_time: 0.0053  last_data_time: 0.0080   lr: 5e-06  max_mem: 3029M
[03/05 13:57:41] d2.utils.events INFO:  eta: 0:38:36  iter: 41859  total_loss: 2.434  loss_ce: 0.342  loss_giou: 0.3109  loss_bbox: 0.2324  loss_ce_0: 0.3527  loss_giou_0: 0.3172  loss_bbox_0: 0.269  loss_rpn_cls: 0.1968  loss_rpn_reg: 0.4571  time: 0.1891  last_time: 0.1879  data_time: 0.0052  last_data_time: 0.0035   lr: 5e-06  max_mem: 3029M
[03/05 13:57:44] d2.utils.events INFO:  eta: 0:38:31  iter: 41879  total_loss: 2.11  loss_ce: 0.2377  loss_giou: 0.2616  loss_bbox: 0.2028  loss_ce_0: 0.3155  loss_giou_0: 0.2779  loss_bbox_0: 0.2428  loss_rpn_cls: 0.1837  loss_rpn_reg: 0.3895  time: 0.1891  last_time: 0.1737  data_time: 0.0052  last_data_time: 0.0035   lr: 5e-06  max_mem: 3029M
[03/05 13:57:48] d2.utils.events INFO:  eta: 0:38:30  iter: 41899  total_loss: 2.293  loss_ce: 0.2835  loss_giou: 0.2555  loss_bbox: 0.2167  loss_ce_0: 0.3086  loss_giou_0: 0.2851  loss_bbox_0: 0.2369  loss_rpn_cls: 0.1742  loss_rpn_reg: 0.4037  time: 0.1891  last_time: 0.2031  data_time: 0.0054  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 13:57:52] d2.utils.events INFO:  eta: 0:38:25  iter: 41919  total_loss: 2.243  loss_ce: 0.2677  loss_giou: 0.2729  loss_bbox: 0.2406  loss_ce_0: 0.3277  loss_giou_0: 0.2749  loss_bbox_0: 0.2636  loss_rpn_cls: 0.1816  loss_rpn_reg: 0.4467  time: 0.1891  last_time: 0.1773  data_time: 0.0051  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 13:57:56] d2.utils.events INFO:  eta: 0:38:21  iter: 41939  total_loss: 2.287  loss_ce: 0.2855  loss_giou: 0.3342  loss_bbox: 0.2266  loss_ce_0: 0.3222  loss_giou_0: 0.3519  loss_bbox_0: 0.2274  loss_rpn_cls: 0.2091  loss_rpn_reg: 0.433  time: 0.1891  last_time: 0.1788  data_time: 0.0053  last_data_time: 0.0048   lr: 5e-06  max_mem: 3029M
[03/05 13:58:00] d2.utils.events INFO:  eta: 0:38:19  iter: 41959  total_loss: 2.401  loss_ce: 0.2995  loss_giou: 0.2919  loss_bbox: 0.247  loss_ce_0: 0.3728  loss_giou_0: 0.2985  loss_bbox_0: 0.2535  loss_rpn_cls: 0.1987  loss_rpn_reg: 0.3988  time: 0.1891  last_time: 0.1755  data_time: 0.0058  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 13:58:04] d2.utils.events INFO:  eta: 0:38:17  iter: 41979  total_loss: 2.373  loss_ce: 0.2742  loss_giou: 0.2814  loss_bbox: 0.2459  loss_ce_0: 0.3469  loss_giou_0: 0.2696  loss_bbox_0: 0.2576  loss_rpn_cls: 0.1881  loss_rpn_reg: 0.395  time: 0.1891  last_time: 0.1831  data_time: 0.0050  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 13:58:07] d2.utils.events INFO:  eta: 0:38:16  iter: 41999  total_loss: 2.216  loss_ce: 0.2575  loss_giou: 0.2538  loss_bbox: 0.2436  loss_ce_0: 0.2719  loss_giou_0: 0.2777  loss_bbox_0: 0.2604  loss_rpn_cls: 0.1586  loss_rpn_reg: 0.3769  time: 0.1891  last_time: 0.1918  data_time: 0.0055  last_data_time: 0.0046   lr: 5e-06  max_mem: 3029M
[03/05 13:58:11] d2.utils.events INFO:  eta: 0:38:14  iter: 42019  total_loss: 2.62  loss_ce: 0.2921  loss_giou: 0.3092  loss_bbox: 0.2116  loss_ce_0: 0.333  loss_giou_0: 0.334  loss_bbox_0: 0.2153  loss_rpn_cls: 0.1911  loss_rpn_reg: 0.4642  time: 0.1891  last_time: 0.2126  data_time: 0.0054  last_data_time: 0.0062   lr: 5e-06  max_mem: 3029M
[03/05 13:58:15] d2.utils.events INFO:  eta: 0:38:13  iter: 42039  total_loss: 2.183  loss_ce: 0.2807  loss_giou: 0.26  loss_bbox: 0.2193  loss_ce_0: 0.301  loss_giou_0: 0.2767  loss_bbox_0: 0.2265  loss_rpn_cls: 0.1991  loss_rpn_reg: 0.3745  time: 0.1891  last_time: 0.2235  data_time: 0.0055  last_data_time: 0.0085   lr: 5e-06  max_mem: 3029M
[03/05 13:58:19] d2.utils.events INFO:  eta: 0:38:09  iter: 42059  total_loss: 2.228  loss_ce: 0.2598  loss_giou: 0.2757  loss_bbox: 0.2001  loss_ce_0: 0.298  loss_giou_0: 0.2625  loss_bbox_0: 0.2745  loss_rpn_cls: 0.17  loss_rpn_reg: 0.4033  time: 0.1891  last_time: 0.1936  data_time: 0.0046  last_data_time: 0.0065   lr: 5e-06  max_mem: 3029M
[03/05 13:58:23] d2.utils.events INFO:  eta: 0:38:05  iter: 42079  total_loss: 2.499  loss_ce: 0.3172  loss_giou: 0.3633  loss_bbox: 0.2526  loss_ce_0: 0.3616  loss_giou_0: 0.3745  loss_bbox_0: 0.2839  loss_rpn_cls: 0.2046  loss_rpn_reg: 0.4454  time: 0.1891  last_time: 0.2010  data_time: 0.0053  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 13:58:27] d2.utils.events INFO:  eta: 0:37:58  iter: 42099  total_loss: 2.239  loss_ce: 0.2408  loss_giou: 0.2462  loss_bbox: 0.2227  loss_ce_0: 0.2893  loss_giou_0: 0.2555  loss_bbox_0: 0.2708  loss_rpn_cls: 0.1752  loss_rpn_reg: 0.4106  time: 0.1891  last_time: 0.1766  data_time: 0.0052  last_data_time: 0.0053   lr: 5e-06  max_mem: 3029M
[03/05 13:58:30] d2.utils.events INFO:  eta: 0:37:52  iter: 42119  total_loss: 2.237  loss_ce: 0.3146  loss_giou: 0.2524  loss_bbox: 0.2289  loss_ce_0: 0.3841  loss_giou_0: 0.2849  loss_bbox_0: 0.2618  loss_rpn_cls: 0.192  loss_rpn_reg: 0.4313  time: 0.1891  last_time: 0.2064  data_time: 0.0054  last_data_time: 0.0048   lr: 5e-06  max_mem: 3029M
[03/05 13:58:34] d2.utils.events INFO:  eta: 0:37:47  iter: 42139  total_loss: 2.469  loss_ce: 0.2644  loss_giou: 0.2827  loss_bbox: 0.2405  loss_ce_0: 0.3329  loss_giou_0: 0.3141  loss_bbox_0: 0.266  loss_rpn_cls: 0.1972  loss_rpn_reg: 0.4641  time: 0.1891  last_time: 0.1690  data_time: 0.0055  last_data_time: 0.0051   lr: 5e-06  max_mem: 3029M
[03/05 13:58:38] d2.utils.events INFO:  eta: 0:37:43  iter: 42159  total_loss: 2.032  loss_ce: 0.2286  loss_giou: 0.2343  loss_bbox: 0.2235  loss_ce_0: 0.2696  loss_giou_0: 0.2609  loss_bbox_0: 0.2587  loss_rpn_cls: 0.1498  loss_rpn_reg: 0.3716  time: 0.1891  last_time: 0.1960  data_time: 0.0054  last_data_time: 0.0045   lr: 5e-06  max_mem: 3029M
[03/05 13:58:42] d2.utils.events INFO:  eta: 0:37:40  iter: 42179  total_loss: 2.446  loss_ce: 0.3118  loss_giou: 0.2801  loss_bbox: 0.271  loss_ce_0: 0.3707  loss_giou_0: 0.2699  loss_bbox_0: 0.2756  loss_rpn_cls: 0.2023  loss_rpn_reg: 0.4145  time: 0.1891  last_time: 0.1901  data_time: 0.0055  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 13:58:46] d2.utils.events INFO:  eta: 0:37:36  iter: 42199  total_loss: 2.539  loss_ce: 0.3154  loss_giou: 0.2747  loss_bbox: 0.2572  loss_ce_0: 0.3627  loss_giou_0: 0.3031  loss_bbox_0: 0.2681  loss_rpn_cls: 0.1911  loss_rpn_reg: 0.4557  time: 0.1891  last_time: 0.2081  data_time: 0.0047  last_data_time: 0.0087   lr: 5e-06  max_mem: 3029M
[03/05 13:58:50] d2.utils.events INFO:  eta: 0:37:30  iter: 42219  total_loss: 2.327  loss_ce: 0.3017  loss_giou: 0.3091  loss_bbox: 0.2057  loss_ce_0: 0.337  loss_giou_0: 0.3165  loss_bbox_0: 0.2328  loss_rpn_cls: 0.1782  loss_rpn_reg: 0.4513  time: 0.1891  last_time: 0.2126  data_time: 0.0048  last_data_time: 0.0111   lr: 5e-06  max_mem: 3029M
[03/05 13:58:53] d2.utils.events INFO:  eta: 0:37:24  iter: 42239  total_loss: 2.249  loss_ce: 0.2802  loss_giou: 0.2896  loss_bbox: 0.2507  loss_ce_0: 0.3292  loss_giou_0: 0.3045  loss_bbox_0: 0.2687  loss_rpn_cls: 0.1926  loss_rpn_reg: 0.4212  time: 0.1891  last_time: 0.1791  data_time: 0.0048  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 13:58:57] d2.utils.events INFO:  eta: 0:37:22  iter: 42259  total_loss: 2.283  loss_ce: 0.264  loss_giou: 0.2409  loss_bbox: 0.2207  loss_ce_0: 0.3039  loss_giou_0: 0.2856  loss_bbox_0: 0.248  loss_rpn_cls: 0.1935  loss_rpn_reg: 0.4256  time: 0.1891  last_time: 0.1839  data_time: 0.0046  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 13:59:01] d2.utils.events INFO:  eta: 0:37:18  iter: 42279  total_loss: 2.316  loss_ce: 0.2968  loss_giou: 0.2484  loss_bbox: 0.2336  loss_ce_0: 0.3613  loss_giou_0: 0.2551  loss_bbox_0: 0.2803  loss_rpn_cls: 0.1855  loss_rpn_reg: 0.4296  time: 0.1891  last_time: 0.2093  data_time: 0.0050  last_data_time: 0.0058   lr: 5e-06  max_mem: 3029M
[03/05 13:59:05] d2.utils.events INFO:  eta: 0:37:15  iter: 42299  total_loss: 2.703  loss_ce: 0.2705  loss_giou: 0.3625  loss_bbox: 0.2481  loss_ce_0: 0.2785  loss_giou_0: 0.3942  loss_bbox_0: 0.2756  loss_rpn_cls: 0.2124  loss_rpn_reg: 0.4543  time: 0.1891  last_time: 0.1857  data_time: 0.0054  last_data_time: 0.0077   lr: 5e-06  max_mem: 3029M
[03/05 13:59:09] d2.utils.events INFO:  eta: 0:37:11  iter: 42319  total_loss: 2.509  loss_ce: 0.3096  loss_giou: 0.3283  loss_bbox: 0.2458  loss_ce_0: 0.344  loss_giou_0: 0.3428  loss_bbox_0: 0.2783  loss_rpn_cls: 0.217  loss_rpn_reg: 0.4578  time: 0.1891  last_time: 0.1832  data_time: 0.0056  last_data_time: 0.0086   lr: 5e-06  max_mem: 3029M
[03/05 13:59:13] d2.utils.events INFO:  eta: 0:37:07  iter: 42339  total_loss: 2.237  loss_ce: 0.2789  loss_giou: 0.2418  loss_bbox: 0.209  loss_ce_0: 0.326  loss_giou_0: 0.2724  loss_bbox_0: 0.2403  loss_rpn_cls: 0.1713  loss_rpn_reg: 0.4223  time: 0.1891  last_time: 0.1832  data_time: 0.0050  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 13:59:16] d2.utils.events INFO:  eta: 0:37:05  iter: 42359  total_loss: 2.219  loss_ce: 0.2547  loss_giou: 0.2821  loss_bbox: 0.2004  loss_ce_0: 0.2846  loss_giou_0: 0.3173  loss_bbox_0: 0.2181  loss_rpn_cls: 0.1889  loss_rpn_reg: 0.4236  time: 0.1891  last_time: 0.1760  data_time: 0.0052  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 13:59:20] d2.utils.events INFO:  eta: 0:37:01  iter: 42379  total_loss: 2.764  loss_ce: 0.346  loss_giou: 0.3766  loss_bbox: 0.2694  loss_ce_0: 0.3735  loss_giou_0: 0.3911  loss_bbox_0: 0.2944  loss_rpn_cls: 0.2101  loss_rpn_reg: 0.4344  time: 0.1891  last_time: 0.1782  data_time: 0.0043  last_data_time: 0.0029   lr: 5e-06  max_mem: 3029M
[03/05 13:59:24] d2.utils.events INFO:  eta: 0:36:55  iter: 42399  total_loss: 2  loss_ce: 0.2457  loss_giou: 0.2666  loss_bbox: 0.1942  loss_ce_0: 0.2563  loss_giou_0: 0.2899  loss_bbox_0: 0.2057  loss_rpn_cls: 0.1812  loss_rpn_reg: 0.4212  time: 0.1891  last_time: 0.1812  data_time: 0.0053  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 13:59:28] d2.utils.events INFO:  eta: 0:36:52  iter: 42419  total_loss: 2.553  loss_ce: 0.3691  loss_giou: 0.2941  loss_bbox: 0.2465  loss_ce_0: 0.4087  loss_giou_0: 0.3089  loss_bbox_0: 0.2586  loss_rpn_cls: 0.2222  loss_rpn_reg: 0.4226  time: 0.1891  last_time: 0.2001  data_time: 0.0048  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 13:59:32] d2.utils.events INFO:  eta: 0:36:48  iter: 42439  total_loss: 2.39  loss_ce: 0.3093  loss_giou: 0.317  loss_bbox: 0.2162  loss_ce_0: 0.3071  loss_giou_0: 0.3554  loss_bbox_0: 0.2498  loss_rpn_cls: 0.1994  loss_rpn_reg: 0.4295  time: 0.1891  last_time: 0.1714  data_time: 0.0051  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 13:59:36] d2.utils.events INFO:  eta: 0:36:44  iter: 42459  total_loss: 2.519  loss_ce: 0.3491  loss_giou: 0.3196  loss_bbox: 0.2604  loss_ce_0: 0.3773  loss_giou_0: 0.3181  loss_bbox_0: 0.2692  loss_rpn_cls: 0.2038  loss_rpn_reg: 0.4444  time: 0.1891  last_time: 0.2004  data_time: 0.0058  last_data_time: 0.0100   lr: 5e-06  max_mem: 3029M
[03/05 13:59:40] d2.utils.events INFO:  eta: 0:36:39  iter: 42479  total_loss: 2.479  loss_ce: 0.2263  loss_giou: 0.3538  loss_bbox: 0.2167  loss_ce_0: 0.283  loss_giou_0: 0.3628  loss_bbox_0: 0.2359  loss_rpn_cls: 0.1865  loss_rpn_reg: 0.4386  time: 0.1891  last_time: 0.2072  data_time: 0.0050  last_data_time: 0.0053   lr: 5e-06  max_mem: 3029M
[03/05 13:59:43] d2.utils.events INFO:  eta: 0:36:33  iter: 42499  total_loss: 2.431  loss_ce: 0.2722  loss_giou: 0.2994  loss_bbox: 0.1998  loss_ce_0: 0.3166  loss_giou_0: 0.3015  loss_bbox_0: 0.2289  loss_rpn_cls: 0.1885  loss_rpn_reg: 0.4303  time: 0.1891  last_time: 0.2042  data_time: 0.0049  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 13:59:47] d2.utils.events INFO:  eta: 0:36:28  iter: 42519  total_loss: 2.296  loss_ce: 0.2405  loss_giou: 0.267  loss_bbox: 0.2169  loss_ce_0: 0.3104  loss_giou_0: 0.2888  loss_bbox_0: 0.2498  loss_rpn_cls: 0.183  loss_rpn_reg: 0.4256  time: 0.1891  last_time: 0.1725  data_time: 0.0051  last_data_time: 0.0078   lr: 5e-06  max_mem: 3029M
[03/05 13:59:51] d2.utils.events INFO:  eta: 0:36:22  iter: 42539  total_loss: 2.186  loss_ce: 0.2516  loss_giou: 0.2381  loss_bbox: 0.1902  loss_ce_0: 0.2893  loss_giou_0: 0.277  loss_bbox_0: 0.224  loss_rpn_cls: 0.1699  loss_rpn_reg: 0.408  time: 0.1891  last_time: 0.1887  data_time: 0.0054  last_data_time: 0.0049   lr: 5e-06  max_mem: 3029M
[03/05 13:59:55] d2.utils.events INFO:  eta: 0:36:14  iter: 42559  total_loss: 2.247  loss_ce: 0.2985  loss_giou: 0.2341  loss_bbox: 0.2271  loss_ce_0: 0.3449  loss_giou_0: 0.2367  loss_bbox_0: 0.2388  loss_rpn_cls: 0.1789  loss_rpn_reg: 0.4213  time: 0.1891  last_time: 0.1978  data_time: 0.0052  last_data_time: 0.0071   lr: 5e-06  max_mem: 3029M
[03/05 13:59:59] d2.utils.events INFO:  eta: 0:36:10  iter: 42579  total_loss: 2.338  loss_ce: 0.303  loss_giou: 0.2981  loss_bbox: 0.2361  loss_ce_0: 0.3282  loss_giou_0: 0.3031  loss_bbox_0: 0.267  loss_rpn_cls: 0.1914  loss_rpn_reg: 0.4098  time: 0.1891  last_time: 0.2026  data_time: 0.0047  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 14:00:02] d2.utils.events INFO:  eta: 0:36:04  iter: 42599  total_loss: 2.323  loss_ce: 0.2966  loss_giou: 0.2675  loss_bbox: 0.2225  loss_ce_0: 0.308  loss_giou_0: 0.2945  loss_bbox_0: 0.2337  loss_rpn_cls: 0.2138  loss_rpn_reg: 0.423  time: 0.1891  last_time: 0.1970  data_time: 0.0048  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 14:00:06] d2.utils.events INFO:  eta: 0:35:59  iter: 42619  total_loss: 2.298  loss_ce: 0.3078  loss_giou: 0.2871  loss_bbox: 0.228  loss_ce_0: 0.3123  loss_giou_0: 0.3211  loss_bbox_0: 0.267  loss_rpn_cls: 0.1987  loss_rpn_reg: 0.4338  time: 0.1891  last_time: 0.1926  data_time: 0.0054  last_data_time: 0.0053   lr: 5e-06  max_mem: 3029M
[03/05 14:00:10] d2.utils.events INFO:  eta: 0:35:54  iter: 42639  total_loss: 2.457  loss_ce: 0.3455  loss_giou: 0.3048  loss_bbox: 0.2099  loss_ce_0: 0.4056  loss_giou_0: 0.3136  loss_bbox_0: 0.2223  loss_rpn_cls: 0.1832  loss_rpn_reg: 0.4442  time: 0.1891  last_time: 0.2204  data_time: 0.0050  last_data_time: 0.0055   lr: 5e-06  max_mem: 3029M
[03/05 14:00:14] d2.utils.events INFO:  eta: 0:35:49  iter: 42659  total_loss: 2.354  loss_ce: 0.3028  loss_giou: 0.297  loss_bbox: 0.2165  loss_ce_0: 0.3484  loss_giou_0: 0.3193  loss_bbox_0: 0.2608  loss_rpn_cls: 0.1715  loss_rpn_reg: 0.4063  time: 0.1891  last_time: 0.1852  data_time: 0.0053  last_data_time: 0.0081   lr: 5e-06  max_mem: 3029M
[03/05 14:00:18] d2.utils.events INFO:  eta: 0:35:43  iter: 42679  total_loss: 2.5  loss_ce: 0.2843  loss_giou: 0.3241  loss_bbox: 0.2277  loss_ce_0: 0.3563  loss_giou_0: 0.351  loss_bbox_0: 0.2529  loss_rpn_cls: 0.2016  loss_rpn_reg: 0.4801  time: 0.1891  last_time: 0.1928  data_time: 0.0051  last_data_time: 0.0048   lr: 5e-06  max_mem: 3029M
[03/05 14:00:22] d2.utils.events INFO:  eta: 0:35:39  iter: 42699  total_loss: 2.38  loss_ce: 0.3319  loss_giou: 0.2954  loss_bbox: 0.2288  loss_ce_0: 0.3344  loss_giou_0: 0.2867  loss_bbox_0: 0.2498  loss_rpn_cls: 0.1776  loss_rpn_reg: 0.4363  time: 0.1891  last_time: 0.2077  data_time: 0.0053  last_data_time: 0.0058   lr: 5e-06  max_mem: 3029M
[03/05 14:00:25] d2.utils.events INFO:  eta: 0:35:35  iter: 42719  total_loss: 2.368  loss_ce: 0.2887  loss_giou: 0.3006  loss_bbox: 0.2011  loss_ce_0: 0.3543  loss_giou_0: 0.3228  loss_bbox_0: 0.2437  loss_rpn_cls: 0.2102  loss_rpn_reg: 0.4538  time: 0.1891  last_time: 0.1907  data_time: 0.0051  last_data_time: 0.0047   lr: 5e-06  max_mem: 3029M
[03/05 14:00:29] d2.utils.events INFO:  eta: 0:35:30  iter: 42739  total_loss: 2.302  loss_ce: 0.298  loss_giou: 0.2727  loss_bbox: 0.2282  loss_ce_0: 0.3762  loss_giou_0: 0.2855  loss_bbox_0: 0.2517  loss_rpn_cls: 0.1945  loss_rpn_reg: 0.4065  time: 0.1891  last_time: 0.1836  data_time: 0.0050  last_data_time: 0.0035   lr: 5e-06  max_mem: 3029M
[03/05 14:00:33] d2.utils.events INFO:  eta: 0:35:24  iter: 42759  total_loss: 2.041  loss_ce: 0.2191  loss_giou: 0.2792  loss_bbox: 0.2278  loss_ce_0: 0.2653  loss_giou_0: 0.3113  loss_bbox_0: 0.2387  loss_rpn_cls: 0.1696  loss_rpn_reg: 0.3979  time: 0.1891  last_time: 0.1733  data_time: 0.0051  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 14:00:37] d2.utils.events INFO:  eta: 0:35:18  iter: 42779  total_loss: 2.371  loss_ce: 0.2957  loss_giou: 0.2864  loss_bbox: 0.2679  loss_ce_0: 0.3645  loss_giou_0: 0.3072  loss_bbox_0: 0.2846  loss_rpn_cls: 0.1822  loss_rpn_reg: 0.4127  time: 0.1891  last_time: 0.1757  data_time: 0.0049  last_data_time: 0.0020   lr: 5e-06  max_mem: 3029M
[03/05 14:00:40] d2.utils.events INFO:  eta: 0:35:12  iter: 42799  total_loss: 2.769  loss_ce: 0.3477  loss_giou: 0.3328  loss_bbox: 0.2953  loss_ce_0: 0.3962  loss_giou_0: 0.3675  loss_bbox_0: 0.3161  loss_rpn_cls: 0.2122  loss_rpn_reg: 0.4475  time: 0.1891  last_time: 0.2055  data_time: 0.0051  last_data_time: 0.0026   lr: 5e-06  max_mem: 3029M
[03/05 14:00:44] d2.utils.events INFO:  eta: 0:35:08  iter: 42819  total_loss: 2.34  loss_ce: 0.2819  loss_giou: 0.2852  loss_bbox: 0.2211  loss_ce_0: 0.2711  loss_giou_0: 0.3278  loss_bbox_0: 0.2727  loss_rpn_cls: 0.1873  loss_rpn_reg: 0.4204  time: 0.1891  last_time: 0.2441  data_time: 0.0056  last_data_time: 0.0049   lr: 5e-06  max_mem: 3029M
[03/05 14:00:48] d2.utils.events INFO:  eta: 0:35:04  iter: 42839  total_loss: 2.155  loss_ce: 0.2524  loss_giou: 0.2806  loss_bbox: 0.1981  loss_ce_0: 0.2827  loss_giou_0: 0.3174  loss_bbox_0: 0.2232  loss_rpn_cls: 0.1833  loss_rpn_reg: 0.3866  time: 0.1891  last_time: 0.1898  data_time: 0.0062  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 14:00:52] d2.utils.events INFO:  eta: 0:35:01  iter: 42859  total_loss: 2.412  loss_ce: 0.3221  loss_giou: 0.2479  loss_bbox: 0.2336  loss_ce_0: 0.3457  loss_giou_0: 0.2967  loss_bbox_0: 0.2902  loss_rpn_cls: 0.1857  loss_rpn_reg: 0.4113  time: 0.1891  last_time: 0.2044  data_time: 0.0052  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 14:00:56] d2.utils.events INFO:  eta: 0:34:58  iter: 42879  total_loss: 2.341  loss_ce: 0.3259  loss_giou: 0.2959  loss_bbox: 0.2374  loss_ce_0: 0.3939  loss_giou_0: 0.2871  loss_bbox_0: 0.2653  loss_rpn_cls: 0.1777  loss_rpn_reg: 0.4301  time: 0.1891  last_time: 0.2027  data_time: 0.0054  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 14:01:00] d2.utils.events INFO:  eta: 0:34:53  iter: 42899  total_loss: 2.247  loss_ce: 0.2493  loss_giou: 0.3388  loss_bbox: 0.2375  loss_ce_0: 0.2921  loss_giou_0: 0.3444  loss_bbox_0: 0.2597  loss_rpn_cls: 0.1793  loss_rpn_reg: 0.4166  time: 0.1891  last_time: 0.1826  data_time: 0.0052  last_data_time: 0.0031   lr: 5e-06  max_mem: 3029M
[03/05 14:01:04] d2.utils.events INFO:  eta: 0:34:50  iter: 42919  total_loss: 2.363  loss_ce: 0.2434  loss_giou: 0.2916  loss_bbox: 0.2363  loss_ce_0: 0.2904  loss_giou_0: 0.3185  loss_bbox_0: 0.2389  loss_rpn_cls: 0.1999  loss_rpn_reg: 0.4483  time: 0.1891  last_time: 0.1893  data_time: 0.0054  last_data_time: 0.0032   lr: 5e-06  max_mem: 3029M
[03/05 14:01:08] d2.utils.events INFO:  eta: 0:34:48  iter: 42939  total_loss: 2.26  loss_ce: 0.2904  loss_giou: 0.2599  loss_bbox: 0.2075  loss_ce_0: 0.355  loss_giou_0: 0.2925  loss_bbox_0: 0.2254  loss_rpn_cls: 0.1942  loss_rpn_reg: 0.4126  time: 0.1891  last_time: 0.2156  data_time: 0.0049  last_data_time: 0.0047   lr: 5e-06  max_mem: 3029M
[03/05 14:01:12] d2.utils.events INFO:  eta: 0:34:43  iter: 42959  total_loss: 2.243  loss_ce: 0.2508  loss_giou: 0.2903  loss_bbox: 0.222  loss_ce_0: 0.2993  loss_giou_0: 0.3089  loss_bbox_0: 0.2307  loss_rpn_cls: 0.1771  loss_rpn_reg: 0.4225  time: 0.1891  last_time: 0.1693  data_time: 0.0053  last_data_time: 0.0058   lr: 5e-06  max_mem: 3029M
[03/05 14:01:15] d2.utils.events INFO:  eta: 0:34:38  iter: 42979  total_loss: 2.211  loss_ce: 0.2782  loss_giou: 0.2653  loss_bbox: 0.2275  loss_ce_0: 0.3228  loss_giou_0: 0.2974  loss_bbox_0: 0.2762  loss_rpn_cls: 0.1842  loss_rpn_reg: 0.4122  time: 0.1891  last_time: 0.1957  data_time: 0.0048  last_data_time: 0.0069   lr: 5e-06  max_mem: 3029M
[03/05 14:01:19] d2.utils.events INFO:  eta: 0:34:34  iter: 42999  total_loss: 2.22  loss_ce: 0.2837  loss_giou: 0.2489  loss_bbox: 0.2225  loss_ce_0: 0.3366  loss_giou_0: 0.2673  loss_bbox_0: 0.2265  loss_rpn_cls: 0.1701  loss_rpn_reg: 0.4125  time: 0.1891  last_time: 0.1818  data_time: 0.0052  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 14:01:23] d2.utils.events INFO:  eta: 0:34:30  iter: 43019  total_loss: 2.595  loss_ce: 0.3473  loss_giou: 0.322  loss_bbox: 0.2208  loss_ce_0: 0.3668  loss_giou_0: 0.3501  loss_bbox_0: 0.2557  loss_rpn_cls: 0.2057  loss_rpn_reg: 0.4356  time: 0.1891  last_time: 0.1884  data_time: 0.0055  last_data_time: 0.0047   lr: 5e-06  max_mem: 3029M
[03/05 14:01:27] d2.utils.events INFO:  eta: 0:34:25  iter: 43039  total_loss: 2.432  loss_ce: 0.3115  loss_giou: 0.2913  loss_bbox: 0.2552  loss_ce_0: 0.3509  loss_giou_0: 0.3165  loss_bbox_0: 0.299  loss_rpn_cls: 0.1757  loss_rpn_reg: 0.4269  time: 0.1891  last_time: 0.1679  data_time: 0.0054  last_data_time: 0.0055   lr: 5e-06  max_mem: 3029M
[03/05 14:01:31] d2.utils.events INFO:  eta: 0:34:21  iter: 43059  total_loss: 2.204  loss_ce: 0.256  loss_giou: 0.2658  loss_bbox: 0.2184  loss_ce_0: 0.2719  loss_giou_0: 0.2753  loss_bbox_0: 0.2722  loss_rpn_cls: 0.1928  loss_rpn_reg: 0.409  time: 0.1891  last_time: 0.1889  data_time: 0.0054  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 14:01:35] d2.utils.events INFO:  eta: 0:34:17  iter: 43079  total_loss: 2.288  loss_ce: 0.3081  loss_giou: 0.2737  loss_bbox: 0.2147  loss_ce_0: 0.3448  loss_giou_0: 0.2895  loss_bbox_0: 0.2381  loss_rpn_cls: 0.1996  loss_rpn_reg: 0.4356  time: 0.1891  last_time: 0.1833  data_time: 0.0052  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 14:01:38] d2.utils.events INFO:  eta: 0:34:14  iter: 43099  total_loss: 2.261  loss_ce: 0.2578  loss_giou: 0.3138  loss_bbox: 0.1914  loss_ce_0: 0.3072  loss_giou_0: 0.3235  loss_bbox_0: 0.2118  loss_rpn_cls: 0.1943  loss_rpn_reg: 0.4428  time: 0.1891  last_time: 0.1815  data_time: 0.0051  last_data_time: 0.0049   lr: 5e-06  max_mem: 3029M
[03/05 14:01:42] d2.utils.events INFO:  eta: 0:34:10  iter: 43119  total_loss: 2.073  loss_ce: 0.253  loss_giou: 0.2358  loss_bbox: 0.2099  loss_ce_0: 0.2902  loss_giou_0: 0.2553  loss_bbox_0: 0.226  loss_rpn_cls: 0.1794  loss_rpn_reg: 0.4022  time: 0.1891  last_time: 0.1897  data_time: 0.0050  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 14:01:46] d2.utils.events INFO:  eta: 0:34:06  iter: 43139  total_loss: 2.24  loss_ce: 0.2401  loss_giou: 0.2736  loss_bbox: 0.2289  loss_ce_0: 0.3125  loss_giou_0: 0.2864  loss_bbox_0: 0.2574  loss_rpn_cls: 0.184  loss_rpn_reg: 0.4164  time: 0.1891  last_time: 0.2102  data_time: 0.0047  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 14:01:50] d2.utils.events INFO:  eta: 0:34:01  iter: 43159  total_loss: 2.151  loss_ce: 0.2906  loss_giou: 0.3209  loss_bbox: 0.1945  loss_ce_0: 0.311  loss_giou_0: 0.3371  loss_bbox_0: 0.2479  loss_rpn_cls: 0.2054  loss_rpn_reg: 0.4058  time: 0.1891  last_time: 0.1806  data_time: 0.0054  last_data_time: 0.0060   lr: 5e-06  max_mem: 3029M
[03/05 14:01:54] d2.utils.events INFO:  eta: 0:33:57  iter: 43179  total_loss: 2.478  loss_ce: 0.3279  loss_giou: 0.3361  loss_bbox: 0.2407  loss_ce_0: 0.3385  loss_giou_0: 0.3415  loss_bbox_0: 0.2628  loss_rpn_cls: 0.2054  loss_rpn_reg: 0.4363  time: 0.1891  last_time: 0.1915  data_time: 0.0056  last_data_time: 0.0055   lr: 5e-06  max_mem: 3029M
[03/05 14:01:58] d2.utils.events INFO:  eta: 0:33:54  iter: 43199  total_loss: 2.247  loss_ce: 0.3034  loss_giou: 0.3059  loss_bbox: 0.204  loss_ce_0: 0.3391  loss_giou_0: 0.322  loss_bbox_0: 0.2268  loss_rpn_cls: 0.1602  loss_rpn_reg: 0.4214  time: 0.1891  last_time: 0.1945  data_time: 0.0050  last_data_time: 0.0049   lr: 5e-06  max_mem: 3029M
[03/05 14:02:01] d2.utils.events INFO:  eta: 0:33:50  iter: 43219  total_loss: 2.41  loss_ce: 0.2974  loss_giou: 0.2815  loss_bbox: 0.2185  loss_ce_0: 0.3584  loss_giou_0: 0.3022  loss_bbox_0: 0.2358  loss_rpn_cls: 0.1988  loss_rpn_reg: 0.4267  time: 0.1891  last_time: 0.1771  data_time: 0.0057  last_data_time: 0.0066   lr: 5e-06  max_mem: 3029M
[03/05 14:02:05] d2.utils.events INFO:  eta: 0:33:46  iter: 43239  total_loss: 2.226  loss_ce: 0.2893  loss_giou: 0.2538  loss_bbox: 0.2378  loss_ce_0: 0.3262  loss_giou_0: 0.2728  loss_bbox_0: 0.2541  loss_rpn_cls: 0.1818  loss_rpn_reg: 0.436  time: 0.1891  last_time: 0.1905  data_time: 0.0053  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 14:02:09] d2.utils.events INFO:  eta: 0:33:43  iter: 43259  total_loss: 2.448  loss_ce: 0.3117  loss_giou: 0.3018  loss_bbox: 0.2503  loss_ce_0: 0.3433  loss_giou_0: 0.3294  loss_bbox_0: 0.243  loss_rpn_cls: 0.1763  loss_rpn_reg: 0.4578  time: 0.1891  last_time: 0.1902  data_time: 0.0049  last_data_time: 0.0058   lr: 5e-06  max_mem: 3029M
[03/05 14:02:13] d2.utils.events INFO:  eta: 0:33:38  iter: 43279  total_loss: 2.625  loss_ce: 0.3039  loss_giou: 0.3157  loss_bbox: 0.2045  loss_ce_0: 0.3667  loss_giou_0: 0.3381  loss_bbox_0: 0.2548  loss_rpn_cls: 0.2276  loss_rpn_reg: 0.4336  time: 0.1891  last_time: 0.1695  data_time: 0.0048  last_data_time: 0.0035   lr: 5e-06  max_mem: 3029M
[03/05 14:02:16] d2.utils.events INFO:  eta: 0:33:33  iter: 43299  total_loss: 2.312  loss_ce: 0.2711  loss_giou: 0.2919  loss_bbox: 0.2488  loss_ce_0: 0.3443  loss_giou_0: 0.3064  loss_bbox_0: 0.2879  loss_rpn_cls: 0.1638  loss_rpn_reg: 0.4284  time: 0.1891  last_time: 0.1847  data_time: 0.0054  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:02:20] d2.utils.events INFO:  eta: 0:33:30  iter: 43319  total_loss: 2.331  loss_ce: 0.2869  loss_giou: 0.2885  loss_bbox: 0.2224  loss_ce_0: 0.293  loss_giou_0: 0.2987  loss_bbox_0: 0.2372  loss_rpn_cls: 0.1902  loss_rpn_reg: 0.4366  time: 0.1891  last_time: 0.2070  data_time: 0.0055  last_data_time: 0.0049   lr: 5e-06  max_mem: 3029M
[03/05 14:02:24] d2.utils.events INFO:  eta: 0:33:28  iter: 43339  total_loss: 2.279  loss_ce: 0.246  loss_giou: 0.3327  loss_bbox: 0.2214  loss_ce_0: 0.2851  loss_giou_0: 0.347  loss_bbox_0: 0.2409  loss_rpn_cls: 0.1952  loss_rpn_reg: 0.4149  time: 0.1891  last_time: 0.2123  data_time: 0.0051  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:02:28] d2.utils.events INFO:  eta: 0:33:24  iter: 43359  total_loss: 2.554  loss_ce: 0.303  loss_giou: 0.291  loss_bbox: 0.2246  loss_ce_0: 0.3557  loss_giou_0: 0.3191  loss_bbox_0: 0.2487  loss_rpn_cls: 0.2016  loss_rpn_reg: 0.436  time: 0.1891  last_time: 0.1964  data_time: 0.0060  last_data_time: 0.0053   lr: 5e-06  max_mem: 3029M
[03/05 14:02:32] d2.utils.events INFO:  eta: 0:33:20  iter: 43379  total_loss: 2.39  loss_ce: 0.3026  loss_giou: 0.3337  loss_bbox: 0.2266  loss_ce_0: 0.3347  loss_giou_0: 0.3407  loss_bbox_0: 0.2187  loss_rpn_cls: 0.186  loss_rpn_reg: 0.433  time: 0.1891  last_time: 0.2143  data_time: 0.0058  last_data_time: 0.0062   lr: 5e-06  max_mem: 3029M
[03/05 14:02:36] d2.utils.events INFO:  eta: 0:33:16  iter: 43399  total_loss: 2.364  loss_ce: 0.319  loss_giou: 0.2879  loss_bbox: 0.2316  loss_ce_0: 0.3546  loss_giou_0: 0.2928  loss_bbox_0: 0.2371  loss_rpn_cls: 0.2181  loss_rpn_reg: 0.4061  time: 0.1891  last_time: 0.1733  data_time: 0.0055  last_data_time: 0.0063   lr: 5e-06  max_mem: 3029M
[03/05 14:02:40] d2.utils.events INFO:  eta: 0:33:12  iter: 43419  total_loss: 2.312  loss_ce: 0.2597  loss_giou: 0.3216  loss_bbox: 0.2225  loss_ce_0: 0.3233  loss_giou_0: 0.3264  loss_bbox_0: 0.2409  loss_rpn_cls: 0.2005  loss_rpn_reg: 0.4143  time: 0.1891  last_time: 0.1696  data_time: 0.0054  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 14:02:44] d2.utils.events INFO:  eta: 0:33:08  iter: 43439  total_loss: 2.33  loss_ce: 0.2999  loss_giou: 0.3272  loss_bbox: 0.2108  loss_ce_0: 0.326  loss_giou_0: 0.324  loss_bbox_0: 0.2375  loss_rpn_cls: 0.2048  loss_rpn_reg: 0.45  time: 0.1891  last_time: 0.1988  data_time: 0.0051  last_data_time: 0.0079   lr: 5e-06  max_mem: 3029M
[03/05 14:02:48] d2.utils.events INFO:  eta: 0:33:05  iter: 43459  total_loss: 2.353  loss_ce: 0.323  loss_giou: 0.2739  loss_bbox: 0.2216  loss_ce_0: 0.3497  loss_giou_0: 0.2929  loss_bbox_0: 0.2411  loss_rpn_cls: 0.1955  loss_rpn_reg: 0.4161  time: 0.1891  last_time: 0.1773  data_time: 0.0052  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 14:02:51] d2.utils.events INFO:  eta: 0:33:01  iter: 43479  total_loss: 2.522  loss_ce: 0.2996  loss_giou: 0.3154  loss_bbox: 0.247  loss_ce_0: 0.3419  loss_giou_0: 0.342  loss_bbox_0: 0.2582  loss_rpn_cls: 0.2071  loss_rpn_reg: 0.4255  time: 0.1891  last_time: 0.1727  data_time: 0.0053  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 14:02:55] d2.utils.events INFO:  eta: 0:32:55  iter: 43499  total_loss: 2.153  loss_ce: 0.2397  loss_giou: 0.287  loss_bbox: 0.2052  loss_ce_0: 0.2855  loss_giou_0: 0.2908  loss_bbox_0: 0.2131  loss_rpn_cls: 0.1832  loss_rpn_reg: 0.3902  time: 0.1891  last_time: 0.1790  data_time: 0.0053  last_data_time: 0.0058   lr: 5e-06  max_mem: 3029M
[03/05 14:02:59] d2.utils.events INFO:  eta: 0:32:52  iter: 43519  total_loss: 2.546  loss_ce: 0.336  loss_giou: 0.3042  loss_bbox: 0.2603  loss_ce_0: 0.3844  loss_giou_0: 0.3201  loss_bbox_0: 0.2963  loss_rpn_cls: 0.206  loss_rpn_reg: 0.4342  time: 0.1891  last_time: 0.1820  data_time: 0.0061  last_data_time: 0.0067   lr: 5e-06  max_mem: 3029M
[03/05 14:03:03] d2.utils.events INFO:  eta: 0:32:47  iter: 43539  total_loss: 2.488  loss_ce: 0.2923  loss_giou: 0.3276  loss_bbox: 0.2449  loss_ce_0: 0.3417  loss_giou_0: 0.3143  loss_bbox_0: 0.2703  loss_rpn_cls: 0.205  loss_rpn_reg: 0.4128  time: 0.1891  last_time: 0.1833  data_time: 0.0052  last_data_time: 0.0055   lr: 5e-06  max_mem: 3029M
[03/05 14:03:06] d2.utils.events INFO:  eta: 0:32:44  iter: 43559  total_loss: 2.072  loss_ce: 0.2492  loss_giou: 0.2436  loss_bbox: 0.2505  loss_ce_0: 0.358  loss_giou_0: 0.2525  loss_bbox_0: 0.2503  loss_rpn_cls: 0.1817  loss_rpn_reg: 0.4145  time: 0.1891  last_time: 0.1660  data_time: 0.0051  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 14:03:10] d2.utils.events INFO:  eta: 0:32:41  iter: 43579  total_loss: 2.332  loss_ce: 0.2651  loss_giou: 0.2869  loss_bbox: 0.2079  loss_ce_0: 0.3017  loss_giou_0: 0.3089  loss_bbox_0: 0.2319  loss_rpn_cls: 0.1703  loss_rpn_reg: 0.4239  time: 0.1891  last_time: 0.1852  data_time: 0.0049  last_data_time: 0.0060   lr: 5e-06  max_mem: 3029M
[03/05 14:03:14] d2.utils.events INFO:  eta: 0:32:36  iter: 43599  total_loss: 2.355  loss_ce: 0.2978  loss_giou: 0.2623  loss_bbox: 0.246  loss_ce_0: 0.3153  loss_giou_0: 0.2844  loss_bbox_0: 0.2594  loss_rpn_cls: 0.1714  loss_rpn_reg: 0.424  time: 0.1891  last_time: 0.1775  data_time: 0.0053  last_data_time: 0.0059   lr: 5e-06  max_mem: 3029M
[03/05 14:03:18] d2.utils.events INFO:  eta: 0:32:32  iter: 43619  total_loss: 2.287  loss_ce: 0.2605  loss_giou: 0.2747  loss_bbox: 0.2151  loss_ce_0: 0.3379  loss_giou_0: 0.3005  loss_bbox_0: 0.2333  loss_rpn_cls: 0.1869  loss_rpn_reg: 0.4275  time: 0.1891  last_time: 0.2064  data_time: 0.0052  last_data_time: 0.0051   lr: 5e-06  max_mem: 3029M
[03/05 14:03:21] d2.utils.events INFO:  eta: 0:32:27  iter: 43639  total_loss: 2.048  loss_ce: 0.2648  loss_giou: 0.2538  loss_bbox: 0.2477  loss_ce_0: 0.3065  loss_giou_0: 0.27  loss_bbox_0: 0.2551  loss_rpn_cls: 0.1813  loss_rpn_reg: 0.4157  time: 0.1891  last_time: 0.1818  data_time: 0.0047  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 14:03:25] d2.utils.events INFO:  eta: 0:32:23  iter: 43659  total_loss: 2.095  loss_ce: 0.2896  loss_giou: 0.2491  loss_bbox: 0.2014  loss_ce_0: 0.3321  loss_giou_0: 0.2695  loss_bbox_0: 0.2502  loss_rpn_cls: 0.1907  loss_rpn_reg: 0.3629  time: 0.1891  last_time: 0.1847  data_time: 0.0051  last_data_time: 0.0029   lr: 5e-06  max_mem: 3029M
[03/05 14:03:29] d2.utils.events INFO:  eta: 0:32:18  iter: 43679  total_loss: 2.388  loss_ce: 0.3059  loss_giou: 0.3077  loss_bbox: 0.242  loss_ce_0: 0.3143  loss_giou_0: 0.3121  loss_bbox_0: 0.2216  loss_rpn_cls: 0.1779  loss_rpn_reg: 0.4134  time: 0.1891  last_time: 0.1885  data_time: 0.0051  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 14:03:33] d2.utils.events INFO:  eta: 0:32:14  iter: 43699  total_loss: 2.149  loss_ce: 0.2516  loss_giou: 0.2657  loss_bbox: 0.2074  loss_ce_0: 0.2846  loss_giou_0: 0.2612  loss_bbox_0: 0.2394  loss_rpn_cls: 0.1597  loss_rpn_reg: 0.3971  time: 0.1891  last_time: 0.1999  data_time: 0.0047  last_data_time: 0.0080   lr: 5e-06  max_mem: 3029M
[03/05 14:03:37] d2.utils.events INFO:  eta: 0:32:11  iter: 43719  total_loss: 2.503  loss_ce: 0.3511  loss_giou: 0.2684  loss_bbox: 0.2663  loss_ce_0: 0.3453  loss_giou_0: 0.3128  loss_bbox_0: 0.2981  loss_rpn_cls: 0.1897  loss_rpn_reg: 0.4279  time: 0.1891  last_time: 0.2218  data_time: 0.0051  last_data_time: 0.0071   lr: 5e-06  max_mem: 3029M
[03/05 14:03:40] d2.utils.events INFO:  eta: 0:32:07  iter: 43739  total_loss: 2.318  loss_ce: 0.3009  loss_giou: 0.2906  loss_bbox: 0.2378  loss_ce_0: 0.3291  loss_giou_0: 0.2988  loss_bbox_0: 0.2524  loss_rpn_cls: 0.1992  loss_rpn_reg: 0.4215  time: 0.1891  last_time: 0.1779  data_time: 0.0048  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 14:03:44] d2.utils.events INFO:  eta: 0:32:05  iter: 43759  total_loss: 2.165  loss_ce: 0.3194  loss_giou: 0.2441  loss_bbox: 0.2034  loss_ce_0: 0.3179  loss_giou_0: 0.2594  loss_bbox_0: 0.238  loss_rpn_cls: 0.1769  loss_rpn_reg: 0.3794  time: 0.1891  last_time: 0.1939  data_time: 0.0050  last_data_time: 0.0045   lr: 5e-06  max_mem: 3029M
[03/05 14:03:48] d2.utils.events INFO:  eta: 0:32:01  iter: 43779  total_loss: 2.376  loss_ce: 0.3146  loss_giou: 0.2894  loss_bbox: 0.2083  loss_ce_0: 0.3483  loss_giou_0: 0.3036  loss_bbox_0: 0.2376  loss_rpn_cls: 0.192  loss_rpn_reg: 0.4451  time: 0.1891  last_time: 0.1692  data_time: 0.0050  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:03:52] d2.utils.events INFO:  eta: 0:31:58  iter: 43799  total_loss: 2.558  loss_ce: 0.2733  loss_giou: 0.3165  loss_bbox: 0.2459  loss_ce_0: 0.3305  loss_giou_0: 0.3478  loss_bbox_0: 0.3017  loss_rpn_cls: 0.2116  loss_rpn_reg: 0.4802  time: 0.1891  last_time: 0.2208  data_time: 0.0049  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 14:03:56] d2.utils.events INFO:  eta: 0:31:54  iter: 43819  total_loss: 2.28  loss_ce: 0.3294  loss_giou: 0.2886  loss_bbox: 0.2134  loss_ce_0: 0.3356  loss_giou_0: 0.2746  loss_bbox_0: 0.2503  loss_rpn_cls: 0.201  loss_rpn_reg: 0.4176  time: 0.1891  last_time: 0.2042  data_time: 0.0054  last_data_time: 0.0055   lr: 5e-06  max_mem: 3029M
[03/05 14:03:59] d2.utils.events INFO:  eta: 0:31:47  iter: 43839  total_loss: 2.602  loss_ce: 0.3353  loss_giou: 0.3583  loss_bbox: 0.2555  loss_ce_0: 0.3513  loss_giou_0: 0.3588  loss_bbox_0: 0.2772  loss_rpn_cls: 0.1858  loss_rpn_reg: 0.4354  time: 0.1891  last_time: 0.1580  data_time: 0.0050  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 14:04:03] d2.utils.events INFO:  eta: 0:31:39  iter: 43859  total_loss: 2.285  loss_ce: 0.2638  loss_giou: 0.2574  loss_bbox: 0.227  loss_ce_0: 0.3124  loss_giou_0: 0.2784  loss_bbox_0: 0.2533  loss_rpn_cls: 0.1983  loss_rpn_reg: 0.3999  time: 0.1891  last_time: 0.1794  data_time: 0.0049  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 14:04:07] d2.utils.events INFO:  eta: 0:31:34  iter: 43879  total_loss: 2.323  loss_ce: 0.2859  loss_giou: 0.2571  loss_bbox: 0.2398  loss_ce_0: 0.3501  loss_giou_0: 0.2815  loss_bbox_0: 0.266  loss_rpn_cls: 0.1964  loss_rpn_reg: 0.403  time: 0.1891  last_time: 0.1925  data_time: 0.0050  last_data_time: 0.0087   lr: 5e-06  max_mem: 3029M
[03/05 14:04:11] d2.utils.events INFO:  eta: 0:31:28  iter: 43899  total_loss: 2.369  loss_ce: 0.2882  loss_giou: 0.2358  loss_bbox: 0.2529  loss_ce_0: 0.324  loss_giou_0: 0.2771  loss_bbox_0: 0.2754  loss_rpn_cls: 0.1639  loss_rpn_reg: 0.4238  time: 0.1891  last_time: 0.1985  data_time: 0.0049  last_data_time: 0.0069   lr: 5e-06  max_mem: 3029M
[03/05 14:04:15] d2.utils.events INFO:  eta: 0:31:24  iter: 43919  total_loss: 2.189  loss_ce: 0.3008  loss_giou: 0.2926  loss_bbox: 0.209  loss_ce_0: 0.3461  loss_giou_0: 0.3064  loss_bbox_0: 0.2397  loss_rpn_cls: 0.1741  loss_rpn_reg: 0.4312  time: 0.1891  last_time: 0.2182  data_time: 0.0055  last_data_time: 0.0070   lr: 5e-06  max_mem: 3029M
[03/05 14:04:18] d2.utils.events INFO:  eta: 0:31:19  iter: 43939  total_loss: 2.574  loss_ce: 0.323  loss_giou: 0.323  loss_bbox: 0.2593  loss_ce_0: 0.3619  loss_giou_0: 0.3306  loss_bbox_0: 0.2499  loss_rpn_cls: 0.2126  loss_rpn_reg: 0.4466  time: 0.1891  last_time: 0.1947  data_time: 0.0047  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 14:04:22] d2.utils.events INFO:  eta: 0:31:15  iter: 43959  total_loss: 2.385  loss_ce: 0.3196  loss_giou: 0.2526  loss_bbox: 0.2701  loss_ce_0: 0.3748  loss_giou_0: 0.2881  loss_bbox_0: 0.2878  loss_rpn_cls: 0.1946  loss_rpn_reg: 0.4243  time: 0.1891  last_time: 0.1702  data_time: 0.0049  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 14:04:26] d2.utils.events INFO:  eta: 0:31:12  iter: 43979  total_loss: 2.448  loss_ce: 0.3362  loss_giou: 0.2718  loss_bbox: 0.2273  loss_ce_0: 0.3897  loss_giou_0: 0.2885  loss_bbox_0: 0.2453  loss_rpn_cls: 0.1985  loss_rpn_reg: 0.4233  time: 0.1891  last_time: 0.1865  data_time: 0.0051  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 14:04:30] d2.utils.events INFO:  eta: 0:31:08  iter: 43999  total_loss: 2.409  loss_ce: 0.3234  loss_giou: 0.314  loss_bbox: 0.2657  loss_ce_0: 0.365  loss_giou_0: 0.3313  loss_bbox_0: 0.3091  loss_rpn_cls: 0.1764  loss_rpn_reg: 0.4518  time: 0.1891  last_time: 0.1781  data_time: 0.0047  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 14:04:34] d2.utils.events INFO:  eta: 0:31:03  iter: 44019  total_loss: 2.275  loss_ce: 0.2895  loss_giou: 0.2484  loss_bbox: 0.2146  loss_ce_0: 0.3487  loss_giou_0: 0.2517  loss_bbox_0: 0.2439  loss_rpn_cls: 0.178  loss_rpn_reg: 0.4351  time: 0.1891  last_time: 0.1725  data_time: 0.0048  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 14:04:37] d2.utils.events INFO:  eta: 0:30:58  iter: 44039  total_loss: 2.311  loss_ce: 0.2844  loss_giou: 0.2888  loss_bbox: 0.2209  loss_ce_0: 0.3169  loss_giou_0: 0.3008  loss_bbox_0: 0.2374  loss_rpn_cls: 0.1808  loss_rpn_reg: 0.4098  time: 0.1891  last_time: 0.1588  data_time: 0.0049  last_data_time: 0.0031   lr: 5e-06  max_mem: 3029M
[03/05 14:04:41] d2.utils.events INFO:  eta: 0:30:55  iter: 44059  total_loss: 2.268  loss_ce: 0.3064  loss_giou: 0.2692  loss_bbox: 0.2201  loss_ce_0: 0.3351  loss_giou_0: 0.2912  loss_bbox_0: 0.2579  loss_rpn_cls: 0.1585  loss_rpn_reg: 0.4086  time: 0.1891  last_time: 0.1976  data_time: 0.0052  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 14:04:45] d2.utils.events INFO:  eta: 0:30:51  iter: 44079  total_loss: 2.5  loss_ce: 0.3352  loss_giou: 0.2796  loss_bbox: 0.2211  loss_ce_0: 0.3829  loss_giou_0: 0.33  loss_bbox_0: 0.2742  loss_rpn_cls: 0.1856  loss_rpn_reg: 0.4423  time: 0.1891  last_time: 0.1803  data_time: 0.0047  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:04:49] d2.utils.events INFO:  eta: 0:30:48  iter: 44099  total_loss: 2.308  loss_ce: 0.2612  loss_giou: 0.2508  loss_bbox: 0.2108  loss_ce_0: 0.3165  loss_giou_0: 0.2826  loss_bbox_0: 0.2655  loss_rpn_cls: 0.1812  loss_rpn_reg: 0.4303  time: 0.1891  last_time: 0.1731  data_time: 0.0065  last_data_time: 0.0178   lr: 5e-06  max_mem: 3029M
[03/05 14:04:52] d2.utils.events INFO:  eta: 0:30:44  iter: 44119  total_loss: 2.187  loss_ce: 0.2965  loss_giou: 0.2868  loss_bbox: 0.2293  loss_ce_0: 0.3204  loss_giou_0: 0.3042  loss_bbox_0: 0.2413  loss_rpn_cls: 0.1623  loss_rpn_reg: 0.4269  time: 0.1891  last_time: 0.1759  data_time: 0.0052  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 14:04:56] d2.utils.events INFO:  eta: 0:30:40  iter: 44139  total_loss: 2.517  loss_ce: 0.3446  loss_giou: 0.2841  loss_bbox: 0.2412  loss_ce_0: 0.3665  loss_giou_0: 0.3106  loss_bbox_0: 0.2868  loss_rpn_cls: 0.2048  loss_rpn_reg: 0.4258  time: 0.1891  last_time: 0.1913  data_time: 0.0049  last_data_time: 0.0033   lr: 5e-06  max_mem: 3029M
[03/05 14:05:00] d2.utils.events INFO:  eta: 0:30:36  iter: 44159  total_loss: 2.449  loss_ce: 0.3563  loss_giou: 0.3468  loss_bbox: 0.2292  loss_ce_0: 0.3973  loss_giou_0: 0.3562  loss_bbox_0: 0.2416  loss_rpn_cls: 0.2257  loss_rpn_reg: 0.4192  time: 0.1891  last_time: 0.1971  data_time: 0.0054  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 14:05:04] d2.utils.events INFO:  eta: 0:30:32  iter: 44179  total_loss: 2.298  loss_ce: 0.2918  loss_giou: 0.3057  loss_bbox: 0.1858  loss_ce_0: 0.3185  loss_giou_0: 0.3129  loss_bbox_0: 0.2104  loss_rpn_cls: 0.2089  loss_rpn_reg: 0.4214  time: 0.1891  last_time: 0.1965  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 14:05:08] d2.utils.events INFO:  eta: 0:30:29  iter: 44199  total_loss: 2.299  loss_ce: 0.3027  loss_giou: 0.2857  loss_bbox: 0.2358  loss_ce_0: 0.3135  loss_giou_0: 0.307  loss_bbox_0: 0.276  loss_rpn_cls: 0.1731  loss_rpn_reg: 0.4063  time: 0.1891  last_time: 0.1922  data_time: 0.0053  last_data_time: 0.0069   lr: 5e-06  max_mem: 3029M
[03/05 14:05:12] d2.utils.events INFO:  eta: 0:30:26  iter: 44219  total_loss: 2.448  loss_ce: 0.2638  loss_giou: 0.2801  loss_bbox: 0.2278  loss_ce_0: 0.3058  loss_giou_0: 0.2886  loss_bbox_0: 0.2599  loss_rpn_cls: 0.1931  loss_rpn_reg: 0.4056  time: 0.1891  last_time: 0.1919  data_time: 0.0049  last_data_time: 0.0048   lr: 5e-06  max_mem: 3029M
[03/05 14:05:15] d2.utils.events INFO:  eta: 0:30:21  iter: 44239  total_loss: 2.367  loss_ce: 0.2694  loss_giou: 0.2647  loss_bbox: 0.2444  loss_ce_0: 0.3118  loss_giou_0: 0.2836  loss_bbox_0: 0.2624  loss_rpn_cls: 0.1794  loss_rpn_reg: 0.4344  time: 0.1891  last_time: 0.2045  data_time: 0.0049  last_data_time: 0.0057   lr: 5e-06  max_mem: 3029M
[03/05 14:05:19] d2.utils.events INFO:  eta: 0:30:18  iter: 44259  total_loss: 2.249  loss_ce: 0.2642  loss_giou: 0.2944  loss_bbox: 0.1864  loss_ce_0: 0.3133  loss_giou_0: 0.3015  loss_bbox_0: 0.2228  loss_rpn_cls: 0.1956  loss_rpn_reg: 0.4406  time: 0.1891  last_time: 0.1629  data_time: 0.0047  last_data_time: 0.0073   lr: 5e-06  max_mem: 3029M
[03/05 14:05:23] d2.utils.events INFO:  eta: 0:30:14  iter: 44279  total_loss: 2.562  loss_ce: 0.3281  loss_giou: 0.3257  loss_bbox: 0.2643  loss_ce_0: 0.4014  loss_giou_0: 0.3451  loss_bbox_0: 0.3059  loss_rpn_cls: 0.2124  loss_rpn_reg: 0.4201  time: 0.1891  last_time: 0.1853  data_time: 0.0049  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 14:05:27] d2.utils.events INFO:  eta: 0:30:12  iter: 44299  total_loss: 2.31  loss_ce: 0.243  loss_giou: 0.3227  loss_bbox: 0.256  loss_ce_0: 0.2671  loss_giou_0: 0.3191  loss_bbox_0: 0.2643  loss_rpn_cls: 0.1642  loss_rpn_reg: 0.4291  time: 0.1891  last_time: 0.2024  data_time: 0.0055  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 14:05:30] d2.utils.events INFO:  eta: 0:30:07  iter: 44319  total_loss: 2.217  loss_ce: 0.286  loss_giou: 0.2413  loss_bbox: 0.2205  loss_ce_0: 0.3092  loss_giou_0: 0.2632  loss_bbox_0: 0.2299  loss_rpn_cls: 0.1678  loss_rpn_reg: 0.41  time: 0.1891  last_time: 0.1705  data_time: 0.0053  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 14:05:34] d2.utils.events INFO:  eta: 0:30:02  iter: 44339  total_loss: 2.263  loss_ce: 0.373  loss_giou: 0.2357  loss_bbox: 0.2059  loss_ce_0: 0.3878  loss_giou_0: 0.256  loss_bbox_0: 0.2636  loss_rpn_cls: 0.1892  loss_rpn_reg: 0.4017  time: 0.1891  last_time: 0.1723  data_time: 0.0049  last_data_time: 0.0045   lr: 5e-06  max_mem: 3029M
[03/05 14:05:38] d2.utils.events INFO:  eta: 0:29:58  iter: 44359  total_loss: 2.719  loss_ce: 0.3249  loss_giou: 0.331  loss_bbox: 0.24  loss_ce_0: 0.3862  loss_giou_0: 0.3413  loss_bbox_0: 0.2615  loss_rpn_cls: 0.2165  loss_rpn_reg: 0.4538  time: 0.1890  last_time: 0.1923  data_time: 0.0049  last_data_time: 0.0074   lr: 5e-06  max_mem: 3029M
[03/05 14:05:42] d2.utils.events INFO:  eta: 0:29:51  iter: 44379  total_loss: 2.404  loss_ce: 0.327  loss_giou: 0.2265  loss_bbox: 0.1975  loss_ce_0: 0.3778  loss_giou_0: 0.2597  loss_bbox_0: 0.2295  loss_rpn_cls: 0.2048  loss_rpn_reg: 0.423  time: 0.1890  last_time: 0.1659  data_time: 0.0051  last_data_time: 0.0029   lr: 5e-06  max_mem: 3029M
[03/05 14:05:46] d2.utils.events INFO:  eta: 0:29:47  iter: 44399  total_loss: 2.489  loss_ce: 0.3242  loss_giou: 0.2787  loss_bbox: 0.2179  loss_ce_0: 0.3786  loss_giou_0: 0.2954  loss_bbox_0: 0.2493  loss_rpn_cls: 0.1968  loss_rpn_reg: 0.4141  time: 0.1890  last_time: 0.1768  data_time: 0.0049  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 14:05:49] d2.utils.events INFO:  eta: 0:29:45  iter: 44419  total_loss: 2.53  loss_ce: 0.2743  loss_giou: 0.2989  loss_bbox: 0.2401  loss_ce_0: 0.3434  loss_giou_0: 0.3052  loss_bbox_0: 0.2844  loss_rpn_cls: 0.1896  loss_rpn_reg: 0.4305  time: 0.1890  last_time: 0.1803  data_time: 0.0050  last_data_time: 0.0050   lr: 5e-06  max_mem: 3029M
[03/05 14:05:53] d2.utils.events INFO:  eta: 0:29:39  iter: 44439  total_loss: 2.095  loss_ce: 0.2453  loss_giou: 0.2661  loss_bbox: 0.2091  loss_ce_0: 0.2697  loss_giou_0: 0.2852  loss_bbox_0: 0.2538  loss_rpn_cls: 0.1585  loss_rpn_reg: 0.4044  time: 0.1890  last_time: 0.2177  data_time: 0.0051  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 14:05:57] d2.utils.events INFO:  eta: 0:29:33  iter: 44459  total_loss: 2.158  loss_ce: 0.2514  loss_giou: 0.269  loss_bbox: 0.2137  loss_ce_0: 0.3213  loss_giou_0: 0.2953  loss_bbox_0: 0.2338  loss_rpn_cls: 0.1712  loss_rpn_reg: 0.4252  time: 0.1890  last_time: 0.1852  data_time: 0.0053  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:06:01] d2.utils.events INFO:  eta: 0:29:30  iter: 44479  total_loss: 2.355  loss_ce: 0.2569  loss_giou: 0.2948  loss_bbox: 0.2546  loss_ce_0: 0.3079  loss_giou_0: 0.3106  loss_bbox_0: 0.2643  loss_rpn_cls: 0.1789  loss_rpn_reg: 0.4159  time: 0.1890  last_time: 0.1987  data_time: 0.0048  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 14:06:05] d2.utils.events INFO:  eta: 0:29:28  iter: 44499  total_loss: 2.041  loss_ce: 0.2721  loss_giou: 0.251  loss_bbox: 0.1923  loss_ce_0: 0.328  loss_giou_0: 0.2578  loss_bbox_0: 0.2069  loss_rpn_cls: 0.1765  loss_rpn_reg: 0.3821  time: 0.1890  last_time: 0.1949  data_time: 0.0053  last_data_time: 0.0094   lr: 5e-06  max_mem: 3029M
[03/05 14:06:08] d2.utils.events INFO:  eta: 0:29:24  iter: 44519  total_loss: 2.323  loss_ce: 0.2698  loss_giou: 0.3199  loss_bbox: 0.2133  loss_ce_0: 0.2892  loss_giou_0: 0.3314  loss_bbox_0: 0.2353  loss_rpn_cls: 0.2083  loss_rpn_reg: 0.4529  time: 0.1890  last_time: 0.1980  data_time: 0.0053  last_data_time: 0.0053   lr: 5e-06  max_mem: 3029M
[03/05 14:06:12] d2.utils.events INFO:  eta: 0:29:21  iter: 44539  total_loss: 2.585  loss_ce: 0.3583  loss_giou: 0.3094  loss_bbox: 0.2343  loss_ce_0: 0.3917  loss_giou_0: 0.326  loss_bbox_0: 0.2675  loss_rpn_cls: 0.2274  loss_rpn_reg: 0.4437  time: 0.1890  last_time: 0.1882  data_time: 0.0051  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 14:06:16] d2.utils.events INFO:  eta: 0:29:18  iter: 44559  total_loss: 2.226  loss_ce: 0.2511  loss_giou: 0.2768  loss_bbox: 0.2208  loss_ce_0: 0.3191  loss_giou_0: 0.2901  loss_bbox_0: 0.219  loss_rpn_cls: 0.1584  loss_rpn_reg: 0.4461  time: 0.1890  last_time: 0.2021  data_time: 0.0050  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 14:06:20] d2.utils.events INFO:  eta: 0:29:14  iter: 44579  total_loss: 2.348  loss_ce: 0.2806  loss_giou: 0.2476  loss_bbox: 0.1897  loss_ce_0: 0.3485  loss_giou_0: 0.2406  loss_bbox_0: 0.2211  loss_rpn_cls: 0.1582  loss_rpn_reg: 0.3736  time: 0.1890  last_time: 0.1886  data_time: 0.0051  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:06:24] d2.utils.events INFO:  eta: 0:29:13  iter: 44599  total_loss: 2.251  loss_ce: 0.3041  loss_giou: 0.2666  loss_bbox: 0.2247  loss_ce_0: 0.3388  loss_giou_0: 0.2941  loss_bbox_0: 0.259  loss_rpn_cls: 0.1833  loss_rpn_reg: 0.4493  time: 0.1890  last_time: 0.1620  data_time: 0.0056  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:06:28] d2.utils.events INFO:  eta: 0:29:10  iter: 44619  total_loss: 2.384  loss_ce: 0.2811  loss_giou: 0.2802  loss_bbox: 0.2526  loss_ce_0: 0.3221  loss_giou_0: 0.2698  loss_bbox_0: 0.2848  loss_rpn_cls: 0.1971  loss_rpn_reg: 0.4552  time: 0.1890  last_time: 0.1773  data_time: 0.0045  last_data_time: 0.0061   lr: 5e-06  max_mem: 3029M
[03/05 14:06:32] d2.utils.events INFO:  eta: 0:29:06  iter: 44639  total_loss: 2.158  loss_ce: 0.2788  loss_giou: 0.2595  loss_bbox: 0.1895  loss_ce_0: 0.3093  loss_giou_0: 0.2773  loss_bbox_0: 0.2138  loss_rpn_cls: 0.1869  loss_rpn_reg: 0.3986  time: 0.1890  last_time: 0.1835  data_time: 0.0053  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 14:06:35] d2.utils.events INFO:  eta: 0:29:03  iter: 44659  total_loss: 2.599  loss_ce: 0.3414  loss_giou: 0.3027  loss_bbox: 0.253  loss_ce_0: 0.3921  loss_giou_0: 0.3113  loss_bbox_0: 0.261  loss_rpn_cls: 0.208  loss_rpn_reg: 0.4213  time: 0.1890  last_time: 0.1901  data_time: 0.0054  last_data_time: 0.0057   lr: 5e-06  max_mem: 3029M
[03/05 14:06:39] d2.utils.events INFO:  eta: 0:28:59  iter: 44679  total_loss: 2.14  loss_ce: 0.2241  loss_giou: 0.2809  loss_bbox: 0.207  loss_ce_0: 0.2938  loss_giou_0: 0.291  loss_bbox_0: 0.2244  loss_rpn_cls: 0.1747  loss_rpn_reg: 0.4142  time: 0.1890  last_time: 0.1897  data_time: 0.0050  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 14:06:43] d2.utils.events INFO:  eta: 0:28:56  iter: 44699  total_loss: 2.136  loss_ce: 0.2714  loss_giou: 0.2458  loss_bbox: 0.2206  loss_ce_0: 0.299  loss_giou_0: 0.2916  loss_bbox_0: 0.2736  loss_rpn_cls: 0.1507  loss_rpn_reg: 0.4154  time: 0.1890  last_time: 0.2085  data_time: 0.0053  last_data_time: 0.0073   lr: 5e-06  max_mem: 3029M
[03/05 14:06:47] d2.utils.events INFO:  eta: 0:28:52  iter: 44719  total_loss: 2.075  loss_ce: 0.2363  loss_giou: 0.296  loss_bbox: 0.1964  loss_ce_0: 0.258  loss_giou_0: 0.318  loss_bbox_0: 0.2442  loss_rpn_cls: 0.1685  loss_rpn_reg: 0.4104  time: 0.1890  last_time: 0.1572  data_time: 0.0051  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:06:50] d2.utils.events INFO:  eta: 0:28:49  iter: 44739  total_loss: 2.232  loss_ce: 0.2768  loss_giou: 0.256  loss_bbox: 0.215  loss_ce_0: 0.3466  loss_giou_0: 0.2739  loss_bbox_0: 0.2549  loss_rpn_cls: 0.1679  loss_rpn_reg: 0.3752  time: 0.1890  last_time: 0.1897  data_time: 0.0047  last_data_time: 0.0007   lr: 5e-06  max_mem: 3029M
[03/05 14:06:54] d2.utils.events INFO:  eta: 0:28:45  iter: 44759  total_loss: 2.29  loss_ce: 0.292  loss_giou: 0.3279  loss_bbox: 0.2068  loss_ce_0: 0.362  loss_giou_0: 0.3407  loss_bbox_0: 0.2308  loss_rpn_cls: 0.2033  loss_rpn_reg: 0.4708  time: 0.1890  last_time: 0.1794  data_time: 0.0054  last_data_time: 0.0034   lr: 5e-06  max_mem: 3029M
[03/05 14:06:58] d2.utils.events INFO:  eta: 0:28:43  iter: 44779  total_loss: 2.109  loss_ce: 0.3035  loss_giou: 0.2777  loss_bbox: 0.2254  loss_ce_0: 0.3003  loss_giou_0: 0.3011  loss_bbox_0: 0.2351  loss_rpn_cls: 0.1685  loss_rpn_reg: 0.4153  time: 0.1890  last_time: 0.1602  data_time: 0.0054  last_data_time: 0.0050   lr: 5e-06  max_mem: 3029M
[03/05 14:07:02] d2.utils.events INFO:  eta: 0:28:39  iter: 44799  total_loss: 2.185  loss_ce: 0.2799  loss_giou: 0.2831  loss_bbox: 0.2157  loss_ce_0: 0.316  loss_giou_0: 0.3031  loss_bbox_0: 0.2191  loss_rpn_cls: 0.202  loss_rpn_reg: 0.3973  time: 0.1890  last_time: 0.1909  data_time: 0.0049  last_data_time: 0.0053   lr: 5e-06  max_mem: 3029M
[03/05 14:07:06] d2.utils.events INFO:  eta: 0:28:35  iter: 44819  total_loss: 2.165  loss_ce: 0.2573  loss_giou: 0.2748  loss_bbox: 0.1884  loss_ce_0: 0.3152  loss_giou_0: 0.288  loss_bbox_0: 0.2218  loss_rpn_cls: 0.1658  loss_rpn_reg: 0.4198  time: 0.1890  last_time: 0.1930  data_time: 0.0054  last_data_time: 0.0056   lr: 5e-06  max_mem: 3029M
[03/05 14:07:10] d2.utils.events INFO:  eta: 0:28:32  iter: 44839  total_loss: 2.23  loss_ce: 0.2585  loss_giou: 0.3169  loss_bbox: 0.2493  loss_ce_0: 0.2998  loss_giou_0: 0.298  loss_bbox_0: 0.2608  loss_rpn_cls: 0.1824  loss_rpn_reg: 0.4257  time: 0.1890  last_time: 0.1853  data_time: 0.0053  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 14:07:13] d2.utils.events INFO:  eta: 0:28:28  iter: 44859  total_loss: 2.226  loss_ce: 0.2648  loss_giou: 0.2899  loss_bbox: 0.2198  loss_ce_0: 0.3102  loss_giou_0: 0.2956  loss_bbox_0: 0.2428  loss_rpn_cls: 0.1843  loss_rpn_reg: 0.4044  time: 0.1890  last_time: 0.1763  data_time: 0.0051  last_data_time: 0.0026   lr: 5e-06  max_mem: 3029M
[03/05 14:07:17] d2.utils.events INFO:  eta: 0:28:24  iter: 44879  total_loss: 2.066  loss_ce: 0.2138  loss_giou: 0.2884  loss_bbox: 0.2227  loss_ce_0: 0.2263  loss_giou_0: 0.2892  loss_bbox_0: 0.2349  loss_rpn_cls: 0.1763  loss_rpn_reg: 0.38  time: 0.1890  last_time: 0.1852  data_time: 0.0054  last_data_time: 0.0045   lr: 5e-06  max_mem: 3029M
[03/05 14:07:21] d2.utils.events INFO:  eta: 0:28:20  iter: 44899  total_loss: 2.507  loss_ce: 0.3204  loss_giou: 0.3285  loss_bbox: 0.2355  loss_ce_0: 0.3885  loss_giou_0: 0.3507  loss_bbox_0: 0.2604  loss_rpn_cls: 0.21  loss_rpn_reg: 0.4542  time: 0.1890  last_time: 0.1893  data_time: 0.0052  last_data_time: 0.0045   lr: 5e-06  max_mem: 3029M
[03/05 14:07:24] d2.utils.events INFO:  eta: 0:28:16  iter: 44919  total_loss: 2.251  loss_ce: 0.2747  loss_giou: 0.2904  loss_bbox: 0.2333  loss_ce_0: 0.2966  loss_giou_0: 0.3105  loss_bbox_0: 0.2405  loss_rpn_cls: 0.1855  loss_rpn_reg: 0.4203  time: 0.1890  last_time: 0.1815  data_time: 0.0051  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 14:07:28] d2.utils.events INFO:  eta: 0:28:11  iter: 44939  total_loss: 2.292  loss_ce: 0.3147  loss_giou: 0.301  loss_bbox: 0.2536  loss_ce_0: 0.3413  loss_giou_0: 0.2844  loss_bbox_0: 0.2596  loss_rpn_cls: 0.186  loss_rpn_reg: 0.3889  time: 0.1890  last_time: 0.1785  data_time: 0.0051  last_data_time: 0.0056   lr: 5e-06  max_mem: 3029M
[03/05 14:07:32] d2.utils.events INFO:  eta: 0:28:07  iter: 44959  total_loss: 2.267  loss_ce: 0.2827  loss_giou: 0.3191  loss_bbox: 0.2211  loss_ce_0: 0.3194  loss_giou_0: 0.3252  loss_bbox_0: 0.2412  loss_rpn_cls: 0.215  loss_rpn_reg: 0.4244  time: 0.1890  last_time: 0.1642  data_time: 0.0047  last_data_time: 0.0026   lr: 5e-06  max_mem: 3029M
[03/05 14:07:36] d2.utils.events INFO:  eta: 0:28:03  iter: 44979  total_loss: 2.128  loss_ce: 0.2268  loss_giou: 0.2998  loss_bbox: 0.2031  loss_ce_0: 0.2785  loss_giou_0: 0.3163  loss_bbox_0: 0.2185  loss_rpn_cls: 0.1728  loss_rpn_reg: 0.429  time: 0.1890  last_time: 0.1958  data_time: 0.0047  last_data_time: 0.0069   lr: 5e-06  max_mem: 3029M
[03/05 14:07:40] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/t1/model_0044999.pth
[03/05 14:07:41] d2.utils.events INFO:  eta: 0:27:59  iter: 44999  total_loss: 2.202  loss_ce: 0.2719  loss_giou: 0.2462  loss_bbox: 0.1978  loss_ce_0: 0.3155  loss_giou_0: 0.2706  loss_bbox_0: 0.2101  loss_rpn_cls: 0.1729  loss_rpn_reg: 0.4272  time: 0.1890  last_time: 0.2067  data_time: 0.0051  last_data_time: 0.0082   lr: 5e-06  max_mem: 3029M
[03/05 14:07:45] d2.utils.events INFO:  eta: 0:27:58  iter: 45019  total_loss: 2.06  loss_ce: 0.2208  loss_giou: 0.2161  loss_bbox: 0.2184  loss_ce_0: 0.2843  loss_giou_0: 0.2265  loss_bbox_0: 0.271  loss_rpn_cls: 0.151  loss_rpn_reg: 0.3629  time: 0.1890  last_time: 0.2100  data_time: 0.0056  last_data_time: 0.0092   lr: 5e-06  max_mem: 3029M
[03/05 14:07:49] d2.utils.events INFO:  eta: 0:27:57  iter: 45039  total_loss: 2.395  loss_ce: 0.3141  loss_giou: 0.3323  loss_bbox: 0.2383  loss_ce_0: 0.3127  loss_giou_0: 0.3615  loss_bbox_0: 0.2724  loss_rpn_cls: 0.1834  loss_rpn_reg: 0.4504  time: 0.1890  last_time: 0.1871  data_time: 0.0047  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 14:07:52] d2.utils.events INFO:  eta: 0:27:53  iter: 45059  total_loss: 2.078  loss_ce: 0.205  loss_giou: 0.2463  loss_bbox: 0.223  loss_ce_0: 0.2714  loss_giou_0: 0.269  loss_bbox_0: 0.2512  loss_rpn_cls: 0.1728  loss_rpn_reg: 0.3938  time: 0.1890  last_time: 0.1939  data_time: 0.0062  last_data_time: 0.0032   lr: 5e-06  max_mem: 3029M
[03/05 14:07:56] d2.utils.events INFO:  eta: 0:27:49  iter: 45079  total_loss: 2.189  loss_ce: 0.2675  loss_giou: 0.2498  loss_bbox: 0.2089  loss_ce_0: 0.3023  loss_giou_0: 0.2732  loss_bbox_0: 0.2184  loss_rpn_cls: 0.2083  loss_rpn_reg: 0.402  time: 0.1890  last_time: 0.2058  data_time: 0.0051  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 14:08:00] d2.utils.events INFO:  eta: 0:27:46  iter: 45099  total_loss: 2.292  loss_ce: 0.2383  loss_giou: 0.2684  loss_bbox: 0.2528  loss_ce_0: 0.271  loss_giou_0: 0.2755  loss_bbox_0: 0.279  loss_rpn_cls: 0.1817  loss_rpn_reg: 0.3892  time: 0.1890  last_time: 0.1785  data_time: 0.0049  last_data_time: 0.0046   lr: 5e-06  max_mem: 3029M
[03/05 14:08:04] d2.utils.events INFO:  eta: 0:27:43  iter: 45119  total_loss: 2.504  loss_ce: 0.3115  loss_giou: 0.321  loss_bbox: 0.2478  loss_ce_0: 0.3266  loss_giou_0: 0.3027  loss_bbox_0: 0.3112  loss_rpn_cls: 0.1746  loss_rpn_reg: 0.4377  time: 0.1890  last_time: 0.1639  data_time: 0.0053  last_data_time: 0.0066   lr: 5e-06  max_mem: 3029M
[03/05 14:08:08] d2.utils.events INFO:  eta: 0:27:38  iter: 45139  total_loss: 2.293  loss_ce: 0.2821  loss_giou: 0.2707  loss_bbox: 0.2492  loss_ce_0: 0.2804  loss_giou_0: 0.31  loss_bbox_0: 0.2647  loss_rpn_cls: 0.1811  loss_rpn_reg: 0.405  time: 0.1890  last_time: 0.1589  data_time: 0.0050  last_data_time: 0.0050   lr: 5e-06  max_mem: 3029M
[03/05 14:08:12] d2.utils.events INFO:  eta: 0:27:36  iter: 45159  total_loss: 2.258  loss_ce: 0.2757  loss_giou: 0.2355  loss_bbox: 0.2159  loss_ce_0: 0.3375  loss_giou_0: 0.2407  loss_bbox_0: 0.2609  loss_rpn_cls: 0.1892  loss_rpn_reg: 0.4139  time: 0.1890  last_time: 0.1850  data_time: 0.0060  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 14:08:15] d2.utils.events INFO:  eta: 0:27:35  iter: 45179  total_loss: 2.223  loss_ce: 0.2817  loss_giou: 0.2678  loss_bbox: 0.248  loss_ce_0: 0.3536  loss_giou_0: 0.2984  loss_bbox_0: 0.2581  loss_rpn_cls: 0.1771  loss_rpn_reg: 0.4007  time: 0.1890  last_time: 0.1978  data_time: 0.0059  last_data_time: 0.0066   lr: 5e-06  max_mem: 3029M
[03/05 14:08:19] d2.utils.events INFO:  eta: 0:27:31  iter: 45199  total_loss: 2.204  loss_ce: 0.3151  loss_giou: 0.2605  loss_bbox: 0.2046  loss_ce_0: 0.3727  loss_giou_0: 0.2682  loss_bbox_0: 0.2257  loss_rpn_cls: 0.186  loss_rpn_reg: 0.4212  time: 0.1890  last_time: 0.2069  data_time: 0.0054  last_data_time: 0.0089   lr: 5e-06  max_mem: 3029M
[03/05 14:08:23] d2.utils.events INFO:  eta: 0:27:27  iter: 45219  total_loss: 2.209  loss_ce: 0.2615  loss_giou: 0.2772  loss_bbox: 0.2135  loss_ce_0: 0.2975  loss_giou_0: 0.2975  loss_bbox_0: 0.2412  loss_rpn_cls: 0.1773  loss_rpn_reg: 0.4081  time: 0.1890  last_time: 0.1987  data_time: 0.0051  last_data_time: 0.0059   lr: 5e-06  max_mem: 3029M
[03/05 14:08:27] d2.utils.events INFO:  eta: 0:27:24  iter: 45239  total_loss: 2.286  loss_ce: 0.1911  loss_giou: 0.3302  loss_bbox: 0.1994  loss_ce_0: 0.2384  loss_giou_0: 0.3324  loss_bbox_0: 0.2117  loss_rpn_cls: 0.1757  loss_rpn_reg: 0.4347  time: 0.1890  last_time: 0.1789  data_time: 0.0051  last_data_time: 0.0031   lr: 5e-06  max_mem: 3029M
[03/05 14:08:31] d2.utils.events INFO:  eta: 0:27:21  iter: 45259  total_loss: 2.237  loss_ce: 0.2979  loss_giou: 0.2386  loss_bbox: 0.2099  loss_ce_0: 0.3568  loss_giou_0: 0.27  loss_bbox_0: 0.2552  loss_rpn_cls: 0.205  loss_rpn_reg: 0.3995  time: 0.1890  last_time: 0.1686  data_time: 0.0056  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 14:08:35] d2.utils.events INFO:  eta: 0:27:19  iter: 45279  total_loss: 2.291  loss_ce: 0.3356  loss_giou: 0.2639  loss_bbox: 0.213  loss_ce_0: 0.3582  loss_giou_0: 0.3055  loss_bbox_0: 0.2437  loss_rpn_cls: 0.1621  loss_rpn_reg: 0.4253  time: 0.1890  last_time: 0.2023  data_time: 0.0055  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 14:08:39] d2.utils.events INFO:  eta: 0:27:15  iter: 45299  total_loss: 2.405  loss_ce: 0.271  loss_giou: 0.2675  loss_bbox: 0.2259  loss_ce_0: 0.3093  loss_giou_0: 0.2902  loss_bbox_0: 0.2742  loss_rpn_cls: 0.1816  loss_rpn_reg: 0.4416  time: 0.1890  last_time: 0.1925  data_time: 0.0055  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:08:43] d2.utils.events INFO:  eta: 0:27:12  iter: 45319  total_loss: 2.458  loss_ce: 0.2999  loss_giou: 0.2739  loss_bbox: 0.2123  loss_ce_0: 0.347  loss_giou_0: 0.2611  loss_bbox_0: 0.2169  loss_rpn_cls: 0.197  loss_rpn_reg: 0.4029  time: 0.1890  last_time: 0.1993  data_time: 0.0060  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 14:08:47] d2.utils.events INFO:  eta: 0:27:10  iter: 45339  total_loss: 2.4  loss_ce: 0.2833  loss_giou: 0.2917  loss_bbox: 0.2456  loss_ce_0: 0.3403  loss_giou_0: 0.3156  loss_bbox_0: 0.2585  loss_rpn_cls: 0.2035  loss_rpn_reg: 0.4629  time: 0.1890  last_time: 0.1986  data_time: 0.0056  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 14:08:51] d2.utils.events INFO:  eta: 0:27:07  iter: 45359  total_loss: 2.291  loss_ce: 0.2908  loss_giou: 0.2418  loss_bbox: 0.2022  loss_ce_0: 0.3197  loss_giou_0: 0.2826  loss_bbox_0: 0.2261  loss_rpn_cls: 0.1955  loss_rpn_reg: 0.3942  time: 0.1890  last_time: 0.1988  data_time: 0.0056  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 14:08:55] d2.utils.events INFO:  eta: 0:27:05  iter: 45379  total_loss: 1.953  loss_ce: 0.2303  loss_giou: 0.2583  loss_bbox: 0.2005  loss_ce_0: 0.2661  loss_giou_0: 0.2331  loss_bbox_0: 0.2346  loss_rpn_cls: 0.1823  loss_rpn_reg: 0.4112  time: 0.1890  last_time: 0.1949  data_time: 0.0056  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:08:58] d2.utils.events INFO:  eta: 0:27:01  iter: 45399  total_loss: 2.416  loss_ce: 0.31  loss_giou: 0.2396  loss_bbox: 0.2508  loss_ce_0: 0.3436  loss_giou_0: 0.2657  loss_bbox_0: 0.2665  loss_rpn_cls: 0.1891  loss_rpn_reg: 0.3937  time: 0.1890  last_time: 0.1793  data_time: 0.0051  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 14:09:02] d2.utils.events INFO:  eta: 0:26:58  iter: 45419  total_loss: 2.339  loss_ce: 0.2478  loss_giou: 0.2678  loss_bbox: 0.2345  loss_ce_0: 0.2824  loss_giou_0: 0.299  loss_bbox_0: 0.2612  loss_rpn_cls: 0.1643  loss_rpn_reg: 0.4215  time: 0.1890  last_time: 0.1900  data_time: 0.0060  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:09:06] d2.utils.events INFO:  eta: 0:26:55  iter: 45439  total_loss: 2.447  loss_ce: 0.2887  loss_giou: 0.3121  loss_bbox: 0.24  loss_ce_0: 0.3408  loss_giou_0: 0.2971  loss_bbox_0: 0.2741  loss_rpn_cls: 0.1825  loss_rpn_reg: 0.4451  time: 0.1890  last_time: 0.2128  data_time: 0.0059  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 14:09:10] d2.utils.events INFO:  eta: 0:26:50  iter: 45459  total_loss: 2.248  loss_ce: 0.3035  loss_giou: 0.3012  loss_bbox: 0.2181  loss_ce_0: 0.3398  loss_giou_0: 0.3148  loss_bbox_0: 0.2296  loss_rpn_cls: 0.1822  loss_rpn_reg: 0.4346  time: 0.1890  last_time: 0.1831  data_time: 0.0046  last_data_time: 0.0068   lr: 5e-06  max_mem: 3029M
[03/05 14:09:14] d2.utils.events INFO:  eta: 0:26:47  iter: 45479  total_loss: 2.405  loss_ce: 0.3359  loss_giou: 0.2525  loss_bbox: 0.2617  loss_ce_0: 0.3989  loss_giou_0: 0.2591  loss_bbox_0: 0.2389  loss_rpn_cls: 0.2045  loss_rpn_reg: 0.4006  time: 0.1890  last_time: 0.2165  data_time: 0.0049  last_data_time: 0.0055   lr: 5e-06  max_mem: 3029M
[03/05 14:09:18] d2.utils.events INFO:  eta: 0:26:45  iter: 45499  total_loss: 2.588  loss_ce: 0.3134  loss_giou: 0.343  loss_bbox: 0.2126  loss_ce_0: 0.3428  loss_giou_0: 0.3595  loss_bbox_0: 0.247  loss_rpn_cls: 0.2091  loss_rpn_reg: 0.4572  time: 0.1890  last_time: 0.1946  data_time: 0.0058  last_data_time: 0.0057   lr: 5e-06  max_mem: 3029M
[03/05 14:09:21] d2.utils.events INFO:  eta: 0:26:40  iter: 45519  total_loss: 2.25  loss_ce: 0.2953  loss_giou: 0.2783  loss_bbox: 0.157  loss_ce_0: 0.3025  loss_giou_0: 0.2883  loss_bbox_0: 0.2213  loss_rpn_cls: 0.1702  loss_rpn_reg: 0.4052  time: 0.1890  last_time: 0.1881  data_time: 0.0051  last_data_time: 0.0051   lr: 5e-06  max_mem: 3029M
[03/05 14:09:25] d2.utils.events INFO:  eta: 0:26:35  iter: 45539  total_loss: 2.167  loss_ce: 0.2656  loss_giou: 0.2707  loss_bbox: 0.2127  loss_ce_0: 0.3145  loss_giou_0: 0.2808  loss_bbox_0: 0.2247  loss_rpn_cls: 0.1662  loss_rpn_reg: 0.4043  time: 0.1890  last_time: 0.2055  data_time: 0.0050  last_data_time: 0.0056   lr: 5e-06  max_mem: 3029M
[03/05 14:09:29] d2.utils.events INFO:  eta: 0:26:30  iter: 45559  total_loss: 2.14  loss_ce: 0.2547  loss_giou: 0.2482  loss_bbox: 0.2155  loss_ce_0: 0.2909  loss_giou_0: 0.2591  loss_bbox_0: 0.2352  loss_rpn_cls: 0.1693  loss_rpn_reg: 0.3784  time: 0.1890  last_time: 0.1887  data_time: 0.0054  last_data_time: 0.0105   lr: 5e-06  max_mem: 3029M
[03/05 14:09:33] d2.utils.events INFO:  eta: 0:26:27  iter: 45579  total_loss: 2.24  loss_ce: 0.3055  loss_giou: 0.3113  loss_bbox: 0.2446  loss_ce_0: 0.3454  loss_giou_0: 0.3207  loss_bbox_0: 0.2656  loss_rpn_cls: 0.1811  loss_rpn_reg: 0.4405  time: 0.1890  last_time: 0.1712  data_time: 0.0053  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:09:37] d2.utils.events INFO:  eta: 0:26:25  iter: 45599  total_loss: 2.339  loss_ce: 0.3102  loss_giou: 0.2385  loss_bbox: 0.2316  loss_ce_0: 0.3699  loss_giou_0: 0.2571  loss_bbox_0: 0.2437  loss_rpn_cls: 0.179  loss_rpn_reg: 0.396  time: 0.1890  last_time: 0.1848  data_time: 0.0053  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 14:09:41] d2.utils.events INFO:  eta: 0:26:20  iter: 45619  total_loss: 2.117  loss_ce: 0.2764  loss_giou: 0.2131  loss_bbox: 0.1751  loss_ce_0: 0.312  loss_giou_0: 0.2331  loss_bbox_0: 0.2012  loss_rpn_cls: 0.1665  loss_rpn_reg: 0.3999  time: 0.1890  last_time: 0.2212  data_time: 0.0051  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 14:09:44] d2.utils.events INFO:  eta: 0:26:17  iter: 45639  total_loss: 2.266  loss_ce: 0.2494  loss_giou: 0.2504  loss_bbox: 0.2076  loss_ce_0: 0.3112  loss_giou_0: 0.2601  loss_bbox_0: 0.2374  loss_rpn_cls: 0.1532  loss_rpn_reg: 0.4274  time: 0.1890  last_time: 0.1958  data_time: 0.0058  last_data_time: 0.0047   lr: 5e-06  max_mem: 3029M
[03/05 14:09:48] d2.utils.events INFO:  eta: 0:26:12  iter: 45659  total_loss: 2.315  loss_ce: 0.2672  loss_giou: 0.3064  loss_bbox: 0.2275  loss_ce_0: 0.3066  loss_giou_0: 0.3164  loss_bbox_0: 0.2373  loss_rpn_cls: 0.1724  loss_rpn_reg: 0.4155  time: 0.1890  last_time: 0.1784  data_time: 0.0054  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 14:09:52] d2.utils.events INFO:  eta: 0:26:10  iter: 45679  total_loss: 2.467  loss_ce: 0.2958  loss_giou: 0.3025  loss_bbox: 0.2088  loss_ce_0: 0.3483  loss_giou_0: 0.3301  loss_bbox_0: 0.2419  loss_rpn_cls: 0.2084  loss_rpn_reg: 0.4552  time: 0.1890  last_time: 0.2080  data_time: 0.0054  last_data_time: 0.0046   lr: 5e-06  max_mem: 3029M
[03/05 14:09:56] d2.utils.events INFO:  eta: 0:26:06  iter: 45699  total_loss: 2.194  loss_ce: 0.2132  loss_giou: 0.2834  loss_bbox: 0.1993  loss_ce_0: 0.2599  loss_giou_0: 0.29  loss_bbox_0: 0.2189  loss_rpn_cls: 0.1599  loss_rpn_reg: 0.4199  time: 0.1890  last_time: 0.1884  data_time: 0.0058  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 14:10:00] d2.utils.events INFO:  eta: 0:26:02  iter: 45719  total_loss: 1.991  loss_ce: 0.2327  loss_giou: 0.2799  loss_bbox: 0.1902  loss_ce_0: 0.2724  loss_giou_0: 0.3099  loss_bbox_0: 0.212  loss_rpn_cls: 0.1756  loss_rpn_reg: 0.4023  time: 0.1890  last_time: 0.1990  data_time: 0.0052  last_data_time: 0.0070   lr: 5e-06  max_mem: 3029M
[03/05 14:10:04] d2.utils.events INFO:  eta: 0:25:58  iter: 45739  total_loss: 2.499  loss_ce: 0.29  loss_giou: 0.3229  loss_bbox: 0.217  loss_ce_0: 0.3402  loss_giou_0: 0.3502  loss_bbox_0: 0.2364  loss_rpn_cls: 0.1757  loss_rpn_reg: 0.4433  time: 0.1890  last_time: 0.2246  data_time: 0.0045  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 14:10:08] d2.utils.events INFO:  eta: 0:25:55  iter: 45759  total_loss: 2.126  loss_ce: 0.2495  loss_giou: 0.262  loss_bbox: 0.2144  loss_ce_0: 0.2807  loss_giou_0: 0.2799  loss_bbox_0: 0.247  loss_rpn_cls: 0.1738  loss_rpn_reg: 0.4046  time: 0.1890  last_time: 0.1874  data_time: 0.0051  last_data_time: 0.0061   lr: 5e-06  max_mem: 3029M
[03/05 14:10:11] d2.utils.events INFO:  eta: 0:25:51  iter: 45779  total_loss: 2.407  loss_ce: 0.2375  loss_giou: 0.3314  loss_bbox: 0.2104  loss_ce_0: 0.3178  loss_giou_0: 0.3534  loss_bbox_0: 0.2401  loss_rpn_cls: 0.1847  loss_rpn_reg: 0.4184  time: 0.1890  last_time: 0.1809  data_time: 0.0049  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 14:10:15] d2.utils.events INFO:  eta: 0:25:47  iter: 45799  total_loss: 2.17  loss_ce: 0.2449  loss_giou: 0.2299  loss_bbox: 0.226  loss_ce_0: 0.2854  loss_giou_0: 0.2578  loss_bbox_0: 0.2594  loss_rpn_cls: 0.1637  loss_rpn_reg: 0.4214  time: 0.1890  last_time: 0.2051  data_time: 0.0056  last_data_time: 0.0105   lr: 5e-06  max_mem: 3029M
[03/05 14:10:19] d2.utils.events INFO:  eta: 0:25:43  iter: 45819  total_loss: 2.329  loss_ce: 0.2986  loss_giou: 0.2728  loss_bbox: 0.2155  loss_ce_0: 0.368  loss_giou_0: 0.2716  loss_bbox_0: 0.2555  loss_rpn_cls: 0.1871  loss_rpn_reg: 0.4142  time: 0.1890  last_time: 0.1770  data_time: 0.0050  last_data_time: 0.0008   lr: 5e-06  max_mem: 3029M
[03/05 14:10:23] d2.utils.events INFO:  eta: 0:25:39  iter: 45839  total_loss: 2.415  loss_ce: 0.3081  loss_giou: 0.3108  loss_bbox: 0.2216  loss_ce_0: 0.3317  loss_giou_0: 0.3316  loss_bbox_0: 0.2551  loss_rpn_cls: 0.1756  loss_rpn_reg: 0.4279  time: 0.1890  last_time: 0.1799  data_time: 0.0054  last_data_time: 0.0058   lr: 5e-06  max_mem: 3029M
[03/05 14:10:27] d2.utils.events INFO:  eta: 0:25:39  iter: 45859  total_loss: 2.364  loss_ce: 0.3166  loss_giou: 0.2441  loss_bbox: 0.1953  loss_ce_0: 0.338  loss_giou_0: 0.3013  loss_bbox_0: 0.2346  loss_rpn_cls: 0.1858  loss_rpn_reg: 0.434  time: 0.1890  last_time: 0.1871  data_time: 0.0051  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 14:10:31] d2.utils.events INFO:  eta: 0:25:37  iter: 45879  total_loss: 2.435  loss_ce: 0.2623  loss_giou: 0.2885  loss_bbox: 0.2542  loss_ce_0: 0.3364  loss_giou_0: 0.319  loss_bbox_0: 0.2831  loss_rpn_cls: 0.1802  loss_rpn_reg: 0.4138  time: 0.1890  last_time: 0.2132  data_time: 0.0052  last_data_time: 0.0029   lr: 5e-06  max_mem: 3029M
[03/05 14:10:35] d2.utils.events INFO:  eta: 0:25:35  iter: 45899  total_loss: 2.015  loss_ce: 0.2349  loss_giou: 0.2688  loss_bbox: 0.181  loss_ce_0: 0.2641  loss_giou_0: 0.282  loss_bbox_0: 0.2046  loss_rpn_cls: 0.1729  loss_rpn_reg: 0.4065  time: 0.1890  last_time: 0.1914  data_time: 0.0057  last_data_time: 0.0048   lr: 5e-06  max_mem: 3029M
[03/05 14:10:39] d2.utils.events INFO:  eta: 0:25:32  iter: 45919  total_loss: 2.254  loss_ce: 0.3099  loss_giou: 0.3268  loss_bbox: 0.1905  loss_ce_0: 0.3052  loss_giou_0: 0.3492  loss_bbox_0: 0.2274  loss_rpn_cls: 0.1905  loss_rpn_reg: 0.4604  time: 0.1891  last_time: 0.2251  data_time: 0.0068  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 14:10:43] d2.utils.events INFO:  eta: 0:25:28  iter: 45939  total_loss: 1.998  loss_ce: 0.181  loss_giou: 0.2397  loss_bbox: 0.2036  loss_ce_0: 0.2892  loss_giou_0: 0.2487  loss_bbox_0: 0.2226  loss_rpn_cls: 0.1718  loss_rpn_reg: 0.3832  time: 0.1890  last_time: 0.1706  data_time: 0.0053  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 14:10:46] d2.utils.events INFO:  eta: 0:25:25  iter: 45959  total_loss: 1.956  loss_ce: 0.232  loss_giou: 0.224  loss_bbox: 0.1756  loss_ce_0: 0.3272  loss_giou_0: 0.2435  loss_bbox_0: 0.2112  loss_rpn_cls: 0.1666  loss_rpn_reg: 0.4139  time: 0.1890  last_time: 0.2062  data_time: 0.0049  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 14:10:50] d2.utils.events INFO:  eta: 0:25:20  iter: 45979  total_loss: 2.374  loss_ce: 0.2738  loss_giou: 0.3187  loss_bbox: 0.2327  loss_ce_0: 0.309  loss_giou_0: 0.3424  loss_bbox_0: 0.256  loss_rpn_cls: 0.1791  loss_rpn_reg: 0.4092  time: 0.1890  last_time: 0.1830  data_time: 0.0048  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 14:10:54] d2.utils.events INFO:  eta: 0:25:16  iter: 45999  total_loss: 2.275  loss_ce: 0.2751  loss_giou: 0.28  loss_bbox: 0.2443  loss_ce_0: 0.3016  loss_giou_0: 0.3053  loss_bbox_0: 0.2837  loss_rpn_cls: 0.1879  loss_rpn_reg: 0.4392  time: 0.1890  last_time: 0.1830  data_time: 0.0051  last_data_time: 0.0055   lr: 5e-06  max_mem: 3029M
[03/05 14:10:58] d2.utils.events INFO:  eta: 0:25:11  iter: 46019  total_loss: 2.43  loss_ce: 0.282  loss_giou: 0.2994  loss_bbox: 0.1947  loss_ce_0: 0.3363  loss_giou_0: 0.3251  loss_bbox_0: 0.2128  loss_rpn_cls: 0.1889  loss_rpn_reg: 0.4361  time: 0.1890  last_time: 0.1901  data_time: 0.0054  last_data_time: 0.0026   lr: 5e-06  max_mem: 3029M
[03/05 14:11:02] d2.utils.events INFO:  eta: 0:25:07  iter: 46039  total_loss: 2.369  loss_ce: 0.2609  loss_giou: 0.2735  loss_bbox: 0.2352  loss_ce_0: 0.2747  loss_giou_0: 0.2418  loss_bbox_0: 0.2438  loss_rpn_cls: 0.2021  loss_rpn_reg: 0.387  time: 0.1890  last_time: 0.1858  data_time: 0.0055  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 14:11:05] d2.utils.events INFO:  eta: 0:25:02  iter: 46059  total_loss: 1.797  loss_ce: 0.1957  loss_giou: 0.2294  loss_bbox: 0.1977  loss_ce_0: 0.2615  loss_giou_0: 0.2376  loss_bbox_0: 0.2177  loss_rpn_cls: 0.165  loss_rpn_reg: 0.4227  time: 0.1890  last_time: 0.1833  data_time: 0.0046  last_data_time: 0.0034   lr: 5e-06  max_mem: 3029M
[03/05 14:11:09] d2.utils.events INFO:  eta: 0:24:58  iter: 46079  total_loss: 2.169  loss_ce: 0.2554  loss_giou: 0.2469  loss_bbox: 0.2175  loss_ce_0: 0.2963  loss_giou_0: 0.2825  loss_bbox_0: 0.2207  loss_rpn_cls: 0.1672  loss_rpn_reg: 0.4056  time: 0.1890  last_time: 0.1865  data_time: 0.0050  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 14:11:13] d2.utils.events INFO:  eta: 0:24:55  iter: 46099  total_loss: 2.395  loss_ce: 0.313  loss_giou: 0.31  loss_bbox: 0.2206  loss_ce_0: 0.3356  loss_giou_0: 0.3153  loss_bbox_0: 0.2388  loss_rpn_cls: 0.1952  loss_rpn_reg: 0.4313  time: 0.1890  last_time: 0.2073  data_time: 0.0050  last_data_time: 0.0045   lr: 5e-06  max_mem: 3029M
[03/05 14:11:17] d2.utils.events INFO:  eta: 0:24:50  iter: 46119  total_loss: 2.381  loss_ce: 0.2859  loss_giou: 0.2659  loss_bbox: 0.2541  loss_ce_0: 0.3323  loss_giou_0: 0.2857  loss_bbox_0: 0.2645  loss_rpn_cls: 0.1888  loss_rpn_reg: 0.423  time: 0.1890  last_time: 0.1670  data_time: 0.0049  last_data_time: 0.0025   lr: 5e-06  max_mem: 3029M
[03/05 14:11:21] d2.utils.events INFO:  eta: 0:24:50  iter: 46139  total_loss: 2.396  loss_ce: 0.2921  loss_giou: 0.3399  loss_bbox: 0.192  loss_ce_0: 0.3252  loss_giou_0: 0.3378  loss_bbox_0: 0.2218  loss_rpn_cls: 0.1874  loss_rpn_reg: 0.4333  time: 0.1890  last_time: 0.2369  data_time: 0.0052  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:11:25] d2.utils.events INFO:  eta: 0:24:46  iter: 46159  total_loss: 1.897  loss_ce: 0.2404  loss_giou: 0.24  loss_bbox: 0.1949  loss_ce_0: 0.2416  loss_giou_0: 0.2354  loss_bbox_0: 0.2248  loss_rpn_cls: 0.1509  loss_rpn_reg: 0.3654  time: 0.1890  last_time: 0.1867  data_time: 0.0049  last_data_time: 0.0034   lr: 5e-06  max_mem: 3029M
[03/05 14:11:28] d2.utils.events INFO:  eta: 0:24:40  iter: 46179  total_loss: 2.539  loss_ce: 0.2888  loss_giou: 0.3234  loss_bbox: 0.2326  loss_ce_0: 0.3164  loss_giou_0: 0.3402  loss_bbox_0: 0.2591  loss_rpn_cls: 0.1979  loss_rpn_reg: 0.4314  time: 0.1890  last_time: 0.1943  data_time: 0.0042  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 14:11:32] d2.utils.events INFO:  eta: 0:24:36  iter: 46199  total_loss: 2.315  loss_ce: 0.2838  loss_giou: 0.2697  loss_bbox: 0.2254  loss_ce_0: 0.3371  loss_giou_0: 0.2717  loss_bbox_0: 0.2545  loss_rpn_cls: 0.193  loss_rpn_reg: 0.4126  time: 0.1890  last_time: 0.2001  data_time: 0.0054  last_data_time: 0.0051   lr: 5e-06  max_mem: 3029M
[03/05 14:11:36] d2.utils.events INFO:  eta: 0:24:31  iter: 46219  total_loss: 2.36  loss_ce: 0.3056  loss_giou: 0.2777  loss_bbox: 0.2365  loss_ce_0: 0.3465  loss_giou_0: 0.2952  loss_bbox_0: 0.2382  loss_rpn_cls: 0.1905  loss_rpn_reg: 0.3916  time: 0.1890  last_time: 0.1911  data_time: 0.0050  last_data_time: 0.0032   lr: 5e-06  max_mem: 3029M
[03/05 14:11:40] d2.utils.events INFO:  eta: 0:24:27  iter: 46239  total_loss: 2.227  loss_ce: 0.2839  loss_giou: 0.2939  loss_bbox: 0.1803  loss_ce_0: 0.3082  loss_giou_0: 0.3154  loss_bbox_0: 0.2299  loss_rpn_cls: 0.1889  loss_rpn_reg: 0.4025  time: 0.1890  last_time: 0.1920  data_time: 0.0052  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 14:11:44] d2.utils.events INFO:  eta: 0:24:24  iter: 46259  total_loss: 2.21  loss_ce: 0.2647  loss_giou: 0.2661  loss_bbox: 0.2308  loss_ce_0: 0.2962  loss_giou_0: 0.293  loss_bbox_0: 0.2352  loss_rpn_cls: 0.1884  loss_rpn_reg: 0.4224  time: 0.1890  last_time: 0.1930  data_time: 0.0066  last_data_time: 0.0059   lr: 5e-06  max_mem: 3029M
[03/05 14:11:48] d2.utils.events INFO:  eta: 0:24:19  iter: 46279  total_loss: 2.456  loss_ce: 0.3151  loss_giou: 0.2932  loss_bbox: 0.2311  loss_ce_0: 0.3479  loss_giou_0: 0.3134  loss_bbox_0: 0.2649  loss_rpn_cls: 0.1931  loss_rpn_reg: 0.4356  time: 0.1890  last_time: 0.1799  data_time: 0.0049  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 14:11:51] d2.utils.events INFO:  eta: 0:24:14  iter: 46299  total_loss: 2.367  loss_ce: 0.3349  loss_giou: 0.2941  loss_bbox: 0.2474  loss_ce_0: 0.3261  loss_giou_0: 0.2985  loss_bbox_0: 0.286  loss_rpn_cls: 0.1903  loss_rpn_reg: 0.4321  time: 0.1890  last_time: 0.1773  data_time: 0.0047  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 14:11:55] d2.utils.events INFO:  eta: 0:24:09  iter: 46319  total_loss: 2.086  loss_ce: 0.2931  loss_giou: 0.2489  loss_bbox: 0.2316  loss_ce_0: 0.3488  loss_giou_0: 0.2482  loss_bbox_0: 0.2266  loss_rpn_cls: 0.1753  loss_rpn_reg: 0.3865  time: 0.1890  last_time: 0.2133  data_time: 0.0052  last_data_time: 0.0067   lr: 5e-06  max_mem: 3029M
[03/05 14:11:59] d2.utils.events INFO:  eta: 0:24:05  iter: 46339  total_loss: 1.883  loss_ce: 0.2015  loss_giou: 0.2245  loss_bbox: 0.1753  loss_ce_0: 0.2739  loss_giou_0: 0.2383  loss_bbox_0: 0.1999  loss_rpn_cls: 0.1646  loss_rpn_reg: 0.387  time: 0.1890  last_time: 0.1541  data_time: 0.0048  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 14:12:03] d2.utils.events INFO:  eta: 0:24:01  iter: 46359  total_loss: 2.354  loss_ce: 0.2848  loss_giou: 0.3188  loss_bbox: 0.2002  loss_ce_0: 0.3021  loss_giou_0: 0.3509  loss_bbox_0: 0.2533  loss_rpn_cls: 0.1806  loss_rpn_reg: 0.4404  time: 0.1890  last_time: 0.2056  data_time: 0.0047  last_data_time: 0.0070   lr: 5e-06  max_mem: 3029M
[03/05 14:12:07] d2.utils.events INFO:  eta: 0:23:57  iter: 46379  total_loss: 2.467  loss_ce: 0.274  loss_giou: 0.3373  loss_bbox: 0.2652  loss_ce_0: 0.3511  loss_giou_0: 0.3401  loss_bbox_0: 0.2785  loss_rpn_cls: 0.1962  loss_rpn_reg: 0.4201  time: 0.1890  last_time: 0.2011  data_time: 0.0049  last_data_time: 0.0058   lr: 5e-06  max_mem: 3029M
[03/05 14:12:10] d2.utils.events INFO:  eta: 0:23:52  iter: 46399  total_loss: 2.396  loss_ce: 0.3014  loss_giou: 0.2943  loss_bbox: 0.2713  loss_ce_0: 0.3506  loss_giou_0: 0.3045  loss_bbox_0: 0.3108  loss_rpn_cls: 0.1986  loss_rpn_reg: 0.4496  time: 0.1890  last_time: 0.1689  data_time: 0.0043  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 14:12:14] d2.utils.events INFO:  eta: 0:23:46  iter: 46419  total_loss: 2.331  loss_ce: 0.3041  loss_giou: 0.2986  loss_bbox: 0.2329  loss_ce_0: 0.3487  loss_giou_0: 0.3321  loss_bbox_0: 0.2677  loss_rpn_cls: 0.213  loss_rpn_reg: 0.4049  time: 0.1890  last_time: 0.1846  data_time: 0.0051  last_data_time: 0.0055   lr: 5e-06  max_mem: 3029M
[03/05 14:12:18] d2.utils.events INFO:  eta: 0:23:40  iter: 46439  total_loss: 2.242  loss_ce: 0.2493  loss_giou: 0.2715  loss_bbox: 0.2168  loss_ce_0: 0.3309  loss_giou_0: 0.2861  loss_bbox_0: 0.239  loss_rpn_cls: 0.1878  loss_rpn_reg: 0.4311  time: 0.1890  last_time: 0.1888  data_time: 0.0049  last_data_time: 0.0057   lr: 5e-06  max_mem: 3029M
[03/05 14:12:22] d2.utils.events INFO:  eta: 0:23:38  iter: 46459  total_loss: 2.381  loss_ce: 0.2711  loss_giou: 0.295  loss_bbox: 0.2321  loss_ce_0: 0.3355  loss_giou_0: 0.3143  loss_bbox_0: 0.2417  loss_rpn_cls: 0.184  loss_rpn_reg: 0.44  time: 0.1890  last_time: 0.1919  data_time: 0.0053  last_data_time: 0.0044   lr: 5e-06  max_mem: 3029M
[03/05 14:12:25] d2.utils.events INFO:  eta: 0:23:35  iter: 46479  total_loss: 2.192  loss_ce: 0.2449  loss_giou: 0.2902  loss_bbox: 0.1953  loss_ce_0: 0.2714  loss_giou_0: 0.3051  loss_bbox_0: 0.2221  loss_rpn_cls: 0.1806  loss_rpn_reg: 0.4014  time: 0.1890  last_time: 0.1781  data_time: 0.0052  last_data_time: 0.0029   lr: 5e-06  max_mem: 3029M
[03/05 14:12:29] d2.utils.events INFO:  eta: 0:23:30  iter: 46499  total_loss: 2.355  loss_ce: 0.315  loss_giou: 0.2595  loss_bbox: 0.253  loss_ce_0: 0.3443  loss_giou_0: 0.2573  loss_bbox_0: 0.2824  loss_rpn_cls: 0.1873  loss_rpn_reg: 0.4129  time: 0.1890  last_time: 0.1776  data_time: 0.0051  last_data_time: 0.0066   lr: 5e-06  max_mem: 3029M
[03/05 14:12:33] d2.utils.events INFO:  eta: 0:23:27  iter: 46519  total_loss: 2.239  loss_ce: 0.2803  loss_giou: 0.2881  loss_bbox: 0.21  loss_ce_0: 0.3249  loss_giou_0: 0.2992  loss_bbox_0: 0.2264  loss_rpn_cls: 0.1782  loss_rpn_reg: 0.4303  time: 0.1890  last_time: 0.2210  data_time: 0.0050  last_data_time: 0.0095   lr: 5e-06  max_mem: 3029M
[03/05 14:12:37] d2.utils.events INFO:  eta: 0:23:24  iter: 46539  total_loss: 2.049  loss_ce: 0.2271  loss_giou: 0.2681  loss_bbox: 0.1909  loss_ce_0: 0.2767  loss_giou_0: 0.2849  loss_bbox_0: 0.2111  loss_rpn_cls: 0.1832  loss_rpn_reg: 0.4017  time: 0.1890  last_time: 0.1655  data_time: 0.0051  last_data_time: 0.0050   lr: 5e-06  max_mem: 3029M
[03/05 14:12:40] d2.utils.events INFO:  eta: 0:23:18  iter: 46559  total_loss: 2.422  loss_ce: 0.3131  loss_giou: 0.3194  loss_bbox: 0.2639  loss_ce_0: 0.3359  loss_giou_0: 0.3352  loss_bbox_0: 0.2772  loss_rpn_cls: 0.1825  loss_rpn_reg: 0.4539  time: 0.1890  last_time: 0.1649  data_time: 0.0047  last_data_time: 0.0059   lr: 5e-06  max_mem: 3029M
[03/05 14:12:44] d2.utils.events INFO:  eta: 0:23:13  iter: 46579  total_loss: 2.044  loss_ce: 0.2454  loss_giou: 0.2387  loss_bbox: 0.1972  loss_ce_0: 0.2916  loss_giou_0: 0.2471  loss_bbox_0: 0.2309  loss_rpn_cls: 0.1809  loss_rpn_reg: 0.3561  time: 0.1890  last_time: 0.1853  data_time: 0.0054  last_data_time: 0.0053   lr: 5e-06  max_mem: 3029M
[03/05 14:12:48] d2.utils.events INFO:  eta: 0:23:08  iter: 46599  total_loss: 2.327  loss_ce: 0.2598  loss_giou: 0.2941  loss_bbox: 0.2187  loss_ce_0: 0.3243  loss_giou_0: 0.3153  loss_bbox_0: 0.2679  loss_rpn_cls: 0.1963  loss_rpn_reg: 0.4249  time: 0.1890  last_time: 0.1955  data_time: 0.0053  last_data_time: 0.0047   lr: 5e-06  max_mem: 3029M
[03/05 14:12:52] d2.utils.events INFO:  eta: 0:23:03  iter: 46619  total_loss: 2.239  loss_ce: 0.2687  loss_giou: 0.2581  loss_bbox: 0.2222  loss_ce_0: 0.3138  loss_giou_0: 0.2744  loss_bbox_0: 0.2598  loss_rpn_cls: 0.1928  loss_rpn_reg: 0.4138  time: 0.1890  last_time: 0.1883  data_time: 0.0044  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 14:12:55] d2.utils.events INFO:  eta: 0:22:58  iter: 46639  total_loss: 2.446  loss_ce: 0.321  loss_giou: 0.3642  loss_bbox: 0.2206  loss_ce_0: 0.3223  loss_giou_0: 0.3724  loss_bbox_0: 0.2297  loss_rpn_cls: 0.2096  loss_rpn_reg: 0.4604  time: 0.1890  last_time: 0.1834  data_time: 0.0049  last_data_time: 0.0051   lr: 5e-06  max_mem: 3029M
[03/05 14:12:59] d2.utils.events INFO:  eta: 0:22:54  iter: 46659  total_loss: 2.689  loss_ce: 0.337  loss_giou: 0.3517  loss_bbox: 0.2703  loss_ce_0: 0.3314  loss_giou_0: 0.3766  loss_bbox_0: 0.2903  loss_rpn_cls: 0.2047  loss_rpn_reg: 0.4555  time: 0.1890  last_time: 0.1542  data_time: 0.0049  last_data_time: 0.0047   lr: 5e-06  max_mem: 3029M
[03/05 14:13:03] d2.utils.events INFO:  eta: 0:22:49  iter: 46679  total_loss: 2.322  loss_ce: 0.2914  loss_giou: 0.2657  loss_bbox: 0.2219  loss_ce_0: 0.3406  loss_giou_0: 0.3053  loss_bbox_0: 0.2374  loss_rpn_cls: 0.1901  loss_rpn_reg: 0.4393  time: 0.1890  last_time: 0.2023  data_time: 0.0045  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 14:13:07] d2.utils.events INFO:  eta: 0:22:43  iter: 46699  total_loss: 2.042  loss_ce: 0.2746  loss_giou: 0.2617  loss_bbox: 0.1741  loss_ce_0: 0.2924  loss_giou_0: 0.2746  loss_bbox_0: 0.2061  loss_rpn_cls: 0.1525  loss_rpn_reg: 0.3818  time: 0.1890  last_time: 0.1669  data_time: 0.0043  last_data_time: 0.0034   lr: 5e-06  max_mem: 3029M
[03/05 14:13:10] d2.utils.events INFO:  eta: 0:22:38  iter: 46719  total_loss: 2.261  loss_ce: 0.2952  loss_giou: 0.2909  loss_bbox: 0.2012  loss_ce_0: 0.3193  loss_giou_0: 0.2903  loss_bbox_0: 0.2231  loss_rpn_cls: 0.1819  loss_rpn_reg: 0.42  time: 0.1890  last_time: 0.1817  data_time: 0.0045  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:13:14] d2.utils.events INFO:  eta: 0:22:37  iter: 46739  total_loss: 2.098  loss_ce: 0.2271  loss_giou: 0.2769  loss_bbox: 0.1802  loss_ce_0: 0.2504  loss_giou_0: 0.2889  loss_bbox_0: 0.2182  loss_rpn_cls: 0.1605  loss_rpn_reg: 0.4125  time: 0.1890  last_time: 0.1974  data_time: 0.0054  last_data_time: 0.0082   lr: 5e-06  max_mem: 3029M
[03/05 14:13:18] d2.utils.events INFO:  eta: 0:22:34  iter: 46759  total_loss: 2.259  loss_ce: 0.2143  loss_giou: 0.267  loss_bbox: 0.2379  loss_ce_0: 0.2731  loss_giou_0: 0.2731  loss_bbox_0: 0.2679  loss_rpn_cls: 0.1797  loss_rpn_reg: 0.3874  time: 0.1890  last_time: 0.1908  data_time: 0.0049  last_data_time: 0.0046   lr: 5e-06  max_mem: 3029M
[03/05 14:13:22] d2.utils.events INFO:  eta: 0:22:29  iter: 46779  total_loss: 2.246  loss_ce: 0.2889  loss_giou: 0.2495  loss_bbox: 0.2002  loss_ce_0: 0.311  loss_giou_0: 0.2771  loss_bbox_0: 0.2133  loss_rpn_cls: 0.2002  loss_rpn_reg: 0.3994  time: 0.1890  last_time: 0.1603  data_time: 0.0047  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 14:13:26] d2.utils.events INFO:  eta: 0:22:24  iter: 46799  total_loss: 2.232  loss_ce: 0.2834  loss_giou: 0.2657  loss_bbox: 0.2061  loss_ce_0: 0.2693  loss_giou_0: 0.3057  loss_bbox_0: 0.2292  loss_rpn_cls: 0.1593  loss_rpn_reg: 0.4068  time: 0.1890  last_time: 0.1780  data_time: 0.0047  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 14:13:30] d2.utils.events INFO:  eta: 0:22:19  iter: 46819  total_loss: 2.272  loss_ce: 0.2508  loss_giou: 0.3035  loss_bbox: 0.2137  loss_ce_0: 0.3076  loss_giou_0: 0.3156  loss_bbox_0: 0.2241  loss_rpn_cls: 0.1891  loss_rpn_reg: 0.4134  time: 0.1890  last_time: 0.1865  data_time: 0.0049  last_data_time: 0.0047   lr: 5e-06  max_mem: 3029M
[03/05 14:13:33] d2.utils.events INFO:  eta: 0:22:15  iter: 46839  total_loss: 2.11  loss_ce: 0.2464  loss_giou: 0.2435  loss_bbox: 0.2014  loss_ce_0: 0.309  loss_giou_0: 0.2604  loss_bbox_0: 0.2209  loss_rpn_cls: 0.1815  loss_rpn_reg: 0.4004  time: 0.1890  last_time: 0.1909  data_time: 0.0049  last_data_time: 0.0057   lr: 5e-06  max_mem: 3029M
[03/05 14:13:37] d2.utils.events INFO:  eta: 0:22:09  iter: 46859  total_loss: 2.288  loss_ce: 0.2526  loss_giou: 0.3068  loss_bbox: 0.2329  loss_ce_0: 0.2823  loss_giou_0: 0.3207  loss_bbox_0: 0.2671  loss_rpn_cls: 0.1611  loss_rpn_reg: 0.4458  time: 0.1890  last_time: 0.1593  data_time: 0.0047  last_data_time: 0.0040   lr: 5e-06  max_mem: 3029M
[03/05 14:13:41] d2.utils.events INFO:  eta: 0:22:04  iter: 46879  total_loss: 2.502  loss_ce: 0.2831  loss_giou: 0.2883  loss_bbox: 0.216  loss_ce_0: 0.3357  loss_giou_0: 0.2884  loss_bbox_0: 0.2552  loss_rpn_cls: 0.2005  loss_rpn_reg: 0.4696  time: 0.1890  last_time: 0.1647  data_time: 0.0050  last_data_time: 0.0055   lr: 5e-06  max_mem: 3029M
[03/05 14:13:45] d2.utils.events INFO:  eta: 0:21:58  iter: 46899  total_loss: 2.306  loss_ce: 0.3499  loss_giou: 0.2668  loss_bbox: 0.2285  loss_ce_0: 0.3826  loss_giou_0: 0.2874  loss_bbox_0: 0.252  loss_rpn_cls: 0.1828  loss_rpn_reg: 0.3722  time: 0.1890  last_time: 0.1856  data_time: 0.0055  last_data_time: 0.0057   lr: 5e-06  max_mem: 3029M
[03/05 14:13:48] d2.utils.events INFO:  eta: 0:21:53  iter: 46919  total_loss: 2.649  loss_ce: 0.3623  loss_giou: 0.3315  loss_bbox: 0.2514  loss_ce_0: 0.3663  loss_giou_0: 0.3652  loss_bbox_0: 0.304  loss_rpn_cls: 0.2117  loss_rpn_reg: 0.4381  time: 0.1890  last_time: 0.1965  data_time: 0.0052  last_data_time: 0.0047   lr: 5e-06  max_mem: 3029M
[03/05 14:13:52] d2.utils.events INFO:  eta: 0:21:51  iter: 46939  total_loss: 2.153  loss_ce: 0.2388  loss_giou: 0.2894  loss_bbox: 0.1988  loss_ce_0: 0.2713  loss_giou_0: 0.3068  loss_bbox_0: 0.2347  loss_rpn_cls: 0.1657  loss_rpn_reg: 0.4183  time: 0.1890  last_time: 0.1818  data_time: 0.0052  last_data_time: 0.0055   lr: 5e-06  max_mem: 3029M
[03/05 14:13:56] d2.utils.events INFO:  eta: 0:21:46  iter: 46959  total_loss: 2.219  loss_ce: 0.2493  loss_giou: 0.2484  loss_bbox: 0.2659  loss_ce_0: 0.3121  loss_giou_0: 0.267  loss_bbox_0: 0.2845  loss_rpn_cls: 0.1609  loss_rpn_reg: 0.4155  time: 0.1890  last_time: 0.1814  data_time: 0.0046  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 14:14:00] d2.utils.events INFO:  eta: 0:21:43  iter: 46979  total_loss: 2.362  loss_ce: 0.3039  loss_giou: 0.2965  loss_bbox: 0.2539  loss_ce_0: 0.3274  loss_giou_0: 0.3142  loss_bbox_0: 0.2773  loss_rpn_cls: 0.1827  loss_rpn_reg: 0.401  time: 0.1890  last_time: 0.1740  data_time: 0.0050  last_data_time: 0.0047   lr: 5e-06  max_mem: 3029M
[03/05 14:14:04] d2.utils.events INFO:  eta: 0:21:40  iter: 46999  total_loss: 2.251  loss_ce: 0.2745  loss_giou: 0.2725  loss_bbox: 0.2234  loss_ce_0: 0.3309  loss_giou_0: 0.2944  loss_bbox_0: 0.2542  loss_rpn_cls: 0.1841  loss_rpn_reg: 0.4325  time: 0.1890  last_time: 0.2002  data_time: 0.0048  last_data_time: 0.0049   lr: 5e-06  max_mem: 3029M
[03/05 14:14:07] d2.utils.events INFO:  eta: 0:21:35  iter: 47019  total_loss: 2.576  loss_ce: 0.2623  loss_giou: 0.3074  loss_bbox: 0.2066  loss_ce_0: 0.3071  loss_giou_0: 0.3081  loss_bbox_0: 0.229  loss_rpn_cls: 0.1945  loss_rpn_reg: 0.4351  time: 0.1890  last_time: 0.1964  data_time: 0.0044  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 14:14:11] d2.utils.events INFO:  eta: 0:21:31  iter: 47039  total_loss: 2.431  loss_ce: 0.3347  loss_giou: 0.2525  loss_bbox: 0.2597  loss_ce_0: 0.3582  loss_giou_0: 0.2829  loss_bbox_0: 0.2894  loss_rpn_cls: 0.2201  loss_rpn_reg: 0.4146  time: 0.1890  last_time: 0.1821  data_time: 0.0053  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 14:14:15] d2.utils.events INFO:  eta: 0:21:27  iter: 47059  total_loss: 2.338  loss_ce: 0.2918  loss_giou: 0.2765  loss_bbox: 0.2394  loss_ce_0: 0.3287  loss_giou_0: 0.3222  loss_bbox_0: 0.257  loss_rpn_cls: 0.1778  loss_rpn_reg: 0.453  time: 0.1890  last_time: 0.1979  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 14:14:19] d2.utils.events INFO:  eta: 0:21:24  iter: 47079  total_loss: 2.035  loss_ce: 0.2424  loss_giou: 0.2591  loss_bbox: 0.1911  loss_ce_0: 0.2781  loss_giou_0: 0.2746  loss_bbox_0: 0.2182  loss_rpn_cls: 0.1549  loss_rpn_reg: 0.4201  time: 0.1890  last_time: 0.1867  data_time: 0.0055  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:14:23] d2.utils.events INFO:  eta: 0:21:20  iter: 47099  total_loss: 2.186  loss_ce: 0.2338  loss_giou: 0.2729  loss_bbox: 0.2238  loss_ce_0: 0.2624  loss_giou_0: 0.2983  loss_bbox_0: 0.2515  loss_rpn_cls: 0.157  loss_rpn_reg: 0.3664  time: 0.1890  last_time: 0.2065  data_time: 0.0045  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 14:14:26] d2.utils.events INFO:  eta: 0:21:17  iter: 47119  total_loss: 2.411  loss_ce: 0.2808  loss_giou: 0.3066  loss_bbox: 0.2471  loss_ce_0: 0.3547  loss_giou_0: 0.3164  loss_bbox_0: 0.2738  loss_rpn_cls: 0.1964  loss_rpn_reg: 0.4357  time: 0.1890  last_time: 0.2144  data_time: 0.0047  last_data_time: 0.0047   lr: 5e-06  max_mem: 3029M
[03/05 14:14:30] d2.utils.events INFO:  eta: 0:21:13  iter: 47139  total_loss: 2.283  loss_ce: 0.3195  loss_giou: 0.2542  loss_bbox: 0.2154  loss_ce_0: 0.345  loss_giou_0: 0.2858  loss_bbox_0: 0.2779  loss_rpn_cls: 0.1913  loss_rpn_reg: 0.402  time: 0.1890  last_time: 0.1840  data_time: 0.0050  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:14:34] d2.utils.events INFO:  eta: 0:21:09  iter: 47159  total_loss: 2.184  loss_ce: 0.245  loss_giou: 0.2743  loss_bbox: 0.2182  loss_ce_0: 0.281  loss_giou_0: 0.2971  loss_bbox_0: 0.2304  loss_rpn_cls: 0.1801  loss_rpn_reg: 0.3981  time: 0.1890  last_time: 0.1565  data_time: 0.0047  last_data_time: 0.0048   lr: 5e-06  max_mem: 3029M
[03/05 14:14:38] d2.utils.events INFO:  eta: 0:21:05  iter: 47179  total_loss: 2.077  loss_ce: 0.2922  loss_giou: 0.2707  loss_bbox: 0.2051  loss_ce_0: 0.3212  loss_giou_0: 0.2854  loss_bbox_0: 0.2456  loss_rpn_cls: 0.1817  loss_rpn_reg: 0.4291  time: 0.1890  last_time: 0.1767  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 14:14:41] d2.utils.events INFO:  eta: 0:21:01  iter: 47199  total_loss: 2.5  loss_ce: 0.3152  loss_giou: 0.3313  loss_bbox: 0.2487  loss_ce_0: 0.3417  loss_giou_0: 0.36  loss_bbox_0: 0.2615  loss_rpn_cls: 0.2065  loss_rpn_reg: 0.4601  time: 0.1890  last_time: 0.1967  data_time: 0.0046  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 14:14:45] d2.utils.events INFO:  eta: 0:20:56  iter: 47219  total_loss: 2.323  loss_ce: 0.3209  loss_giou: 0.3016  loss_bbox: 0.1986  loss_ce_0: 0.3625  loss_giou_0: 0.3258  loss_bbox_0: 0.2381  loss_rpn_cls: 0.1913  loss_rpn_reg: 0.4253  time: 0.1890  last_time: 0.2029  data_time: 0.0044  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 14:14:49] d2.utils.events INFO:  eta: 0:20:52  iter: 47239  total_loss: 2.17  loss_ce: 0.2477  loss_giou: 0.286  loss_bbox: 0.2157  loss_ce_0: 0.2748  loss_giou_0: 0.2848  loss_bbox_0: 0.2277  loss_rpn_cls: 0.1763  loss_rpn_reg: 0.3919  time: 0.1890  last_time: 0.1924  data_time: 0.0057  last_data_time: 0.0051   lr: 5e-06  max_mem: 3029M
[03/05 14:14:53] d2.utils.events INFO:  eta: 0:20:48  iter: 47259  total_loss: 2.078  loss_ce: 0.3049  loss_giou: 0.2713  loss_bbox: 0.2205  loss_ce_0: 0.3369  loss_giou_0: 0.2792  loss_bbox_0: 0.2109  loss_rpn_cls: 0.2042  loss_rpn_reg: 0.4028  time: 0.1890  last_time: 0.1957  data_time: 0.0048  last_data_time: 0.0071   lr: 5e-06  max_mem: 3029M
[03/05 14:14:57] d2.utils.events INFO:  eta: 0:20:45  iter: 47279  total_loss: 2.35  loss_ce: 0.2279  loss_giou: 0.2769  loss_bbox: 0.2062  loss_ce_0: 0.2781  loss_giou_0: 0.2856  loss_bbox_0: 0.2241  loss_rpn_cls: 0.175  loss_rpn_reg: 0.3929  time: 0.1890  last_time: 0.2074  data_time: 0.0050  last_data_time: 0.0058   lr: 5e-06  max_mem: 3029M
[03/05 14:15:01] d2.utils.events INFO:  eta: 0:20:43  iter: 47299  total_loss: 2.239  loss_ce: 0.2667  loss_giou: 0.2535  loss_bbox: 0.2858  loss_ce_0: 0.3349  loss_giou_0: 0.269  loss_bbox_0: 0.3194  loss_rpn_cls: 0.1844  loss_rpn_reg: 0.4027  time: 0.1890  last_time: 0.1940  data_time: 0.0048  last_data_time: 0.0048   lr: 5e-06  max_mem: 3029M
[03/05 14:15:04] d2.utils.events INFO:  eta: 0:20:39  iter: 47319  total_loss: 2.854  loss_ce: 0.2972  loss_giou: 0.3318  loss_bbox: 0.2842  loss_ce_0: 0.3621  loss_giou_0: 0.3427  loss_bbox_0: 0.3332  loss_rpn_cls: 0.2076  loss_rpn_reg: 0.4557  time: 0.1890  last_time: 0.1974  data_time: 0.0051  last_data_time: 0.0065   lr: 5e-06  max_mem: 3029M
[03/05 14:15:08] d2.utils.events INFO:  eta: 0:20:34  iter: 47339  total_loss: 2.19  loss_ce: 0.2749  loss_giou: 0.2385  loss_bbox: 0.224  loss_ce_0: 0.3005  loss_giou_0: 0.2627  loss_bbox_0: 0.2359  loss_rpn_cls: 0.1852  loss_rpn_reg: 0.429  time: 0.1890  last_time: 0.1680  data_time: 0.0042  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 14:15:12] d2.utils.events INFO:  eta: 0:20:30  iter: 47359  total_loss: 2.244  loss_ce: 0.2746  loss_giou: 0.2787  loss_bbox: 0.2168  loss_ce_0: 0.3138  loss_giou_0: 0.2876  loss_bbox_0: 0.2449  loss_rpn_cls: 0.1775  loss_rpn_reg: 0.4179  time: 0.1890  last_time: 0.2044  data_time: 0.0050  last_data_time: 0.0065   lr: 5e-06  max_mem: 3029M
[03/05 14:15:16] d2.utils.events INFO:  eta: 0:20:28  iter: 47379  total_loss: 2.382  loss_ce: 0.2407  loss_giou: 0.2906  loss_bbox: 0.2467  loss_ce_0: 0.3139  loss_giou_0: 0.303  loss_bbox_0: 0.252  loss_rpn_cls: 0.183  loss_rpn_reg: 0.4502  time: 0.1890  last_time: 0.1872  data_time: 0.0046  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 14:15:19] d2.utils.events INFO:  eta: 0:20:24  iter: 47399  total_loss: 2.291  loss_ce: 0.2684  loss_giou: 0.3181  loss_bbox: 0.2118  loss_ce_0: 0.2858  loss_giou_0: 0.3131  loss_bbox_0: 0.2486  loss_rpn_cls: 0.1764  loss_rpn_reg: 0.4389  time: 0.1890  last_time: 0.1880  data_time: 0.0047  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 14:15:23] d2.utils.events INFO:  eta: 0:20:21  iter: 47419  total_loss: 2.31  loss_ce: 0.2879  loss_giou: 0.283  loss_bbox: 0.2206  loss_ce_0: 0.2887  loss_giou_0: 0.3088  loss_bbox_0: 0.2445  loss_rpn_cls: 0.1729  loss_rpn_reg: 0.4524  time: 0.1890  last_time: 0.1844  data_time: 0.0045  last_data_time: 0.0051   lr: 5e-06  max_mem: 3029M
[03/05 14:15:27] d2.utils.events INFO:  eta: 0:20:17  iter: 47439  total_loss: 2.195  loss_ce: 0.262  loss_giou: 0.2146  loss_bbox: 0.2026  loss_ce_0: 0.311  loss_giou_0: 0.2432  loss_bbox_0: 0.2325  loss_rpn_cls: 0.1692  loss_rpn_reg: 0.4051  time: 0.1890  last_time: 0.1747  data_time: 0.0047  last_data_time: 0.0035   lr: 5e-06  max_mem: 3029M
[03/05 14:15:30] d2.utils.events INFO:  eta: 0:20:12  iter: 47459  total_loss: 2.542  loss_ce: 0.3547  loss_giou: 0.2834  loss_bbox: 0.2385  loss_ce_0: 0.3781  loss_giou_0: 0.2988  loss_bbox_0: 0.2595  loss_rpn_cls: 0.2013  loss_rpn_reg: 0.4421  time: 0.1890  last_time: 0.1948  data_time: 0.0045  last_data_time: 0.0057   lr: 5e-06  max_mem: 3029M
[03/05 14:15:34] d2.utils.events INFO:  eta: 0:20:08  iter: 47479  total_loss: 2.454  loss_ce: 0.2707  loss_giou: 0.311  loss_bbox: 0.2115  loss_ce_0: 0.3085  loss_giou_0: 0.3248  loss_bbox_0: 0.2436  loss_rpn_cls: 0.1857  loss_rpn_reg: 0.4106  time: 0.1890  last_time: 0.1591  data_time: 0.0051  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 14:15:38] d2.utils.events INFO:  eta: 0:20:04  iter: 47499  total_loss: 2.171  loss_ce: 0.2739  loss_giou: 0.278  loss_bbox: 0.1843  loss_ce_0: 0.3143  loss_giou_0: 0.3182  loss_bbox_0: 0.218  loss_rpn_cls: 0.1895  loss_rpn_reg: 0.3864  time: 0.1890  last_time: 0.1770  data_time: 0.0055  last_data_time: 0.0041   lr: 5e-06  max_mem: 3029M
[03/05 14:15:42] d2.utils.events INFO:  eta: 0:20:00  iter: 47519  total_loss: 2.341  loss_ce: 0.2591  loss_giou: 0.274  loss_bbox: 0.2255  loss_ce_0: 0.3144  loss_giou_0: 0.2745  loss_bbox_0: 0.2453  loss_rpn_cls: 0.1913  loss_rpn_reg: 0.4074  time: 0.1890  last_time: 0.1744  data_time: 0.0047  last_data_time: 0.0033   lr: 5e-06  max_mem: 3029M
[03/05 14:15:45] d2.utils.events INFO:  eta: 0:19:57  iter: 47539  total_loss: 2.457  loss_ce: 0.2449  loss_giou: 0.3137  loss_bbox: 0.2494  loss_ce_0: 0.2759  loss_giou_0: 0.3291  loss_bbox_0: 0.2326  loss_rpn_cls: 0.1472  loss_rpn_reg: 0.4178  time: 0.1890  last_time: 0.1769  data_time: 0.0046  last_data_time: 0.0033   lr: 5e-06  max_mem: 3029M
[03/05 14:15:49] d2.utils.events INFO:  eta: 0:19:53  iter: 47559  total_loss: 2.657  loss_ce: 0.293  loss_giou: 0.2794  loss_bbox: 0.2861  loss_ce_0: 0.34  loss_giou_0: 0.2875  loss_bbox_0: 0.3229  loss_rpn_cls: 0.2158  loss_rpn_reg: 0.4219  time: 0.1890  last_time: 0.1968  data_time: 0.0046  last_data_time: 0.0048   lr: 5e-06  max_mem: 3029M
[03/05 14:15:53] d2.utils.events INFO:  eta: 0:19:49  iter: 47579  total_loss: 2.598  loss_ce: 0.2776  loss_giou: 0.3134  loss_bbox: 0.2519  loss_ce_0: 0.3242  loss_giou_0: 0.3324  loss_bbox_0: 0.2879  loss_rpn_cls: 0.2006  loss_rpn_reg: 0.4767  time: 0.1890  last_time: 0.1778  data_time: 0.0048  last_data_time: 0.0066   lr: 5e-06  max_mem: 3029M
[03/05 14:15:57] d2.utils.events INFO:  eta: 0:19:45  iter: 47599  total_loss: 2.451  loss_ce: 0.2955  loss_giou: 0.3063  loss_bbox: 0.222  loss_ce_0: 0.3468  loss_giou_0: 0.2988  loss_bbox_0: 0.2501  loss_rpn_cls: 0.1816  loss_rpn_reg: 0.4387  time: 0.1890  last_time: 0.1673  data_time: 0.0043  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:16:00] d2.utils.events INFO:  eta: 0:19:41  iter: 47619  total_loss: 2.264  loss_ce: 0.2608  loss_giou: 0.2481  loss_bbox: 0.2261  loss_ce_0: 0.307  loss_giou_0: 0.2641  loss_bbox_0: 0.2562  loss_rpn_cls: 0.1681  loss_rpn_reg: 0.3944  time: 0.1889  last_time: 0.1847  data_time: 0.0044  last_data_time: 0.0050   lr: 5e-06  max_mem: 3029M
[03/05 14:16:04] d2.utils.events INFO:  eta: 0:19:38  iter: 47639  total_loss: 2.178  loss_ce: 0.2434  loss_giou: 0.3128  loss_bbox: 0.1897  loss_ce_0: 0.2938  loss_giou_0: 0.3223  loss_bbox_0: 0.2309  loss_rpn_cls: 0.1885  loss_rpn_reg: 0.4117  time: 0.1889  last_time: 0.1979  data_time: 0.0049  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 14:16:08] d2.utils.events INFO:  eta: 0:19:34  iter: 47659  total_loss: 2.123  loss_ce: 0.2641  loss_giou: 0.2407  loss_bbox: 0.2184  loss_ce_0: 0.3133  loss_giou_0: 0.2496  loss_bbox_0: 0.2488  loss_rpn_cls: 0.1827  loss_rpn_reg: 0.3751  time: 0.1889  last_time: 0.1936  data_time: 0.0043  last_data_time: 0.0022   lr: 5e-06  max_mem: 3029M
[03/05 14:16:12] d2.utils.events INFO:  eta: 0:19:31  iter: 47679  total_loss: 2.262  loss_ce: 0.2651  loss_giou: 0.2518  loss_bbox: 0.2682  loss_ce_0: 0.3178  loss_giou_0: 0.2803  loss_bbox_0: 0.2798  loss_rpn_cls: 0.2082  loss_rpn_reg: 0.3918  time: 0.1889  last_time: 0.1918  data_time: 0.0045  last_data_time: 0.0039   lr: 5e-06  max_mem: 3029M
[03/05 14:16:16] d2.utils.events INFO:  eta: 0:19:27  iter: 47699  total_loss: 2.46  loss_ce: 0.3302  loss_giou: 0.3166  loss_bbox: 0.2459  loss_ce_0: 0.3869  loss_giou_0: 0.3413  loss_bbox_0: 0.3107  loss_rpn_cls: 0.2181  loss_rpn_reg: 0.4383  time: 0.1889  last_time: 0.1993  data_time: 0.0052  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 14:16:19] d2.utils.events INFO:  eta: 0:19:23  iter: 47719  total_loss: 2.131  loss_ce: 0.286  loss_giou: 0.2221  loss_bbox: 0.187  loss_ce_0: 0.3342  loss_giou_0: 0.2638  loss_bbox_0: 0.2063  loss_rpn_cls: 0.1728  loss_rpn_reg: 0.4148  time: 0.1889  last_time: 0.1830  data_time: 0.0046  last_data_time: 0.0038   lr: 5e-06  max_mem: 3029M
[03/05 14:16:23] d2.utils.events INFO:  eta: 0:19:19  iter: 47739  total_loss: 2.252  loss_ce: 0.2856  loss_giou: 0.2761  loss_bbox: 0.1824  loss_ce_0: 0.3469  loss_giou_0: 0.2734  loss_bbox_0: 0.234  loss_rpn_cls: 0.1965  loss_rpn_reg: 0.3785  time: 0.1889  last_time: 0.1949  data_time: 0.0045  last_data_time: 0.0059   lr: 5e-06  max_mem: 3029M
[03/05 14:16:27] d2.utils.events INFO:  eta: 0:19:14  iter: 47759  total_loss: 2.182  loss_ce: 0.2351  loss_giou: 0.2525  loss_bbox: 0.2189  loss_ce_0: 0.3266  loss_giou_0: 0.2562  loss_bbox_0: 0.2362  loss_rpn_cls: 0.1865  loss_rpn_reg: 0.4343  time: 0.1889  last_time: 0.2166  data_time: 0.0047  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 14:16:31] d2.utils.events INFO:  eta: 0:19:10  iter: 47779  total_loss: 2.318  loss_ce: 0.2658  loss_giou: 0.2961  loss_bbox: 0.2117  loss_ce_0: 0.3323  loss_giou_0: 0.3063  loss_bbox_0: 0.233  loss_rpn_cls: 0.1606  loss_rpn_reg: 0.4446  time: 0.1889  last_time: 0.2140  data_time: 0.0047  last_data_time: 0.0045   lr: 5e-06  max_mem: 3029M
[03/05 14:16:35] d2.utils.events INFO:  eta: 0:19:06  iter: 47799  total_loss: 2.164  loss_ce: 0.2563  loss_giou: 0.259  loss_bbox: 0.2258  loss_ce_0: 0.2739  loss_giou_0: 0.287  loss_bbox_0: 0.2414  loss_rpn_cls: 0.1862  loss_rpn_reg: 0.433  time: 0.1889  last_time: 0.1999  data_time: 0.0050  last_data_time: 0.0049   lr: 5e-06  max_mem: 3029M
[03/05 14:16:38] d2.utils.events INFO:  eta: 0:19:02  iter: 47819  total_loss: 2.409  loss_ce: 0.2918  loss_giou: 0.3151  loss_bbox: 0.2138  loss_ce_0: 0.2757  loss_giou_0: 0.3545  loss_bbox_0: 0.2757  loss_rpn_cls: 0.1883  loss_rpn_reg: 0.4519  time: 0.1889  last_time: 0.1705  data_time: 0.0047  last_data_time: 0.0046   lr: 5e-06  max_mem: 3029M
[03/05 14:16:42] d2.utils.events INFO:  eta: 0:19:00  iter: 47839  total_loss: 2.359  loss_ce: 0.2828  loss_giou: 0.2966  loss_bbox: 0.2559  loss_ce_0: 0.2973  loss_giou_0: 0.3092  loss_bbox_0: 0.2635  loss_rpn_cls: 0.181  loss_rpn_reg: 0.4162  time: 0.1889  last_time: 0.2090  data_time: 0.0045  last_data_time: 0.0052   lr: 5e-06  max_mem: 3029M
[03/05 14:16:46] d2.utils.events INFO:  eta: 0:18:56  iter: 47859  total_loss: 2.351  loss_ce: 0.2202  loss_giou: 0.285  loss_bbox: 0.2252  loss_ce_0: 0.2665  loss_giou_0: 0.3035  loss_bbox_0: 0.2468  loss_rpn_cls: 0.1758  loss_rpn_reg: 0.4039  time: 0.1889  last_time: 0.1833  data_time: 0.0042  last_data_time: 0.0070   lr: 5e-06  max_mem: 3029M
[03/05 14:16:50] d2.utils.events INFO:  eta: 0:18:52  iter: 47879  total_loss: 1.96  loss_ce: 0.1969  loss_giou: 0.2602  loss_bbox: 0.2038  loss_ce_0: 0.2388  loss_giou_0: 0.2853  loss_bbox_0: 0.2222  loss_rpn_cls: 0.1779  loss_rpn_reg: 0.3962  time: 0.1889  last_time: 0.2024  data_time: 0.0043  last_data_time: 0.0037   lr: 5e-06  max_mem: 3029M
[03/05 14:16:53] d2.utils.events INFO:  eta: 0:18:50  iter: 47899  total_loss: 2.443  loss_ce: 0.299  loss_giou: 0.2912  loss_bbox: 0.2257  loss_ce_0: 0.3407  loss_giou_0: 0.3168  loss_bbox_0: 0.2397  loss_rpn_cls: 0.1887  loss_rpn_reg: 0.4565  time: 0.1889  last_time: 0.1972  data_time: 0.0046  last_data_time: 0.0042   lr: 5e-06  max_mem: 3029M
[03/05 14:16:57] d2.utils.events INFO:  eta: 0:18:46  iter: 47919  total_loss: 2.578  loss_ce: 0.2665  loss_giou: 0.3443  loss_bbox: 0.2823  loss_ce_0: 0.3172  loss_giou_0: 0.3709  loss_bbox_0: 0.2847  loss_rpn_cls: 0.1778  loss_rpn_reg: 0.4489  time: 0.1889  last_time: 0.1624  data_time: 0.0048  last_data_time: 0.0043   lr: 5e-06  max_mem: 3029M
[03/05 14:17:01] d2.utils.events INFO:  eta: 0:18:42  iter: 47939  total_loss: 2.448  loss_ce: 0.2743  loss_giou: 0.3385  loss_bbox: 0.2948  loss_ce_0: 0.3117  loss_giou_0: 0.3687  loss_bbox_0: 0.3458  loss_rpn_cls: 0.1789  loss_rpn_reg: 0.4434  time: 0.1889  last_time: 0.1570  data_time: 0.0046  last_data_time: 0.0046   lr: 5e-06  max_mem: 3029M
[03/05 14:17:05] d2.utils.events INFO:  eta: 0:18:38  iter: 47959  total_loss: 2.475  loss_ce: 0.2841  loss_giou: 0.2618  loss_bbox: 0.2493  loss_ce_0: 0.3319  loss_giou_0: 0.277  loss_bbox_0: 0.2827  loss_rpn_cls: 0.1515  loss_rpn_reg: 0.4163  time: 0.1889  last_time: 0.2009  data_time: 0.0049  last_data_time: 0.0036   lr: 5e-06  max_mem: 3029M
[03/05 14:17:08] d2.utils.events INFO:  eta: 0:18:34  iter: 47979  total_loss: 2.289  loss_ce: 0.2389  loss_giou: 0.2851  loss_bbox: 0.2089  loss_ce_0: 0.2954  loss_giou_0: 0.3342  loss_bbox_0: 0.2488  loss_rpn_cls: 0.1697  loss_rpn_reg: 0.4204  time: 0.1889  last_time: 0.1959  data_time: 0.0047  last_data_time: 0.0026   lr: 5e-06  max_mem: 3029M
[03/05 14:17:12] d2.utils.events INFO:  eta: 0:18:30  iter: 47999  total_loss: 2.275  loss_ce: 0.3001  loss_giou: 0.2695  loss_bbox: 0.2329  loss_ce_0: 0.3132  loss_giou_0: 0.2688  loss_bbox_0: 0.2464  loss_rpn_cls: 0.1942  loss_rpn_reg: 0.4419  time: 0.1889  last_time: 0.1883  data_time: 0.0045  last_data_time: 0.0054   lr: 5e-06  max_mem: 3029M
[03/05 14:17:16] d2.utils.events INFO:  eta: 0:18:26  iter: 48019  total_loss: 2.057  loss_ce: 0.2282  loss_giou: 0.2628  loss_bbox: 0.2088  loss_ce_0: 0.2846  loss_giou_0: 0.2521  loss_bbox_0: 0.2182  loss_rpn_cls: 0.1893  loss_rpn_reg: 0.385  time: 0.1889  last_time: 0.1809  data_time: 0.0051  last_data_time: 0.0053   lr: 5e-07  max_mem: 3029M
[03/05 14:17:20] d2.utils.events INFO:  eta: 0:18:23  iter: 48039  total_loss: 2.371  loss_ce: 0.2816  loss_giou: 0.2783  loss_bbox: 0.2373  loss_ce_0: 0.3431  loss_giou_0: 0.3121  loss_bbox_0: 0.2501  loss_rpn_cls: 0.1841  loss_rpn_reg: 0.4214  time: 0.1889  last_time: 0.2118  data_time: 0.0045  last_data_time: 0.0046   lr: 5e-07  max_mem: 3029M
[03/05 14:17:23] d2.utils.events INFO:  eta: 0:18:19  iter: 48059  total_loss: 2.199  loss_ce: 0.279  loss_giou: 0.2984  loss_bbox: 0.202  loss_ce_0: 0.2959  loss_giou_0: 0.3286  loss_bbox_0: 0.2296  loss_rpn_cls: 0.1826  loss_rpn_reg: 0.426  time: 0.1889  last_time: 0.1856  data_time: 0.0044  last_data_time: 0.0034   lr: 5e-07  max_mem: 3029M
[03/05 14:17:27] d2.utils.events INFO:  eta: 0:18:15  iter: 48079  total_loss: 2.348  loss_ce: 0.2948  loss_giou: 0.2912  loss_bbox: 0.2228  loss_ce_0: 0.3486  loss_giou_0: 0.3097  loss_bbox_0: 0.2173  loss_rpn_cls: 0.2187  loss_rpn_reg: 0.4076  time: 0.1889  last_time: 0.1629  data_time: 0.0052  last_data_time: 0.0034   lr: 5e-07  max_mem: 3029M
[03/05 14:17:31] d2.utils.events INFO:  eta: 0:18:10  iter: 48099  total_loss: 2.281  loss_ce: 0.2728  loss_giou: 0.3108  loss_bbox: 0.233  loss_ce_0: 0.324  loss_giou_0: 0.3155  loss_bbox_0: 0.2365  loss_rpn_cls: 0.1828  loss_rpn_reg: 0.408  time: 0.1889  last_time: 0.1945  data_time: 0.0047  last_data_time: 0.0036   lr: 5e-07  max_mem: 3029M
[03/05 14:17:35] d2.utils.events INFO:  eta: 0:18:06  iter: 48119  total_loss: 2.306  loss_ce: 0.3009  loss_giou: 0.2844  loss_bbox: 0.2422  loss_ce_0: 0.3367  loss_giou_0: 0.293  loss_bbox_0: 0.228  loss_rpn_cls: 0.198  loss_rpn_reg: 0.3909  time: 0.1889  last_time: 0.2038  data_time: 0.0048  last_data_time: 0.0022   lr: 5e-07  max_mem: 3029M
[03/05 14:17:38] d2.utils.events INFO:  eta: 0:18:02  iter: 48139  total_loss: 2.344  loss_ce: 0.256  loss_giou: 0.2663  loss_bbox: 0.2147  loss_ce_0: 0.3446  loss_giou_0: 0.2854  loss_bbox_0: 0.247  loss_rpn_cls: 0.2009  loss_rpn_reg: 0.4176  time: 0.1889  last_time: 0.1804  data_time: 0.0048  last_data_time: 0.0040   lr: 5e-07  max_mem: 3029M
[03/05 14:17:42] d2.utils.events INFO:  eta: 0:17:58  iter: 48159  total_loss: 2.308  loss_ce: 0.2937  loss_giou: 0.2589  loss_bbox: 0.2164  loss_ce_0: 0.3452  loss_giou_0: 0.2993  loss_bbox_0: 0.227  loss_rpn_cls: 0.1937  loss_rpn_reg: 0.4328  time: 0.1889  last_time: 0.2231  data_time: 0.0055  last_data_time: 0.0065   lr: 5e-07  max_mem: 3029M
[03/05 14:17:46] d2.utils.events INFO:  eta: 0:17:55  iter: 48179  total_loss: 2.681  loss_ce: 0.2949  loss_giou: 0.3648  loss_bbox: 0.296  loss_ce_0: 0.3185  loss_giou_0: 0.385  loss_bbox_0: 0.3109  loss_rpn_cls: 0.2223  loss_rpn_reg: 0.443  time: 0.1889  last_time: 0.2019  data_time: 0.0068  last_data_time: 0.0049   lr: 5e-07  max_mem: 3029M
[03/05 14:17:50] d2.utils.events INFO:  eta: 0:17:51  iter: 48199  total_loss: 2.188  loss_ce: 0.2694  loss_giou: 0.2499  loss_bbox: 0.2537  loss_ce_0: 0.305  loss_giou_0: 0.2709  loss_bbox_0: 0.2758  loss_rpn_cls: 0.1764  loss_rpn_reg: 0.3873  time: 0.1889  last_time: 0.1896  data_time: 0.0049  last_data_time: 0.0040   lr: 5e-07  max_mem: 3029M
[03/05 14:17:54] d2.utils.events INFO:  eta: 0:17:48  iter: 48219  total_loss: 2.386  loss_ce: 0.2758  loss_giou: 0.3051  loss_bbox: 0.2648  loss_ce_0: 0.3397  loss_giou_0: 0.3313  loss_bbox_0: 0.2987  loss_rpn_cls: 0.1839  loss_rpn_reg: 0.4337  time: 0.1889  last_time: 0.1843  data_time: 0.0049  last_data_time: 0.0110   lr: 5e-07  max_mem: 3029M
[03/05 14:17:58] d2.utils.events INFO:  eta: 0:17:45  iter: 48239  total_loss: 2.016  loss_ce: 0.2201  loss_giou: 0.2654  loss_bbox: 0.1796  loss_ce_0: 0.2569  loss_giou_0: 0.2922  loss_bbox_0: 0.2079  loss_rpn_cls: 0.1836  loss_rpn_reg: 0.3902  time: 0.1889  last_time: 0.1878  data_time: 0.0049  last_data_time: 0.0084   lr: 5e-07  max_mem: 3029M
[03/05 14:18:02] d2.utils.events INFO:  eta: 0:17:42  iter: 48259  total_loss: 2.332  loss_ce: 0.3042  loss_giou: 0.3171  loss_bbox: 0.2424  loss_ce_0: 0.3462  loss_giou_0: 0.3244  loss_bbox_0: 0.2612  loss_rpn_cls: 0.2003  loss_rpn_reg: 0.4075  time: 0.1889  last_time: 0.1930  data_time: 0.0051  last_data_time: 0.0065   lr: 5e-07  max_mem: 3029M
[03/05 14:18:05] d2.utils.events INFO:  eta: 0:17:38  iter: 48279  total_loss: 2.248  loss_ce: 0.2908  loss_giou: 0.2686  loss_bbox: 0.2207  loss_ce_0: 0.2945  loss_giou_0: 0.2709  loss_bbox_0: 0.2235  loss_rpn_cls: 0.1697  loss_rpn_reg: 0.41  time: 0.1889  last_time: 0.1973  data_time: 0.0044  last_data_time: 0.0034   lr: 5e-07  max_mem: 3029M
[03/05 14:18:09] d2.utils.events INFO:  eta: 0:17:34  iter: 48299  total_loss: 2.582  loss_ce: 0.2721  loss_giou: 0.3377  loss_bbox: 0.2556  loss_ce_0: 0.3193  loss_giou_0: 0.3502  loss_bbox_0: 0.2446  loss_rpn_cls: 0.1885  loss_rpn_reg: 0.468  time: 0.1889  last_time: 0.1888  data_time: 0.0053  last_data_time: 0.0070   lr: 5e-07  max_mem: 3029M
[03/05 14:18:13] d2.utils.events INFO:  eta: 0:17:31  iter: 48319  total_loss: 2.318  loss_ce: 0.2045  loss_giou: 0.2982  loss_bbox: 0.2481  loss_ce_0: 0.2409  loss_giou_0: 0.31  loss_bbox_0: 0.2523  loss_rpn_cls: 0.1615  loss_rpn_reg: 0.4214  time: 0.1889  last_time: 0.2208  data_time: 0.0047  last_data_time: 0.0056   lr: 5e-07  max_mem: 3029M
[03/05 14:18:17] d2.utils.events INFO:  eta: 0:17:28  iter: 48339  total_loss: 2.31  loss_ce: 0.3259  loss_giou: 0.2839  loss_bbox: 0.251  loss_ce_0: 0.3548  loss_giou_0: 0.2841  loss_bbox_0: 0.2652  loss_rpn_cls: 0.1891  loss_rpn_reg: 0.4287  time: 0.1889  last_time: 0.1878  data_time: 0.0048  last_data_time: 0.0032   lr: 5e-07  max_mem: 3029M
[03/05 14:18:21] d2.utils.events INFO:  eta: 0:17:25  iter: 48359  total_loss: 2.442  loss_ce: 0.2882  loss_giou: 0.2944  loss_bbox: 0.2086  loss_ce_0: 0.3279  loss_giou_0: 0.3103  loss_bbox_0: 0.2451  loss_rpn_cls: 0.2105  loss_rpn_reg: 0.4378  time: 0.1889  last_time: 0.2044  data_time: 0.0054  last_data_time: 0.0082   lr: 5e-07  max_mem: 3029M
[03/05 14:18:25] d2.utils.events INFO:  eta: 0:17:21  iter: 48379  total_loss: 2.39  loss_ce: 0.258  loss_giou: 0.2752  loss_bbox: 0.2396  loss_ce_0: 0.3014  loss_giou_0: 0.2905  loss_bbox_0: 0.2522  loss_rpn_cls: 0.1717  loss_rpn_reg: 0.4207  time: 0.1889  last_time: 0.1573  data_time: 0.0049  last_data_time: 0.0047   lr: 5e-07  max_mem: 3029M
[03/05 14:18:28] d2.utils.events INFO:  eta: 0:17:17  iter: 48399  total_loss: 2.364  loss_ce: 0.2927  loss_giou: 0.2897  loss_bbox: 0.2538  loss_ce_0: 0.3443  loss_giou_0: 0.3182  loss_bbox_0: 0.2719  loss_rpn_cls: 0.167  loss_rpn_reg: 0.4256  time: 0.1889  last_time: 0.1916  data_time: 0.0052  last_data_time: 0.0039   lr: 5e-07  max_mem: 3029M
[03/05 14:18:32] d2.utils.events INFO:  eta: 0:17:14  iter: 48419  total_loss: 2.352  loss_ce: 0.2673  loss_giou: 0.3255  loss_bbox: 0.1746  loss_ce_0: 0.3194  loss_giou_0: 0.3384  loss_bbox_0: 0.1888  loss_rpn_cls: 0.2064  loss_rpn_reg: 0.4474  time: 0.1889  last_time: 0.1897  data_time: 0.0052  last_data_time: 0.0049   lr: 5e-07  max_mem: 3029M
[03/05 14:18:36] d2.utils.events INFO:  eta: 0:17:11  iter: 48439  total_loss: 2.235  loss_ce: 0.2508  loss_giou: 0.2986  loss_bbox: 0.2294  loss_ce_0: 0.2961  loss_giou_0: 0.3332  loss_bbox_0: 0.254  loss_rpn_cls: 0.2058  loss_rpn_reg: 0.4071  time: 0.1889  last_time: 0.2087  data_time: 0.0044  last_data_time: 0.0033   lr: 5e-07  max_mem: 3029M
[03/05 14:18:40] d2.utils.events INFO:  eta: 0:17:08  iter: 48459  total_loss: 2.108  loss_ce: 0.2457  loss_giou: 0.2745  loss_bbox: 0.179  loss_ce_0: 0.2795  loss_giou_0: 0.292  loss_bbox_0: 0.2036  loss_rpn_cls: 0.1744  loss_rpn_reg: 0.4109  time: 0.1889  last_time: 0.2017  data_time: 0.0044  last_data_time: 0.0037   lr: 5e-07  max_mem: 3029M
[03/05 14:18:44] d2.utils.events INFO:  eta: 0:17:05  iter: 48479  total_loss: 2.018  loss_ce: 0.2441  loss_giou: 0.2568  loss_bbox: 0.1833  loss_ce_0: 0.2899  loss_giou_0: 0.278  loss_bbox_0: 0.2074  loss_rpn_cls: 0.1517  loss_rpn_reg: 0.4132  time: 0.1889  last_time: 0.2209  data_time: 0.0047  last_data_time: 0.0043   lr: 5e-07  max_mem: 3029M
[03/05 14:18:47] d2.utils.events INFO:  eta: 0:17:02  iter: 48499  total_loss: 2.536  loss_ce: 0.2852  loss_giou: 0.3375  loss_bbox: 0.2373  loss_ce_0: 0.3119  loss_giou_0: 0.3537  loss_bbox_0: 0.2404  loss_rpn_cls: 0.2154  loss_rpn_reg: 0.4545  time: 0.1889  last_time: 0.1973  data_time: 0.0048  last_data_time: 0.0043   lr: 5e-07  max_mem: 3029M
[03/05 14:18:51] d2.utils.events INFO:  eta: 0:16:59  iter: 48519  total_loss: 2.239  loss_ce: 0.2117  loss_giou: 0.2953  loss_bbox: 0.2119  loss_ce_0: 0.2618  loss_giou_0: 0.3189  loss_bbox_0: 0.2292  loss_rpn_cls: 0.1876  loss_rpn_reg: 0.4097  time: 0.1889  last_time: 0.2060  data_time: 0.0055  last_data_time: 0.0047   lr: 5e-07  max_mem: 3029M
[03/05 14:18:55] d2.utils.events INFO:  eta: 0:16:55  iter: 48539  total_loss: 2.038  loss_ce: 0.2292  loss_giou: 0.2477  loss_bbox: 0.2139  loss_ce_0: 0.2644  loss_giou_0: 0.255  loss_bbox_0: 0.2437  loss_rpn_cls: 0.1632  loss_rpn_reg: 0.3857  time: 0.1889  last_time: 0.1740  data_time: 0.0047  last_data_time: 0.0035   lr: 5e-07  max_mem: 3029M
[03/05 14:18:59] d2.utils.events INFO:  eta: 0:16:52  iter: 48559  total_loss: 2.238  loss_ce: 0.3306  loss_giou: 0.2703  loss_bbox: 0.1866  loss_ce_0: 0.3486  loss_giou_0: 0.2807  loss_bbox_0: 0.2054  loss_rpn_cls: 0.1809  loss_rpn_reg: 0.4317  time: 0.1889  last_time: 0.1888  data_time: 0.0048  last_data_time: 0.0053   lr: 5e-07  max_mem: 3029M
[03/05 14:19:03] d2.utils.events INFO:  eta: 0:16:48  iter: 48579  total_loss: 2.143  loss_ce: 0.2079  loss_giou: 0.2646  loss_bbox: 0.1968  loss_ce_0: 0.294  loss_giou_0: 0.2657  loss_bbox_0: 0.2175  loss_rpn_cls: 0.1686  loss_rpn_reg: 0.4038  time: 0.1889  last_time: 0.2032  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-07  max_mem: 3029M
[03/05 14:19:07] d2.utils.events INFO:  eta: 0:16:47  iter: 48599  total_loss: 2.309  loss_ce: 0.2906  loss_giou: 0.2658  loss_bbox: 0.2144  loss_ce_0: 0.3134  loss_giou_0: 0.2774  loss_bbox_0: 0.2421  loss_rpn_cls: 0.1958  loss_rpn_reg: 0.4391  time: 0.1889  last_time: 0.1940  data_time: 0.0049  last_data_time: 0.0034   lr: 5e-07  max_mem: 3029M
[03/05 14:19:11] d2.utils.events INFO:  eta: 0:16:45  iter: 48619  total_loss: 2.351  loss_ce: 0.3349  loss_giou: 0.2958  loss_bbox: 0.2116  loss_ce_0: 0.3532  loss_giou_0: 0.2995  loss_bbox_0: 0.2363  loss_rpn_cls: 0.1871  loss_rpn_reg: 0.4481  time: 0.1889  last_time: 0.2088  data_time: 0.0057  last_data_time: 0.0071   lr: 5e-07  max_mem: 3029M
[03/05 14:19:14] d2.utils.events INFO:  eta: 0:16:40  iter: 48639  total_loss: 2.317  loss_ce: 0.2811  loss_giou: 0.2929  loss_bbox: 0.2416  loss_ce_0: 0.3165  loss_giou_0: 0.3075  loss_bbox_0: 0.2649  loss_rpn_cls: 0.1946  loss_rpn_reg: 0.4113  time: 0.1889  last_time: 0.1806  data_time: 0.0052  last_data_time: 0.0040   lr: 5e-07  max_mem: 3029M
[03/05 14:19:18] d2.utils.events INFO:  eta: 0:16:36  iter: 48659  total_loss: 2.275  loss_ce: 0.2084  loss_giou: 0.3039  loss_bbox: 0.2646  loss_ce_0: 0.3362  loss_giou_0: 0.2931  loss_bbox_0: 0.2529  loss_rpn_cls: 0.2041  loss_rpn_reg: 0.3843  time: 0.1889  last_time: 0.1785  data_time: 0.0049  last_data_time: 0.0052   lr: 5e-07  max_mem: 3029M
[03/05 14:19:22] d2.utils.events INFO:  eta: 0:16:32  iter: 48679  total_loss: 2.199  loss_ce: 0.2411  loss_giou: 0.287  loss_bbox: 0.2163  loss_ce_0: 0.3031  loss_giou_0: 0.2885  loss_bbox_0: 0.2343  loss_rpn_cls: 0.1601  loss_rpn_reg: 0.4209  time: 0.1889  last_time: 0.1838  data_time: 0.0048  last_data_time: 0.0048   lr: 5e-07  max_mem: 3029M
[03/05 14:19:26] d2.utils.events INFO:  eta: 0:16:29  iter: 48699  total_loss: 2.364  loss_ce: 0.2482  loss_giou: 0.2891  loss_bbox: 0.2528  loss_ce_0: 0.3093  loss_giou_0: 0.2965  loss_bbox_0: 0.2742  loss_rpn_cls: 0.1751  loss_rpn_reg: 0.4255  time: 0.1889  last_time: 0.2366  data_time: 0.0056  last_data_time: 0.0054   lr: 5e-07  max_mem: 3029M
[03/05 14:19:30] d2.utils.events INFO:  eta: 0:16:27  iter: 48719  total_loss: 2.209  loss_ce: 0.272  loss_giou: 0.2901  loss_bbox: 0.2272  loss_ce_0: 0.342  loss_giou_0: 0.322  loss_bbox_0: 0.2404  loss_rpn_cls: 0.181  loss_rpn_reg: 0.4172  time: 0.1889  last_time: 0.1867  data_time: 0.0051  last_data_time: 0.0067   lr: 5e-07  max_mem: 3029M
[03/05 14:19:34] d2.utils.events INFO:  eta: 0:16:25  iter: 48739  total_loss: 2.176  loss_ce: 0.2352  loss_giou: 0.2583  loss_bbox: 0.2046  loss_ce_0: 0.2937  loss_giou_0: 0.2633  loss_bbox_0: 0.2608  loss_rpn_cls: 0.1652  loss_rpn_reg: 0.3971  time: 0.1889  last_time: 0.2075  data_time: 0.0050  last_data_time: 0.0070   lr: 5e-07  max_mem: 3029M
[03/05 14:19:38] d2.utils.events INFO:  eta: 0:16:21  iter: 48759  total_loss: 2.124  loss_ce: 0.2661  loss_giou: 0.3005  loss_bbox: 0.2044  loss_ce_0: 0.3264  loss_giou_0: 0.304  loss_bbox_0: 0.2192  loss_rpn_cls: 0.1648  loss_rpn_reg: 0.4402  time: 0.1889  last_time: 0.1847  data_time: 0.0051  last_data_time: 0.0039   lr: 5e-07  max_mem: 3029M
[03/05 14:19:41] d2.utils.events INFO:  eta: 0:16:17  iter: 48779  total_loss: 2.31  loss_ce: 0.2422  loss_giou: 0.256  loss_bbox: 0.2474  loss_ce_0: 0.2674  loss_giou_0: 0.3014  loss_bbox_0: 0.2615  loss_rpn_cls: 0.1692  loss_rpn_reg: 0.4014  time: 0.1889  last_time: 0.1783  data_time: 0.0049  last_data_time: 0.0062   lr: 5e-07  max_mem: 3029M
[03/05 14:19:45] d2.utils.events INFO:  eta: 0:16:13  iter: 48799  total_loss: 2.388  loss_ce: 0.3024  loss_giou: 0.3051  loss_bbox: 0.2178  loss_ce_0: 0.3113  loss_giou_0: 0.3111  loss_bbox_0: 0.22  loss_rpn_cls: 0.1857  loss_rpn_reg: 0.4125  time: 0.1889  last_time: 0.1870  data_time: 0.0049  last_data_time: 0.0041   lr: 5e-07  max_mem: 3029M
[03/05 14:19:49] d2.utils.events INFO:  eta: 0:16:10  iter: 48819  total_loss: 2.224  loss_ce: 0.2921  loss_giou: 0.2345  loss_bbox: 0.2178  loss_ce_0: 0.3464  loss_giou_0: 0.2785  loss_bbox_0: 0.2317  loss_rpn_cls: 0.1657  loss_rpn_reg: 0.4346  time: 0.1889  last_time: 0.2079  data_time: 0.0053  last_data_time: 0.0032   lr: 5e-07  max_mem: 3029M
[03/05 14:19:53] d2.utils.events INFO:  eta: 0:16:08  iter: 48839  total_loss: 2.142  loss_ce: 0.2413  loss_giou: 0.2414  loss_bbox: 0.2289  loss_ce_0: 0.3141  loss_giou_0: 0.2508  loss_bbox_0: 0.244  loss_rpn_cls: 0.2019  loss_rpn_reg: 0.3945  time: 0.1889  last_time: 0.2058  data_time: 0.0051  last_data_time: 0.0065   lr: 5e-07  max_mem: 3029M
[03/05 14:19:57] d2.utils.events INFO:  eta: 0:16:05  iter: 48859  total_loss: 2.365  loss_ce: 0.3031  loss_giou: 0.3501  loss_bbox: 0.2455  loss_ce_0: 0.3111  loss_giou_0: 0.378  loss_bbox_0: 0.2818  loss_rpn_cls: 0.183  loss_rpn_reg: 0.4259  time: 0.1889  last_time: 0.2002  data_time: 0.0045  last_data_time: 0.0038   lr: 5e-07  max_mem: 3029M
[03/05 14:20:01] d2.utils.events INFO:  eta: 0:16:01  iter: 48879  total_loss: 2.335  loss_ce: 0.2651  loss_giou: 0.282  loss_bbox: 0.211  loss_ce_0: 0.3328  loss_giou_0: 0.3304  loss_bbox_0: 0.2368  loss_rpn_cls: 0.1904  loss_rpn_reg: 0.4039  time: 0.1889  last_time: 0.2128  data_time: 0.0056  last_data_time: 0.0072   lr: 5e-07  max_mem: 3029M
[03/05 14:20:05] d2.utils.events INFO:  eta: 0:15:59  iter: 48899  total_loss: 2.217  loss_ce: 0.258  loss_giou: 0.2805  loss_bbox: 0.1993  loss_ce_0: 0.3026  loss_giou_0: 0.291  loss_bbox_0: 0.2209  loss_rpn_cls: 0.1952  loss_rpn_reg: 0.3948  time: 0.1889  last_time: 0.1745  data_time: 0.0046  last_data_time: 0.0036   lr: 5e-07  max_mem: 3029M
[03/05 14:20:09] d2.utils.events INFO:  eta: 0:15:56  iter: 48919  total_loss: 2.106  loss_ce: 0.2716  loss_giou: 0.2813  loss_bbox: 0.2054  loss_ce_0: 0.3027  loss_giou_0: 0.2874  loss_bbox_0: 0.23  loss_rpn_cls: 0.167  loss_rpn_reg: 0.4163  time: 0.1889  last_time: 0.2031  data_time: 0.0050  last_data_time: 0.0045   lr: 5e-07  max_mem: 3029M
[03/05 14:20:12] d2.utils.events INFO:  eta: 0:15:53  iter: 48939  total_loss: 2.389  loss_ce: 0.2766  loss_giou: 0.3125  loss_bbox: 0.2358  loss_ce_0: 0.2902  loss_giou_0: 0.3068  loss_bbox_0: 0.235  loss_rpn_cls: 0.1801  loss_rpn_reg: 0.4469  time: 0.1889  last_time: 0.1705  data_time: 0.0046  last_data_time: 0.0051   lr: 5e-07  max_mem: 3029M
[03/05 14:20:16] d2.utils.events INFO:  eta: 0:15:50  iter: 48959  total_loss: 2.174  loss_ce: 0.2572  loss_giou: 0.2846  loss_bbox: 0.1989  loss_ce_0: 0.3025  loss_giou_0: 0.3015  loss_bbox_0: 0.2431  loss_rpn_cls: 0.1735  loss_rpn_reg: 0.4206  time: 0.1889  last_time: 0.1660  data_time: 0.0050  last_data_time: 0.0057   lr: 5e-07  max_mem: 3029M
[03/05 14:20:20] d2.utils.events INFO:  eta: 0:15:47  iter: 48979  total_loss: 1.97  loss_ce: 0.2361  loss_giou: 0.2528  loss_bbox: 0.1647  loss_ce_0: 0.2721  loss_giou_0: 0.2559  loss_bbox_0: 0.1942  loss_rpn_cls: 0.1796  loss_rpn_reg: 0.3917  time: 0.1889  last_time: 0.1877  data_time: 0.0057  last_data_time: 0.0038   lr: 5e-07  max_mem: 3029M
[03/05 14:20:24] d2.utils.events INFO:  eta: 0:15:43  iter: 48999  total_loss: 1.868  loss_ce: 0.2167  loss_giou: 0.2531  loss_bbox: 0.1971  loss_ce_0: 0.2771  loss_giou_0: 0.2643  loss_bbox_0: 0.1908  loss_rpn_cls: 0.1743  loss_rpn_reg: 0.3755  time: 0.1889  last_time: 0.1904  data_time: 0.0050  last_data_time: 0.0040   lr: 5e-07  max_mem: 3029M
[03/05 14:20:28] d2.utils.events INFO:  eta: 0:15:39  iter: 49019  total_loss: 2.354  loss_ce: 0.2992  loss_giou: 0.2848  loss_bbox: 0.2374  loss_ce_0: 0.334  loss_giou_0: 0.3044  loss_bbox_0: 0.2762  loss_rpn_cls: 0.1838  loss_rpn_reg: 0.4138  time: 0.1889  last_time: 0.1858  data_time: 0.0050  last_data_time: 0.0060   lr: 5e-07  max_mem: 3029M
[03/05 14:20:32] d2.utils.events INFO:  eta: 0:15:36  iter: 49039  total_loss: 2.25  loss_ce: 0.2816  loss_giou: 0.249  loss_bbox: 0.1971  loss_ce_0: 0.332  loss_giou_0: 0.2653  loss_bbox_0: 0.2282  loss_rpn_cls: 0.1691  loss_rpn_reg: 0.4023  time: 0.1889  last_time: 0.1953  data_time: 0.0054  last_data_time: 0.0062   lr: 5e-07  max_mem: 3029M
[03/05 14:20:36] d2.utils.events INFO:  eta: 0:15:33  iter: 49059  total_loss: 2.287  loss_ce: 0.1998  loss_giou: 0.2594  loss_bbox: 0.2657  loss_ce_0: 0.2875  loss_giou_0: 0.2754  loss_bbox_0: 0.2891  loss_rpn_cls: 0.1504  loss_rpn_reg: 0.4255  time: 0.1889  last_time: 0.2016  data_time: 0.0050  last_data_time: 0.0054   lr: 5e-07  max_mem: 3029M
[03/05 14:20:40] d2.utils.events INFO:  eta: 0:15:30  iter: 49079  total_loss: 2.222  loss_ce: 0.2781  loss_giou: 0.3163  loss_bbox: 0.2168  loss_ce_0: 0.3131  loss_giou_0: 0.3233  loss_bbox_0: 0.2296  loss_rpn_cls: 0.1936  loss_rpn_reg: 0.4053  time: 0.1889  last_time: 0.1922  data_time: 0.0047  last_data_time: 0.0087   lr: 5e-07  max_mem: 3029M
[03/05 14:20:44] d2.utils.events INFO:  eta: 0:15:27  iter: 49099  total_loss: 2.14  loss_ce: 0.2262  loss_giou: 0.2891  loss_bbox: 0.1978  loss_ce_0: 0.2646  loss_giou_0: 0.288  loss_bbox_0: 0.2019  loss_rpn_cls: 0.167  loss_rpn_reg: 0.4116  time: 0.1889  last_time: 0.1941  data_time: 0.0051  last_data_time: 0.0045   lr: 5e-07  max_mem: 3029M
[03/05 14:20:48] d2.utils.events INFO:  eta: 0:15:23  iter: 49119  total_loss: 2.232  loss_ce: 0.2382  loss_giou: 0.2381  loss_bbox: 0.2403  loss_ce_0: 0.3026  loss_giou_0: 0.2412  loss_bbox_0: 0.2483  loss_rpn_cls: 0.1682  loss_rpn_reg: 0.418  time: 0.1889  last_time: 0.1717  data_time: 0.0043  last_data_time: 0.0063   lr: 5e-07  max_mem: 3029M
[03/05 14:20:51] d2.utils.events INFO:  eta: 0:15:20  iter: 49139  total_loss: 2.196  loss_ce: 0.2848  loss_giou: 0.2691  loss_bbox: 0.2035  loss_ce_0: 0.3009  loss_giou_0: 0.286  loss_bbox_0: 0.2154  loss_rpn_cls: 0.1775  loss_rpn_reg: 0.415  time: 0.1889  last_time: 0.1787  data_time: 0.0050  last_data_time: 0.0030   lr: 5e-07  max_mem: 3029M
[03/05 14:20:55] d2.utils.events INFO:  eta: 0:15:16  iter: 49159  total_loss: 2.317  loss_ce: 0.2892  loss_giou: 0.2631  loss_bbox: 0.2299  loss_ce_0: 0.3335  loss_giou_0: 0.2758  loss_bbox_0: 0.2417  loss_rpn_cls: 0.1744  loss_rpn_reg: 0.4053  time: 0.1889  last_time: 0.1842  data_time: 0.0053  last_data_time: 0.0036   lr: 5e-07  max_mem: 3029M
[03/05 14:20:59] d2.utils.events INFO:  eta: 0:15:12  iter: 49179  total_loss: 2.129  loss_ce: 0.2415  loss_giou: 0.2634  loss_bbox: 0.2054  loss_ce_0: 0.3009  loss_giou_0: 0.2916  loss_bbox_0: 0.2295  loss_rpn_cls: 0.1851  loss_rpn_reg: 0.3768  time: 0.1889  last_time: 0.1848  data_time: 0.0057  last_data_time: 0.0047   lr: 5e-07  max_mem: 3029M
[03/05 14:21:03] d2.utils.events INFO:  eta: 0:15:10  iter: 49199  total_loss: 2.081  loss_ce: 0.2569  loss_giou: 0.2754  loss_bbox: 0.2087  loss_ce_0: 0.2911  loss_giou_0: 0.2589  loss_bbox_0: 0.2242  loss_rpn_cls: 0.1685  loss_rpn_reg: 0.3855  time: 0.1889  last_time: 0.1965  data_time: 0.0055  last_data_time: 0.0048   lr: 5e-07  max_mem: 3029M
[03/05 14:21:07] d2.utils.events INFO:  eta: 0:15:05  iter: 49219  total_loss: 2.382  loss_ce: 0.2664  loss_giou: 0.3185  loss_bbox: 0.2311  loss_ce_0: 0.3477  loss_giou_0: 0.3374  loss_bbox_0: 0.2373  loss_rpn_cls: 0.1991  loss_rpn_reg: 0.443  time: 0.1889  last_time: 0.1645  data_time: 0.0058  last_data_time: 0.0092   lr: 5e-07  max_mem: 3029M
[03/05 14:21:11] d2.utils.events INFO:  eta: 0:15:01  iter: 49239  total_loss: 2.186  loss_ce: 0.2555  loss_giou: 0.2835  loss_bbox: 0.2339  loss_ce_0: 0.2919  loss_giou_0: 0.3021  loss_bbox_0: 0.2563  loss_rpn_cls: 0.1806  loss_rpn_reg: 0.4041  time: 0.1889  last_time: 0.2024  data_time: 0.0051  last_data_time: 0.0053   lr: 5e-07  max_mem: 3029M
[03/05 14:21:15] d2.utils.events INFO:  eta: 0:14:57  iter: 49259  total_loss: 2.243  loss_ce: 0.237  loss_giou: 0.3287  loss_bbox: 0.2162  loss_ce_0: 0.2969  loss_giou_0: 0.3312  loss_bbox_0: 0.2419  loss_rpn_cls: 0.1688  loss_rpn_reg: 0.422  time: 0.1889  last_time: 0.1763  data_time: 0.0048  last_data_time: 0.0053   lr: 5e-07  max_mem: 3029M
[03/05 14:21:18] d2.utils.events INFO:  eta: 0:14:55  iter: 49279  total_loss: 2.171  loss_ce: 0.2473  loss_giou: 0.2922  loss_bbox: 0.2244  loss_ce_0: 0.2807  loss_giou_0: 0.3222  loss_bbox_0: 0.254  loss_rpn_cls: 0.1674  loss_rpn_reg: 0.3815  time: 0.1889  last_time: 0.1947  data_time: 0.0056  last_data_time: 0.0036   lr: 5e-07  max_mem: 3029M
[03/05 14:21:22] d2.utils.events INFO:  eta: 0:14:51  iter: 49299  total_loss: 2.108  loss_ce: 0.2332  loss_giou: 0.2793  loss_bbox: 0.2026  loss_ce_0: 0.2862  loss_giou_0: 0.2889  loss_bbox_0: 0.2344  loss_rpn_cls: 0.1694  loss_rpn_reg: 0.3908  time: 0.1889  last_time: 0.1793  data_time: 0.0056  last_data_time: 0.0037   lr: 5e-07  max_mem: 3029M
[03/05 14:21:26] d2.utils.events INFO:  eta: 0:14:48  iter: 49319  total_loss: 2.172  loss_ce: 0.2408  loss_giou: 0.2968  loss_bbox: 0.2132  loss_ce_0: 0.3004  loss_giou_0: 0.3048  loss_bbox_0: 0.2369  loss_rpn_cls: 0.1822  loss_rpn_reg: 0.4129  time: 0.1889  last_time: 0.2122  data_time: 0.0055  last_data_time: 0.0068   lr: 5e-07  max_mem: 3029M
[03/05 14:21:30] d2.utils.events INFO:  eta: 0:14:44  iter: 49339  total_loss: 2.11  loss_ce: 0.2196  loss_giou: 0.2839  loss_bbox: 0.1915  loss_ce_0: 0.2685  loss_giou_0: 0.2934  loss_bbox_0: 0.2095  loss_rpn_cls: 0.1489  loss_rpn_reg: 0.4202  time: 0.1889  last_time: 0.2074  data_time: 0.0050  last_data_time: 0.0035   lr: 5e-07  max_mem: 3029M
[03/05 14:21:34] d2.utils.events INFO:  eta: 0:14:40  iter: 49359  total_loss: 2.066  loss_ce: 0.2181  loss_giou: 0.2642  loss_bbox: 0.2366  loss_ce_0: 0.261  loss_giou_0: 0.2921  loss_bbox_0: 0.2959  loss_rpn_cls: 0.1529  loss_rpn_reg: 0.4021  time: 0.1889  last_time: 0.1942  data_time: 0.0055  last_data_time: 0.0074   lr: 5e-07  max_mem: 3029M
[03/05 14:21:38] d2.utils.events INFO:  eta: 0:14:37  iter: 49379  total_loss: 2.251  loss_ce: 0.2645  loss_giou: 0.2486  loss_bbox: 0.2332  loss_ce_0: 0.3164  loss_giou_0: 0.2782  loss_bbox_0: 0.2733  loss_rpn_cls: 0.2197  loss_rpn_reg: 0.4043  time: 0.1889  last_time: 0.2125  data_time: 0.0054  last_data_time: 0.0052   lr: 5e-07  max_mem: 3029M
[03/05 14:21:42] d2.utils.events INFO:  eta: 0:14:35  iter: 49399  total_loss: 2.238  loss_ce: 0.2759  loss_giou: 0.3155  loss_bbox: 0.2094  loss_ce_0: 0.3254  loss_giou_0: 0.3238  loss_bbox_0: 0.2355  loss_rpn_cls: 0.1755  loss_rpn_reg: 0.4245  time: 0.1889  last_time: 0.2003  data_time: 0.0051  last_data_time: 0.0056   lr: 5e-07  max_mem: 3029M
[03/05 14:21:46] d2.utils.events INFO:  eta: 0:14:32  iter: 49419  total_loss: 2.158  loss_ce: 0.2569  loss_giou: 0.3022  loss_bbox: 0.2262  loss_ce_0: 0.2912  loss_giou_0: 0.3243  loss_bbox_0: 0.234  loss_rpn_cls: 0.1658  loss_rpn_reg: 0.4399  time: 0.1889  last_time: 0.2136  data_time: 0.0046  last_data_time: 0.0041   lr: 5e-07  max_mem: 3029M
[03/05 14:21:50] d2.utils.events INFO:  eta: 0:14:28  iter: 49439  total_loss: 2.26  loss_ce: 0.2637  loss_giou: 0.3095  loss_bbox: 0.2393  loss_ce_0: 0.2998  loss_giou_0: 0.3083  loss_bbox_0: 0.2663  loss_rpn_cls: 0.1637  loss_rpn_reg: 0.4153  time: 0.1889  last_time: 0.1565  data_time: 0.0045  last_data_time: 0.0045   lr: 5e-07  max_mem: 3029M
[03/05 14:21:53] d2.utils.events INFO:  eta: 0:14:24  iter: 49459  total_loss: 2.238  loss_ce: 0.315  loss_giou: 0.2623  loss_bbox: 0.2298  loss_ce_0: 0.349  loss_giou_0: 0.2823  loss_bbox_0: 0.2745  loss_rpn_cls: 0.1888  loss_rpn_reg: 0.4455  time: 0.1889  last_time: 0.1588  data_time: 0.0049  last_data_time: 0.0021   lr: 5e-07  max_mem: 3029M
[03/05 14:21:57] d2.utils.events INFO:  eta: 0:14:21  iter: 49479  total_loss: 2.368  loss_ce: 0.2994  loss_giou: 0.3185  loss_bbox: 0.2128  loss_ce_0: 0.3363  loss_giou_0: 0.3309  loss_bbox_0: 0.2355  loss_rpn_cls: 0.1741  loss_rpn_reg: 0.4327  time: 0.1889  last_time: 0.1729  data_time: 0.0059  last_data_time: 0.0050   lr: 5e-07  max_mem: 3029M
[03/05 14:22:01] d2.utils.events INFO:  eta: 0:14:16  iter: 49499  total_loss: 2.135  loss_ce: 0.2022  loss_giou: 0.2787  loss_bbox: 0.185  loss_ce_0: 0.2933  loss_giou_0: 0.302  loss_bbox_0: 0.2026  loss_rpn_cls: 0.1915  loss_rpn_reg: 0.4187  time: 0.1889  last_time: 0.1658  data_time: 0.0051  last_data_time: 0.0077   lr: 5e-07  max_mem: 3029M
[03/05 14:22:05] d2.utils.events INFO:  eta: 0:14:12  iter: 49519  total_loss: 2.359  loss_ce: 0.2858  loss_giou: 0.2476  loss_bbox: 0.2234  loss_ce_0: 0.4016  loss_giou_0: 0.264  loss_bbox_0: 0.2481  loss_rpn_cls: 0.1765  loss_rpn_reg: 0.4276  time: 0.1889  last_time: 0.2060  data_time: 0.0049  last_data_time: 0.0036   lr: 5e-07  max_mem: 3029M
[03/05 14:22:09] d2.utils.events INFO:  eta: 0:14:09  iter: 49539  total_loss: 2.333  loss_ce: 0.2418  loss_giou: 0.321  loss_bbox: 0.2384  loss_ce_0: 0.3064  loss_giou_0: 0.3188  loss_bbox_0: 0.2427  loss_rpn_cls: 0.1854  loss_rpn_reg: 0.4478  time: 0.1889  last_time: 0.1854  data_time: 0.0050  last_data_time: 0.0058   lr: 5e-07  max_mem: 3029M
[03/05 14:22:13] d2.utils.events INFO:  eta: 0:14:05  iter: 49559  total_loss: 2.17  loss_ce: 0.2609  loss_giou: 0.293  loss_bbox: 0.2181  loss_ce_0: 0.291  loss_giou_0: 0.314  loss_bbox_0: 0.2402  loss_rpn_cls: 0.1902  loss_rpn_reg: 0.4048  time: 0.1890  last_time: 0.2144  data_time: 0.0057  last_data_time: 0.0044   lr: 5e-07  max_mem: 3029M
[03/05 14:22:17] d2.utils.events INFO:  eta: 0:14:02  iter: 49579  total_loss: 2.078  loss_ce: 0.2378  loss_giou: 0.2353  loss_bbox: 0.2015  loss_ce_0: 0.2712  loss_giou_0: 0.2606  loss_bbox_0: 0.2163  loss_rpn_cls: 0.1714  loss_rpn_reg: 0.3751  time: 0.1890  last_time: 0.1763  data_time: 0.0048  last_data_time: 0.0045   lr: 5e-07  max_mem: 3029M
[03/05 14:22:20] d2.utils.events INFO:  eta: 0:13:58  iter: 49599  total_loss: 1.982  loss_ce: 0.2118  loss_giou: 0.2848  loss_bbox: 0.2  loss_ce_0: 0.263  loss_giou_0: 0.3052  loss_bbox_0: 0.2181  loss_rpn_cls: 0.1517  loss_rpn_reg: 0.4113  time: 0.1890  last_time: 0.1888  data_time: 0.0048  last_data_time: 0.0047   lr: 5e-07  max_mem: 3029M
[03/05 14:22:25] d2.utils.events INFO:  eta: 0:13:54  iter: 49619  total_loss: 2.126  loss_ce: 0.2699  loss_giou: 0.2804  loss_bbox: 0.2013  loss_ce_0: 0.3143  loss_giou_0: 0.2932  loss_bbox_0: 0.2076  loss_rpn_cls: 0.1946  loss_rpn_reg: 0.4024  time: 0.1890  last_time: 0.1949  data_time: 0.0052  last_data_time: 0.0044   lr: 5e-07  max_mem: 3029M
[03/05 14:22:29] d2.utils.events INFO:  eta: 0:13:51  iter: 49639  total_loss: 2.354  loss_ce: 0.2509  loss_giou: 0.2414  loss_bbox: 0.2235  loss_ce_0: 0.3471  loss_giou_0: 0.2621  loss_bbox_0: 0.2496  loss_rpn_cls: 0.2001  loss_rpn_reg: 0.3878  time: 0.1890  last_time: 0.1947  data_time: 0.0056  last_data_time: 0.0036   lr: 5e-07  max_mem: 3029M
[03/05 14:22:32] d2.utils.events INFO:  eta: 0:13:48  iter: 49659  total_loss: 2.229  loss_ce: 0.2843  loss_giou: 0.2646  loss_bbox: 0.2323  loss_ce_0: 0.3149  loss_giou_0: 0.2957  loss_bbox_0: 0.27  loss_rpn_cls: 0.1961  loss_rpn_reg: 0.4249  time: 0.1890  last_time: 0.2105  data_time: 0.0058  last_data_time: 0.0038   lr: 5e-07  max_mem: 3029M
[03/05 14:22:36] d2.utils.events INFO:  eta: 0:13:44  iter: 49679  total_loss: 2.144  loss_ce: 0.2507  loss_giou: 0.2774  loss_bbox: 0.198  loss_ce_0: 0.2693  loss_giou_0: 0.2994  loss_bbox_0: 0.2439  loss_rpn_cls: 0.1595  loss_rpn_reg: 0.4183  time: 0.1890  last_time: 0.2035  data_time: 0.0055  last_data_time: 0.0034   lr: 5e-07  max_mem: 3029M
[03/05 14:22:40] d2.utils.events INFO:  eta: 0:13:41  iter: 49699  total_loss: 2.5  loss_ce: 0.3337  loss_giou: 0.2533  loss_bbox: 0.1869  loss_ce_0: 0.358  loss_giou_0: 0.2775  loss_bbox_0: 0.2307  loss_rpn_cls: 0.1833  loss_rpn_reg: 0.4147  time: 0.1890  last_time: 0.1862  data_time: 0.0048  last_data_time: 0.0035   lr: 5e-07  max_mem: 3029M
[03/05 14:22:44] d2.utils.events INFO:  eta: 0:13:37  iter: 49719  total_loss: 2.25  loss_ce: 0.2038  loss_giou: 0.3149  loss_bbox: 0.2412  loss_ce_0: 0.2731  loss_giou_0: 0.3307  loss_bbox_0: 0.2565  loss_rpn_cls: 0.1703  loss_rpn_reg: 0.4256  time: 0.1890  last_time: 0.1895  data_time: 0.0048  last_data_time: 0.0050   lr: 5e-07  max_mem: 3029M
[03/05 14:22:48] d2.utils.events INFO:  eta: 0:13:33  iter: 49739  total_loss: 2.101  loss_ce: 0.2377  loss_giou: 0.2831  loss_bbox: 0.1912  loss_ce_0: 0.3123  loss_giou_0: 0.278  loss_bbox_0: 0.2107  loss_rpn_cls: 0.1666  loss_rpn_reg: 0.4116  time: 0.1890  last_time: 0.1861  data_time: 0.0048  last_data_time: 0.0057   lr: 5e-07  max_mem: 3029M
[03/05 14:22:52] d2.utils.events INFO:  eta: 0:13:29  iter: 49759  total_loss: 2.439  loss_ce: 0.2797  loss_giou: 0.3203  loss_bbox: 0.2453  loss_ce_0: 0.3102  loss_giou_0: 0.3296  loss_bbox_0: 0.2834  loss_rpn_cls: 0.1872  loss_rpn_reg: 0.4644  time: 0.1890  last_time: 0.1853  data_time: 0.0055  last_data_time: 0.0047   lr: 5e-07  max_mem: 3029M
[03/05 14:22:56] d2.utils.events INFO:  eta: 0:13:25  iter: 49779  total_loss: 2.259  loss_ce: 0.2635  loss_giou: 0.3191  loss_bbox: 0.1966  loss_ce_0: 0.3233  loss_giou_0: 0.3235  loss_bbox_0: 0.2361  loss_rpn_cls: 0.1928  loss_rpn_reg: 0.4076  time: 0.1890  last_time: 0.1967  data_time: 0.0054  last_data_time: 0.0058   lr: 5e-07  max_mem: 3029M
[03/05 14:23:00] d2.utils.events INFO:  eta: 0:13:23  iter: 49799  total_loss: 2.051  loss_ce: 0.2218  loss_giou: 0.2232  loss_bbox: 0.1984  loss_ce_0: 0.2708  loss_giou_0: 0.262  loss_bbox_0: 0.2074  loss_rpn_cls: 0.1604  loss_rpn_reg: 0.3804  time: 0.1890  last_time: 0.2171  data_time: 0.0060  last_data_time: 0.0118   lr: 5e-07  max_mem: 3029M
[03/05 14:23:04] d2.utils.events INFO:  eta: 0:13:19  iter: 49819  total_loss: 2.336  loss_ce: 0.291  loss_giou: 0.2912  loss_bbox: 0.242  loss_ce_0: 0.3053  loss_giou_0: 0.2969  loss_bbox_0: 0.2586  loss_rpn_cls: 0.1826  loss_rpn_reg: 0.4079  time: 0.1890  last_time: 0.1924  data_time: 0.0057  last_data_time: 0.0031   lr: 5e-07  max_mem: 3029M
[03/05 14:23:08] d2.utils.events INFO:  eta: 0:13:14  iter: 49839  total_loss: 2.308  loss_ce: 0.2672  loss_giou: 0.277  loss_bbox: 0.2407  loss_ce_0: 0.3197  loss_giou_0: 0.2855  loss_bbox_0: 0.2609  loss_rpn_cls: 0.1708  loss_rpn_reg: 0.3856  time: 0.1890  last_time: 0.1690  data_time: 0.0051  last_data_time: 0.0039   lr: 5e-07  max_mem: 3029M
[03/05 14:23:11] d2.utils.events INFO:  eta: 0:13:09  iter: 49859  total_loss: 2.341  loss_ce: 0.1983  loss_giou: 0.2867  loss_bbox: 0.2692  loss_ce_0: 0.3319  loss_giou_0: 0.2841  loss_bbox_0: 0.2803  loss_rpn_cls: 0.1631  loss_rpn_reg: 0.418  time: 0.1890  last_time: 0.1913  data_time: 0.0051  last_data_time: 0.0043   lr: 5e-07  max_mem: 3029M
[03/05 14:23:15] d2.utils.events INFO:  eta: 0:13:05  iter: 49879  total_loss: 2.31  loss_ce: 0.3233  loss_giou: 0.2847  loss_bbox: 0.2105  loss_ce_0: 0.3408  loss_giou_0: 0.2997  loss_bbox_0: 0.2413  loss_rpn_cls: 0.1804  loss_rpn_reg: 0.4038  time: 0.1890  last_time: 0.1873  data_time: 0.0051  last_data_time: 0.0052   lr: 5e-07  max_mem: 3029M
[03/05 14:23:19] d2.utils.events INFO:  eta: 0:13:01  iter: 49899  total_loss: 2.49  loss_ce: 0.2788  loss_giou: 0.2896  loss_bbox: 0.2018  loss_ce_0: 0.3276  loss_giou_0: 0.2971  loss_bbox_0: 0.2438  loss_rpn_cls: 0.2029  loss_rpn_reg: 0.4286  time: 0.1890  last_time: 0.1841  data_time: 0.0057  last_data_time: 0.0039   lr: 5e-07  max_mem: 3029M
[03/05 14:23:23] d2.utils.events INFO:  eta: 0:12:57  iter: 49919  total_loss: 2.552  loss_ce: 0.3067  loss_giou: 0.3429  loss_bbox: 0.2539  loss_ce_0: 0.3344  loss_giou_0: 0.3627  loss_bbox_0: 0.2678  loss_rpn_cls: 0.2051  loss_rpn_reg: 0.4334  time: 0.1890  last_time: 0.1692  data_time: 0.0048  last_data_time: 0.0031   lr: 5e-07  max_mem: 3029M
[03/05 14:23:27] d2.utils.events INFO:  eta: 0:12:54  iter: 49939  total_loss: 2.407  loss_ce: 0.2757  loss_giou: 0.371  loss_bbox: 0.182  loss_ce_0: 0.322  loss_giou_0: 0.3685  loss_bbox_0: 0.2035  loss_rpn_cls: 0.2027  loss_rpn_reg: 0.441  time: 0.1890  last_time: 0.1790  data_time: 0.0046  last_data_time: 0.0046   lr: 5e-07  max_mem: 3029M
[03/05 14:23:30] d2.utils.events INFO:  eta: 0:12:49  iter: 49959  total_loss: 2.129  loss_ce: 0.2886  loss_giou: 0.256  loss_bbox: 0.1939  loss_ce_0: 0.3214  loss_giou_0: 0.2553  loss_bbox_0: 0.2072  loss_rpn_cls: 0.1674  loss_rpn_reg: 0.3917  time: 0.1890  last_time: 0.1991  data_time: 0.0054  last_data_time: 0.0082   lr: 5e-07  max_mem: 3029M
[03/05 14:23:34] d2.utils.events INFO:  eta: 0:12:46  iter: 49979  total_loss: 2.051  loss_ce: 0.1946  loss_giou: 0.2427  loss_bbox: 0.2324  loss_ce_0: 0.2883  loss_giou_0: 0.2659  loss_bbox_0: 0.2468  loss_rpn_cls: 0.1604  loss_rpn_reg: 0.3844  time: 0.1890  last_time: 0.1750  data_time: 0.0052  last_data_time: 0.0060   lr: 5e-07  max_mem: 3029M
[03/05 14:23:38] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/t1/model_0049999.pth
[03/05 14:23:40] d2.utils.events INFO:  eta: 0:12:43  iter: 49999  total_loss: 2.244  loss_ce: 0.2603  loss_giou: 0.2916  loss_bbox: 0.202  loss_ce_0: 0.2949  loss_giou_0: 0.3012  loss_bbox_0: 0.2309  loss_rpn_cls: 0.1919  loss_rpn_reg: 0.4213  time: 0.1890  last_time: 0.2021  data_time: 0.0058  last_data_time: 0.0062   lr: 5e-07  max_mem: 3029M
[03/05 14:23:43] d2.utils.events INFO:  eta: 0:12:39  iter: 50019  total_loss: 2.114  loss_ce: 0.2642  loss_giou: 0.245  loss_bbox: 0.1904  loss_ce_0: 0.2688  loss_giou_0: 0.2693  loss_bbox_0: 0.2132  loss_rpn_cls: 0.1748  loss_rpn_reg: 0.4081  time: 0.1890  last_time: 0.1713  data_time: 0.0056  last_data_time: 0.0079   lr: 5e-07  max_mem: 3029M
[03/05 14:23:47] d2.utils.events INFO:  eta: 0:12:35  iter: 50039  total_loss: 2.207  loss_ce: 0.2697  loss_giou: 0.3479  loss_bbox: 0.1939  loss_ce_0: 0.3014  loss_giou_0: 0.3696  loss_bbox_0: 0.2146  loss_rpn_cls: 0.1835  loss_rpn_reg: 0.4308  time: 0.1890  last_time: 0.2240  data_time: 0.0055  last_data_time: 0.0046   lr: 5e-07  max_mem: 3029M
[03/05 14:23:51] d2.utils.events INFO:  eta: 0:12:30  iter: 50059  total_loss: 2.255  loss_ce: 0.2915  loss_giou: 0.2729  loss_bbox: 0.2445  loss_ce_0: 0.3437  loss_giou_0: 0.2959  loss_bbox_0: 0.261  loss_rpn_cls: 0.2062  loss_rpn_reg: 0.399  time: 0.1890  last_time: 0.1713  data_time: 0.0056  last_data_time: 0.0049   lr: 5e-07  max_mem: 3029M
[03/05 14:23:55] d2.utils.events INFO:  eta: 0:12:26  iter: 50079  total_loss: 2.025  loss_ce: 0.2124  loss_giou: 0.3066  loss_bbox: 0.1959  loss_ce_0: 0.2848  loss_giou_0: 0.2986  loss_bbox_0: 0.2304  loss_rpn_cls: 0.1626  loss_rpn_reg: 0.4072  time: 0.1890  last_time: 0.1902  data_time: 0.0046  last_data_time: 0.0050   lr: 5e-07  max_mem: 3029M
[03/05 14:23:59] d2.utils.events INFO:  eta: 0:12:22  iter: 50099  total_loss: 2.335  loss_ce: 0.3344  loss_giou: 0.2571  loss_bbox: 0.2274  loss_ce_0: 0.3673  loss_giou_0: 0.3195  loss_bbox_0: 0.2629  loss_rpn_cls: 0.1809  loss_rpn_reg: 0.4262  time: 0.1890  last_time: 0.1831  data_time: 0.0057  last_data_time: 0.0063   lr: 5e-07  max_mem: 3029M
[03/05 14:24:03] d2.utils.events INFO:  eta: 0:12:19  iter: 50119  total_loss: 2.104  loss_ce: 0.2515  loss_giou: 0.2553  loss_bbox: 0.1937  loss_ce_0: 0.2815  loss_giou_0: 0.262  loss_bbox_0: 0.221  loss_rpn_cls: 0.1898  loss_rpn_reg: 0.3885  time: 0.1890  last_time: 0.1967  data_time: 0.0046  last_data_time: 0.0049   lr: 5e-07  max_mem: 3029M
[03/05 14:24:06] d2.utils.events INFO:  eta: 0:12:15  iter: 50139  total_loss: 2.251  loss_ce: 0.2647  loss_giou: 0.266  loss_bbox: 0.2179  loss_ce_0: 0.2906  loss_giou_0: 0.2976  loss_bbox_0: 0.2418  loss_rpn_cls: 0.1844  loss_rpn_reg: 0.4103  time: 0.1890  last_time: 0.1851  data_time: 0.0045  last_data_time: 0.0034   lr: 5e-07  max_mem: 3029M
[03/05 14:24:10] d2.utils.events INFO:  eta: 0:12:10  iter: 50159  total_loss: 2.268  loss_ce: 0.2621  loss_giou: 0.2876  loss_bbox: 0.1872  loss_ce_0: 0.291  loss_giou_0: 0.3121  loss_bbox_0: 0.2182  loss_rpn_cls: 0.2099  loss_rpn_reg: 0.3911  time: 0.1890  last_time: 0.1691  data_time: 0.0046  last_data_time: 0.0031   lr: 5e-07  max_mem: 3029M
[03/05 14:24:14] d2.utils.events INFO:  eta: 0:12:06  iter: 50179  total_loss: 2.523  loss_ce: 0.3217  loss_giou: 0.3021  loss_bbox: 0.248  loss_ce_0: 0.3629  loss_giou_0: 0.3324  loss_bbox_0: 0.2907  loss_rpn_cls: 0.2115  loss_rpn_reg: 0.4257  time: 0.1890  last_time: 0.2053  data_time: 0.0050  last_data_time: 0.0045   lr: 5e-07  max_mem: 3029M
[03/05 14:24:18] d2.utils.events INFO:  eta: 0:12:02  iter: 50199  total_loss: 2.298  loss_ce: 0.3205  loss_giou: 0.2806  loss_bbox: 0.2073  loss_ce_0: 0.3468  loss_giou_0: 0.3138  loss_bbox_0: 0.2396  loss_rpn_cls: 0.1721  loss_rpn_reg: 0.4298  time: 0.1890  last_time: 0.2027  data_time: 0.0057  last_data_time: 0.0055   lr: 5e-07  max_mem: 3029M
[03/05 14:24:22] d2.utils.events INFO:  eta: 0:11:58  iter: 50219  total_loss: 2.307  loss_ce: 0.3034  loss_giou: 0.2843  loss_bbox: 0.2044  loss_ce_0: 0.3332  loss_giou_0: 0.3095  loss_bbox_0: 0.2324  loss_rpn_cls: 0.1954  loss_rpn_reg: 0.3858  time: 0.1890  last_time: 0.1797  data_time: 0.0051  last_data_time: 0.0062   lr: 5e-07  max_mem: 3029M
[03/05 14:24:26] d2.utils.events INFO:  eta: 0:11:55  iter: 50239  total_loss: 2.366  loss_ce: 0.2739  loss_giou: 0.2624  loss_bbox: 0.2517  loss_ce_0: 0.277  loss_giou_0: 0.2923  loss_bbox_0: 0.2611  loss_rpn_cls: 0.1712  loss_rpn_reg: 0.4463  time: 0.1890  last_time: 0.1816  data_time: 0.0053  last_data_time: 0.0055   lr: 5e-07  max_mem: 3029M
[03/05 14:24:29] d2.utils.events INFO:  eta: 0:11:51  iter: 50259  total_loss: 2.03  loss_ce: 0.2378  loss_giou: 0.2553  loss_bbox: 0.2071  loss_ce_0: 0.3057  loss_giou_0: 0.2577  loss_bbox_0: 0.2237  loss_rpn_cls: 0.1875  loss_rpn_reg: 0.3901  time: 0.1890  last_time: 0.2089  data_time: 0.0050  last_data_time: 0.0042   lr: 5e-07  max_mem: 3029M
[03/05 14:24:33] d2.utils.events INFO:  eta: 0:11:47  iter: 50279  total_loss: 2.099  loss_ce: 0.2193  loss_giou: 0.2651  loss_bbox: 0.2281  loss_ce_0: 0.2832  loss_giou_0: 0.2786  loss_bbox_0: 0.2514  loss_rpn_cls: 0.1722  loss_rpn_reg: 0.3881  time: 0.1890  last_time: 0.1946  data_time: 0.0049  last_data_time: 0.0060   lr: 5e-07  max_mem: 3029M
[03/05 14:24:37] d2.utils.events INFO:  eta: 0:11:42  iter: 50299  total_loss: 2.436  loss_ce: 0.325  loss_giou: 0.2935  loss_bbox: 0.2119  loss_ce_0: 0.3904  loss_giou_0: 0.302  loss_bbox_0: 0.2412  loss_rpn_cls: 0.1925  loss_rpn_reg: 0.4382  time: 0.1890  last_time: 0.1634  data_time: 0.0048  last_data_time: 0.0037   lr: 5e-07  max_mem: 3029M
[03/05 14:24:41] d2.utils.events INFO:  eta: 0:11:38  iter: 50319  total_loss: 2.448  loss_ce: 0.29  loss_giou: 0.2761  loss_bbox: 0.2443  loss_ce_0: 0.2909  loss_giou_0: 0.3047  loss_bbox_0: 0.2372  loss_rpn_cls: 0.1976  loss_rpn_reg: 0.4274  time: 0.1890  last_time: 0.1776  data_time: 0.0052  last_data_time: 0.0062   lr: 5e-07  max_mem: 3029M
[03/05 14:24:45] d2.utils.events INFO:  eta: 0:11:34  iter: 50339  total_loss: 2.206  loss_ce: 0.2615  loss_giou: 0.2703  loss_bbox: 0.223  loss_ce_0: 0.2907  loss_giou_0: 0.296  loss_bbox_0: 0.2426  loss_rpn_cls: 0.1804  loss_rpn_reg: 0.3955  time: 0.1890  last_time: 0.1872  data_time: 0.0054  last_data_time: 0.0040   lr: 5e-07  max_mem: 3029M
[03/05 14:24:48] d2.utils.events INFO:  eta: 0:11:30  iter: 50359  total_loss: 2.091  loss_ce: 0.2595  loss_giou: 0.2633  loss_bbox: 0.194  loss_ce_0: 0.3213  loss_giou_0: 0.2917  loss_bbox_0: 0.2256  loss_rpn_cls: 0.1807  loss_rpn_reg: 0.4001  time: 0.1890  last_time: 0.1717  data_time: 0.0052  last_data_time: 0.0079   lr: 5e-07  max_mem: 3029M
[03/05 14:24:52] d2.utils.events INFO:  eta: 0:11:25  iter: 50379  total_loss: 2.464  loss_ce: 0.2885  loss_giou: 0.307  loss_bbox: 0.2293  loss_ce_0: 0.3256  loss_giou_0: 0.2995  loss_bbox_0: 0.2401  loss_rpn_cls: 0.2052  loss_rpn_reg: 0.4528  time: 0.1890  last_time: 0.1758  data_time: 0.0055  last_data_time: 0.0067   lr: 5e-07  max_mem: 3029M
[03/05 14:24:56] d2.utils.events INFO:  eta: 0:11:20  iter: 50399  total_loss: 2.466  loss_ce: 0.2716  loss_giou: 0.2998  loss_bbox: 0.2108  loss_ce_0: 0.3116  loss_giou_0: 0.3154  loss_bbox_0: 0.2186  loss_rpn_cls: 0.206  loss_rpn_reg: 0.4366  time: 0.1890  last_time: 0.1882  data_time: 0.0060  last_data_time: 0.0054   lr: 5e-07  max_mem: 3029M
[03/05 14:25:00] d2.utils.events INFO:  eta: 0:11:15  iter: 50419  total_loss: 2.398  loss_ce: 0.29  loss_giou: 0.3184  loss_bbox: 0.2353  loss_ce_0: 0.311  loss_giou_0: 0.324  loss_bbox_0: 0.2683  loss_rpn_cls: 0.1932  loss_rpn_reg: 0.3969  time: 0.1890  last_time: 0.1939  data_time: 0.0048  last_data_time: 0.0037   lr: 5e-07  max_mem: 3029M
[03/05 14:25:03] d2.utils.events INFO:  eta: 0:11:12  iter: 50439  total_loss: 2.174  loss_ce: 0.2161  loss_giou: 0.3081  loss_bbox: 0.2058  loss_ce_0: 0.2632  loss_giou_0: 0.3141  loss_bbox_0: 0.2239  loss_rpn_cls: 0.1821  loss_rpn_reg: 0.4606  time: 0.1890  last_time: 0.1801  data_time: 0.0054  last_data_time: 0.0034   lr: 5e-07  max_mem: 3029M
[03/05 14:25:07] d2.utils.events INFO:  eta: 0:11:08  iter: 50459  total_loss: 2.195  loss_ce: 0.2292  loss_giou: 0.2761  loss_bbox: 0.2148  loss_ce_0: 0.3038  loss_giou_0: 0.2715  loss_bbox_0: 0.2487  loss_rpn_cls: 0.1824  loss_rpn_reg: 0.4268  time: 0.1890  last_time: 0.1894  data_time: 0.0055  last_data_time: 0.0060   lr: 5e-07  max_mem: 3029M
[03/05 14:25:11] d2.utils.events INFO:  eta: 0:11:04  iter: 50479  total_loss: 2.415  loss_ce: 0.3115  loss_giou: 0.2892  loss_bbox: 0.2717  loss_ce_0: 0.3647  loss_giou_0: 0.2939  loss_bbox_0: 0.2943  loss_rpn_cls: 0.1689  loss_rpn_reg: 0.41  time: 0.1890  last_time: 0.2022  data_time: 0.0050  last_data_time: 0.0030   lr: 5e-07  max_mem: 3029M
[03/05 14:25:15] d2.utils.events INFO:  eta: 0:11:00  iter: 50499  total_loss: 2.1  loss_ce: 0.2117  loss_giou: 0.2519  loss_bbox: 0.2212  loss_ce_0: 0.2687  loss_giou_0: 0.265  loss_bbox_0: 0.2353  loss_rpn_cls: 0.1772  loss_rpn_reg: 0.3933  time: 0.1890  last_time: 0.1838  data_time: 0.0047  last_data_time: 0.0025   lr: 5e-07  max_mem: 3029M
[03/05 14:25:19] d2.utils.events INFO:  eta: 0:10:57  iter: 50519  total_loss: 2.051  loss_ce: 0.2284  loss_giou: 0.2969  loss_bbox: 0.2043  loss_ce_0: 0.2921  loss_giou_0: 0.3138  loss_bbox_0: 0.2276  loss_rpn_cls: 0.178  loss_rpn_reg: 0.3984  time: 0.1890  last_time: 0.2036  data_time: 0.0051  last_data_time: 0.0048   lr: 5e-07  max_mem: 3029M
[03/05 14:25:23] d2.utils.events INFO:  eta: 0:10:53  iter: 50539  total_loss: 2.101  loss_ce: 0.232  loss_giou: 0.2566  loss_bbox: 0.2181  loss_ce_0: 0.2938  loss_giou_0: 0.2968  loss_bbox_0: 0.2532  loss_rpn_cls: 0.1712  loss_rpn_reg: 0.4164  time: 0.1890  last_time: 0.1951  data_time: 0.0048  last_data_time: 0.0057   lr: 5e-07  max_mem: 3029M
[03/05 14:25:26] d2.utils.events INFO:  eta: 0:10:49  iter: 50559  total_loss: 2.173  loss_ce: 0.2775  loss_giou: 0.2612  loss_bbox: 0.2073  loss_ce_0: 0.328  loss_giou_0: 0.2603  loss_bbox_0: 0.2252  loss_rpn_cls: 0.1782  loss_rpn_reg: 0.3955  time: 0.1890  last_time: 0.1842  data_time: 0.0051  last_data_time: 0.0038   lr: 5e-07  max_mem: 3029M
[03/05 14:25:30] d2.utils.events INFO:  eta: 0:10:45  iter: 50579  total_loss: 2.349  loss_ce: 0.263  loss_giou: 0.2834  loss_bbox: 0.2407  loss_ce_0: 0.3203  loss_giou_0: 0.3061  loss_bbox_0: 0.2488  loss_rpn_cls: 0.1772  loss_rpn_reg: 0.3992  time: 0.1890  last_time: 0.1941  data_time: 0.0048  last_data_time: 0.0041   lr: 5e-07  max_mem: 3029M
[03/05 14:25:34] d2.utils.events INFO:  eta: 0:10:41  iter: 50599  total_loss: 2.146  loss_ce: 0.2687  loss_giou: 0.2639  loss_bbox: 0.2098  loss_ce_0: 0.2955  loss_giou_0: 0.2863  loss_bbox_0: 0.2358  loss_rpn_cls: 0.2019  loss_rpn_reg: 0.4078  time: 0.1890  last_time: 0.1842  data_time: 0.0054  last_data_time: 0.0101   lr: 5e-07  max_mem: 3029M
[03/05 14:25:38] d2.utils.events INFO:  eta: 0:10:36  iter: 50619  total_loss: 2.268  loss_ce: 0.2066  loss_giou: 0.2995  loss_bbox: 0.2646  loss_ce_0: 0.2421  loss_giou_0: 0.2966  loss_bbox_0: 0.2532  loss_rpn_cls: 0.1638  loss_rpn_reg: 0.3956  time: 0.1890  last_time: 0.1866  data_time: 0.0049  last_data_time: 0.0053   lr: 5e-07  max_mem: 3029M
[03/05 14:25:41] d2.utils.events INFO:  eta: 0:10:31  iter: 50639  total_loss: 2.34  loss_ce: 0.2852  loss_giou: 0.2947  loss_bbox: 0.2583  loss_ce_0: 0.3533  loss_giou_0: 0.3103  loss_bbox_0: 0.2844  loss_rpn_cls: 0.2037  loss_rpn_reg: 0.4279  time: 0.1890  last_time: 0.1657  data_time: 0.0046  last_data_time: 0.0050   lr: 5e-07  max_mem: 3029M
[03/05 14:25:45] d2.utils.events INFO:  eta: 0:10:27  iter: 50659  total_loss: 2.298  loss_ce: 0.2721  loss_giou: 0.2816  loss_bbox: 0.2138  loss_ce_0: 0.3261  loss_giou_0: 0.2933  loss_bbox_0: 0.2455  loss_rpn_cls: 0.1739  loss_rpn_reg: 0.393  time: 0.1890  last_time: 0.2066  data_time: 0.0057  last_data_time: 0.0045   lr: 5e-07  max_mem: 3029M
[03/05 14:25:49] d2.utils.events INFO:  eta: 0:10:23  iter: 50679  total_loss: 2.484  loss_ce: 0.2942  loss_giou: 0.2851  loss_bbox: 0.2158  loss_ce_0: 0.3676  loss_giou_0: 0.3007  loss_bbox_0: 0.235  loss_rpn_cls: 0.1954  loss_rpn_reg: 0.4216  time: 0.1890  last_time: 0.2035  data_time: 0.0053  last_data_time: 0.0063   lr: 5e-07  max_mem: 3029M
[03/05 14:25:53] d2.utils.events INFO:  eta: 0:10:20  iter: 50699  total_loss: 2.297  loss_ce: 0.2586  loss_giou: 0.3145  loss_bbox: 0.2224  loss_ce_0: 0.2725  loss_giou_0: 0.337  loss_bbox_0: 0.2433  loss_rpn_cls: 0.1575  loss_rpn_reg: 0.4152  time: 0.1890  last_time: 0.1741  data_time: 0.0059  last_data_time: 0.0028   lr: 5e-07  max_mem: 3029M
[03/05 14:25:57] d2.utils.events INFO:  eta: 0:10:15  iter: 50719  total_loss: 2.19  loss_ce: 0.2893  loss_giou: 0.2586  loss_bbox: 0.2335  loss_ce_0: 0.292  loss_giou_0: 0.269  loss_bbox_0: 0.2614  loss_rpn_cls: 0.1886  loss_rpn_reg: 0.4228  time: 0.1890  last_time: 0.1704  data_time: 0.0056  last_data_time: 0.0042   lr: 5e-07  max_mem: 3029M
[03/05 14:26:01] d2.utils.events INFO:  eta: 0:10:13  iter: 50739  total_loss: 2.138  loss_ce: 0.2716  loss_giou: 0.2617  loss_bbox: 0.221  loss_ce_0: 0.3048  loss_giou_0: 0.2743  loss_bbox_0: 0.2397  loss_rpn_cls: 0.1815  loss_rpn_reg: 0.3805  time: 0.1890  last_time: 0.1833  data_time: 0.0052  last_data_time: 0.0061   lr: 5e-07  max_mem: 3029M
[03/05 14:26:05] d2.utils.events INFO:  eta: 0:10:09  iter: 50759  total_loss: 2.207  loss_ce: 0.2683  loss_giou: 0.2369  loss_bbox: 0.1954  loss_ce_0: 0.3104  loss_giou_0: 0.2693  loss_bbox_0: 0.243  loss_rpn_cls: 0.1911  loss_rpn_reg: 0.4301  time: 0.1890  last_time: 0.1762  data_time: 0.0053  last_data_time: 0.0043   lr: 5e-07  max_mem: 3029M
[03/05 14:26:09] d2.utils.events INFO:  eta: 0:10:05  iter: 50779  total_loss: 1.926  loss_ce: 0.2345  loss_giou: 0.2159  loss_bbox: 0.2154  loss_ce_0: 0.2592  loss_giou_0: 0.2161  loss_bbox_0: 0.2526  loss_rpn_cls: 0.1603  loss_rpn_reg: 0.3844  time: 0.1890  last_time: 0.1777  data_time: 0.0048  last_data_time: 0.0071   lr: 5e-07  max_mem: 3029M
[03/05 14:26:13] d2.utils.events INFO:  eta: 0:10:02  iter: 50799  total_loss: 2.072  loss_ce: 0.2396  loss_giou: 0.2711  loss_bbox: 0.23  loss_ce_0: 0.3319  loss_giou_0: 0.2751  loss_bbox_0: 0.2282  loss_rpn_cls: 0.1808  loss_rpn_reg: 0.4127  time: 0.1890  last_time: 0.1743  data_time: 0.0052  last_data_time: 0.0051   lr: 5e-07  max_mem: 3029M
[03/05 14:26:16] d2.utils.events INFO:  eta: 0:09:58  iter: 50819  total_loss: 1.984  loss_ce: 0.2271  loss_giou: 0.2198  loss_bbox: 0.1848  loss_ce_0: 0.2588  loss_giou_0: 0.2296  loss_bbox_0: 0.2091  loss_rpn_cls: 0.1583  loss_rpn_reg: 0.373  time: 0.1890  last_time: 0.1755  data_time: 0.0049  last_data_time: 0.0054   lr: 5e-07  max_mem: 3029M
[03/05 14:26:20] d2.utils.events INFO:  eta: 0:09:54  iter: 50839  total_loss: 2.19  loss_ce: 0.2836  loss_giou: 0.2358  loss_bbox: 0.2238  loss_ce_0: 0.3179  loss_giou_0: 0.2582  loss_bbox_0: 0.2407  loss_rpn_cls: 0.1785  loss_rpn_reg: 0.3932  time: 0.1890  last_time: 0.1744  data_time: 0.0058  last_data_time: 0.0050   lr: 5e-07  max_mem: 3029M
[03/05 14:26:24] d2.utils.events INFO:  eta: 0:09:50  iter: 50859  total_loss: 2.403  loss_ce: 0.2448  loss_giou: 0.3203  loss_bbox: 0.2484  loss_ce_0: 0.3108  loss_giou_0: 0.316  loss_bbox_0: 0.257  loss_rpn_cls: 0.193  loss_rpn_reg: 0.4531  time: 0.1890  last_time: 0.1684  data_time: 0.0056  last_data_time: 0.0075   lr: 5e-07  max_mem: 3029M
[03/05 14:26:28] d2.utils.events INFO:  eta: 0:09:47  iter: 50879  total_loss: 2.211  loss_ce: 0.2857  loss_giou: 0.2997  loss_bbox: 0.161  loss_ce_0: 0.3013  loss_giou_0: 0.319  loss_bbox_0: 0.1863  loss_rpn_cls: 0.1733  loss_rpn_reg: 0.4325  time: 0.1890  last_time: 0.1662  data_time: 0.0054  last_data_time: 0.0040   lr: 5e-07  max_mem: 3029M
[03/05 14:26:32] d2.utils.events INFO:  eta: 0:09:43  iter: 50899  total_loss: 2.21  loss_ce: 0.2312  loss_giou: 0.2864  loss_bbox: 0.2237  loss_ce_0: 0.2766  loss_giou_0: 0.3076  loss_bbox_0: 0.2556  loss_rpn_cls: 0.1641  loss_rpn_reg: 0.4204  time: 0.1890  last_time: 0.1910  data_time: 0.0056  last_data_time: 0.0052   lr: 5e-07  max_mem: 3029M
[03/05 14:26:36] d2.utils.events INFO:  eta: 0:09:39  iter: 50919  total_loss: 2.398  loss_ce: 0.3011  loss_giou: 0.2611  loss_bbox: 0.2526  loss_ce_0: 0.339  loss_giou_0: 0.2809  loss_bbox_0: 0.2822  loss_rpn_cls: 0.1645  loss_rpn_reg: 0.4087  time: 0.1890  last_time: 0.1826  data_time: 0.0051  last_data_time: 0.0045   lr: 5e-07  max_mem: 3029M
[03/05 14:26:40] d2.utils.events INFO:  eta: 0:09:35  iter: 50939  total_loss: 2.317  loss_ce: 0.2381  loss_giou: 0.2962  loss_bbox: 0.2224  loss_ce_0: 0.318  loss_giou_0: 0.3056  loss_bbox_0: 0.2108  loss_rpn_cls: 0.1948  loss_rpn_reg: 0.4195  time: 0.1890  last_time: 0.2036  data_time: 0.0057  last_data_time: 0.0041   lr: 5e-07  max_mem: 3029M
[03/05 14:26:43] d2.utils.events INFO:  eta: 0:09:32  iter: 50959  total_loss: 2.241  loss_ce: 0.276  loss_giou: 0.279  loss_bbox: 0.2233  loss_ce_0: 0.2933  loss_giou_0: 0.3103  loss_bbox_0: 0.2326  loss_rpn_cls: 0.1703  loss_rpn_reg: 0.4019  time: 0.1890  last_time: 0.1754  data_time: 0.0052  last_data_time: 0.0149   lr: 5e-07  max_mem: 3029M
[03/05 14:26:47] d2.utils.events INFO:  eta: 0:09:28  iter: 50979  total_loss: 2.121  loss_ce: 0.2737  loss_giou: 0.2375  loss_bbox: 0.2127  loss_ce_0: 0.3236  loss_giou_0: 0.2549  loss_bbox_0: 0.2206  loss_rpn_cls: 0.1907  loss_rpn_reg: 0.3682  time: 0.1890  last_time: 0.1929  data_time: 0.0052  last_data_time: 0.0041   lr: 5e-07  max_mem: 3029M
[03/05 14:26:51] d2.utils.events INFO:  eta: 0:09:23  iter: 50999  total_loss: 2.319  loss_ce: 0.2642  loss_giou: 0.3414  loss_bbox: 0.1986  loss_ce_0: 0.3215  loss_giou_0: 0.3509  loss_bbox_0: 0.2461  loss_rpn_cls: 0.188  loss_rpn_reg: 0.4402  time: 0.1890  last_time: 0.1977  data_time: 0.0053  last_data_time: 0.0040   lr: 5e-07  max_mem: 3029M
[03/05 14:26:55] d2.utils.events INFO:  eta: 0:09:19  iter: 51019  total_loss: 2.083  loss_ce: 0.2017  loss_giou: 0.2518  loss_bbox: 0.236  loss_ce_0: 0.2513  loss_giou_0: 0.249  loss_bbox_0: 0.2246  loss_rpn_cls: 0.168  loss_rpn_reg: 0.3874  time: 0.1890  last_time: 0.1625  data_time: 0.0052  last_data_time: 0.0043   lr: 5e-07  max_mem: 3029M
[03/05 14:26:58] d2.utils.events INFO:  eta: 0:09:15  iter: 51039  total_loss: 2.116  loss_ce: 0.2598  loss_giou: 0.2609  loss_bbox: 0.2123  loss_ce_0: 0.2827  loss_giou_0: 0.2734  loss_bbox_0: 0.2416  loss_rpn_cls: 0.1589  loss_rpn_reg: 0.369  time: 0.1890  last_time: 0.1833  data_time: 0.0055  last_data_time: 0.0084   lr: 5e-07  max_mem: 3029M
[03/05 14:27:02] d2.utils.events INFO:  eta: 0:09:11  iter: 51059  total_loss: 2.565  loss_ce: 0.3  loss_giou: 0.3358  loss_bbox: 0.2612  loss_ce_0: 0.3283  loss_giou_0: 0.3353  loss_bbox_0: 0.2788  loss_rpn_cls: 0.1924  loss_rpn_reg: 0.4333  time: 0.1890  last_time: 0.1863  data_time: 0.0054  last_data_time: 0.0036   lr: 5e-07  max_mem: 3029M
[03/05 14:27:06] d2.utils.events INFO:  eta: 0:09:07  iter: 51079  total_loss: 2.304  loss_ce: 0.2478  loss_giou: 0.2731  loss_bbox: 0.2436  loss_ce_0: 0.3094  loss_giou_0: 0.3009  loss_bbox_0: 0.2434  loss_rpn_cls: 0.1857  loss_rpn_reg: 0.4382  time: 0.1890  last_time: 0.2069  data_time: 0.0047  last_data_time: 0.0041   lr: 5e-07  max_mem: 3029M
[03/05 14:27:10] d2.utils.events INFO:  eta: 0:09:04  iter: 51099  total_loss: 2.305  loss_ce: 0.2931  loss_giou: 0.282  loss_bbox: 0.1866  loss_ce_0: 0.3129  loss_giou_0: 0.2976  loss_bbox_0: 0.2208  loss_rpn_cls: 0.195  loss_rpn_reg: 0.4362  time: 0.1890  last_time: 0.1797  data_time: 0.0050  last_data_time: 0.0041   lr: 5e-07  max_mem: 3029M
[03/05 14:27:14] d2.utils.events INFO:  eta: 0:08:59  iter: 51119  total_loss: 2.293  loss_ce: 0.2911  loss_giou: 0.2631  loss_bbox: 0.2346  loss_ce_0: 0.3284  loss_giou_0: 0.274  loss_bbox_0: 0.244  loss_rpn_cls: 0.1846  loss_rpn_reg: 0.3993  time: 0.1890  last_time: 0.1945  data_time: 0.0045  last_data_time: 0.0061   lr: 5e-07  max_mem: 3029M
[03/05 14:27:18] d2.utils.events INFO:  eta: 0:08:56  iter: 51139  total_loss: 2.186  loss_ce: 0.2076  loss_giou: 0.2775  loss_bbox: 0.2239  loss_ce_0: 0.2426  loss_giou_0: 0.3054  loss_bbox_0: 0.2378  loss_rpn_cls: 0.1604  loss_rpn_reg: 0.4232  time: 0.1890  last_time: 0.2016  data_time: 0.0051  last_data_time: 0.0033   lr: 5e-07  max_mem: 3029M
[03/05 14:27:21] d2.utils.events INFO:  eta: 0:08:53  iter: 51159  total_loss: 2.164  loss_ce: 0.2689  loss_giou: 0.3183  loss_bbox: 0.2293  loss_ce_0: 0.2938  loss_giou_0: 0.3192  loss_bbox_0: 0.2432  loss_rpn_cls: 0.1778  loss_rpn_reg: 0.3988  time: 0.1890  last_time: 0.2045  data_time: 0.0048  last_data_time: 0.0098   lr: 5e-07  max_mem: 3029M
[03/05 14:27:25] d2.utils.events INFO:  eta: 0:08:49  iter: 51179  total_loss: 2.181  loss_ce: 0.2877  loss_giou: 0.2711  loss_bbox: 0.206  loss_ce_0: 0.3173  loss_giou_0: 0.2893  loss_bbox_0: 0.2126  loss_rpn_cls: 0.1857  loss_rpn_reg: 0.3955  time: 0.1890  last_time: 0.2137  data_time: 0.0054  last_data_time: 0.0034   lr: 5e-07  max_mem: 3029M
[03/05 14:27:29] d2.utils.events INFO:  eta: 0:08:45  iter: 51199  total_loss: 2.203  loss_ce: 0.253  loss_giou: 0.2492  loss_bbox: 0.2227  loss_ce_0: 0.3025  loss_giou_0: 0.2611  loss_bbox_0: 0.2473  loss_rpn_cls: 0.1823  loss_rpn_reg: 0.4109  time: 0.1890  last_time: 0.1757  data_time: 0.0058  last_data_time: 0.0062   lr: 5e-07  max_mem: 3029M
[03/05 14:27:33] d2.utils.events INFO:  eta: 0:08:42  iter: 51219  total_loss: 2.48  loss_ce: 0.2869  loss_giou: 0.307  loss_bbox: 0.2674  loss_ce_0: 0.3507  loss_giou_0: 0.3253  loss_bbox_0: 0.2699  loss_rpn_cls: 0.2208  loss_rpn_reg: 0.4168  time: 0.1890  last_time: 0.1865  data_time: 0.0052  last_data_time: 0.0048   lr: 5e-07  max_mem: 3029M
[03/05 14:27:37] d2.utils.events INFO:  eta: 0:08:39  iter: 51239  total_loss: 2.13  loss_ce: 0.2658  loss_giou: 0.2342  loss_bbox: 0.2458  loss_ce_0: 0.3079  loss_giou_0: 0.2466  loss_bbox_0: 0.2569  loss_rpn_cls: 0.2059  loss_rpn_reg: 0.3663  time: 0.1890  last_time: 0.1809  data_time: 0.0055  last_data_time: 0.0031   lr: 5e-07  max_mem: 3029M
[03/05 14:27:41] d2.utils.events INFO:  eta: 0:08:34  iter: 51259  total_loss: 2.293  loss_ce: 0.2957  loss_giou: 0.2969  loss_bbox: 0.2184  loss_ce_0: 0.3236  loss_giou_0: 0.3058  loss_bbox_0: 0.2361  loss_rpn_cls: 0.2077  loss_rpn_reg: 0.4271  time: 0.1890  last_time: 0.1681  data_time: 0.0054  last_data_time: 0.0041   lr: 5e-07  max_mem: 3029M
[03/05 14:27:44] d2.utils.events INFO:  eta: 0:08:31  iter: 51279  total_loss: 2.271  loss_ce: 0.2568  loss_giou: 0.2582  loss_bbox: 0.2031  loss_ce_0: 0.3138  loss_giou_0: 0.2931  loss_bbox_0: 0.2536  loss_rpn_cls: 0.1694  loss_rpn_reg: 0.4016  time: 0.1890  last_time: 0.2061  data_time: 0.0053  last_data_time: 0.0051   lr: 5e-07  max_mem: 3029M
[03/05 14:27:48] d2.utils.events INFO:  eta: 0:08:27  iter: 51299  total_loss: 2.194  loss_ce: 0.282  loss_giou: 0.2573  loss_bbox: 0.2243  loss_ce_0: 0.3012  loss_giou_0: 0.2998  loss_bbox_0: 0.2464  loss_rpn_cls: 0.1647  loss_rpn_reg: 0.4034  time: 0.1890  last_time: 0.1888  data_time: 0.0051  last_data_time: 0.0025   lr: 5e-07  max_mem: 3029M
[03/05 14:27:52] d2.utils.events INFO:  eta: 0:08:23  iter: 51319  total_loss: 2.24  loss_ce: 0.2288  loss_giou: 0.2551  loss_bbox: 0.2084  loss_ce_0: 0.2749  loss_giou_0: 0.2691  loss_bbox_0: 0.2342  loss_rpn_cls: 0.1709  loss_rpn_reg: 0.4301  time: 0.1890  last_time: 0.2111  data_time: 0.0054  last_data_time: 0.0052   lr: 5e-07  max_mem: 3029M
[03/05 14:27:56] d2.utils.events INFO:  eta: 0:08:19  iter: 51339  total_loss: 2.294  loss_ce: 0.2751  loss_giou: 0.2863  loss_bbox: 0.2  loss_ce_0: 0.3087  loss_giou_0: 0.2983  loss_bbox_0: 0.2199  loss_rpn_cls: 0.1629  loss_rpn_reg: 0.4143  time: 0.1890  last_time: 0.1972  data_time: 0.0050  last_data_time: 0.0059   lr: 5e-07  max_mem: 3029M
[03/05 14:28:00] d2.utils.events INFO:  eta: 0:08:16  iter: 51359  total_loss: 2.291  loss_ce: 0.2311  loss_giou: 0.2911  loss_bbox: 0.2541  loss_ce_0: 0.2808  loss_giou_0: 0.2883  loss_bbox_0: 0.2732  loss_rpn_cls: 0.1587  loss_rpn_reg: 0.4106  time: 0.1890  last_time: 0.1969  data_time: 0.0053  last_data_time: 0.0037   lr: 5e-07  max_mem: 3029M
[03/05 14:28:03] d2.utils.events INFO:  eta: 0:08:12  iter: 51379  total_loss: 2.085  loss_ce: 0.2178  loss_giou: 0.2232  loss_bbox: 0.2257  loss_ce_0: 0.2917  loss_giou_0: 0.2349  loss_bbox_0: 0.2358  loss_rpn_cls: 0.1798  loss_rpn_reg: 0.3899  time: 0.1889  last_time: 0.1816  data_time: 0.0053  last_data_time: 0.0038   lr: 5e-07  max_mem: 3029M
[03/05 14:28:07] d2.utils.events INFO:  eta: 0:08:08  iter: 51399  total_loss: 2.096  loss_ce: 0.235  loss_giou: 0.2797  loss_bbox: 0.2051  loss_ce_0: 0.2624  loss_giou_0: 0.279  loss_bbox_0: 0.2143  loss_rpn_cls: 0.1667  loss_rpn_reg: 0.4157  time: 0.1889  last_time: 0.2103  data_time: 0.0056  last_data_time: 0.0034   lr: 5e-07  max_mem: 3029M
[03/05 14:28:11] d2.utils.events INFO:  eta: 0:08:05  iter: 51419  total_loss: 2.139  loss_ce: 0.2401  loss_giou: 0.2297  loss_bbox: 0.2193  loss_ce_0: 0.3094  loss_giou_0: 0.2427  loss_bbox_0: 0.2367  loss_rpn_cls: 0.1774  loss_rpn_reg: 0.3904  time: 0.1890  last_time: 0.1999  data_time: 0.0054  last_data_time: 0.0055   lr: 5e-07  max_mem: 3029M
[03/05 14:28:15] d2.utils.events INFO:  eta: 0:08:02  iter: 51439  total_loss: 2.43  loss_ce: 0.2505  loss_giou: 0.3204  loss_bbox: 0.2446  loss_ce_0: 0.3194  loss_giou_0: 0.324  loss_bbox_0: 0.2531  loss_rpn_cls: 0.1626  loss_rpn_reg: 0.4673  time: 0.1890  last_time: 0.1924  data_time: 0.0056  last_data_time: 0.0047   lr: 5e-07  max_mem: 3029M
[03/05 14:28:19] d2.utils.events INFO:  eta: 0:07:57  iter: 51459  total_loss: 2.139  loss_ce: 0.2391  loss_giou: 0.2409  loss_bbox: 0.2205  loss_ce_0: 0.3205  loss_giou_0: 0.2312  loss_bbox_0: 0.2478  loss_rpn_cls: 0.1671  loss_rpn_reg: 0.4097  time: 0.1890  last_time: 0.2108  data_time: 0.0050  last_data_time: 0.0052   lr: 5e-07  max_mem: 3029M
[03/05 14:28:23] d2.utils.events INFO:  eta: 0:07:54  iter: 51479  total_loss: 2.15  loss_ce: 0.2479  loss_giou: 0.2476  loss_bbox: 0.1712  loss_ce_0: 0.3168  loss_giou_0: 0.2674  loss_bbox_0: 0.2284  loss_rpn_cls: 0.1746  loss_rpn_reg: 0.4451  time: 0.1889  last_time: 0.1679  data_time: 0.0052  last_data_time: 0.0053   lr: 5e-07  max_mem: 3029M
[03/05 14:28:26] d2.utils.events INFO:  eta: 0:07:50  iter: 51499  total_loss: 2.062  loss_ce: 0.2792  loss_giou: 0.2434  loss_bbox: 0.1977  loss_ce_0: 0.2991  loss_giou_0: 0.2634  loss_bbox_0: 0.2263  loss_rpn_cls: 0.1843  loss_rpn_reg: 0.3884  time: 0.1889  last_time: 0.1942  data_time: 0.0050  last_data_time: 0.0047   lr: 5e-07  max_mem: 3029M
[03/05 14:28:30] d2.utils.events INFO:  eta: 0:07:46  iter: 51519  total_loss: 1.994  loss_ce: 0.2275  loss_giou: 0.2583  loss_bbox: 0.1866  loss_ce_0: 0.2766  loss_giou_0: 0.2857  loss_bbox_0: 0.2058  loss_rpn_cls: 0.1657  loss_rpn_reg: 0.4095  time: 0.1889  last_time: 0.1705  data_time: 0.0054  last_data_time: 0.0042   lr: 5e-07  max_mem: 3029M
[03/05 14:28:34] d2.utils.events INFO:  eta: 0:07:42  iter: 51539  total_loss: 2.35  loss_ce: 0.2417  loss_giou: 0.2935  loss_bbox: 0.2246  loss_ce_0: 0.2935  loss_giou_0: 0.3094  loss_bbox_0: 0.237  loss_rpn_cls: 0.1873  loss_rpn_reg: 0.4094  time: 0.1890  last_time: 0.1885  data_time: 0.0052  last_data_time: 0.0054   lr: 5e-07  max_mem: 3029M
[03/05 14:28:38] d2.utils.events INFO:  eta: 0:07:39  iter: 51559  total_loss: 2.194  loss_ce: 0.2196  loss_giou: 0.2453  loss_bbox: 0.201  loss_ce_0: 0.3014  loss_giou_0: 0.2619  loss_bbox_0: 0.2296  loss_rpn_cls: 0.1599  loss_rpn_reg: 0.4104  time: 0.1890  last_time: 0.1907  data_time: 0.0047  last_data_time: 0.0042   lr: 5e-07  max_mem: 3029M
[03/05 14:28:42] d2.utils.events INFO:  eta: 0:07:36  iter: 51579  total_loss: 2.163  loss_ce: 0.2942  loss_giou: 0.2855  loss_bbox: 0.1815  loss_ce_0: 0.3058  loss_giou_0: 0.2984  loss_bbox_0: 0.2154  loss_rpn_cls: 0.1945  loss_rpn_reg: 0.4082  time: 0.1890  last_time: 0.1934  data_time: 0.0049  last_data_time: 0.0029   lr: 5e-07  max_mem: 3029M
[03/05 14:28:46] d2.utils.events INFO:  eta: 0:07:31  iter: 51599  total_loss: 1.986  loss_ce: 0.1768  loss_giou: 0.2581  loss_bbox: 0.2323  loss_ce_0: 0.2592  loss_giou_0: 0.2771  loss_bbox_0: 0.2304  loss_rpn_cls: 0.1453  loss_rpn_reg: 0.3872  time: 0.1890  last_time: 0.1896  data_time: 0.0048  last_data_time: 0.0077   lr: 5e-07  max_mem: 3029M
[03/05 14:28:50] d2.utils.events INFO:  eta: 0:07:28  iter: 51619  total_loss: 2.17  loss_ce: 0.2846  loss_giou: 0.2836  loss_bbox: 0.2997  loss_ce_0: 0.323  loss_giou_0: 0.2807  loss_bbox_0: 0.304  loss_rpn_cls: 0.1619  loss_rpn_reg: 0.4056  time: 0.1890  last_time: 0.1871  data_time: 0.0047  last_data_time: 0.0049   lr: 5e-07  max_mem: 3029M
[03/05 14:28:53] d2.utils.events INFO:  eta: 0:07:24  iter: 51639  total_loss: 2.17  loss_ce: 0.2658  loss_giou: 0.2515  loss_bbox: 0.2389  loss_ce_0: 0.3039  loss_giou_0: 0.2724  loss_bbox_0: 0.2473  loss_rpn_cls: 0.1755  loss_rpn_reg: 0.3985  time: 0.1890  last_time: 0.2049  data_time: 0.0047  last_data_time: 0.0049   lr: 5e-07  max_mem: 3029M
[03/05 14:28:57] d2.utils.events INFO:  eta: 0:07:21  iter: 51659  total_loss: 2.206  loss_ce: 0.2509  loss_giou: 0.2874  loss_bbox: 0.209  loss_ce_0: 0.2766  loss_giou_0: 0.2974  loss_bbox_0: 0.2413  loss_rpn_cls: 0.1815  loss_rpn_reg: 0.418  time: 0.1890  last_time: 0.1899  data_time: 0.0055  last_data_time: 0.0102   lr: 5e-07  max_mem: 3029M
[03/05 14:29:01] d2.utils.events INFO:  eta: 0:07:17  iter: 51679  total_loss: 1.863  loss_ce: 0.1905  loss_giou: 0.2635  loss_bbox: 0.1804  loss_ce_0: 0.2687  loss_giou_0: 0.2656  loss_bbox_0: 0.2001  loss_rpn_cls: 0.1564  loss_rpn_reg: 0.4046  time: 0.1890  last_time: 0.1813  data_time: 0.0056  last_data_time: 0.0047   lr: 5e-07  max_mem: 3029M
[03/05 14:29:05] d2.utils.events INFO:  eta: 0:07:13  iter: 51699  total_loss: 2.206  loss_ce: 0.256  loss_giou: 0.3419  loss_bbox: 0.2466  loss_ce_0: 0.3179  loss_giou_0: 0.3357  loss_bbox_0: 0.2562  loss_rpn_cls: 0.1521  loss_rpn_reg: 0.4559  time: 0.1890  last_time: 0.2086  data_time: 0.0050  last_data_time: 0.0036   lr: 5e-07  max_mem: 3029M
[03/05 14:29:09] d2.utils.events INFO:  eta: 0:07:10  iter: 51719  total_loss: 2.003  loss_ce: 0.2374  loss_giou: 0.2677  loss_bbox: 0.2153  loss_ce_0: 0.2699  loss_giou_0: 0.2703  loss_bbox_0: 0.2519  loss_rpn_cls: 0.1358  loss_rpn_reg: 0.4228  time: 0.1890  last_time: 0.1913  data_time: 0.0052  last_data_time: 0.0048   lr: 5e-07  max_mem: 3029M
[03/05 14:29:13] d2.utils.events INFO:  eta: 0:07:05  iter: 51739  total_loss: 2.105  loss_ce: 0.2531  loss_giou: 0.2668  loss_bbox: 0.1924  loss_ce_0: 0.3003  loss_giou_0: 0.2819  loss_bbox_0: 0.2051  loss_rpn_cls: 0.1733  loss_rpn_reg: 0.3853  time: 0.1890  last_time: 0.2049  data_time: 0.0053  last_data_time: 0.0050   lr: 5e-07  max_mem: 3029M
[03/05 14:29:16] d2.utils.events INFO:  eta: 0:07:01  iter: 51759  total_loss: 2.808  loss_ce: 0.2666  loss_giou: 0.371  loss_bbox: 0.2716  loss_ce_0: 0.3002  loss_giou_0: 0.3949  loss_bbox_0: 0.3019  loss_rpn_cls: 0.225  loss_rpn_reg: 0.426  time: 0.1889  last_time: 0.1972  data_time: 0.0050  last_data_time: 0.0040   lr: 5e-07  max_mem: 3029M
[03/05 14:29:20] d2.utils.events INFO:  eta: 0:06:57  iter: 51779  total_loss: 2.056  loss_ce: 0.2417  loss_giou: 0.2658  loss_bbox: 0.1886  loss_ce_0: 0.2804  loss_giou_0: 0.2779  loss_bbox_0: 0.2112  loss_rpn_cls: 0.1818  loss_rpn_reg: 0.4239  time: 0.1889  last_time: 0.1810  data_time: 0.0051  last_data_time: 0.0062   lr: 5e-07  max_mem: 3029M
[03/05 14:29:24] d2.utils.events INFO:  eta: 0:06:52  iter: 51799  total_loss: 2.403  loss_ce: 0.27  loss_giou: 0.3027  loss_bbox: 0.2422  loss_ce_0: 0.3469  loss_giou_0: 0.325  loss_bbox_0: 0.2435  loss_rpn_cls: 0.1886  loss_rpn_reg: 0.4272  time: 0.1889  last_time: 0.1785  data_time: 0.0048  last_data_time: 0.0073   lr: 5e-07  max_mem: 3029M
[03/05 14:29:27] d2.utils.events INFO:  eta: 0:06:48  iter: 51819  total_loss: 2.102  loss_ce: 0.2224  loss_giou: 0.2602  loss_bbox: 0.2113  loss_ce_0: 0.2593  loss_giou_0: 0.28  loss_bbox_0: 0.2359  loss_rpn_cls: 0.1689  loss_rpn_reg: 0.3949  time: 0.1889  last_time: 0.1954  data_time: 0.0052  last_data_time: 0.0053   lr: 5e-07  max_mem: 3029M
[03/05 14:29:31] d2.utils.events INFO:  eta: 0:06:45  iter: 51839  total_loss: 2.184  loss_ce: 0.2466  loss_giou: 0.3234  loss_bbox: 0.2373  loss_ce_0: 0.2679  loss_giou_0: 0.2992  loss_bbox_0: 0.2642  loss_rpn_cls: 0.1836  loss_rpn_reg: 0.4108  time: 0.1889  last_time: 0.1804  data_time: 0.0050  last_data_time: 0.0036   lr: 5e-07  max_mem: 3029M
[03/05 14:29:35] d2.utils.events INFO:  eta: 0:06:42  iter: 51859  total_loss: 2.143  loss_ce: 0.2015  loss_giou: 0.273  loss_bbox: 0.2108  loss_ce_0: 0.2805  loss_giou_0: 0.2869  loss_bbox_0: 0.2239  loss_rpn_cls: 0.1612  loss_rpn_reg: 0.4233  time: 0.1889  last_time: 0.2056  data_time: 0.0050  last_data_time: 0.0052   lr: 5e-07  max_mem: 3029M
[03/05 14:29:39] d2.utils.events INFO:  eta: 0:06:37  iter: 51879  total_loss: 2.408  loss_ce: 0.3019  loss_giou: 0.2879  loss_bbox: 0.2299  loss_ce_0: 0.3732  loss_giou_0: 0.3003  loss_bbox_0: 0.2511  loss_rpn_cls: 0.1914  loss_rpn_reg: 0.4113  time: 0.1889  last_time: 0.1859  data_time: 0.0050  last_data_time: 0.0054   lr: 5e-07  max_mem: 3029M
[03/05 14:29:43] d2.utils.events INFO:  eta: 0:06:34  iter: 51899  total_loss: 2.144  loss_ce: 0.2558  loss_giou: 0.2507  loss_bbox: 0.1814  loss_ce_0: 0.3091  loss_giou_0: 0.2624  loss_bbox_0: 0.2161  loss_rpn_cls: 0.1719  loss_rpn_reg: 0.3876  time: 0.1889  last_time: 0.1859  data_time: 0.0057  last_data_time: 0.0084   lr: 5e-07  max_mem: 3029M
[03/05 14:29:47] d2.utils.events INFO:  eta: 0:06:30  iter: 51919  total_loss: 2.113  loss_ce: 0.308  loss_giou: 0.2735  loss_bbox: 0.2229  loss_ce_0: 0.2998  loss_giou_0: 0.2934  loss_bbox_0: 0.2641  loss_rpn_cls: 0.1692  loss_rpn_reg: 0.3931  time: 0.1889  last_time: 0.2139  data_time: 0.0064  last_data_time: 0.0079   lr: 5e-07  max_mem: 3029M
[03/05 14:29:51] d2.utils.events INFO:  eta: 0:06:26  iter: 51939  total_loss: 2.223  loss_ce: 0.2852  loss_giou: 0.2562  loss_bbox: 0.2292  loss_ce_0: 0.3556  loss_giou_0: 0.2914  loss_bbox_0: 0.2427  loss_rpn_cls: 0.187  loss_rpn_reg: 0.3814  time: 0.1889  last_time: 0.1557  data_time: 0.0054  last_data_time: 0.0055   lr: 5e-07  max_mem: 3029M
[03/05 14:29:55] d2.utils.events INFO:  eta: 0:06:23  iter: 51959  total_loss: 2.055  loss_ce: 0.2813  loss_giou: 0.2432  loss_bbox: 0.1718  loss_ce_0: 0.3344  loss_giou_0: 0.2442  loss_bbox_0: 0.1848  loss_rpn_cls: 0.199  loss_rpn_reg: 0.3859  time: 0.1889  last_time: 0.1847  data_time: 0.0049  last_data_time: 0.0036   lr: 5e-07  max_mem: 3029M
[03/05 14:29:58] d2.utils.events INFO:  eta: 0:06:19  iter: 51979  total_loss: 2.078  loss_ce: 0.2189  loss_giou: 0.2926  loss_bbox: 0.2098  loss_ce_0: 0.2571  loss_giou_0: 0.2928  loss_bbox_0: 0.2126  loss_rpn_cls: 0.1676  loss_rpn_reg: 0.4281  time: 0.1889  last_time: 0.1835  data_time: 0.0062  last_data_time: 0.0052   lr: 5e-07  max_mem: 3029M
[03/05 14:30:02] d2.utils.events INFO:  eta: 0:06:15  iter: 51999  total_loss: 2.428  loss_ce: 0.2916  loss_giou: 0.2822  loss_bbox: 0.2168  loss_ce_0: 0.3619  loss_giou_0: 0.2902  loss_bbox_0: 0.2449  loss_rpn_cls: 0.1913  loss_rpn_reg: 0.4325  time: 0.1889  last_time: 0.1851  data_time: 0.0052  last_data_time: 0.0034   lr: 5e-07  max_mem: 3029M
[03/05 14:30:06] d2.utils.events INFO:  eta: 0:06:12  iter: 52019  total_loss: 2.359  loss_ce: 0.2851  loss_giou: 0.3501  loss_bbox: 0.2593  loss_ce_0: 0.3404  loss_giou_0: 0.3485  loss_bbox_0: 0.2829  loss_rpn_cls: 0.1652  loss_rpn_reg: 0.4605  time: 0.1889  last_time: 0.2062  data_time: 0.0050  last_data_time: 0.0030   lr: 5e-07  max_mem: 3029M
[03/05 14:30:10] d2.utils.events INFO:  eta: 0:06:08  iter: 52039  total_loss: 2.177  loss_ce: 0.258  loss_giou: 0.2584  loss_bbox: 0.28  loss_ce_0: 0.3141  loss_giou_0: 0.2539  loss_bbox_0: 0.2935  loss_rpn_cls: 0.1785  loss_rpn_reg: 0.4214  time: 0.1889  last_time: 0.1880  data_time: 0.0049  last_data_time: 0.0043   lr: 5e-07  max_mem: 3029M
[03/05 14:30:14] d2.utils.events INFO:  eta: 0:06:04  iter: 52059  total_loss: 2.077  loss_ce: 0.2298  loss_giou: 0.2816  loss_bbox: 0.1783  loss_ce_0: 0.259  loss_giou_0: 0.2936  loss_bbox_0: 0.1917  loss_rpn_cls: 0.1471  loss_rpn_reg: 0.4002  time: 0.1889  last_time: 0.1652  data_time: 0.0048  last_data_time: 0.0053   lr: 5e-07  max_mem: 3029M
[03/05 14:30:18] d2.utils.events INFO:  eta: 0:06:01  iter: 52079  total_loss: 2.11  loss_ce: 0.2617  loss_giou: 0.2966  loss_bbox: 0.212  loss_ce_0: 0.3123  loss_giou_0: 0.312  loss_bbox_0: 0.2447  loss_rpn_cls: 0.1786  loss_rpn_reg: 0.4149  time: 0.1889  last_time: 0.1791  data_time: 0.0051  last_data_time: 0.0032   lr: 5e-07  max_mem: 3029M
[03/05 14:30:21] d2.utils.events INFO:  eta: 0:05:57  iter: 52099  total_loss: 2.229  loss_ce: 0.2775  loss_giou: 0.2339  loss_bbox: 0.2168  loss_ce_0: 0.3477  loss_giou_0: 0.2632  loss_bbox_0: 0.227  loss_rpn_cls: 0.1779  loss_rpn_reg: 0.3909  time: 0.1889  last_time: 0.1765  data_time: 0.0057  last_data_time: 0.0065   lr: 5e-07  max_mem: 3029M
[03/05 14:30:25] d2.utils.events INFO:  eta: 0:05:54  iter: 52119  total_loss: 2.011  loss_ce: 0.2495  loss_giou: 0.2492  loss_bbox: 0.2144  loss_ce_0: 0.2955  loss_giou_0: 0.2582  loss_bbox_0: 0.2485  loss_rpn_cls: 0.1797  loss_rpn_reg: 0.4006  time: 0.1889  last_time: 0.1787  data_time: 0.0050  last_data_time: 0.0023   lr: 5e-07  max_mem: 3029M
[03/05 14:30:29] d2.utils.events INFO:  eta: 0:05:50  iter: 52139  total_loss: 2.12  loss_ce: 0.283  loss_giou: 0.2584  loss_bbox: 0.2172  loss_ce_0: 0.3288  loss_giou_0: 0.2602  loss_bbox_0: 0.2309  loss_rpn_cls: 0.1666  loss_rpn_reg: 0.3949  time: 0.1889  last_time: 0.2344  data_time: 0.0047  last_data_time: 0.0034   lr: 5e-07  max_mem: 3029M
[03/05 14:30:33] d2.utils.events INFO:  eta: 0:05:46  iter: 52159  total_loss: 2.21  loss_ce: 0.2785  loss_giou: 0.2464  loss_bbox: 0.2192  loss_ce_0: 0.3046  loss_giou_0: 0.2612  loss_bbox_0: 0.2719  loss_rpn_cls: 0.2007  loss_rpn_reg: 0.4086  time: 0.1889  last_time: 0.1804  data_time: 0.0046  last_data_time: 0.0045   lr: 5e-07  max_mem: 3029M
[03/05 14:30:37] d2.utils.events INFO:  eta: 0:05:42  iter: 52179  total_loss: 1.965  loss_ce: 0.2299  loss_giou: 0.245  loss_bbox: 0.2048  loss_ce_0: 0.3034  loss_giou_0: 0.2489  loss_bbox_0: 0.2283  loss_rpn_cls: 0.1518  loss_rpn_reg: 0.4047  time: 0.1889  last_time: 0.2097  data_time: 0.0049  last_data_time: 0.0030   lr: 5e-07  max_mem: 3029M
[03/05 14:30:41] d2.utils.events INFO:  eta: 0:05:38  iter: 52199  total_loss: 2.081  loss_ce: 0.2285  loss_giou: 0.2428  loss_bbox: 0.1811  loss_ce_0: 0.2646  loss_giou_0: 0.2683  loss_bbox_0: 0.2118  loss_rpn_cls: 0.1664  loss_rpn_reg: 0.388  time: 0.1889  last_time: 0.2094  data_time: 0.0049  last_data_time: 0.0049   lr: 5e-07  max_mem: 3029M
[03/05 14:30:44] d2.utils.events INFO:  eta: 0:05:34  iter: 52219  total_loss: 2.304  loss_ce: 0.2359  loss_giou: 0.2926  loss_bbox: 0.2131  loss_ce_0: 0.2892  loss_giou_0: 0.3299  loss_bbox_0: 0.2314  loss_rpn_cls: 0.1619  loss_rpn_reg: 0.4431  time: 0.1889  last_time: 0.1887  data_time: 0.0054  last_data_time: 0.0041   lr: 5e-07  max_mem: 3029M
[03/05 14:30:48] d2.utils.events INFO:  eta: 0:05:30  iter: 52239  total_loss: 1.985  loss_ce: 0.2309  loss_giou: 0.2521  loss_bbox: 0.228  loss_ce_0: 0.3071  loss_giou_0: 0.2783  loss_bbox_0: 0.2338  loss_rpn_cls: 0.1638  loss_rpn_reg: 0.3879  time: 0.1889  last_time: 0.1881  data_time: 0.0057  last_data_time: 0.0054   lr: 5e-07  max_mem: 3029M
[03/05 14:30:52] d2.utils.events INFO:  eta: 0:05:27  iter: 52259  total_loss: 2.291  loss_ce: 0.3431  loss_giou: 0.3034  loss_bbox: 0.2001  loss_ce_0: 0.3475  loss_giou_0: 0.3314  loss_bbox_0: 0.2133  loss_rpn_cls: 0.1952  loss_rpn_reg: 0.4055  time: 0.1889  last_time: 0.1778  data_time: 0.0056  last_data_time: 0.0043   lr: 5e-07  max_mem: 3029M
[03/05 14:30:56] d2.utils.events INFO:  eta: 0:05:23  iter: 52279  total_loss: 2.261  loss_ce: 0.2459  loss_giou: 0.2784  loss_bbox: 0.2473  loss_ce_0: 0.2887  loss_giou_0: 0.2907  loss_bbox_0: 0.2536  loss_rpn_cls: 0.1831  loss_rpn_reg: 0.4398  time: 0.1889  last_time: 0.1723  data_time: 0.0054  last_data_time: 0.0063   lr: 5e-07  max_mem: 3029M
[03/05 14:31:00] d2.utils.events INFO:  eta: 0:05:20  iter: 52299  total_loss: 2.107  loss_ce: 0.2435  loss_giou: 0.2486  loss_bbox: 0.2226  loss_ce_0: 0.2779  loss_giou_0: 0.2739  loss_bbox_0: 0.2591  loss_rpn_cls: 0.1457  loss_rpn_reg: 0.4048  time: 0.1889  last_time: 0.1653  data_time: 0.0050  last_data_time: 0.0037   lr: 5e-07  max_mem: 3029M
[03/05 14:31:03] d2.utils.events INFO:  eta: 0:05:16  iter: 52319  total_loss: 2.195  loss_ce: 0.2253  loss_giou: 0.2583  loss_bbox: 0.2449  loss_ce_0: 0.2669  loss_giou_0: 0.2726  loss_bbox_0: 0.2702  loss_rpn_cls: 0.1824  loss_rpn_reg: 0.399  time: 0.1889  last_time: 0.1846  data_time: 0.0047  last_data_time: 0.0048   lr: 5e-07  max_mem: 3029M
[03/05 14:31:07] d2.utils.events INFO:  eta: 0:05:12  iter: 52339  total_loss: 2.293  loss_ce: 0.2624  loss_giou: 0.2778  loss_bbox: 0.2343  loss_ce_0: 0.317  loss_giou_0: 0.2731  loss_bbox_0: 0.2662  loss_rpn_cls: 0.1768  loss_rpn_reg: 0.4131  time: 0.1889  last_time: 0.1981  data_time: 0.0054  last_data_time: 0.0068   lr: 5e-07  max_mem: 3029M
[03/05 14:31:11] d2.utils.events INFO:  eta: 0:05:08  iter: 52359  total_loss: 2.429  loss_ce: 0.3185  loss_giou: 0.2869  loss_bbox: 0.2076  loss_ce_0: 0.3197  loss_giou_0: 0.3132  loss_bbox_0: 0.2465  loss_rpn_cls: 0.1887  loss_rpn_reg: 0.435  time: 0.1889  last_time: 0.1862  data_time: 0.0065  last_data_time: 0.0073   lr: 5e-07  max_mem: 3029M
[03/05 14:31:15] d2.utils.events INFO:  eta: 0:05:05  iter: 52379  total_loss: 2.159  loss_ce: 0.2851  loss_giou: 0.2251  loss_bbox: 0.2134  loss_ce_0: 0.3052  loss_giou_0: 0.2383  loss_bbox_0: 0.2405  loss_rpn_cls: 0.1831  loss_rpn_reg: 0.4106  time: 0.1889  last_time: 0.2159  data_time: 0.0057  last_data_time: 0.0041   lr: 5e-07  max_mem: 3029M
[03/05 14:31:19] d2.utils.events INFO:  eta: 0:05:01  iter: 52399  total_loss: 2.107  loss_ce: 0.241  loss_giou: 0.266  loss_bbox: 0.1794  loss_ce_0: 0.3161  loss_giou_0: 0.2612  loss_bbox_0: 0.1891  loss_rpn_cls: 0.1744  loss_rpn_reg: 0.3918  time: 0.1889  last_time: 0.1926  data_time: 0.0047  last_data_time: 0.0047   lr: 5e-07  max_mem: 3029M
[03/05 14:31:23] d2.utils.events INFO:  eta: 0:04:57  iter: 52419  total_loss: 2.22  loss_ce: 0.2583  loss_giou: 0.2964  loss_bbox: 0.231  loss_ce_0: 0.2683  loss_giou_0: 0.3207  loss_bbox_0: 0.2592  loss_rpn_cls: 0.1782  loss_rpn_reg: 0.4204  time: 0.1889  last_time: 0.1807  data_time: 0.0049  last_data_time: 0.0030   lr: 5e-07  max_mem: 3029M
[03/05 14:31:27] d2.utils.events INFO:  eta: 0:04:53  iter: 52439  total_loss: 2.434  loss_ce: 0.2962  loss_giou: 0.2888  loss_bbox: 0.2041  loss_ce_0: 0.3413  loss_giou_0: 0.3091  loss_bbox_0: 0.2431  loss_rpn_cls: 0.1706  loss_rpn_reg: 0.4719  time: 0.1889  last_time: 0.2020  data_time: 0.0051  last_data_time: 0.0054   lr: 5e-07  max_mem: 3029M
[03/05 14:31:31] d2.utils.events INFO:  eta: 0:04:50  iter: 52459  total_loss: 2.541  loss_ce: 0.3486  loss_giou: 0.3323  loss_bbox: 0.2096  loss_ce_0: 0.3552  loss_giou_0: 0.3485  loss_bbox_0: 0.2387  loss_rpn_cls: 0.2047  loss_rpn_reg: 0.4087  time: 0.1889  last_time: 0.2050  data_time: 0.0049  last_data_time: 0.0039   lr: 5e-07  max_mem: 3029M
[03/05 14:31:35] d2.utils.events INFO:  eta: 0:04:46  iter: 52479  total_loss: 1.995  loss_ce: 0.265  loss_giou: 0.2691  loss_bbox: 0.1913  loss_ce_0: 0.2848  loss_giou_0: 0.2844  loss_bbox_0: 0.2255  loss_rpn_cls: 0.1656  loss_rpn_reg: 0.3997  time: 0.1890  last_time: 0.1947  data_time: 0.0049  last_data_time: 0.0051   lr: 5e-07  max_mem: 3029M
[03/05 14:31:38] d2.utils.events INFO:  eta: 0:04:42  iter: 52499  total_loss: 2.349  loss_ce: 0.3211  loss_giou: 0.3254  loss_bbox: 0.1985  loss_ce_0: 0.3524  loss_giou_0: 0.346  loss_bbox_0: 0.2177  loss_rpn_cls: 0.2137  loss_rpn_reg: 0.4208  time: 0.1890  last_time: 0.1827  data_time: 0.0052  last_data_time: 0.0047   lr: 5e-07  max_mem: 3029M
[03/05 14:31:42] d2.utils.events INFO:  eta: 0:04:38  iter: 52519  total_loss: 1.989  loss_ce: 0.2291  loss_giou: 0.2199  loss_bbox: 0.1795  loss_ce_0: 0.2823  loss_giou_0: 0.2274  loss_bbox_0: 0.2111  loss_rpn_cls: 0.1698  loss_rpn_reg: 0.3898  time: 0.1889  last_time: 0.1867  data_time: 0.0048  last_data_time: 0.0046   lr: 5e-07  max_mem: 3029M
[03/05 14:31:46] d2.utils.events INFO:  eta: 0:04:35  iter: 52539  total_loss: 2.384  loss_ce: 0.2613  loss_giou: 0.2714  loss_bbox: 0.2053  loss_ce_0: 0.3017  loss_giou_0: 0.278  loss_bbox_0: 0.2226  loss_rpn_cls: 0.1733  loss_rpn_reg: 0.3724  time: 0.1890  last_time: 0.1945  data_time: 0.0051  last_data_time: 0.0043   lr: 5e-07  max_mem: 3029M
[03/05 14:31:50] d2.utils.events INFO:  eta: 0:04:31  iter: 52559  total_loss: 2.208  loss_ce: 0.263  loss_giou: 0.258  loss_bbox: 0.207  loss_ce_0: 0.2896  loss_giou_0: 0.265  loss_bbox_0: 0.2442  loss_rpn_cls: 0.1756  loss_rpn_reg: 0.3918  time: 0.1890  last_time: 0.2096  data_time: 0.0054  last_data_time: 0.0075   lr: 5e-07  max_mem: 3029M
[03/05 14:31:54] d2.utils.events INFO:  eta: 0:04:27  iter: 52579  total_loss: 2.196  loss_ce: 0.2459  loss_giou: 0.2715  loss_bbox: 0.1833  loss_ce_0: 0.2901  loss_giou_0: 0.3011  loss_bbox_0: 0.2118  loss_rpn_cls: 0.1894  loss_rpn_reg: 0.4329  time: 0.1890  last_time: 0.2223  data_time: 0.0050  last_data_time: 0.0066   lr: 5e-07  max_mem: 3029M
[03/05 14:31:58] d2.utils.events INFO:  eta: 0:04:23  iter: 52599  total_loss: 2.21  loss_ce: 0.2596  loss_giou: 0.2275  loss_bbox: 0.2546  loss_ce_0: 0.3157  loss_giou_0: 0.2299  loss_bbox_0: 0.2325  loss_rpn_cls: 0.1949  loss_rpn_reg: 0.403  time: 0.1890  last_time: 0.1917  data_time: 0.0052  last_data_time: 0.0030   lr: 5e-07  max_mem: 3029M
[03/05 14:32:02] d2.utils.events INFO:  eta: 0:04:20  iter: 52619  total_loss: 1.912  loss_ce: 0.2692  loss_giou: 0.2234  loss_bbox: 0.1906  loss_ce_0: 0.2647  loss_giou_0: 0.2278  loss_bbox_0: 0.2136  loss_rpn_cls: 0.1522  loss_rpn_reg: 0.3925  time: 0.1890  last_time: 0.2060  data_time: 0.0053  last_data_time: 0.0038   lr: 5e-07  max_mem: 3029M
[03/05 14:32:06] d2.utils.events INFO:  eta: 0:04:16  iter: 52639  total_loss: 2.097  loss_ce: 0.2601  loss_giou: 0.2771  loss_bbox: 0.2347  loss_ce_0: 0.2945  loss_giou_0: 0.2914  loss_bbox_0: 0.2328  loss_rpn_cls: 0.1732  loss_rpn_reg: 0.4204  time: 0.1890  last_time: 0.1799  data_time: 0.0050  last_data_time: 0.0042   lr: 5e-07  max_mem: 3029M
[03/05 14:32:09] d2.utils.events INFO:  eta: 0:04:12  iter: 52659  total_loss: 2.302  loss_ce: 0.2528  loss_giou: 0.2379  loss_bbox: 0.2297  loss_ce_0: 0.2889  loss_giou_0: 0.271  loss_bbox_0: 0.2599  loss_rpn_cls: 0.1638  loss_rpn_reg: 0.398  time: 0.1890  last_time: 0.1941  data_time: 0.0050  last_data_time: 0.0043   lr: 5e-07  max_mem: 3029M
[03/05 14:32:13] d2.utils.events INFO:  eta: 0:04:08  iter: 52679  total_loss: 2.358  loss_ce: 0.2972  loss_giou: 0.2813  loss_bbox: 0.2129  loss_ce_0: 0.3192  loss_giou_0: 0.3041  loss_bbox_0: 0.2329  loss_rpn_cls: 0.1811  loss_rpn_reg: 0.4304  time: 0.1890  last_time: 0.1959  data_time: 0.0050  last_data_time: 0.0047   lr: 5e-07  max_mem: 3029M
[03/05 14:32:17] d2.utils.events INFO:  eta: 0:04:04  iter: 52699  total_loss: 2.363  loss_ce: 0.2979  loss_giou: 0.3264  loss_bbox: 0.2032  loss_ce_0: 0.3088  loss_giou_0: 0.3389  loss_bbox_0: 0.2526  loss_rpn_cls: 0.1867  loss_rpn_reg: 0.4263  time: 0.1890  last_time: 0.2090  data_time: 0.0053  last_data_time: 0.0063   lr: 5e-07  max_mem: 3029M
[03/05 14:32:21] d2.utils.events INFO:  eta: 0:04:01  iter: 52719  total_loss: 2.353  loss_ce: 0.2465  loss_giou: 0.2729  loss_bbox: 0.2186  loss_ce_0: 0.2733  loss_giou_0: 0.2867  loss_bbox_0: 0.2734  loss_rpn_cls: 0.1818  loss_rpn_reg: 0.4046  time: 0.1890  last_time: 0.1796  data_time: 0.0058  last_data_time: 0.0040   lr: 5e-07  max_mem: 3029M
[03/05 14:32:25] d2.utils.events INFO:  eta: 0:03:57  iter: 52739  total_loss: 2.109  loss_ce: 0.2292  loss_giou: 0.2676  loss_bbox: 0.199  loss_ce_0: 0.2947  loss_giou_0: 0.2956  loss_bbox_0: 0.2116  loss_rpn_cls: 0.1617  loss_rpn_reg: 0.4157  time: 0.1890  last_time: 0.2037  data_time: 0.0046  last_data_time: 0.0030   lr: 5e-07  max_mem: 3029M
[03/05 14:32:28] d2.utils.events INFO:  eta: 0:03:53  iter: 52759  total_loss: 2.442  loss_ce: 0.281  loss_giou: 0.3026  loss_bbox: 0.2462  loss_ce_0: 0.3158  loss_giou_0: 0.3102  loss_bbox_0: 0.256  loss_rpn_cls: 0.1917  loss_rpn_reg: 0.4371  time: 0.1890  last_time: 0.1885  data_time: 0.0050  last_data_time: 0.0061   lr: 5e-07  max_mem: 3029M
[03/05 14:32:32] d2.utils.events INFO:  eta: 0:03:50  iter: 52779  total_loss: 1.991  loss_ce: 0.268  loss_giou: 0.2427  loss_bbox: 0.1808  loss_ce_0: 0.2896  loss_giou_0: 0.2779  loss_bbox_0: 0.1906  loss_rpn_cls: 0.1498  loss_rpn_reg: 0.3914  time: 0.1890  last_time: 0.2082  data_time: 0.0055  last_data_time: 0.0066   lr: 5e-07  max_mem: 3029M
[03/05 14:32:36] d2.utils.events INFO:  eta: 0:03:46  iter: 52799  total_loss: 2.208  loss_ce: 0.2723  loss_giou: 0.306  loss_bbox: 0.2156  loss_ce_0: 0.3217  loss_giou_0: 0.3173  loss_bbox_0: 0.2528  loss_rpn_cls: 0.1822  loss_rpn_reg: 0.4097  time: 0.1890  last_time: 0.1827  data_time: 0.0051  last_data_time: 0.0096   lr: 5e-07  max_mem: 3029M
[03/05 14:32:40] d2.utils.events INFO:  eta: 0:03:42  iter: 52819  total_loss: 2.373  loss_ce: 0.2676  loss_giou: 0.3168  loss_bbox: 0.2126  loss_ce_0: 0.3248  loss_giou_0: 0.3165  loss_bbox_0: 0.2352  loss_rpn_cls: 0.1743  loss_rpn_reg: 0.4368  time: 0.1890  last_time: 0.2069  data_time: 0.0047  last_data_time: 0.0045   lr: 5e-07  max_mem: 3029M
[03/05 14:32:44] d2.utils.events INFO:  eta: 0:03:39  iter: 52839  total_loss: 2.211  loss_ce: 0.2749  loss_giou: 0.2394  loss_bbox: 0.21  loss_ce_0: 0.3075  loss_giou_0: 0.2741  loss_bbox_0: 0.2309  loss_rpn_cls: 0.1863  loss_rpn_reg: 0.4446  time: 0.1890  last_time: 0.1890  data_time: 0.0048  last_data_time: 0.0052   lr: 5e-07  max_mem: 3029M
[03/05 14:32:48] d2.utils.events INFO:  eta: 0:03:35  iter: 52859  total_loss: 2.357  loss_ce: 0.2665  loss_giou: 0.3027  loss_bbox: 0.2231  loss_ce_0: 0.3252  loss_giou_0: 0.3  loss_bbox_0: 0.2382  loss_rpn_cls: 0.1737  loss_rpn_reg: 0.4102  time: 0.1890  last_time: 0.1815  data_time: 0.0046  last_data_time: 0.0039   lr: 5e-07  max_mem: 3029M
[03/05 14:32:51] d2.utils.events INFO:  eta: 0:03:31  iter: 52879  total_loss: 1.963  loss_ce: 0.2007  loss_giou: 0.2318  loss_bbox: 0.2236  loss_ce_0: 0.2828  loss_giou_0: 0.2495  loss_bbox_0: 0.2159  loss_rpn_cls: 0.1801  loss_rpn_reg: 0.4113  time: 0.1890  last_time: 0.1665  data_time: 0.0056  last_data_time: 0.0026   lr: 5e-07  max_mem: 3029M
[03/05 14:32:55] d2.utils.events INFO:  eta: 0:03:27  iter: 52899  total_loss: 2.569  loss_ce: 0.3206  loss_giou: 0.3174  loss_bbox: 0.2337  loss_ce_0: 0.3747  loss_giou_0: 0.3284  loss_bbox_0: 0.2672  loss_rpn_cls: 0.1913  loss_rpn_reg: 0.4559  time: 0.1890  last_time: 0.2060  data_time: 0.0054  last_data_time: 0.0053   lr: 5e-07  max_mem: 3029M
[03/05 14:32:59] d2.utils.events INFO:  eta: 0:03:23  iter: 52919  total_loss: 1.936  loss_ce: 0.1914  loss_giou: 0.2292  loss_bbox: 0.2113  loss_ce_0: 0.2485  loss_giou_0: 0.2496  loss_bbox_0: 0.2154  loss_rpn_cls: 0.1684  loss_rpn_reg: 0.3829  time: 0.1890  last_time: 0.1860  data_time: 0.0049  last_data_time: 0.0046   lr: 5e-07  max_mem: 3029M
[03/05 14:33:03] d2.utils.events INFO:  eta: 0:03:19  iter: 52939  total_loss: 2.42  loss_ce: 0.2893  loss_giou: 0.3076  loss_bbox: 0.2298  loss_ce_0: 0.3437  loss_giou_0: 0.3522  loss_bbox_0: 0.2621  loss_rpn_cls: 0.182  loss_rpn_reg: 0.4685  time: 0.1889  last_time: 0.2079  data_time: 0.0054  last_data_time: 0.0083   lr: 5e-07  max_mem: 3029M
[03/05 14:33:07] d2.utils.events INFO:  eta: 0:03:15  iter: 52959  total_loss: 2.267  loss_ce: 0.2407  loss_giou: 0.2692  loss_bbox: 0.2308  loss_ce_0: 0.2937  loss_giou_0: 0.2824  loss_bbox_0: 0.2492  loss_rpn_cls: 0.187  loss_rpn_reg: 0.4248  time: 0.1890  last_time: 0.1751  data_time: 0.0052  last_data_time: 0.0026   lr: 5e-07  max_mem: 3029M
[03/05 14:33:11] d2.utils.events INFO:  eta: 0:03:12  iter: 52979  total_loss: 2.228  loss_ce: 0.2864  loss_giou: 0.2641  loss_bbox: 0.1878  loss_ce_0: 0.3212  loss_giou_0: 0.2901  loss_bbox_0: 0.2085  loss_rpn_cls: 0.2023  loss_rpn_reg: 0.4074  time: 0.1890  last_time: 0.2113  data_time: 0.0061  last_data_time: 0.0063   lr: 5e-07  max_mem: 3029M
[03/05 14:33:15] d2.utils.events INFO:  eta: 0:03:08  iter: 52999  total_loss: 2.29  loss_ce: 0.2611  loss_giou: 0.3068  loss_bbox: 0.2192  loss_ce_0: 0.2699  loss_giou_0: 0.3434  loss_bbox_0: 0.2406  loss_rpn_cls: 0.1485  loss_rpn_reg: 0.4275  time: 0.1890  last_time: 0.1987  data_time: 0.0056  last_data_time: 0.0057   lr: 5e-07  max_mem: 3029M
[03/05 14:33:19] d2.utils.events INFO:  eta: 0:03:05  iter: 53019  total_loss: 2.203  loss_ce: 0.2688  loss_giou: 0.2954  loss_bbox: 0.2124  loss_ce_0: 0.2924  loss_giou_0: 0.3269  loss_bbox_0: 0.2197  loss_rpn_cls: 0.1848  loss_rpn_reg: 0.3936  time: 0.1890  last_time: 0.1883  data_time: 0.0057  last_data_time: 0.0040   lr: 5e-07  max_mem: 3029M
[03/05 14:33:22] d2.utils.events INFO:  eta: 0:03:01  iter: 53039  total_loss: 2.534  loss_ce: 0.2803  loss_giou: 0.3222  loss_bbox: 0.2108  loss_ce_0: 0.3177  loss_giou_0: 0.3554  loss_bbox_0: 0.2294  loss_rpn_cls: 0.1967  loss_rpn_reg: 0.4502  time: 0.1890  last_time: 0.1910  data_time: 0.0051  last_data_time: 0.0050   lr: 5e-07  max_mem: 3029M
[03/05 14:33:26] d2.utils.events INFO:  eta: 0:02:57  iter: 53059  total_loss: 2.181  loss_ce: 0.25  loss_giou: 0.2699  loss_bbox: 0.2374  loss_ce_0: 0.2745  loss_giou_0: 0.2979  loss_bbox_0: 0.2603  loss_rpn_cls: 0.1625  loss_rpn_reg: 0.3835  time: 0.1890  last_time: 0.2002  data_time: 0.0048  last_data_time: 0.0053   lr: 5e-07  max_mem: 3029M
[03/05 14:33:30] d2.utils.events INFO:  eta: 0:02:53  iter: 53079  total_loss: 2.2  loss_ce: 0.2217  loss_giou: 0.2621  loss_bbox: 0.2167  loss_ce_0: 0.2967  loss_giou_0: 0.267  loss_bbox_0: 0.2401  loss_rpn_cls: 0.1502  loss_rpn_reg: 0.4153  time: 0.1890  last_time: 0.1793  data_time: 0.0055  last_data_time: 0.0043   lr: 5e-07  max_mem: 3029M
[03/05 14:33:34] d2.utils.events INFO:  eta: 0:02:49  iter: 53099  total_loss: 2.076  loss_ce: 0.2161  loss_giou: 0.2514  loss_bbox: 0.2279  loss_ce_0: 0.2845  loss_giou_0: 0.2696  loss_bbox_0: 0.245  loss_rpn_cls: 0.1668  loss_rpn_reg: 0.4361  time: 0.1890  last_time: 0.1909  data_time: 0.0048  last_data_time: 0.0054   lr: 5e-07  max_mem: 3029M
[03/05 14:33:38] d2.utils.events INFO:  eta: 0:02:46  iter: 53119  total_loss: 2.119  loss_ce: 0.262  loss_giou: 0.2717  loss_bbox: 0.2035  loss_ce_0: 0.3121  loss_giou_0: 0.285  loss_bbox_0: 0.2215  loss_rpn_cls: 0.1837  loss_rpn_reg: 0.4074  time: 0.1890  last_time: 0.1694  data_time: 0.0063  last_data_time: 0.0039   lr: 5e-07  max_mem: 3029M
[03/05 14:33:42] d2.utils.events INFO:  eta: 0:02:42  iter: 53139  total_loss: 2.237  loss_ce: 0.3064  loss_giou: 0.2668  loss_bbox: 0.1848  loss_ce_0: 0.3509  loss_giou_0: 0.2945  loss_bbox_0: 0.2321  loss_rpn_cls: 0.1863  loss_rpn_reg: 0.4232  time: 0.1890  last_time: 0.1894  data_time: 0.0056  last_data_time: 0.0039   lr: 5e-07  max_mem: 3029M
[03/05 14:33:45] d2.utils.events INFO:  eta: 0:02:38  iter: 53159  total_loss: 2.107  loss_ce: 0.2705  loss_giou: 0.242  loss_bbox: 0.2123  loss_ce_0: 0.3063  loss_giou_0: 0.2657  loss_bbox_0: 0.2491  loss_rpn_cls: 0.1548  loss_rpn_reg: 0.387  time: 0.1890  last_time: 0.1718  data_time: 0.0049  last_data_time: 0.0043   lr: 5e-07  max_mem: 3029M
[03/05 14:33:49] d2.utils.events INFO:  eta: 0:02:34  iter: 53179  total_loss: 2.178  loss_ce: 0.2291  loss_giou: 0.2566  loss_bbox: 0.2189  loss_ce_0: 0.2989  loss_giou_0: 0.2701  loss_bbox_0: 0.2352  loss_rpn_cls: 0.1936  loss_rpn_reg: 0.3747  time: 0.1890  last_time: 0.1953  data_time: 0.0051  last_data_time: 0.0038   lr: 5e-07  max_mem: 3029M
[03/05 14:33:53] d2.utils.events INFO:  eta: 0:02:31  iter: 53199  total_loss: 2.105  loss_ce: 0.2102  loss_giou: 0.2434  loss_bbox: 0.2167  loss_ce_0: 0.284  loss_giou_0: 0.2672  loss_bbox_0: 0.2434  loss_rpn_cls: 0.1755  loss_rpn_reg: 0.3645  time: 0.1890  last_time: 0.1908  data_time: 0.0053  last_data_time: 0.0038   lr: 5e-07  max_mem: 3029M
[03/05 14:33:57] d2.utils.events INFO:  eta: 0:02:27  iter: 53219  total_loss: 2.273  loss_ce: 0.2339  loss_giou: 0.272  loss_bbox: 0.244  loss_ce_0: 0.2922  loss_giou_0: 0.2928  loss_bbox_0: 0.2648  loss_rpn_cls: 0.178  loss_rpn_reg: 0.3988  time: 0.1890  last_time: 0.1818  data_time: 0.0052  last_data_time: 0.0033   lr: 5e-07  max_mem: 3029M
[03/05 14:34:01] d2.utils.events INFO:  eta: 0:02:23  iter: 53239  total_loss: 2.424  loss_ce: 0.3099  loss_giou: 0.2983  loss_bbox: 0.2094  loss_ce_0: 0.3189  loss_giou_0: 0.3234  loss_bbox_0: 0.2547  loss_rpn_cls: 0.1768  loss_rpn_reg: 0.402  time: 0.1890  last_time: 0.1585  data_time: 0.0047  last_data_time: 0.0040   lr: 5e-07  max_mem: 3029M
[03/05 14:34:04] d2.utils.events INFO:  eta: 0:02:20  iter: 53259  total_loss: 2.504  loss_ce: 0.2517  loss_giou: 0.3263  loss_bbox: 0.2603  loss_ce_0: 0.3194  loss_giou_0: 0.3335  loss_bbox_0: 0.2527  loss_rpn_cls: 0.1874  loss_rpn_reg: 0.4576  time: 0.1890  last_time: 0.1707  data_time: 0.0052  last_data_time: 0.0038   lr: 5e-07  max_mem: 3029M
[03/05 14:34:08] d2.utils.events INFO:  eta: 0:02:16  iter: 53279  total_loss: 2.085  loss_ce: 0.2147  loss_giou: 0.2441  loss_bbox: 0.2383  loss_ce_0: 0.2621  loss_giou_0: 0.2772  loss_bbox_0: 0.2644  loss_rpn_cls: 0.1554  loss_rpn_reg: 0.4112  time: 0.1890  last_time: 0.1961  data_time: 0.0052  last_data_time: 0.0038   lr: 5e-07  max_mem: 3029M
[03/05 14:34:12] d2.utils.events INFO:  eta: 0:02:12  iter: 53299  total_loss: 2.225  loss_ce: 0.2595  loss_giou: 0.224  loss_bbox: 0.2053  loss_ce_0: 0.3413  loss_giou_0: 0.2262  loss_bbox_0: 0.2388  loss_rpn_cls: 0.1976  loss_rpn_reg: 0.381  time: 0.1890  last_time: 0.1642  data_time: 0.0053  last_data_time: 0.0026   lr: 5e-07  max_mem: 3029M
[03/05 14:34:16] d2.utils.events INFO:  eta: 0:02:08  iter: 53319  total_loss: 2.264  loss_ce: 0.2287  loss_giou: 0.283  loss_bbox: 0.2303  loss_ce_0: 0.2475  loss_giou_0: 0.3  loss_bbox_0: 0.2753  loss_rpn_cls: 0.1464  loss_rpn_reg: 0.4134  time: 0.1890  last_time: 0.1889  data_time: 0.0052  last_data_time: 0.0024   lr: 5e-07  max_mem: 3029M
[03/05 14:34:20] d2.utils.events INFO:  eta: 0:02:04  iter: 53339  total_loss: 2.274  loss_ce: 0.2764  loss_giou: 0.2921  loss_bbox: 0.2482  loss_ce_0: 0.3043  loss_giou_0: 0.3108  loss_bbox_0: 0.2421  loss_rpn_cls: 0.1936  loss_rpn_reg: 0.4166  time: 0.1890  last_time: 0.1674  data_time: 0.0053  last_data_time: 0.0051   lr: 5e-07  max_mem: 3029M
[03/05 14:34:23] d2.utils.events INFO:  eta: 0:02:00  iter: 53359  total_loss: 2.294  loss_ce: 0.2428  loss_giou: 0.3066  loss_bbox: 0.2325  loss_ce_0: 0.2861  loss_giou_0: 0.3311  loss_bbox_0: 0.2361  loss_rpn_cls: 0.171  loss_rpn_reg: 0.4175  time: 0.1890  last_time: 0.1993  data_time: 0.0054  last_data_time: 0.0041   lr: 5e-07  max_mem: 3029M
[03/05 14:34:27] d2.utils.events INFO:  eta: 0:01:57  iter: 53379  total_loss: 2.064  loss_ce: 0.2727  loss_giou: 0.2018  loss_bbox: 0.204  loss_ce_0: 0.3402  loss_giou_0: 0.2449  loss_bbox_0: 0.2267  loss_rpn_cls: 0.1817  loss_rpn_reg: 0.3928  time: 0.1889  last_time: 0.1854  data_time: 0.0050  last_data_time: 0.0034   lr: 5e-07  max_mem: 3029M
[03/05 14:34:31] d2.utils.events INFO:  eta: 0:01:53  iter: 53399  total_loss: 2.499  loss_ce: 0.2992  loss_giou: 0.3298  loss_bbox: 0.2709  loss_ce_0: 0.3503  loss_giou_0: 0.3656  loss_bbox_0: 0.2751  loss_rpn_cls: 0.2042  loss_rpn_reg: 0.4488  time: 0.1889  last_time: 0.1815  data_time: 0.0047  last_data_time: 0.0065   lr: 5e-07  max_mem: 3029M
[03/05 14:34:35] d2.utils.events INFO:  eta: 0:01:49  iter: 53419  total_loss: 2.43  loss_ce: 0.3043  loss_giou: 0.3108  loss_bbox: 0.2247  loss_ce_0: 0.3261  loss_giou_0: 0.3275  loss_bbox_0: 0.251  loss_rpn_cls: 0.1984  loss_rpn_reg: 0.4374  time: 0.1889  last_time: 0.2073  data_time: 0.0048  last_data_time: 0.0044   lr: 5e-07  max_mem: 3029M
[03/05 14:34:38] d2.utils.events INFO:  eta: 0:01:45  iter: 53439  total_loss: 1.984  loss_ce: 0.2444  loss_giou: 0.2372  loss_bbox: 0.1824  loss_ce_0: 0.3076  loss_giou_0: 0.2628  loss_bbox_0: 0.2114  loss_rpn_cls: 0.1794  loss_rpn_reg: 0.3972  time: 0.1889  last_time: 0.1609  data_time: 0.0049  last_data_time: 0.0040   lr: 5e-07  max_mem: 3029M
[03/05 14:34:42] d2.utils.events INFO:  eta: 0:01:41  iter: 53459  total_loss: 2.204  loss_ce: 0.2933  loss_giou: 0.2728  loss_bbox: 0.2536  loss_ce_0: 0.3473  loss_giou_0: 0.2682  loss_bbox_0: 0.288  loss_rpn_cls: 0.1765  loss_rpn_reg: 0.4152  time: 0.1889  last_time: 0.1754  data_time: 0.0041  last_data_time: 0.0047   lr: 5e-07  max_mem: 3029M
[03/05 14:34:46] d2.utils.events INFO:  eta: 0:01:37  iter: 53479  total_loss: 2.162  loss_ce: 0.2702  loss_giou: 0.277  loss_bbox: 0.198  loss_ce_0: 0.3136  loss_giou_0: 0.2915  loss_bbox_0: 0.2179  loss_rpn_cls: 0.1615  loss_rpn_reg: 0.3979  time: 0.1889  last_time: 0.1751  data_time: 0.0047  last_data_time: 0.0052   lr: 5e-07  max_mem: 3029M
[03/05 14:34:50] d2.utils.events INFO:  eta: 0:01:34  iter: 53499  total_loss: 2.252  loss_ce: 0.2527  loss_giou: 0.3177  loss_bbox: 0.2124  loss_ce_0: 0.2903  loss_giou_0: 0.3443  loss_bbox_0: 0.2731  loss_rpn_cls: 0.1928  loss_rpn_reg: 0.4062  time: 0.1889  last_time: 0.1850  data_time: 0.0073  last_data_time: 0.0113   lr: 5e-07  max_mem: 3029M
[03/05 14:34:54] d2.utils.events INFO:  eta: 0:01:30  iter: 53519  total_loss: 2.101  loss_ce: 0.2121  loss_giou: 0.2591  loss_bbox: 0.2135  loss_ce_0: 0.2788  loss_giou_0: 0.2782  loss_bbox_0: 0.2201  loss_rpn_cls: 0.1876  loss_rpn_reg: 0.3942  time: 0.1889  last_time: 0.1843  data_time: 0.0052  last_data_time: 0.0055   lr: 5e-07  max_mem: 3029M
[03/05 14:34:57] d2.utils.events INFO:  eta: 0:01:26  iter: 53539  total_loss: 2.375  loss_ce: 0.2434  loss_giou: 0.2766  loss_bbox: 0.2192  loss_ce_0: 0.3036  loss_giou_0: 0.292  loss_bbox_0: 0.2122  loss_rpn_cls: 0.1856  loss_rpn_reg: 0.4332  time: 0.1889  last_time: 0.1671  data_time: 0.0049  last_data_time: 0.0037   lr: 5e-07  max_mem: 3029M
[03/05 14:35:01] d2.utils.events INFO:  eta: 0:01:22  iter: 53559  total_loss: 2.304  loss_ce: 0.2924  loss_giou: 0.3034  loss_bbox: 0.2288  loss_ce_0: 0.3172  loss_giou_0: 0.3059  loss_bbox_0: 0.2431  loss_rpn_cls: 0.174  loss_rpn_reg: 0.4146  time: 0.1889  last_time: 0.1879  data_time: 0.0051  last_data_time: 0.0038   lr: 5e-07  max_mem: 3029M
[03/05 14:35:05] d2.utils.events INFO:  eta: 0:01:18  iter: 53579  total_loss: 2.112  loss_ce: 0.3035  loss_giou: 0.2389  loss_bbox: 0.1934  loss_ce_0: 0.3293  loss_giou_0: 0.2525  loss_bbox_0: 0.2236  loss_rpn_cls: 0.1822  loss_rpn_reg: 0.3553  time: 0.1889  last_time: 0.2062  data_time: 0.0053  last_data_time: 0.0085   lr: 5e-07  max_mem: 3029M
[03/05 14:35:09] d2.utils.events INFO:  eta: 0:01:15  iter: 53599  total_loss: 2.202  loss_ce: 0.28  loss_giou: 0.2773  loss_bbox: 0.2071  loss_ce_0: 0.3217  loss_giou_0: 0.2972  loss_bbox_0: 0.2446  loss_rpn_cls: 0.1668  loss_rpn_reg: 0.4306  time: 0.1889  last_time: 0.2046  data_time: 0.0055  last_data_time: 0.0044   lr: 5e-07  max_mem: 3029M
[03/05 14:35:13] d2.utils.events INFO:  eta: 0:01:11  iter: 53619  total_loss: 2.064  loss_ce: 0.2192  loss_giou: 0.2552  loss_bbox: 0.1774  loss_ce_0: 0.2653  loss_giou_0: 0.285  loss_bbox_0: 0.1968  loss_rpn_cls: 0.1641  loss_rpn_reg: 0.4233  time: 0.1889  last_time: 0.2176  data_time: 0.0057  last_data_time: 0.0067   lr: 5e-07  max_mem: 3029M
[03/05 14:35:17] d2.utils.events INFO:  eta: 0:01:07  iter: 53639  total_loss: 2.17  loss_ce: 0.2285  loss_giou: 0.2761  loss_bbox: 0.1948  loss_ce_0: 0.2646  loss_giou_0: 0.2975  loss_bbox_0: 0.2123  loss_rpn_cls: 0.1741  loss_rpn_reg: 0.3937  time: 0.1889  last_time: 0.1996  data_time: 0.0059  last_data_time: 0.0040   lr: 5e-07  max_mem: 3029M
[03/05 14:35:21] d2.utils.events INFO:  eta: 0:01:04  iter: 53659  total_loss: 2.326  loss_ce: 0.2605  loss_giou: 0.3416  loss_bbox: 0.2004  loss_ce_0: 0.2801  loss_giou_0: 0.3429  loss_bbox_0: 0.2207  loss_rpn_cls: 0.1925  loss_rpn_reg: 0.4166  time: 0.1889  last_time: 0.1938  data_time: 0.0050  last_data_time: 0.0040   lr: 5e-07  max_mem: 3029M
[03/05 14:35:24] d2.utils.events INFO:  eta: 0:01:00  iter: 53679  total_loss: 2.181  loss_ce: 0.2655  loss_giou: 0.2682  loss_bbox: 0.1952  loss_ce_0: 0.2953  loss_giou_0: 0.2901  loss_bbox_0: 0.215  loss_rpn_cls: 0.1829  loss_rpn_reg: 0.4038  time: 0.1889  last_time: 0.1901  data_time: 0.0047  last_data_time: 0.0040   lr: 5e-07  max_mem: 3029M
[03/05 14:35:28] d2.utils.events INFO:  eta: 0:00:56  iter: 53699  total_loss: 2.403  loss_ce: 0.2678  loss_giou: 0.3053  loss_bbox: 0.2129  loss_ce_0: 0.3261  loss_giou_0: 0.3088  loss_bbox_0: 0.2189  loss_rpn_cls: 0.1986  loss_rpn_reg: 0.4206  time: 0.1889  last_time: 0.1989  data_time: 0.0048  last_data_time: 0.0042   lr: 5e-07  max_mem: 3029M
[03/05 14:35:32] d2.utils.events INFO:  eta: 0:00:52  iter: 53719  total_loss: 1.992  loss_ce: 0.2158  loss_giou: 0.2358  loss_bbox: 0.2126  loss_ce_0: 0.2537  loss_giou_0: 0.2491  loss_bbox_0: 0.242  loss_rpn_cls: 0.1827  loss_rpn_reg: 0.4122  time: 0.1889  last_time: 0.1847  data_time: 0.0044  last_data_time: 0.0036   lr: 5e-07  max_mem: 3029M
[03/05 14:35:36] d2.utils.events INFO:  eta: 0:00:48  iter: 53739  total_loss: 2.301  loss_ce: 0.2754  loss_giou: 0.2753  loss_bbox: 0.2488  loss_ce_0: 0.3525  loss_giou_0: 0.2722  loss_bbox_0: 0.2861  loss_rpn_cls: 0.172  loss_rpn_reg: 0.4167  time: 0.1889  last_time: 0.1766  data_time: 0.0053  last_data_time: 0.0043   lr: 5e-07  max_mem: 3029M
[03/05 14:35:39] d2.utils.events INFO:  eta: 0:00:45  iter: 53759  total_loss: 2.522  loss_ce: 0.3384  loss_giou: 0.2747  loss_bbox: 0.2019  loss_ce_0: 0.3449  loss_giou_0: 0.2997  loss_bbox_0: 0.2195  loss_rpn_cls: 0.176  loss_rpn_reg: 0.4259  time: 0.1889  last_time: 0.1549  data_time: 0.0047  last_data_time: 0.0008   lr: 5e-07  max_mem: 3029M
[03/05 14:35:44] d2.utils.events INFO:  eta: 0:00:41  iter: 53779  total_loss: 1.997  loss_ce: 0.278  loss_giou: 0.2689  loss_bbox: 0.1771  loss_ce_0: 0.3178  loss_giou_0: 0.2701  loss_bbox_0: 0.1938  loss_rpn_cls: 0.1609  loss_rpn_reg: 0.3645  time: 0.1889  last_time: 0.2011  data_time: 0.0051  last_data_time: 0.0081   lr: 5e-07  max_mem: 3029M
[03/05 14:35:47] d2.utils.events INFO:  eta: 0:00:37  iter: 53799  total_loss: 2.176  loss_ce: 0.2418  loss_giou: 0.271  loss_bbox: 0.2248  loss_ce_0: 0.3071  loss_giou_0: 0.2787  loss_bbox_0: 0.2463  loss_rpn_cls: 0.1661  loss_rpn_reg: 0.3864  time: 0.1889  last_time: 0.1977  data_time: 0.0047  last_data_time: 0.0037   lr: 5e-07  max_mem: 3029M
[03/05 14:35:51] d2.utils.events INFO:  eta: 0:00:33  iter: 53819  total_loss: 1.957  loss_ce: 0.1975  loss_giou: 0.2266  loss_bbox: 0.2129  loss_ce_0: 0.2439  loss_giou_0: 0.2468  loss_bbox_0: 0.2252  loss_rpn_cls: 0.1629  loss_rpn_reg: 0.3738  time: 0.1889  last_time: 0.1753  data_time: 0.0058  last_data_time: 0.0054   lr: 5e-07  max_mem: 3029M
[03/05 14:35:55] d2.utils.events INFO:  eta: 0:00:30  iter: 53839  total_loss: 2.269  loss_ce: 0.2437  loss_giou: 0.2958  loss_bbox: 0.2393  loss_ce_0: 0.283  loss_giou_0: 0.2967  loss_bbox_0: 0.2532  loss_rpn_cls: 0.1986  loss_rpn_reg: 0.412  time: 0.1889  last_time: 0.2176  data_time: 0.0051  last_data_time: 0.0070   lr: 5e-07  max_mem: 3029M
[03/05 14:35:59] d2.utils.events INFO:  eta: 0:00:26  iter: 53859  total_loss: 2.196  loss_ce: 0.2447  loss_giou: 0.3193  loss_bbox: 0.2138  loss_ce_0: 0.3007  loss_giou_0: 0.3077  loss_bbox_0: 0.2261  loss_rpn_cls: 0.1786  loss_rpn_reg: 0.3821  time: 0.1889  last_time: 0.1847  data_time: 0.0047  last_data_time: 0.0042   lr: 5e-07  max_mem: 3029M
[03/05 14:36:02] d2.utils.events INFO:  eta: 0:00:22  iter: 53879  total_loss: 2.214  loss_ce: 0.2706  loss_giou: 0.2745  loss_bbox: 0.2291  loss_ce_0: 0.355  loss_giou_0: 0.2992  loss_bbox_0: 0.2481  loss_rpn_cls: 0.1734  loss_rpn_reg: 0.3892  time: 0.1889  last_time: 0.1720  data_time: 0.0051  last_data_time: 0.0035   lr: 5e-07  max_mem: 3029M
[03/05 14:36:06] d2.utils.events INFO:  eta: 0:00:18  iter: 53899  total_loss: 2.259  loss_ce: 0.2552  loss_giou: 0.2898  loss_bbox: 0.2102  loss_ce_0: 0.3159  loss_giou_0: 0.2965  loss_bbox_0: 0.2227  loss_rpn_cls: 0.1572  loss_rpn_reg: 0.4415  time: 0.1889  last_time: 0.1833  data_time: 0.0050  last_data_time: 0.0055   lr: 5e-07  max_mem: 3029M
[03/05 14:36:10] d2.utils.events INFO:  eta: 0:00:15  iter: 53919  total_loss: 2.098  loss_ce: 0.2327  loss_giou: 0.2527  loss_bbox: 0.2017  loss_ce_0: 0.3078  loss_giou_0: 0.2625  loss_bbox_0: 0.2242  loss_rpn_cls: 0.171  loss_rpn_reg: 0.4026  time: 0.1889  last_time: 0.2012  data_time: 0.0048  last_data_time: 0.0040   lr: 5e-07  max_mem: 3029M
[03/05 14:36:14] d2.utils.events INFO:  eta: 0:00:11  iter: 53939  total_loss: 2.099  loss_ce: 0.2246  loss_giou: 0.2764  loss_bbox: 0.1866  loss_ce_0: 0.2538  loss_giou_0: 0.2837  loss_bbox_0: 0.2308  loss_rpn_cls: 0.1673  loss_rpn_reg: 0.4169  time: 0.1889  last_time: 0.1943  data_time: 0.0052  last_data_time: 0.0045   lr: 5e-07  max_mem: 3029M
[03/05 14:36:17] d2.utils.events INFO:  eta: 0:00:07  iter: 53959  total_loss: 2.281  loss_ce: 0.2775  loss_giou: 0.2638  loss_bbox: 0.2024  loss_ce_0: 0.3118  loss_giou_0: 0.2744  loss_bbox_0: 0.2077  loss_rpn_cls: 0.1777  loss_rpn_reg: 0.4213  time: 0.1889  last_time: 0.1802  data_time: 0.0052  last_data_time: 0.0069   lr: 5e-07  max_mem: 3029M
[03/05 14:36:21] d2.utils.events INFO:  eta: 0:00:03  iter: 53979  total_loss: 2.337  loss_ce: 0.2635  loss_giou: 0.315  loss_bbox: 0.2727  loss_ce_0: 0.3263  loss_giou_0: 0.308  loss_bbox_0: 0.2737  loss_rpn_cls: 0.1888  loss_rpn_reg: 0.4116  time: 0.1889  last_time: 0.1730  data_time: 0.0052  last_data_time: 0.0052   lr: 5e-07  max_mem: 3029M
[03/05 14:36:25] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/t1/model_final.pth
[03/05 14:36:26] d2.utils.events INFO:  eta: 0:00:00  iter: 53999  total_loss: 2.084  loss_ce: 0.23  loss_giou: 0.2639  loss_bbox: 0.2248  loss_ce_0: 0.3205  loss_giou_0: 0.29  loss_bbox_0: 0.1991  loss_rpn_cls: 0.1505  loss_rpn_reg: 0.4047  time: 0.1889  last_time: 0.1865  data_time: 0.0046  last_data_time: 0.0038   lr: 5e-07  max_mem: 3029M
[03/05 14:36:26] d2.engine.hooks INFO: Overall training speed: 53998 iterations in 2:50:02 (0.1889 s / it)
[03/05 14:36:26] d2.engine.hooks INFO: Total training time: 2:52:56 (0:02:53 on hooks)
[03/06 14:03:57] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 14:03:58] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 14:03:58] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 14:03:58] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 14:03:59] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 14:03:59] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 14:04:11] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 14:04:14] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 14:04:14] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 14:04:17] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/06 14:04:17] d2.data.build INFO: Number of datapoints: 16551
[03/06 14:04:17] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 14:04:17] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 14:04:17] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/06 14:04:17] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/06 14:04:17] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/06 14:04:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/06 14:04:25] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/06 14:04:25] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/06 14:04:25] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/06 14:04:25] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/06 14:05:32] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 14:05:33] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 14:05:33] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 14:05:33] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 14:05:33] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 14:05:33] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 14:05:39] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 14:05:42] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 14:05:42] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 14:05:43] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/06 14:05:43] d2.data.build INFO: Number of datapoints: 16551
[03/06 14:05:43] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 14:05:43] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 14:05:43] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/06 14:05:43] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/06 14:05:43] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/06 14:05:43] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/06 14:05:43] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/06 14:05:43] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/06 14:05:44] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/06 14:05:44] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/06 14:09:28] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 14:09:29] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 14:09:29] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 14:09:29] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 14:09:29] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 14:09:29] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 14:09:34] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 14:09:37] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 14:09:37] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 14:09:38] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/06 14:09:38] d2.data.build INFO: Number of datapoints: 16551
[03/06 14:09:38] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 14:09:38] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 14:09:38] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/06 14:09:38] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/06 14:09:38] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/06 14:09:38] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/06 14:09:38] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/06 14:09:38] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/06 14:09:39] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/06 14:09:39] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/06 14:27:06] detectron2 INFO: Rank of current process: 0. World size: 2
[03/06 14:27:07] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 14:27:07] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4'], resume=False)
[03/06 14:27:07] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 14:27:07] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 14:27:07] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 14:27:08] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 14:27:10] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 14:27:10] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 14:27:11] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/06 14:27:11] d2.data.build INFO: Number of datapoints: 16551
[03/06 14:27:11] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 14:27:11] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 14:27:11] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/06 14:27:11] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/06 14:27:11] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[03/06 14:27:11] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/wxf/.torch/iopath_cache/detectron2/ImageNetPretrained/torchvision/R-50.pkl ...
[03/06 14:27:11] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[03/06 14:27:11] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[03/06 14:27:11] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mhead.head_series.0.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.0.class_logits.{bias, weight}[0m
[34mhead.head_series.0.cls_module.0.weight[0m
[34mhead.head_series.0.cls_module.1.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.0.linear1.{bias, weight}[0m
[34mhead.head_series.0.linear2.{bias, weight}[0m
[34mhead.head_series.0.norm1.{bias, weight}[0m
[34mhead.head_series.0.norm2.{bias, weight}[0m
[34mhead.head_series.0.norm3.{bias, weight}[0m
[34mhead.head_series.0.reg_module.0.weight[0m
[34mhead.head_series.0.reg_module.1.{bias, weight}[0m
[34mhead.head_series.0.reg_module.3.weight[0m
[34mhead.head_series.0.reg_module.4.{bias, weight}[0m
[34mhead.head_series.0.reg_module.6.weight[0m
[34mhead.head_series.0.reg_module.7.{bias, weight}[0m
[34mhead.head_series.0.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.1.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.1.class_logits.{bias, weight}[0m
[34mhead.head_series.1.cls_module.0.weight[0m
[34mhead.head_series.1.cls_module.1.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.1.linear1.{bias, weight}[0m
[34mhead.head_series.1.linear2.{bias, weight}[0m
[34mhead.head_series.1.norm1.{bias, weight}[0m
[34mhead.head_series.1.norm2.{bias, weight}[0m
[34mhead.head_series.1.norm3.{bias, weight}[0m
[34mhead.head_series.1.norm4.{bias, weight}[0m
[34mhead.head_series.1.reg_module.0.weight[0m
[34mhead.head_series.1.reg_module.1.{bias, weight}[0m
[34mhead.head_series.1.reg_module.3.weight[0m
[34mhead.head_series.1.reg_module.4.{bias, weight}[0m
[34mhead.head_series.1.reg_module.6.weight[0m
[34mhead.head_series.1.reg_module.7.{bias, weight}[0m
[34mhead.head_series.1.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.1.self_attn_post.out_proj.{bias, weight}[0m
[34mhead.head_series.1.self_attn_post.{in_proj_bias, in_proj_weight}[0m
[34mrpn_head.rpn_head.anchor_deltas.{bias, weight}[0m
[34mrpn_head.rpn_head.conv.{bias, weight}[0m
[34mrpn_head.rpn_head.objectness_logits.{bias, weight}[0m
[34mrpn_head.rpn_head.proposal_feats.{bias, weight}[0m
[34mrpn_head.rpn_head.scales.0.scale[0m
[34mrpn_head.rpn_head.scales.1.scale[0m
[34mrpn_head.rpn_head.scales.2.scale[0m
[34mrpn_head.rpn_head.scales.3.scale[0m
[34mrpn_head.rpn_head.scales.4.scale[0m
[03/06 14:27:11] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[03/06 14:27:11] d2.engine.train_loop INFO: Starting training from iteration 0
[03/06 14:27:19] d2.engine.hooks INFO: Overall training speed: 9 iterations in 0:00:04 (0.5465 s / it)
[03/06 14:27:19] d2.engine.hooks INFO: Total training time: 0:00:04 (0:00:00 on hooks)
[03/06 14:27:19] d2.utils.events INFO:  eta: 7:33:58  iter: 11  total_loss: 21.03  loss_ce: 1.979  loss_giou: 2.088  loss_bbox: 4.72  loss_ce_0: 1.83  loss_giou_0: 2.09  loss_bbox_0: 4.727  loss_rpn_cls: 1.132  loss_rpn_reg: 1.999  time: 0.5092  last_time: 0.5045  data_time: 0.2047  last_data_time: 0.0040   lr: 2.975e-06  max_mem: 2833M
[03/06 14:30:14] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 14:30:16] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 14:30:16] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 14:30:16] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 14:30:16] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 14:30:16] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 14:32:43] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 14:32:46] d2.data.datasets.pascal_voc INFO: Not able to load: /data/wxf/datasets/OWOD/VOC2007/Annotations/2011_000743.xml. Continuing without aboarting...
[03/06 14:32:46] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 14:32:46] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 14:35:43] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 14:35:45] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 14:35:45] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 14:35:45] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 14:35:45] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 14:35:45] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 14:35:50] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 14:35:53] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 14:35:53] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 14:35:54] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/06 14:35:54] d2.data.build INFO: Number of datapoints: 16551
[03/06 14:35:54] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 14:35:54] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 14:35:54] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/06 14:35:54] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/06 14:35:54] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/06 14:35:54] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/06 14:35:55] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/06 14:35:55] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/06 14:35:55] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/06 14:35:55] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/06 14:37:22] d2.data.build INFO: Known classes: range(0, 20)
[03/06 14:37:24] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/06 14:37:55] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[03/06 14:37:55] d2.data.build INFO: Number of datapoints: 10246
[03/06 14:38:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/06 14:40:25] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 14:40:26] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 14:40:26] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 14:40:26] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 14:40:27] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 14:40:27] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 14:40:32] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 14:40:35] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 14:40:35] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 14:40:36] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/06 14:40:36] d2.data.build INFO: Number of datapoints: 16551
[03/06 14:40:36] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 14:40:36] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 14:40:36] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/06 14:40:36] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/06 14:40:36] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/06 14:40:36] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/06 14:40:37] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/06 14:40:37] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/06 14:40:37] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/06 14:40:37] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/06 14:40:39] d2.data.build INFO: Known classes: range(0, 20)
[03/06 14:40:39] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/06 14:40:40] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[03/06 14:40:40] d2.data.build INFO: Number of datapoints: 10246
[03/06 14:40:40] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/06 14:43:11] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 14:43:13] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 14:43:13] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 14:43:13] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 14:43:13] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 14:43:13] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 14:43:19] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 14:43:21] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 14:43:21] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 14:43:22] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/06 14:43:22] d2.data.build INFO: Number of datapoints: 16551
[03/06 14:43:22] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 14:43:22] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 14:43:22] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/06 14:43:23] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/06 14:43:23] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/06 14:43:23] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/06 14:43:23] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/06 14:43:23] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/06 14:43:24] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/06 14:43:24] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/06 14:43:59] d2.data.build INFO: Known classes: range(0, 20)
[03/06 14:43:59] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/06 14:44:00] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[03/06 14:44:00] d2.data.build INFO: Number of datapoints: 10246
[03/06 14:44:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/06 15:16:30] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 15:16:31] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 15:16:31] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 15:16:31] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 15:16:31] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 15:16:31] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 15:16:37] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 15:16:40] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 15:16:40] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 15:16:40] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/06 15:16:40] d2.data.build INFO: Number of datapoints: 16551
[03/06 15:16:40] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 15:16:40] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 15:16:40] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/06 15:16:41] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/06 15:16:41] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/06 15:16:41] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/06 15:16:41] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/06 15:16:41] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/06 15:16:42] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/06 15:16:42] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/06 15:18:57] d2.data.build INFO: Known classes: range(0, 20)
[03/06 15:18:57] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/06 15:18:57] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[03/06 15:18:57] d2.data.build INFO: Number of datapoints: 10246
[03/06 15:18:57] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/06 15:19:10] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 15:19:12] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 15:19:12] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 15:19:12] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 15:19:12] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 15:19:12] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 15:19:18] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 15:20:31] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 15:20:31] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 15:20:32] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/06 15:20:32] d2.data.build INFO: Number of datapoints: 16551
[03/06 15:20:32] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 15:21:50] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 15:21:50] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/06 15:21:51] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/06 15:23:29] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/06 15:23:29] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/06 15:23:30] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/06 15:23:30] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/06 15:23:49] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/06 15:24:22] d2.engine.hooks INFO: Total training time: 0:00:16 (0:00:16 on hooks)
[03/06 15:25:33] d2.data.build INFO: Known classes: range(0, 20)
[03/06 15:25:33] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/06 15:25:34] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[03/06 15:25:34] d2.data.build INFO: Number of datapoints: 10246
[03/06 15:25:34] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/06 15:37:09] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 15:37:10] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 15:37:10] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 15:37:10] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 15:37:10] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 15:37:10] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 15:37:17] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 15:41:21] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 15:41:21] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 15:41:23] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/06 15:41:23] d2.data.build INFO: Number of datapoints: 16551
[03/06 15:41:23] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 15:41:53] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 15:41:53] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/06 15:41:53] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/06 15:41:53] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/06 15:41:53] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/06 15:41:54] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/06 15:41:54] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/06 15:41:54] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/06 15:41:54] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/06 15:41:56] d2.data.build INFO: Known classes: range(0, 20)
[03/06 15:41:56] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/06 15:41:57] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[03/06 15:41:57] d2.data.build INFO: Number of datapoints: 10246
[03/06 15:41:57] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/06 15:42:05] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 15:42:06] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 15:42:06] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 15:42:06] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 15:42:06] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 15:42:07] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 15:42:12] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 15:42:54] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 15:42:54] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 15:42:55] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/06 15:42:55] d2.data.build INFO: Number of datapoints: 16551
[03/06 15:43:04] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 15:46:28] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 15:46:28] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/06 15:46:28] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/06 15:46:28] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/06 15:46:28] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/06 15:46:29] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/06 15:46:29] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/06 15:46:29] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/06 15:46:29] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/06 15:46:31] d2.data.build INFO: Known classes: range(0, 20)
[03/06 15:46:31] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/06 15:46:32] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[03/06 15:46:32] d2.data.build INFO: Number of datapoints: 10246
[03/06 15:46:32] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/06 15:46:53] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 15:46:54] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 15:46:54] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 15:46:54] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 15:46:54] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 15:46:54] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 15:47:00] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 15:47:07] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 15:47:07] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 15:47:08] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/06 15:47:08] d2.data.build INFO: Number of datapoints: 16551
[03/06 15:47:08] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 15:47:57] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 15:47:58] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 15:47:58] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 15:47:58] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 15:47:58] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 15:47:58] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 15:48:03] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 15:48:42] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 15:48:42] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 15:48:43] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/06 15:48:43] d2.data.build INFO: Number of datapoints: 16551
[03/06 15:48:52] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 15:53:25] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 15:53:26] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 15:53:26] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 15:53:26] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 15:53:26] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 15:53:26] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 15:53:31] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 15:55:54] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 15:55:56] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 15:55:56] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 15:55:56] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 15:55:56] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 15:55:56] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 15:56:02] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 16:05:09] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 16:05:10] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 16:05:10] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 16:05:10] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 16:05:10] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 16:05:10] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 16:05:16] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 16:05:25] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 16:05:25] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 16:05:26] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/06 16:05:26] d2.data.build INFO: Number of datapoints: 16551
[03/06 16:05:26] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 16:05:26] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 16:05:26] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/06 16:05:26] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/06 16:05:26] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/06 16:05:26] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/06 16:05:29] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/06 16:05:29] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/06 16:05:29] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/06 16:05:29] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/06 16:05:36] d2.data.build INFO: Known classes: range(0, 20)
[03/06 16:05:36] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/06 16:05:37] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[03/06 16:05:37] d2.data.build INFO: Number of datapoints: 10246
[03/06 16:05:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/06 16:12:17] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 16:12:19] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 16:12:19] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 16:12:19] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 16:12:19] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 16:12:19] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 16:12:24] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 16:12:28] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 16:12:28] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 16:12:29] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/06 16:12:29] d2.data.build INFO: Number of datapoints: 16551
[03/06 16:12:29] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 16:12:29] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 16:12:29] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/06 16:12:29] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/06 16:12:29] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/06 16:12:29] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/06 16:12:30] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/06 16:12:30] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/06 16:12:30] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/06 16:12:30] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/06 16:12:34] d2.data.build INFO: Known classes: range(0, 20)
[03/06 16:12:34] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/06 16:12:35] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[03/06 16:12:35] d2.data.build INFO: Number of datapoints: 10246
[03/06 16:12:35] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/06 16:12:35] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 16:12:35] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[03/06 16:12:35] d2.data.common INFO: Serialized dataset takes 6.49 MiB
[03/06 16:13:27] detectron2 INFO: Rank of current process: 0. World size: 1
[03/06 16:13:28] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 16:13:28] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=True)
[03/06 16:13:28] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 16:13:29] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 16:13:29] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 16:13:34] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 16:13:38] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 16:13:38] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 16:13:39] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/06 16:13:39] d2.data.build INFO: Number of datapoints: 16551
[03/06 16:13:39] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 16:13:39] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 16:13:39] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/06 16:13:39] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/06 16:13:39] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/06 16:13:39] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/06 16:13:40] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/06 16:13:40] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/06 16:13:40] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/06 16:13:40] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/06 16:13:43] d2.data.build INFO: Known classes: range(0, 20)
[03/06 16:13:43] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/06 16:13:44] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[03/06 16:13:44] d2.data.build INFO: Number of datapoints: 10246
[03/06 16:13:44] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/06 16:13:44] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 16:13:44] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[03/06 16:13:44] d2.data.common INFO: Serialized dataset takes 6.49 MiB
[03/06 16:13:44] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/06 16:13:44] d2.evaluation.coco_evaluation INFO: Trying to convert 'voc_coco_2007_test' to COCO format ...
[03/06 16:13:44] d2.data.datasets.coco INFO: Converting annotations of dataset 'voc_coco_2007_test' to COCO format ...)
[03/06 16:13:45] d2.data.datasets.coco INFO: Converting dataset dicts into COCO format
[03/06 16:13:52] d2.data.datasets.coco INFO: Conversion finished, #images: 10246, #annotations: 61707
[03/06 16:13:52] d2.data.datasets.coco INFO: Caching COCO format annotations at './output/t1/inference/voc_coco_2007_test_coco_format.json' ...
[03/06 16:13:58] d2.evaluation.evaluator INFO: Start inference on 10246 batches
[03/06 16:14:08] d2.evaluation.evaluator INFO: Inference done 11/10246. Dataloading: 0.0008 s/iter. Inference: 1.5820 s/iter. Eval: 0.0003 s/iter. Total: 1.5831 s/iter. ETA=4:30:03
[03/06 16:14:13] d2.evaluation.evaluator INFO: Inference done 160/10246. Dataloading: 0.0013 s/iter. Inference: 0.0918 s/iter. Eval: 0.0004 s/iter. Total: 0.0935 s/iter. ETA=0:15:43
[03/06 16:14:18] d2.evaluation.evaluator INFO: Inference done 314/10246. Dataloading: 0.0013 s/iter. Inference: 0.0614 s/iter. Eval: 0.0003 s/iter. Total: 0.0631 s/iter. ETA=0:10:27
[03/06 16:14:23] d2.evaluation.evaluator INFO: Inference done 469/10246. Dataloading: 0.0013 s/iter. Inference: 0.0512 s/iter. Eval: 0.0003 s/iter. Total: 0.0529 s/iter. ETA=0:08:36
[03/06 16:14:28] d2.evaluation.evaluator INFO: Inference done 621/10246. Dataloading: 0.0013 s/iter. Inference: 0.0461 s/iter. Eval: 0.0005 s/iter. Total: 0.0480 s/iter. ETA=0:07:41
[03/06 16:14:33] d2.evaluation.evaluator INFO: Inference done 773/10246. Dataloading: 0.0014 s/iter. Inference: 0.0431 s/iter. Eval: 0.0005 s/iter. Total: 0.0450 s/iter. ETA=0:07:06
[03/06 16:14:38] d2.evaluation.evaluator INFO: Inference done 928/10246. Dataloading: 0.0014 s/iter. Inference: 0.0410 s/iter. Eval: 0.0004 s/iter. Total: 0.0429 s/iter. ETA=0:06:39
[03/06 16:14:43] d2.evaluation.evaluator INFO: Inference done 1081/10246. Dataloading: 0.0013 s/iter. Inference: 0.0396 s/iter. Eval: 0.0004 s/iter. Total: 0.0414 s/iter. ETA=0:06:19
[03/06 16:14:48] d2.evaluation.evaluator INFO: Inference done 1231/10246. Dataloading: 0.0013 s/iter. Inference: 0.0385 s/iter. Eval: 0.0005 s/iter. Total: 0.0404 s/iter. ETA=0:06:04
[03/06 16:14:53] d2.evaluation.evaluator INFO: Inference done 1386/10246. Dataloading: 0.0013 s/iter. Inference: 0.0376 s/iter. Eval: 0.0005 s/iter. Total: 0.0395 s/iter. ETA=0:05:50
[03/06 16:14:58] d2.evaluation.evaluator INFO: Inference done 1540/10246. Dataloading: 0.0013 s/iter. Inference: 0.0370 s/iter. Eval: 0.0005 s/iter. Total: 0.0388 s/iter. ETA=0:05:38
[03/06 16:15:03] d2.evaluation.evaluator INFO: Inference done 1694/10246. Dataloading: 0.0013 s/iter. Inference: 0.0364 s/iter. Eval: 0.0005 s/iter. Total: 0.0383 s/iter. ETA=0:05:27
[03/06 16:15:08] d2.evaluation.evaluator INFO: Inference done 1841/10246. Dataloading: 0.0013 s/iter. Inference: 0.0360 s/iter. Eval: 0.0005 s/iter. Total: 0.0379 s/iter. ETA=0:05:18
[03/06 16:15:13] d2.evaluation.evaluator INFO: Inference done 1994/10246. Dataloading: 0.0013 s/iter. Inference: 0.0356 s/iter. Eval: 0.0005 s/iter. Total: 0.0375 s/iter. ETA=0:05:09
[03/06 16:15:18] d2.evaluation.evaluator INFO: Inference done 2148/10246. Dataloading: 0.0013 s/iter. Inference: 0.0353 s/iter. Eval: 0.0005 s/iter. Total: 0.0372 s/iter. ETA=0:05:00
[03/06 16:15:23] d2.evaluation.evaluator INFO: Inference done 2302/10246. Dataloading: 0.0013 s/iter. Inference: 0.0350 s/iter. Eval: 0.0005 s/iter. Total: 0.0369 s/iter. ETA=0:04:52
[03/06 16:15:28] d2.evaluation.evaluator INFO: Inference done 2456/10246. Dataloading: 0.0013 s/iter. Inference: 0.0347 s/iter. Eval: 0.0005 s/iter. Total: 0.0366 s/iter. ETA=0:04:45
[03/06 16:15:33] d2.evaluation.evaluator INFO: Inference done 2603/10246. Dataloading: 0.0013 s/iter. Inference: 0.0345 s/iter. Eval: 0.0006 s/iter. Total: 0.0364 s/iter. ETA=0:04:38
[03/06 16:15:38] d2.evaluation.evaluator INFO: Inference done 2756/10246. Dataloading: 0.0013 s/iter. Inference: 0.0343 s/iter. Eval: 0.0005 s/iter. Total: 0.0362 s/iter. ETA=0:04:31
[03/06 16:15:43] d2.evaluation.evaluator INFO: Inference done 2910/10246. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0005 s/iter. Total: 0.0360 s/iter. ETA=0:04:24
[03/06 16:15:48] d2.evaluation.evaluator INFO: Inference done 3061/10246. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0005 s/iter. Total: 0.0359 s/iter. ETA=0:04:17
[03/06 16:15:53] d2.evaluation.evaluator INFO: Inference done 3214/10246. Dataloading: 0.0013 s/iter. Inference: 0.0338 s/iter. Eval: 0.0005 s/iter. Total: 0.0358 s/iter. ETA=0:04:11
[03/06 16:15:58] d2.evaluation.evaluator INFO: Inference done 3367/10246. Dataloading: 0.0013 s/iter. Inference: 0.0337 s/iter. Eval: 0.0005 s/iter. Total: 0.0356 s/iter. ETA=0:04:05
[03/06 16:16:53] detectron2 INFO: Rank of current process: 0. World size: 2
[03/06 16:16:54] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/06 16:16:54] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4'], resume=True)
[03/06 16:16:54] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/06 16:16:54] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/06 16:16:54] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/06 16:16:55] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/06 16:16:57] d2.data.build INFO: Valid classes: range(0, 20)
[03/06 16:16:57] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/06 16:16:58] d2.data.build INFO: Distribution of instances among all 81 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |
[03/06 16:16:58] d2.data.build INFO: Number of datapoints: 16551
[03/06 16:16:58] d2.data.build INFO: Using training sampler TrainingSampler
[03/06 16:16:58] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 16:16:58] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/06 16:16:58] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/06 16:16:58] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/06 16:16:58] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/06 16:16:59] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/06 16:16:59] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/06 16:16:59] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/06 16:16:59] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/06 16:17:00] d2.data.build INFO: Known classes: range(0, 20)
[03/06 16:17:00] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/06 16:17:01] d2.data.build INFO: Distribution of instances among all 81 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |
[03/06 16:17:01] d2.data.build INFO: Number of datapoints: 10246
[03/06 16:17:01] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/06 16:17:01] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/06 16:17:01] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[03/06 16:17:01] d2.data.common INFO: Serialized dataset takes 6.49 MiB
[03/06 16:17:01] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/06 16:17:01] d2.evaluation.coco_evaluation INFO: Trying to convert 'voc_coco_2007_test' to COCO format ...
[03/06 16:17:01] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './output/t1/inference/voc_coco_2007_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[03/06 16:17:01] d2.evaluation.evaluator INFO: Start inference on 5123 batches
[03/06 16:17:04] d2.evaluation.evaluator INFO: Inference done 11/5123. Dataloading: 0.0009 s/iter. Inference: 0.0378 s/iter. Eval: 0.0003 s/iter. Total: 0.0390 s/iter. ETA=0:03:19
[03/06 16:17:09] d2.evaluation.evaluator INFO: Inference done 144/5123. Dataloading: 0.0014 s/iter. Inference: 0.0360 s/iter. Eval: 0.0003 s/iter. Total: 0.0377 s/iter. ETA=0:03:07
[03/06 16:17:14] d2.evaluation.evaluator INFO: Inference done 274/5123. Dataloading: 0.0014 s/iter. Inference: 0.0364 s/iter. Eval: 0.0003 s/iter. Total: 0.0381 s/iter. ETA=0:03:04
[03/06 16:17:19] d2.evaluation.evaluator INFO: Inference done 394/5123. Dataloading: 0.0014 s/iter. Inference: 0.0374 s/iter. Eval: 0.0003 s/iter. Total: 0.0393 s/iter. ETA=0:03:05
[03/06 16:17:24] d2.evaluation.evaluator INFO: Inference done 520/5123. Dataloading: 0.0015 s/iter. Inference: 0.0376 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:03:01
[03/06 16:17:29] d2.evaluation.evaluator INFO: Inference done 645/5123. Dataloading: 0.0015 s/iter. Inference: 0.0374 s/iter. Eval: 0.0006 s/iter. Total: 0.0395 s/iter. ETA=0:02:56
[03/06 16:17:34] d2.evaluation.evaluator INFO: Inference done 772/5123. Dataloading: 0.0015 s/iter. Inference: 0.0374 s/iter. Eval: 0.0006 s/iter. Total: 0.0395 s/iter. ETA=0:02:51
[03/06 16:17:39] d2.evaluation.evaluator INFO: Inference done 899/5123. Dataloading: 0.0015 s/iter. Inference: 0.0374 s/iter. Eval: 0.0005 s/iter. Total: 0.0395 s/iter. ETA=0:02:46
[03/06 16:17:44] d2.evaluation.evaluator INFO: Inference done 1031/5123. Dataloading: 0.0015 s/iter. Inference: 0.0372 s/iter. Eval: 0.0005 s/iter. Total: 0.0393 s/iter. ETA=0:02:40
[03/06 16:17:49] d2.evaluation.evaluator INFO: Inference done 1159/5123. Dataloading: 0.0015 s/iter. Inference: 0.0371 s/iter. Eval: 0.0006 s/iter. Total: 0.0393 s/iter. ETA=0:02:35
[03/06 16:17:54] d2.evaluation.evaluator INFO: Inference done 1289/5123. Dataloading: 0.0015 s/iter. Inference: 0.0370 s/iter. Eval: 0.0006 s/iter. Total: 0.0392 s/iter. ETA=0:02:30
[03/06 16:17:59] d2.evaluation.evaluator INFO: Inference done 1423/5123. Dataloading: 0.0015 s/iter. Inference: 0.0369 s/iter. Eval: 0.0006 s/iter. Total: 0.0391 s/iter. ETA=0:02:24
[03/06 16:18:04] d2.evaluation.evaluator INFO: Inference done 1552/5123. Dataloading: 0.0015 s/iter. Inference: 0.0369 s/iter. Eval: 0.0006 s/iter. Total: 0.0391 s/iter. ETA=0:02:19
[03/06 16:18:09] d2.evaluation.evaluator INFO: Inference done 1687/5123. Dataloading: 0.0015 s/iter. Inference: 0.0367 s/iter. Eval: 0.0006 s/iter. Total: 0.0389 s/iter. ETA=0:02:13
[03/06 16:18:14] d2.evaluation.evaluator INFO: Inference done 1814/5123. Dataloading: 0.0016 s/iter. Inference: 0.0367 s/iter. Eval: 0.0007 s/iter. Total: 0.0389 s/iter. ETA=0:02:08
[03/06 16:18:19] d2.evaluation.evaluator INFO: Inference done 1937/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0006 s/iter. Total: 0.0391 s/iter. ETA=0:02:04
[03/06 16:18:24] d2.evaluation.evaluator INFO: Inference done 2061/5123. Dataloading: 0.0016 s/iter. Inference: 0.0369 s/iter. Eval: 0.0006 s/iter. Total: 0.0391 s/iter. ETA=0:01:59
[03/06 16:18:29] d2.evaluation.evaluator INFO: Inference done 2189/5123. Dataloading: 0.0016 s/iter. Inference: 0.0369 s/iter. Eval: 0.0006 s/iter. Total: 0.0391 s/iter. ETA=0:01:54
[03/06 16:18:34] d2.evaluation.evaluator INFO: Inference done 2315/5123. Dataloading: 0.0016 s/iter. Inference: 0.0370 s/iter. Eval: 0.0006 s/iter. Total: 0.0392 s/iter. ETA=0:01:50
[03/06 16:18:39] d2.evaluation.evaluator INFO: Inference done 2446/5123. Dataloading: 0.0016 s/iter. Inference: 0.0369 s/iter. Eval: 0.0006 s/iter. Total: 0.0391 s/iter. ETA=0:01:44
[03/06 16:18:44] d2.evaluation.evaluator INFO: Inference done 2568/5123. Dataloading: 0.0016 s/iter. Inference: 0.0370 s/iter. Eval: 0.0006 s/iter. Total: 0.0392 s/iter. ETA=0:01:40
[03/06 16:18:49] d2.evaluation.evaluator INFO: Inference done 2698/5123. Dataloading: 0.0016 s/iter. Inference: 0.0370 s/iter. Eval: 0.0006 s/iter. Total: 0.0392 s/iter. ETA=0:01:35
[03/06 16:18:54] d2.evaluation.evaluator INFO: Inference done 2832/5123. Dataloading: 0.0016 s/iter. Inference: 0.0369 s/iter. Eval: 0.0006 s/iter. Total: 0.0391 s/iter. ETA=0:01:29
[03/06 16:18:59] d2.evaluation.evaluator INFO: Inference done 2963/5123. Dataloading: 0.0016 s/iter. Inference: 0.0369 s/iter. Eval: 0.0005 s/iter. Total: 0.0391 s/iter. ETA=0:01:24
[03/06 16:19:04] d2.evaluation.evaluator INFO: Inference done 3095/5123. Dataloading: 0.0016 s/iter. Inference: 0.0369 s/iter. Eval: 0.0005 s/iter. Total: 0.0390 s/iter. ETA=0:01:19
[03/06 16:19:09] d2.evaluation.evaluator INFO: Inference done 3227/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0005 s/iter. Total: 0.0390 s/iter. ETA=0:01:13
[03/06 16:19:14] d2.evaluation.evaluator INFO: Inference done 3362/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0005 s/iter. Total: 0.0389 s/iter. ETA=0:01:08
[03/06 16:19:19] d2.evaluation.evaluator INFO: Inference done 3493/5123. Dataloading: 0.0016 s/iter. Inference: 0.0367 s/iter. Eval: 0.0005 s/iter. Total: 0.0389 s/iter. ETA=0:01:03
[03/06 16:19:24] d2.evaluation.evaluator INFO: Inference done 3618/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0005 s/iter. Total: 0.0389 s/iter. ETA=0:00:58
[03/06 16:19:29] d2.evaluation.evaluator INFO: Inference done 3752/5123. Dataloading: 0.0016 s/iter. Inference: 0.0367 s/iter. Eval: 0.0005 s/iter. Total: 0.0389 s/iter. ETA=0:00:53
[03/06 16:19:34] d2.evaluation.evaluator INFO: Inference done 3884/5123. Dataloading: 0.0016 s/iter. Inference: 0.0367 s/iter. Eval: 0.0005 s/iter. Total: 0.0389 s/iter. ETA=0:00:48
[03/06 16:19:39] d2.evaluation.evaluator INFO: Inference done 4016/5123. Dataloading: 0.0016 s/iter. Inference: 0.0367 s/iter. Eval: 0.0005 s/iter. Total: 0.0388 s/iter. ETA=0:00:42
[03/06 16:19:44] d2.evaluation.evaluator INFO: Inference done 4148/5123. Dataloading: 0.0016 s/iter. Inference: 0.0367 s/iter. Eval: 0.0005 s/iter. Total: 0.0388 s/iter. ETA=0:00:37
[03/06 16:19:49] d2.evaluation.evaluator INFO: Inference done 4282/5123. Dataloading: 0.0016 s/iter. Inference: 0.0366 s/iter. Eval: 0.0005 s/iter. Total: 0.0388 s/iter. ETA=0:00:32
[03/06 16:19:54] d2.evaluation.evaluator INFO: Inference done 4417/5123. Dataloading: 0.0016 s/iter. Inference: 0.0366 s/iter. Eval: 0.0005 s/iter. Total: 0.0387 s/iter. ETA=0:00:27
[03/06 16:19:59] d2.evaluation.evaluator INFO: Inference done 4549/5123. Dataloading: 0.0016 s/iter. Inference: 0.0366 s/iter. Eval: 0.0005 s/iter. Total: 0.0387 s/iter. ETA=0:00:22
[03/06 16:20:04] d2.evaluation.evaluator INFO: Inference done 4677/5123. Dataloading: 0.0016 s/iter. Inference: 0.0366 s/iter. Eval: 0.0005 s/iter. Total: 0.0387 s/iter. ETA=0:00:17
[03/06 16:20:10] d2.evaluation.evaluator INFO: Inference done 4802/5123. Dataloading: 0.0016 s/iter. Inference: 0.0366 s/iter. Eval: 0.0006 s/iter. Total: 0.0387 s/iter. ETA=0:00:12
[03/06 16:20:15] d2.evaluation.evaluator INFO: Inference done 4933/5123. Dataloading: 0.0016 s/iter. Inference: 0.0366 s/iter. Eval: 0.0005 s/iter. Total: 0.0387 s/iter. ETA=0:00:07
[03/06 16:20:20] d2.evaluation.evaluator INFO: Inference done 5064/5123. Dataloading: 0.0016 s/iter. Inference: 0.0366 s/iter. Eval: 0.0005 s/iter. Total: 0.0387 s/iter. ETA=0:00:02
[03/06 16:20:22] d2.evaluation.evaluator INFO: Total inference time: 0:03:18.506995 (0.038786 s / iter per device, on 2 devices)
[03/06 16:20:22] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:06 (0.036535 s / iter per device, on 2 devices)
[03/06 16:20:33] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/06 16:20:33] d2.evaluation.coco_evaluation INFO: Saving results to ./output/t1/inference/coco_instances_results.json
[03/06 16:20:39] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/06 16:20:43] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/06 16:21:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.23 seconds.
[03/06 16:21:05] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/06 16:21:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 4.23 seconds.
[03/06 16:21:10] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 9.867 | 14.499 | 10.742 | 2.770 | 7.704 | 12.234 |
[03/06 16:21:10] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP     | category       | AP     | category   | AP     |
|:--------------|:-------|:---------------|:-------|:-----------|:-------|
| aeroplane     | 53.186 | bicycle        | 38.915 | bird       | 35.706 |
| boat          | 22.031 | bottle         | 24.437 | bus        | 53.259 |
| car           | 40.832 | cat            | 64.405 | chair      | 19.395 |
| cow           | 41.186 | diningtable    | 19.223 | dog        | 52.563 |
| horse         | 47.268 | motorbike      | 40.571 | person     | 41.473 |
| pottedplant   | 18.747 | sheep          | 41.831 | sofa       | 35.733 |
| train         | 54.728 | tvmonitor      | 43.909 | truck      | 0.000  |
| traffic light | 0.000  | fire hydrant   | 0.000  | stop sign  | 0.000  |
| parking meter | 0.000  | bench          | 0.000  | elephant   | 0.000  |
| bear          | 0.000  | zebra          | 0.000  | giraffe    | 0.000  |
| backpack      | 0.000  | umbrella       | 0.000  | handbag    | 0.000  |
| tie           | 0.000  | suitcase       | 0.000  | microwave  | 0.000  |
| oven          | 0.000  | toaster        | 0.000  | sink       | 0.000  |
| refrigerator  | 0.000  | frisbee        | 0.000  | skis       | 0.000  |
| snowboard     | 0.000  | sports ball    | 0.000  | kite       | 0.000  |
| baseball bat  | 0.000  | baseball glove | 0.000  | skateboard | 0.000  |
| surfboard     | 0.000  | tennis racket  | 0.000  | banana     | 0.000  |
| apple         | 0.000  | sandwich       | 0.000  | orange     | 0.000  |
| broccoli      | 0.000  | carrot         | 0.000  | hot dog    | 0.000  |
| pizza         | 0.000  | donut          | 0.000  | cake       | 0.000  |
| bed           | 0.000  | toilet         | 0.000  | laptop     | 0.000  |
| mouse         | 0.000  | remote         | 0.000  | keyboard   | 0.000  |
| cell phone    | 0.000  | book           | 0.000  | clock      | 0.000  |
| vase          | 0.000  | scissors       | 0.000  | teddy bear | 0.000  |
| hair drier    | 0.000  | toothbrush     | 0.000  | wine glass | 0.000  |
| cup           | 0.000  | fork           | 0.000  | knife      | 0.000  |
| spoon         | 0.000  | bowl           | 0.000  | unknown    | nan    |
[03/06 16:21:12] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[03/06 16:21:12] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/06 16:21:12] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/06 16:21:12] d2.evaluation.testing INFO: copypaste: 9.8675,14.4987,10.7423,2.7703,7.7044,12.2344
[03/06 16:21:13] d2.utils.events INFO:  iter: 54001     lr: N/A  max_mem: 1406M
[03/07 14:16:11] detectron2 INFO: Rank of current process: 0. World size: 2
[03/07 14:16:12] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/07 14:16:12] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4'], resume=True)
[03/07 14:16:12] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/07 14:16:12] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/07 14:16:12] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/07 14:16:14] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/07 14:16:15] d2.data.build INFO: Valid classes: range(0, 20)
[03/07 14:16:15] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/07 14:16:16] d2.data.build INFO: Distribution of instances among all 81 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |
[03/07 14:16:16] d2.data.build INFO: Number of datapoints: 16551
[03/07 14:16:16] d2.data.build INFO: Using training sampler TrainingSampler
[03/07 14:16:16] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/07 14:16:16] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/07 14:16:16] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/07 14:16:16] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/07 14:16:16] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/07 14:16:17] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/07 14:16:17] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/07 14:16:18] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/07 14:16:18] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/07 14:16:19] d2.data.build INFO: Known classes: range(0, 20)
[03/07 14:16:19] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/07 14:16:19] d2.data.build INFO: Distribution of instances among all 81 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |
[03/07 14:16:19] d2.data.build INFO: Number of datapoints: 10246
[03/07 14:16:19] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/07 14:16:19] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/07 14:16:19] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[03/07 14:16:19] d2.data.common INFO: Serialized dataset takes 6.49 MiB
[03/07 14:16:19] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/07 14:16:19] d2.evaluation.coco_evaluation INFO: Trying to convert 'voc_coco_2007_test' to COCO format ...
[03/07 14:16:19] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './output/t1/inference/voc_coco_2007_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[03/07 14:16:20] d2.evaluation.evaluator INFO: Start inference on 5123 batches
[03/07 14:16:22] d2.evaluation.evaluator INFO: Inference done 11/5123. Dataloading: 0.0006 s/iter. Inference: 0.0460 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:03:59
[03/07 14:16:27] d2.evaluation.evaluator INFO: Inference done 131/5123. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0003 s/iter. Total: 0.0420 s/iter. ETA=0:03:29
[03/07 14:16:32] d2.evaluation.evaluator INFO: Inference done 258/5123. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0003 s/iter. Total: 0.0408 s/iter. ETA=0:03:18
[03/07 14:16:37] d2.evaluation.evaluator INFO: Inference done 383/5123. Dataloading: 0.0015 s/iter. Inference: 0.0386 s/iter. Eval: 0.0003 s/iter. Total: 0.0406 s/iter. ETA=0:03:12
[03/07 14:16:43] d2.evaluation.evaluator INFO: Inference done 511/5123. Dataloading: 0.0015 s/iter. Inference: 0.0383 s/iter. Eval: 0.0004 s/iter. Total: 0.0403 s/iter. ETA=0:03:05
[03/07 14:16:48] d2.evaluation.evaluator INFO: Inference done 638/5123. Dataloading: 0.0016 s/iter. Inference: 0.0378 s/iter. Eval: 0.0006 s/iter. Total: 0.0401 s/iter. ETA=0:02:59
[03/07 14:16:53] d2.evaluation.evaluator INFO: Inference done 762/5123. Dataloading: 0.0015 s/iter. Inference: 0.0379 s/iter. Eval: 0.0006 s/iter. Total: 0.0401 s/iter. ETA=0:02:55
[03/07 14:16:58] d2.evaluation.evaluator INFO: Inference done 892/5123. Dataloading: 0.0015 s/iter. Inference: 0.0377 s/iter. Eval: 0.0005 s/iter. Total: 0.0399 s/iter. ETA=0:02:48
[03/07 14:17:03] d2.evaluation.evaluator INFO: Inference done 1018/5123. Dataloading: 0.0016 s/iter. Inference: 0.0377 s/iter. Eval: 0.0005 s/iter. Total: 0.0399 s/iter. ETA=0:02:43
[03/07 14:17:08] d2.evaluation.evaluator INFO: Inference done 1141/5123. Dataloading: 0.0016 s/iter. Inference: 0.0377 s/iter. Eval: 0.0007 s/iter. Total: 0.0400 s/iter. ETA=0:02:39
[03/07 14:17:13] d2.evaluation.evaluator INFO: Inference done 1270/5123. Dataloading: 0.0016 s/iter. Inference: 0.0376 s/iter. Eval: 0.0007 s/iter. Total: 0.0399 s/iter. ETA=0:02:33
[03/07 14:17:18] d2.evaluation.evaluator INFO: Inference done 1399/5123. Dataloading: 0.0015 s/iter. Inference: 0.0376 s/iter. Eval: 0.0006 s/iter. Total: 0.0398 s/iter. ETA=0:02:28
[03/07 14:17:23] d2.evaluation.evaluator INFO: Inference done 1526/5123. Dataloading: 0.0015 s/iter. Inference: 0.0376 s/iter. Eval: 0.0006 s/iter. Total: 0.0398 s/iter. ETA=0:02:23
[03/07 14:17:28] d2.evaluation.evaluator INFO: Inference done 1640/5123. Dataloading: 0.0015 s/iter. Inference: 0.0379 s/iter. Eval: 0.0006 s/iter. Total: 0.0401 s/iter. ETA=0:02:19
[03/07 14:17:33] d2.evaluation.evaluator INFO: Inference done 1754/5123. Dataloading: 0.0015 s/iter. Inference: 0.0380 s/iter. Eval: 0.0007 s/iter. Total: 0.0403 s/iter. ETA=0:02:15
[03/07 14:17:38] d2.evaluation.evaluator INFO: Inference done 1879/5123. Dataloading: 0.0015 s/iter. Inference: 0.0380 s/iter. Eval: 0.0007 s/iter. Total: 0.0403 s/iter. ETA=0:02:10
[03/07 14:17:43] d2.evaluation.evaluator INFO: Inference done 2002/5123. Dataloading: 0.0015 s/iter. Inference: 0.0381 s/iter. Eval: 0.0007 s/iter. Total: 0.0404 s/iter. ETA=0:02:06
[03/07 14:17:48] d2.evaluation.evaluator INFO: Inference done 2130/5123. Dataloading: 0.0016 s/iter. Inference: 0.0380 s/iter. Eval: 0.0006 s/iter. Total: 0.0403 s/iter. ETA=0:02:00
[03/07 14:17:53] d2.evaluation.evaluator INFO: Inference done 2260/5123. Dataloading: 0.0016 s/iter. Inference: 0.0379 s/iter. Eval: 0.0006 s/iter. Total: 0.0402 s/iter. ETA=0:01:55
[03/07 14:17:58] d2.evaluation.evaluator INFO: Inference done 2383/5123. Dataloading: 0.0016 s/iter. Inference: 0.0380 s/iter. Eval: 0.0006 s/iter. Total: 0.0402 s/iter. ETA=0:01:50
[03/07 14:18:03] d2.evaluation.evaluator INFO: Inference done 2502/5123. Dataloading: 0.0016 s/iter. Inference: 0.0381 s/iter. Eval: 0.0006 s/iter. Total: 0.0403 s/iter. ETA=0:01:45
[03/07 14:18:08] d2.evaluation.evaluator INFO: Inference done 2632/5123. Dataloading: 0.0016 s/iter. Inference: 0.0380 s/iter. Eval: 0.0006 s/iter. Total: 0.0402 s/iter. ETA=0:01:40
[03/07 14:18:13] d2.evaluation.evaluator INFO: Inference done 2761/5123. Dataloading: 0.0016 s/iter. Inference: 0.0380 s/iter. Eval: 0.0006 s/iter. Total: 0.0402 s/iter. ETA=0:01:34
[03/07 14:18:18] d2.evaluation.evaluator INFO: Inference done 2887/5123. Dataloading: 0.0016 s/iter. Inference: 0.0380 s/iter. Eval: 0.0006 s/iter. Total: 0.0402 s/iter. ETA=0:01:29
[03/07 14:18:23] d2.evaluation.evaluator INFO: Inference done 3014/5123. Dataloading: 0.0016 s/iter. Inference: 0.0379 s/iter. Eval: 0.0006 s/iter. Total: 0.0401 s/iter. ETA=0:01:24
[03/07 14:18:28] d2.evaluation.evaluator INFO: Inference done 3148/5123. Dataloading: 0.0016 s/iter. Inference: 0.0378 s/iter. Eval: 0.0005 s/iter. Total: 0.0400 s/iter. ETA=0:01:19
[03/07 14:18:33] d2.evaluation.evaluator INFO: Inference done 3275/5123. Dataloading: 0.0016 s/iter. Inference: 0.0378 s/iter. Eval: 0.0005 s/iter. Total: 0.0400 s/iter. ETA=0:01:13
[03/07 14:18:38] d2.evaluation.evaluator INFO: Inference done 3406/5123. Dataloading: 0.0016 s/iter. Inference: 0.0378 s/iter. Eval: 0.0005 s/iter. Total: 0.0399 s/iter. ETA=0:01:08
[03/07 14:18:43] d2.evaluation.evaluator INFO: Inference done 3524/5123. Dataloading: 0.0016 s/iter. Inference: 0.0379 s/iter. Eval: 0.0005 s/iter. Total: 0.0400 s/iter. ETA=0:01:03
[03/07 14:18:48] d2.evaluation.evaluator INFO: Inference done 3656/5123. Dataloading: 0.0016 s/iter. Inference: 0.0378 s/iter. Eval: 0.0005 s/iter. Total: 0.0399 s/iter. ETA=0:00:58
[03/07 14:18:53] d2.evaluation.evaluator INFO: Inference done 3785/5123. Dataloading: 0.0016 s/iter. Inference: 0.0377 s/iter. Eval: 0.0005 s/iter. Total: 0.0399 s/iter. ETA=0:00:53
[03/07 14:18:58] d2.evaluation.evaluator INFO: Inference done 3911/5123. Dataloading: 0.0016 s/iter. Inference: 0.0378 s/iter. Eval: 0.0005 s/iter. Total: 0.0399 s/iter. ETA=0:00:48
[03/07 14:19:03] d2.evaluation.evaluator INFO: Inference done 4038/5123. Dataloading: 0.0016 s/iter. Inference: 0.0378 s/iter. Eval: 0.0005 s/iter. Total: 0.0399 s/iter. ETA=0:00:43
[03/07 14:19:08] d2.evaluation.evaluator INFO: Inference done 4166/5123. Dataloading: 0.0016 s/iter. Inference: 0.0377 s/iter. Eval: 0.0005 s/iter. Total: 0.0399 s/iter. ETA=0:00:38
[03/07 14:19:13] d2.evaluation.evaluator INFO: Inference done 4293/5123. Dataloading: 0.0016 s/iter. Inference: 0.0377 s/iter. Eval: 0.0005 s/iter. Total: 0.0399 s/iter. ETA=0:00:33
[03/07 14:19:18] d2.evaluation.evaluator INFO: Inference done 4423/5123. Dataloading: 0.0016 s/iter. Inference: 0.0377 s/iter. Eval: 0.0005 s/iter. Total: 0.0398 s/iter. ETA=0:00:27
[03/07 14:19:23] d2.evaluation.evaluator INFO: Inference done 4554/5123. Dataloading: 0.0016 s/iter. Inference: 0.0377 s/iter. Eval: 0.0005 s/iter. Total: 0.0398 s/iter. ETA=0:00:22
[03/07 14:19:28] d2.evaluation.evaluator INFO: Inference done 4687/5123. Dataloading: 0.0016 s/iter. Inference: 0.0376 s/iter. Eval: 0.0005 s/iter. Total: 0.0397 s/iter. ETA=0:00:17
[03/07 14:19:33] d2.evaluation.evaluator INFO: Inference done 4801/5123. Dataloading: 0.0016 s/iter. Inference: 0.0376 s/iter. Eval: 0.0006 s/iter. Total: 0.0398 s/iter. ETA=0:00:12
[03/07 14:19:38] d2.evaluation.evaluator INFO: Inference done 4929/5123. Dataloading: 0.0016 s/iter. Inference: 0.0376 s/iter. Eval: 0.0006 s/iter. Total: 0.0398 s/iter. ETA=0:00:07
[03/07 14:19:43] d2.evaluation.evaluator INFO: Inference done 5052/5123. Dataloading: 0.0016 s/iter. Inference: 0.0376 s/iter. Eval: 0.0006 s/iter. Total: 0.0398 s/iter. ETA=0:00:02
[03/07 14:19:46] d2.evaluation.evaluator INFO: Total inference time: 0:03:24.189976 (0.039896 s / iter per device, on 2 devices)
[03/07 14:19:46] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:12 (0.037628 s / iter per device, on 2 devices)
[03/07 14:19:59] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/07 14:19:59] d2.evaluation.coco_evaluation INFO: Saving results to ./output/t1/inference/coco_instances_results.json
[03/07 14:20:05] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/07 14:20:09] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/07 14:20:30] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 20.84 seconds.
[03/07 14:20:31] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/07 14:20:35] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 3.97 seconds.
[03/07 14:20:35] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 9.867 | 14.499 | 10.742 | 2.770 | 7.704 | 12.234 |
[03/07 14:20:35] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP     | category       | AP     | category   | AP     |
|:--------------|:-------|:---------------|:-------|:-----------|:-------|
| aeroplane     | 53.186 | bicycle        | 38.915 | bird       | 35.706 |
| boat          | 22.031 | bottle         | 24.437 | bus        | 53.259 |
| car           | 40.832 | cat            | 64.405 | chair      | 19.395 |
| cow           | 41.186 | diningtable    | 19.223 | dog        | 52.563 |
| horse         | 47.268 | motorbike      | 40.571 | person     | 41.473 |
| pottedplant   | 18.747 | sheep          | 41.831 | sofa       | 35.733 |
| train         | 54.728 | tvmonitor      | 43.909 | truck      | 0.000  |
| traffic light | 0.000  | fire hydrant   | 0.000  | stop sign  | 0.000  |
| parking meter | 0.000  | bench          | 0.000  | elephant   | 0.000  |
| bear          | 0.000  | zebra          | 0.000  | giraffe    | 0.000  |
| backpack      | 0.000  | umbrella       | 0.000  | handbag    | 0.000  |
| tie           | 0.000  | suitcase       | 0.000  | microwave  | 0.000  |
| oven          | 0.000  | toaster        | 0.000  | sink       | 0.000  |
| refrigerator  | 0.000  | frisbee        | 0.000  | skis       | 0.000  |
| snowboard     | 0.000  | sports ball    | 0.000  | kite       | 0.000  |
| baseball bat  | 0.000  | baseball glove | 0.000  | skateboard | 0.000  |
| surfboard     | 0.000  | tennis racket  | 0.000  | banana     | 0.000  |
| apple         | 0.000  | sandwich       | 0.000  | orange     | 0.000  |
| broccoli      | 0.000  | carrot         | 0.000  | hot dog    | 0.000  |
| pizza         | 0.000  | donut          | 0.000  | cake       | 0.000  |
| bed           | 0.000  | toilet         | 0.000  | laptop     | 0.000  |
| mouse         | 0.000  | remote         | 0.000  | keyboard   | 0.000  |
| cell phone    | 0.000  | book           | 0.000  | clock      | 0.000  |
| vase          | 0.000  | scissors       | 0.000  | teddy bear | 0.000  |
| hair drier    | 0.000  | toothbrush     | 0.000  | wine glass | 0.000  |
| cup           | 0.000  | fork           | 0.000  | knife      | 0.000  |
| spoon         | 0.000  | bowl           | 0.000  | unknown    | nan    |
[03/07 14:20:38] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[03/07 14:20:38] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/07 14:20:38] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/07 14:20:38] d2.evaluation.testing INFO: copypaste: 9.8675,14.4987,10.7423,2.7703,7.7044,12.2344
[03/07 14:20:38] d2.utils.events INFO:  iter: 54001     lr: N/A  max_mem: 1406M
[03/07 14:24:37] detectron2 INFO: Rank of current process: 0. World size: 1
[03/07 14:24:38] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/07 14:24:38] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=True)
[03/07 14:24:38] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/07 14:24:38] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/07 14:24:38] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/07 14:24:48] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/07 14:24:55] d2.data.build INFO: Valid classes: range(0, 20)
[03/07 14:24:55] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/07 14:24:56] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/07 14:24:56] d2.data.build INFO: Number of datapoints: 16551
[03/07 14:24:56] d2.data.build INFO: Using training sampler TrainingSampler
[03/07 14:24:59] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/07 14:24:59] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/07 14:24:59] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/07 14:25:12] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/07 14:25:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/07 14:25:12] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/07 14:25:12] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/07 14:25:20] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/07 14:25:32] d2.engine.hooks INFO: Total training time: 0:00:06 (0:00:06 on hooks)
[03/07 14:25:34] d2.data.build INFO: Known classes: range(0, 20)
[03/07 14:25:34] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/07 14:25:35] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[03/07 14:25:35] d2.data.build INFO: Number of datapoints: 10246
[03/07 14:25:35] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/07 14:25:35] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/07 14:25:35] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[03/07 14:25:35] d2.data.common INFO: Serialized dataset takes 6.49 MiB
[03/07 14:25:35] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/07 14:25:35] d2.evaluation.coco_evaluation INFO: Trying to convert 'voc_coco_2007_test' to COCO format ...
[03/07 14:25:35] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './output/t1/inference/voc_coco_2007_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[03/07 14:25:36] d2.evaluation.evaluator INFO: Start inference on 10246 batches
[03/07 14:25:37] d2.evaluation.evaluator INFO: Inference done 11/10246. Dataloading: 0.0011 s/iter. Inference: 0.0408 s/iter. Eval: 0.0004 s/iter. Total: 0.0423 s/iter. ETA=0:07:13
[03/07 14:27:53] d2.evaluation.evaluator INFO: Inference done 62/10246. Dataloading: 0.0017 s/iter. Inference: 1.6920 s/iter. Eval: 0.7042 s/iter. Total: 2.3980 s/iter. ETA=6:47:01
[03/07 14:28:00] d2.evaluation.evaluator INFO: Inference done 158/10246. Dataloading: 0.0015 s/iter. Inference: 0.6501 s/iter. Eval: 0.2896 s/iter. Total: 0.9413 s/iter. ETA=2:38:15
[03/07 14:28:45] d2.evaluation.evaluator INFO: Inference done 159/10246. Dataloading: 0.0015 s/iter. Inference: 0.6462 s/iter. Eval: 0.5740 s/iter. Total: 1.2217 s/iter. ETA=3:25:23
[03/07 14:28:50] d2.evaluation.evaluator INFO: Inference done 307/10246. Dataloading: 0.0015 s/iter. Inference: 0.3451 s/iter. Eval: 0.2929 s/iter. Total: 0.6396 s/iter. ETA=1:45:56
[03/07 14:28:55] d2.evaluation.evaluator INFO: Inference done 453/10246. Dataloading: 0.0015 s/iter. Inference: 0.2432 s/iter. Eval: 0.1975 s/iter. Total: 0.4423 s/iter. ETA=1:12:11
[03/07 14:29:00] d2.evaluation.evaluator INFO: Inference done 593/10246. Dataloading: 0.0015 s/iter. Inference: 0.1934 s/iter. Eval: 0.1506 s/iter. Total: 0.3455 s/iter. ETA=0:55:35
[03/07 14:29:05] d2.evaluation.evaluator INFO: Inference done 730/10246. Dataloading: 0.0015 s/iter. Inference: 0.1634 s/iter. Eval: 0.1222 s/iter. Total: 0.2872 s/iter. ETA=0:45:32
[03/07 14:29:10] d2.evaluation.evaluator INFO: Inference done 876/10246. Dataloading: 0.0015 s/iter. Inference: 0.1414 s/iter. Eval: 0.1018 s/iter. Total: 0.2448 s/iter. ETA=0:38:13
[03/07 14:29:15] d2.evaluation.evaluator INFO: Inference done 1020/10246. Dataloading: 0.0015 s/iter. Inference: 0.1258 s/iter. Eval: 0.0876 s/iter. Total: 0.2150 s/iter. ETA=0:33:03
[03/07 14:29:20] d2.evaluation.evaluator INFO: Inference done 1172/10246. Dataloading: 0.0015 s/iter. Inference: 0.1135 s/iter. Eval: 0.0762 s/iter. Total: 0.1913 s/iter. ETA=0:28:55
[03/07 14:29:25] d2.evaluation.evaluator INFO: Inference done 1321/10246. Dataloading: 0.0015 s/iter. Inference: 0.1042 s/iter. Eval: 0.0676 s/iter. Total: 0.1734 s/iter. ETA=0:25:47
[03/07 14:29:58] detectron2 INFO: Rank of current process: 0. World size: 2
[03/07 14:30:00] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/07 14:30:00] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4'], resume=True)
[03/07 14:30:00] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/07 14:30:00] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/07 14:30:00] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/07 14:30:01] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/07 14:30:04] d2.data.build INFO: Valid classes: range(0, 20)
[03/07 14:30:04] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/07 14:30:05] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/07 14:30:05] d2.data.build INFO: Number of datapoints: 16551
[03/07 14:30:05] d2.data.build INFO: Using training sampler TrainingSampler
[03/07 14:30:05] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/07 14:30:05] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/07 14:30:05] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/07 14:30:05] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/07 14:30:05] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/07 14:30:06] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/07 14:30:06] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/07 14:30:06] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/07 14:30:06] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/07 14:30:08] d2.data.build INFO: Known classes: range(0, 20)
[03/07 14:30:08] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/07 14:30:08] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[03/07 14:30:08] d2.data.build INFO: Number of datapoints: 10246
[03/07 14:30:09] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/07 14:30:09] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/07 14:30:09] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[03/07 14:30:09] d2.data.common INFO: Serialized dataset takes 6.49 MiB
[03/07 14:30:09] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/07 14:30:09] d2.evaluation.coco_evaluation INFO: Trying to convert 'voc_coco_2007_test' to COCO format ...
[03/07 14:30:09] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './output/t1/inference/voc_coco_2007_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[03/07 14:30:09] d2.evaluation.evaluator INFO: Start inference on 5123 batches
[03/07 14:30:13] d2.evaluation.evaluator INFO: Inference done 11/5123. Dataloading: 0.0006 s/iter. Inference: 0.0494 s/iter. Eval: 0.0004 s/iter. Total: 0.0504 s/iter. ETA=0:04:17
[03/07 14:30:18] d2.evaluation.evaluator INFO: Inference done 123/5123. Dataloading: 0.0015 s/iter. Inference: 0.0431 s/iter. Eval: 0.0004 s/iter. Total: 0.0452 s/iter. ETA=0:03:45
[03/07 14:30:23] d2.evaluation.evaluator INFO: Inference done 242/5123. Dataloading: 0.0016 s/iter. Inference: 0.0416 s/iter. Eval: 0.0004 s/iter. Total: 0.0437 s/iter. ETA=0:03:33
[03/07 14:30:28] d2.evaluation.evaluator INFO: Inference done 363/5123. Dataloading: 0.0017 s/iter. Inference: 0.0408 s/iter. Eval: 0.0004 s/iter. Total: 0.0429 s/iter. ETA=0:03:24
[03/07 14:30:33] d2.evaluation.evaluator INFO: Inference done 481/5123. Dataloading: 0.0017 s/iter. Inference: 0.0406 s/iter. Eval: 0.0004 s/iter. Total: 0.0428 s/iter. ETA=0:03:18
[03/07 14:30:38] d2.evaluation.evaluator INFO: Inference done 605/5123. Dataloading: 0.0017 s/iter. Inference: 0.0399 s/iter. Eval: 0.0007 s/iter. Total: 0.0424 s/iter. ETA=0:03:11
[03/07 14:30:43] d2.evaluation.evaluator INFO: Inference done 728/5123. Dataloading: 0.0017 s/iter. Inference: 0.0396 s/iter. Eval: 0.0007 s/iter. Total: 0.0421 s/iter. ETA=0:03:05
[03/07 14:30:48] d2.evaluation.evaluator INFO: Inference done 851/5123. Dataloading: 0.0017 s/iter. Inference: 0.0395 s/iter. Eval: 0.0006 s/iter. Total: 0.0419 s/iter. ETA=0:02:59
[03/07 14:30:53] d2.evaluation.evaluator INFO: Inference done 979/5123. Dataloading: 0.0017 s/iter. Inference: 0.0392 s/iter. Eval: 0.0006 s/iter. Total: 0.0416 s/iter. ETA=0:02:52
[03/07 14:30:58] d2.evaluation.evaluator INFO: Inference done 1094/5123. Dataloading: 0.0017 s/iter. Inference: 0.0392 s/iter. Eval: 0.0008 s/iter. Total: 0.0418 s/iter. ETA=0:02:48
[03/07 14:31:03] d2.evaluation.evaluator INFO: Inference done 1212/5123. Dataloading: 0.0017 s/iter. Inference: 0.0393 s/iter. Eval: 0.0007 s/iter. Total: 0.0419 s/iter. ETA=0:02:43
[03/07 14:31:08] d2.evaluation.evaluator INFO: Inference done 1342/5123. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0007 s/iter. Total: 0.0415 s/iter. ETA=0:02:37
[03/07 14:31:13] d2.evaluation.evaluator INFO: Inference done 1462/5123. Dataloading: 0.0017 s/iter. Inference: 0.0391 s/iter. Eval: 0.0007 s/iter. Total: 0.0416 s/iter. ETA=0:02:32
[03/07 14:31:18] d2.evaluation.evaluator INFO: Inference done 1582/5123. Dataloading: 0.0017 s/iter. Inference: 0.0391 s/iter. Eval: 0.0007 s/iter. Total: 0.0416 s/iter. ETA=0:02:27
[03/07 14:31:23] d2.evaluation.evaluator INFO: Inference done 1703/5123. Dataloading: 0.0017 s/iter. Inference: 0.0391 s/iter. Eval: 0.0007 s/iter. Total: 0.0416 s/iter. ETA=0:02:22
[03/07 14:31:28] d2.evaluation.evaluator INFO: Inference done 1822/5123. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0008 s/iter. Total: 0.0416 s/iter. ETA=0:02:17
[03/07 14:31:33] d2.evaluation.evaluator INFO: Inference done 1949/5123. Dataloading: 0.0017 s/iter. Inference: 0.0389 s/iter. Eval: 0.0007 s/iter. Total: 0.0415 s/iter. ETA=0:02:11
[03/07 14:31:38] d2.evaluation.evaluator INFO: Inference done 2075/5123. Dataloading: 0.0017 s/iter. Inference: 0.0389 s/iter. Eval: 0.0007 s/iter. Total: 0.0414 s/iter. ETA=0:02:06
[03/07 14:31:43] d2.evaluation.evaluator INFO: Inference done 2200/5123. Dataloading: 0.0017 s/iter. Inference: 0.0388 s/iter. Eval: 0.0007 s/iter. Total: 0.0413 s/iter. ETA=0:02:00
[03/07 14:31:48] d2.evaluation.evaluator INFO: Inference done 2327/5123. Dataloading: 0.0017 s/iter. Inference: 0.0387 s/iter. Eval: 0.0007 s/iter. Total: 0.0412 s/iter. ETA=0:01:55
[03/07 14:31:53] d2.evaluation.evaluator INFO: Inference done 2455/5123. Dataloading: 0.0017 s/iter. Inference: 0.0387 s/iter. Eval: 0.0007 s/iter. Total: 0.0411 s/iter. ETA=0:01:49
[03/07 14:31:58] d2.evaluation.evaluator INFO: Inference done 2577/5123. Dataloading: 0.0017 s/iter. Inference: 0.0387 s/iter. Eval: 0.0007 s/iter. Total: 0.0411 s/iter. ETA=0:01:44
[03/07 14:32:03] d2.evaluation.evaluator INFO: Inference done 2698/5123. Dataloading: 0.0017 s/iter. Inference: 0.0386 s/iter. Eval: 0.0008 s/iter. Total: 0.0411 s/iter. ETA=0:01:39
[03/07 14:32:08] d2.evaluation.evaluator INFO: Inference done 2822/5123. Dataloading: 0.0017 s/iter. Inference: 0.0386 s/iter. Eval: 0.0007 s/iter. Total: 0.0411 s/iter. ETA=0:01:34
[03/07 14:32:13] d2.evaluation.evaluator INFO: Inference done 2952/5123. Dataloading: 0.0017 s/iter. Inference: 0.0385 s/iter. Eval: 0.0007 s/iter. Total: 0.0410 s/iter. ETA=0:01:28
[03/07 14:32:18] d2.evaluation.evaluator INFO: Inference done 3078/5123. Dataloading: 0.0017 s/iter. Inference: 0.0385 s/iter. Eval: 0.0007 s/iter. Total: 0.0409 s/iter. ETA=0:01:23
[03/07 14:32:23] d2.evaluation.evaluator INFO: Inference done 3202/5123. Dataloading: 0.0017 s/iter. Inference: 0.0385 s/iter. Eval: 0.0007 s/iter. Total: 0.0409 s/iter. ETA=0:01:18
[03/07 14:32:28] d2.evaluation.evaluator INFO: Inference done 3324/5123. Dataloading: 0.0017 s/iter. Inference: 0.0385 s/iter. Eval: 0.0007 s/iter. Total: 0.0409 s/iter. ETA=0:01:13
[03/07 14:32:33] d2.evaluation.evaluator INFO: Inference done 3446/5123. Dataloading: 0.0017 s/iter. Inference: 0.0385 s/iter. Eval: 0.0007 s/iter. Total: 0.0409 s/iter. ETA=0:01:08
[03/07 14:32:38] d2.evaluation.evaluator INFO: Inference done 3572/5123. Dataloading: 0.0017 s/iter. Inference: 0.0385 s/iter. Eval: 0.0007 s/iter. Total: 0.0409 s/iter. ETA=0:01:03
[03/07 14:32:43] d2.evaluation.evaluator INFO: Inference done 3689/5123. Dataloading: 0.0017 s/iter. Inference: 0.0385 s/iter. Eval: 0.0007 s/iter. Total: 0.0410 s/iter. ETA=0:00:58
[03/07 14:32:48] d2.evaluation.evaluator INFO: Inference done 3816/5123. Dataloading: 0.0017 s/iter. Inference: 0.0384 s/iter. Eval: 0.0007 s/iter. Total: 0.0409 s/iter. ETA=0:00:53
[03/07 14:32:53] d2.evaluation.evaluator INFO: Inference done 3938/5123. Dataloading: 0.0016 s/iter. Inference: 0.0384 s/iter. Eval: 0.0007 s/iter. Total: 0.0409 s/iter. ETA=0:00:48
[03/07 14:32:58] d2.evaluation.evaluator INFO: Inference done 4064/5123. Dataloading: 0.0016 s/iter. Inference: 0.0384 s/iter. Eval: 0.0007 s/iter. Total: 0.0409 s/iter. ETA=0:00:43
[03/07 14:33:03] d2.evaluation.evaluator INFO: Inference done 4191/5123. Dataloading: 0.0016 s/iter. Inference: 0.0384 s/iter. Eval: 0.0007 s/iter. Total: 0.0408 s/iter. ETA=0:00:38
[03/07 14:33:08] d2.evaluation.evaluator INFO: Inference done 4318/5123. Dataloading: 0.0016 s/iter. Inference: 0.0384 s/iter. Eval: 0.0007 s/iter. Total: 0.0408 s/iter. ETA=0:00:32
[03/07 14:33:13] d2.evaluation.evaluator INFO: Inference done 4444/5123. Dataloading: 0.0016 s/iter. Inference: 0.0383 s/iter. Eval: 0.0007 s/iter. Total: 0.0408 s/iter. ETA=0:00:27
[03/07 14:33:18] d2.evaluation.evaluator INFO: Inference done 4574/5123. Dataloading: 0.0016 s/iter. Inference: 0.0383 s/iter. Eval: 0.0007 s/iter. Total: 0.0407 s/iter. ETA=0:00:22
[03/07 14:33:24] d2.evaluation.evaluator INFO: Inference done 4694/5123. Dataloading: 0.0016 s/iter. Inference: 0.0383 s/iter. Eval: 0.0007 s/iter. Total: 0.0407 s/iter. ETA=0:00:17
[03/07 14:33:29] d2.evaluation.evaluator INFO: Inference done 4816/5123. Dataloading: 0.0016 s/iter. Inference: 0.0383 s/iter. Eval: 0.0007 s/iter. Total: 0.0407 s/iter. ETA=0:00:12
[03/07 14:33:34] d2.evaluation.evaluator INFO: Inference done 4927/5123. Dataloading: 0.0016 s/iter. Inference: 0.0384 s/iter. Eval: 0.0007 s/iter. Total: 0.0408 s/iter. ETA=0:00:08
[03/07 14:33:39] d2.evaluation.evaluator INFO: Inference done 5050/5123. Dataloading: 0.0016 s/iter. Inference: 0.0384 s/iter. Eval: 0.0007 s/iter. Total: 0.0408 s/iter. ETA=0:00:02
[03/07 14:33:42] d2.evaluation.evaluator INFO: Total inference time: 0:03:29.886357 (0.041009 s / iter per device, on 2 devices)
[03/07 14:33:42] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:16 (0.038337 s / iter per device, on 2 devices)
[03/07 14:35:43] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/07 14:39:56] d2.evaluation.coco_evaluation INFO: Saving results to ./output/t1/inference/coco_instances_results.json
[03/07 14:40:02] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/07 14:40:07] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/07 14:40:30] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.46 seconds.
[03/07 14:40:31] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/07 14:40:35] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 4.03 seconds.
[03/07 14:40:35] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 9.867 | 14.499 | 10.742 | 2.770 | 7.704 | 12.234 |
[03/07 14:40:35] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP     | category       | AP     | category   | AP     |
|:--------------|:-------|:---------------|:-------|:-----------|:-------|
| aeroplane     | 53.186 | bicycle        | 38.915 | bird       | 35.706 |
| boat          | 22.031 | bottle         | 24.437 | bus        | 53.259 |
| car           | 40.832 | cat            | 64.405 | chair      | 19.395 |
| cow           | 41.186 | diningtable    | 19.223 | dog        | 52.563 |
| horse         | 47.268 | motorbike      | 40.571 | person     | 41.473 |
| pottedplant   | 18.747 | sheep          | 41.831 | sofa       | 35.733 |
| train         | 54.728 | tvmonitor      | 43.909 | truck      | 0.000  |
| traffic light | 0.000  | fire hydrant   | 0.000  | stop sign  | 0.000  |
| parking meter | 0.000  | bench          | 0.000  | elephant   | 0.000  |
| bear          | 0.000  | zebra          | 0.000  | giraffe    | 0.000  |
| backpack      | 0.000  | umbrella       | 0.000  | handbag    | 0.000  |
| tie           | 0.000  | suitcase       | 0.000  | microwave  | 0.000  |
| oven          | 0.000  | toaster        | 0.000  | sink       | 0.000  |
| refrigerator  | 0.000  | frisbee        | 0.000  | skis       | 0.000  |
| snowboard     | 0.000  | sports ball    | 0.000  | kite       | 0.000  |
| baseball bat  | 0.000  | baseball glove | 0.000  | skateboard | 0.000  |
| surfboard     | 0.000  | tennis racket  | 0.000  | banana     | 0.000  |
| apple         | 0.000  | sandwich       | 0.000  | orange     | 0.000  |
| broccoli      | 0.000  | carrot         | 0.000  | hot dog    | 0.000  |
| pizza         | 0.000  | donut          | 0.000  | cake       | 0.000  |
| bed           | 0.000  | toilet         | 0.000  | laptop     | 0.000  |
| mouse         | 0.000  | remote         | 0.000  | keyboard   | 0.000  |
| cell phone    | 0.000  | book           | 0.000  | clock      | 0.000  |
| vase          | 0.000  | scissors       | 0.000  | teddy bear | 0.000  |
| hair drier    | 0.000  | toothbrush     | 0.000  | wine glass | 0.000  |
| cup           | 0.000  | fork           | 0.000  | knife      | 0.000  |
| spoon         | 0.000  | bowl           | 0.000  | unknown    | nan    |
[03/07 14:40:38] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[03/07 14:40:38] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/07 14:40:38] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/07 14:40:38] d2.evaluation.testing INFO: copypaste: 9.8675,14.4987,10.7423,2.7703,7.7044,12.2344
[03/07 14:40:38] d2.utils.events INFO:  iter: 54001     lr: N/A  max_mem: 1406M
[03/07 18:32:27] detectron2 INFO: Rank of current process: 0. World size: 2
[03/07 18:32:29] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/07 18:32:29] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4'], resume=True)
[03/07 18:32:29] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/07 18:32:29] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/07 18:32:29] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/07 18:32:30] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/07 18:32:33] d2.data.build INFO: Valid classes: range(0, 20)
[03/07 18:32:33] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/07 18:32:34] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/07 18:32:34] d2.data.build INFO: Number of datapoints: 16551
[03/07 18:32:34] d2.data.build INFO: Using training sampler TrainingSampler
[03/07 18:32:34] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/07 18:32:34] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/07 18:32:34] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/07 18:32:34] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/07 18:32:34] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/07 18:32:35] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/07 18:32:35] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/07 18:32:49] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/07 18:32:49] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/07 18:32:51] d2.data.build INFO: Known classes: range(0, 20)
[03/07 18:32:51] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/07 18:32:52] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[03/07 18:32:52] d2.data.build INFO: Number of datapoints: 10246
[03/07 18:32:52] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/07 18:32:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/07 18:32:52] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[03/07 18:32:52] d2.data.common INFO: Serialized dataset takes 6.49 MiB
[03/07 18:32:52] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/07 18:32:52] d2.evaluation.coco_evaluation INFO: Trying to convert 'voc_coco_2007_test' to COCO format ...
[03/07 18:32:52] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './output/t1/inference/voc_coco_2007_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[03/07 18:32:52] d2.evaluation.evaluator INFO: Start inference on 5123 batches
[03/07 18:32:56] d2.evaluation.evaluator INFO: Inference done 11/5123. Dataloading: 0.0009 s/iter. Inference: 0.0441 s/iter. Eval: 0.0004 s/iter. Total: 0.0455 s/iter. ETA=0:03:52
[03/07 18:33:01] d2.evaluation.evaluator INFO: Inference done 134/5123. Dataloading: 0.0017 s/iter. Inference: 0.0377 s/iter. Eval: 0.0017 s/iter. Total: 0.0412 s/iter. ETA=0:03:25
[03/07 18:33:06] d2.evaluation.evaluator INFO: Inference done 259/5123. Dataloading: 0.0017 s/iter. Inference: 0.0378 s/iter. Eval: 0.0011 s/iter. Total: 0.0407 s/iter. ETA=0:03:17
[03/07 18:33:11] d2.evaluation.evaluator INFO: Inference done 381/5123. Dataloading: 0.0016 s/iter. Inference: 0.0382 s/iter. Eval: 0.0009 s/iter. Total: 0.0408 s/iter. ETA=0:03:13
[03/07 18:33:16] d2.evaluation.evaluator INFO: Inference done 505/5123. Dataloading: 0.0016 s/iter. Inference: 0.0383 s/iter. Eval: 0.0008 s/iter. Total: 0.0407 s/iter. ETA=0:03:08
[03/07 18:33:21] d2.evaluation.evaluator INFO: Inference done 626/5123. Dataloading: 0.0017 s/iter. Inference: 0.0382 s/iter. Eval: 0.0009 s/iter. Total: 0.0409 s/iter. ETA=0:03:03
[03/07 18:33:26] d2.evaluation.evaluator INFO: Inference done 749/5123. Dataloading: 0.0017 s/iter. Inference: 0.0383 s/iter. Eval: 0.0009 s/iter. Total: 0.0409 s/iter. ETA=0:02:58
[03/07 18:33:31] d2.evaluation.evaluator INFO: Inference done 874/5123. Dataloading: 0.0017 s/iter. Inference: 0.0382 s/iter. Eval: 0.0008 s/iter. Total: 0.0408 s/iter. ETA=0:02:53
[03/07 18:33:36] d2.evaluation.evaluator INFO: Inference done 1001/5123. Dataloading: 0.0017 s/iter. Inference: 0.0381 s/iter. Eval: 0.0008 s/iter. Total: 0.0406 s/iter. ETA=0:02:47
[03/07 18:33:41] d2.evaluation.evaluator INFO: Inference done 1123/5123. Dataloading: 0.0017 s/iter. Inference: 0.0381 s/iter. Eval: 0.0007 s/iter. Total: 0.0407 s/iter. ETA=0:02:42
[03/07 18:33:46] d2.evaluation.evaluator INFO: Inference done 1251/5123. Dataloading: 0.0017 s/iter. Inference: 0.0380 s/iter. Eval: 0.0007 s/iter. Total: 0.0405 s/iter. ETA=0:02:36
[03/07 18:33:51] d2.evaluation.evaluator INFO: Inference done 1380/5123. Dataloading: 0.0017 s/iter. Inference: 0.0379 s/iter. Eval: 0.0007 s/iter. Total: 0.0403 s/iter. ETA=0:02:31
[03/07 18:33:56] d2.evaluation.evaluator INFO: Inference done 1504/5123. Dataloading: 0.0017 s/iter. Inference: 0.0379 s/iter. Eval: 0.0007 s/iter. Total: 0.0404 s/iter. ETA=0:02:26
[03/07 18:34:01] d2.evaluation.evaluator INFO: Inference done 1626/5123. Dataloading: 0.0017 s/iter. Inference: 0.0380 s/iter. Eval: 0.0006 s/iter. Total: 0.0404 s/iter. ETA=0:02:21
[03/07 18:34:06] d2.evaluation.evaluator INFO: Inference done 1747/5123. Dataloading: 0.0017 s/iter. Inference: 0.0380 s/iter. Eval: 0.0008 s/iter. Total: 0.0405 s/iter. ETA=0:02:16
[03/07 18:34:11] d2.evaluation.evaluator INFO: Inference done 1877/5123. Dataloading: 0.0017 s/iter. Inference: 0.0379 s/iter. Eval: 0.0007 s/iter. Total: 0.0404 s/iter. ETA=0:02:11
[03/07 18:34:16] d2.evaluation.evaluator INFO: Inference done 1994/5123. Dataloading: 0.0017 s/iter. Inference: 0.0380 s/iter. Eval: 0.0007 s/iter. Total: 0.0405 s/iter. ETA=0:02:06
[03/07 18:34:21] d2.evaluation.evaluator INFO: Inference done 2117/5123. Dataloading: 0.0017 s/iter. Inference: 0.0381 s/iter. Eval: 0.0007 s/iter. Total: 0.0405 s/iter. ETA=0:02:01
[03/07 18:34:27] d2.evaluation.evaluator INFO: Inference done 2241/5123. Dataloading: 0.0017 s/iter. Inference: 0.0381 s/iter. Eval: 0.0007 s/iter. Total: 0.0405 s/iter. ETA=0:01:56
[03/07 18:34:32] d2.evaluation.evaluator INFO: Inference done 2364/5123. Dataloading: 0.0017 s/iter. Inference: 0.0381 s/iter. Eval: 0.0007 s/iter. Total: 0.0405 s/iter. ETA=0:01:51
[03/07 18:34:37] d2.evaluation.evaluator INFO: Inference done 2481/5123. Dataloading: 0.0017 s/iter. Inference: 0.0383 s/iter. Eval: 0.0007 s/iter. Total: 0.0407 s/iter. ETA=0:01:47
[03/07 18:34:42] d2.evaluation.evaluator INFO: Inference done 2593/5123. Dataloading: 0.0017 s/iter. Inference: 0.0383 s/iter. Eval: 0.0008 s/iter. Total: 0.0408 s/iter. ETA=0:01:43
[03/07 18:34:47] d2.evaluation.evaluator INFO: Inference done 2714/5123. Dataloading: 0.0017 s/iter. Inference: 0.0384 s/iter. Eval: 0.0007 s/iter. Total: 0.0409 s/iter. ETA=0:01:38
[03/07 18:34:52] d2.evaluation.evaluator INFO: Inference done 2836/5123. Dataloading: 0.0017 s/iter. Inference: 0.0384 s/iter. Eval: 0.0007 s/iter. Total: 0.0409 s/iter. ETA=0:01:33
[03/07 18:34:57] d2.evaluation.evaluator INFO: Inference done 2959/5123. Dataloading: 0.0017 s/iter. Inference: 0.0384 s/iter. Eval: 0.0007 s/iter. Total: 0.0409 s/iter. ETA=0:01:28
[03/07 18:35:02] d2.evaluation.evaluator INFO: Inference done 3086/5123. Dataloading: 0.0017 s/iter. Inference: 0.0384 s/iter. Eval: 0.0007 s/iter. Total: 0.0408 s/iter. ETA=0:01:23
[03/07 18:35:07] d2.evaluation.evaluator INFO: Inference done 3212/5123. Dataloading: 0.0017 s/iter. Inference: 0.0383 s/iter. Eval: 0.0007 s/iter. Total: 0.0408 s/iter. ETA=0:01:17
[03/07 18:35:12] d2.evaluation.evaluator INFO: Inference done 3338/5123. Dataloading: 0.0017 s/iter. Inference: 0.0383 s/iter. Eval: 0.0007 s/iter. Total: 0.0407 s/iter. ETA=0:01:12
[03/07 18:35:17] d2.evaluation.evaluator INFO: Inference done 3458/5123. Dataloading: 0.0017 s/iter. Inference: 0.0384 s/iter. Eval: 0.0007 s/iter. Total: 0.0408 s/iter. ETA=0:01:07
[03/07 18:35:22] d2.evaluation.evaluator INFO: Inference done 3580/5123. Dataloading: 0.0017 s/iter. Inference: 0.0384 s/iter. Eval: 0.0007 s/iter. Total: 0.0408 s/iter. ETA=0:01:02
[03/07 18:35:27] d2.evaluation.evaluator INFO: Inference done 3695/5123. Dataloading: 0.0016 s/iter. Inference: 0.0385 s/iter. Eval: 0.0007 s/iter. Total: 0.0409 s/iter. ETA=0:00:58
[03/07 18:35:32] d2.evaluation.evaluator INFO: Inference done 3815/5123. Dataloading: 0.0016 s/iter. Inference: 0.0385 s/iter. Eval: 0.0007 s/iter. Total: 0.0409 s/iter. ETA=0:00:53
[03/07 18:35:37] d2.evaluation.evaluator INFO: Inference done 3940/5123. Dataloading: 0.0016 s/iter. Inference: 0.0385 s/iter. Eval: 0.0006 s/iter. Total: 0.0409 s/iter. ETA=0:00:48
[03/07 18:35:42] d2.evaluation.evaluator INFO: Inference done 4063/5123. Dataloading: 0.0016 s/iter. Inference: 0.0385 s/iter. Eval: 0.0006 s/iter. Total: 0.0409 s/iter. ETA=0:00:43
[03/07 18:35:47] d2.evaluation.evaluator INFO: Inference done 4181/5123. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0006 s/iter. Total: 0.0409 s/iter. ETA=0:00:38
[03/07 18:35:52] d2.evaluation.evaluator INFO: Inference done 4302/5123. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0006 s/iter. Total: 0.0409 s/iter. ETA=0:00:33
[03/07 18:35:57] d2.evaluation.evaluator INFO: Inference done 4425/5123. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0006 s/iter. Total: 0.0409 s/iter. ETA=0:00:28
[03/07 18:36:02] d2.evaluation.evaluator INFO: Inference done 4550/5123. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0006 s/iter. Total: 0.0409 s/iter. ETA=0:00:23
[03/07 18:36:07] d2.evaluation.evaluator INFO: Inference done 4673/5123. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0006 s/iter. Total: 0.0409 s/iter. ETA=0:00:18
[03/07 18:36:12] d2.evaluation.evaluator INFO: Inference done 4796/5123. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0006 s/iter. Total: 0.0409 s/iter. ETA=0:00:13
[03/07 18:36:17] d2.evaluation.evaluator INFO: Inference done 4910/5123. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0007 s/iter. Total: 0.0410 s/iter. ETA=0:00:08
[03/07 18:36:22] d2.evaluation.evaluator INFO: Inference done 5036/5123. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0007 s/iter. Total: 0.0410 s/iter. ETA=0:00:03
[03/07 18:36:26] d2.evaluation.evaluator INFO: Total inference time: 0:03:30.477705 (0.041125 s / iter per device, on 2 devices)
[03/07 18:36:26] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:17 (0.038525 s / iter per device, on 2 devices)
[03/07 18:55:54] detectron2 INFO: Rank of current process: 0. World size: 2
[03/07 18:55:56] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/07 18:55:56] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4'], resume=True)
[03/07 18:55:56] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/07 18:55:56] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/07 18:55:56] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/07 18:55:57] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/07 18:55:59] d2.data.build INFO: Valid classes: range(0, 20)
[03/07 18:55:59] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/07 18:56:00] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/07 18:56:00] d2.data.build INFO: Number of datapoints: 16551
[03/07 18:56:00] d2.data.build INFO: Using training sampler TrainingSampler
[03/07 18:56:00] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/07 18:56:00] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/07 18:56:01] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/07 18:56:01] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/07 18:56:01] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/07 18:56:01] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/07 18:56:01] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/07 18:56:05] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/07 18:56:05] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/07 18:56:07] d2.data.build INFO: Known classes: range(0, 20)
[03/07 18:56:07] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/07 18:56:07] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[03/07 18:56:07] d2.data.build INFO: Number of datapoints: 10246
[03/07 18:56:07] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/07 18:56:07] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/07 18:56:07] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[03/07 18:56:07] d2.data.common INFO: Serialized dataset takes 6.49 MiB
[03/07 18:56:07] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/07 18:56:07] d2.evaluation.coco_evaluation INFO: Trying to convert 'voc_coco_2007_test' to COCO format ...
[03/07 18:56:07] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './output/t1/inference/voc_coco_2007_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[03/07 18:56:08] d2.evaluation.evaluator INFO: Start inference on 5123 batches
[03/07 18:56:25] d2.evaluation.evaluator INFO: Inference done 11/5123. Dataloading: 0.0007 s/iter. Inference: 0.0361 s/iter. Eval: 0.0004 s/iter. Total: 0.0372 s/iter. ETA=0:03:10
[03/07 18:56:30] d2.evaluation.evaluator INFO: Inference done 146/5123. Dataloading: 0.0016 s/iter. Inference: 0.0351 s/iter. Eval: 0.0004 s/iter. Total: 0.0371 s/iter. ETA=0:03:04
[03/07 18:56:35] d2.evaluation.evaluator INFO: Inference done 288/5123. Dataloading: 0.0016 s/iter. Inference: 0.0343 s/iter. Eval: 0.0004 s/iter. Total: 0.0363 s/iter. ETA=0:02:55
[03/07 18:56:40] d2.evaluation.evaluator INFO: Inference done 420/5123. Dataloading: 0.0016 s/iter. Inference: 0.0348 s/iter. Eval: 0.0004 s/iter. Total: 0.0368 s/iter. ETA=0:02:53
[03/07 18:56:45] d2.evaluation.evaluator INFO: Inference done 541/5123. Dataloading: 0.0016 s/iter. Inference: 0.0355 s/iter. Eval: 0.0007 s/iter. Total: 0.0379 s/iter. ETA=0:02:53
[03/07 18:56:50] d2.evaluation.evaluator INFO: Inference done 667/5123. Dataloading: 0.0016 s/iter. Inference: 0.0359 s/iter. Eval: 0.0007 s/iter. Total: 0.0383 s/iter. ETA=0:02:50
[03/07 18:56:55] d2.evaluation.evaluator INFO: Inference done 784/5123. Dataloading: 0.0016 s/iter. Inference: 0.0366 s/iter. Eval: 0.0006 s/iter. Total: 0.0390 s/iter. ETA=0:02:49
[03/07 18:57:00] d2.evaluation.evaluator INFO: Inference done 906/5123. Dataloading: 0.0017 s/iter. Inference: 0.0369 s/iter. Eval: 0.0006 s/iter. Total: 0.0393 s/iter. ETA=0:02:45
[03/07 18:57:05] d2.evaluation.evaluator INFO: Inference done 1031/5123. Dataloading: 0.0017 s/iter. Inference: 0.0371 s/iter. Eval: 0.0006 s/iter. Total: 0.0394 s/iter. ETA=0:02:41
[03/07 18:57:10] d2.evaluation.evaluator INFO: Inference done 1148/5123. Dataloading: 0.0017 s/iter. Inference: 0.0374 s/iter. Eval: 0.0006 s/iter. Total: 0.0397 s/iter. ETA=0:02:37
[03/07 18:57:15] d2.evaluation.evaluator INFO: Inference done 1272/5123. Dataloading: 0.0017 s/iter. Inference: 0.0375 s/iter. Eval: 0.0006 s/iter. Total: 0.0398 s/iter. ETA=0:02:33
[03/07 18:57:20] d2.evaluation.evaluator INFO: Inference done 1396/5123. Dataloading: 0.0017 s/iter. Inference: 0.0375 s/iter. Eval: 0.0006 s/iter. Total: 0.0399 s/iter. ETA=0:02:28
[03/07 18:57:25] d2.evaluation.evaluator INFO: Inference done 1519/5123. Dataloading: 0.0017 s/iter. Inference: 0.0376 s/iter. Eval: 0.0005 s/iter. Total: 0.0399 s/iter. ETA=0:02:23
[03/07 18:57:30] d2.evaluation.evaluator INFO: Inference done 1646/5123. Dataloading: 0.0017 s/iter. Inference: 0.0376 s/iter. Eval: 0.0005 s/iter. Total: 0.0399 s/iter. ETA=0:02:18
[03/07 18:57:35] d2.evaluation.evaluator INFO: Inference done 1761/5123. Dataloading: 0.0017 s/iter. Inference: 0.0377 s/iter. Eval: 0.0007 s/iter. Total: 0.0401 s/iter. ETA=0:02:14
[03/07 18:57:40] d2.evaluation.evaluator INFO: Inference done 1882/5123. Dataloading: 0.0017 s/iter. Inference: 0.0378 s/iter. Eval: 0.0007 s/iter. Total: 0.0402 s/iter. ETA=0:02:10
[03/07 18:57:45] d2.evaluation.evaluator INFO: Inference done 2004/5123. Dataloading: 0.0017 s/iter. Inference: 0.0379 s/iter. Eval: 0.0006 s/iter. Total: 0.0403 s/iter. ETA=0:02:05
[03/07 18:57:50] d2.evaluation.evaluator INFO: Inference done 2132/5123. Dataloading: 0.0017 s/iter. Inference: 0.0378 s/iter. Eval: 0.0006 s/iter. Total: 0.0402 s/iter. ETA=0:02:00
[03/07 18:57:55] d2.evaluation.evaluator INFO: Inference done 2261/5123. Dataloading: 0.0017 s/iter. Inference: 0.0378 s/iter. Eval: 0.0006 s/iter. Total: 0.0402 s/iter. ETA=0:01:54
[03/07 18:58:00] d2.evaluation.evaluator INFO: Inference done 2379/5123. Dataloading: 0.0017 s/iter. Inference: 0.0379 s/iter. Eval: 0.0006 s/iter. Total: 0.0403 s/iter. ETA=0:01:50
[03/07 18:58:05] d2.evaluation.evaluator INFO: Inference done 2503/5123. Dataloading: 0.0017 s/iter. Inference: 0.0379 s/iter. Eval: 0.0006 s/iter. Total: 0.0403 s/iter. ETA=0:01:45
[03/07 18:58:10] d2.evaluation.evaluator INFO: Inference done 2620/5123. Dataloading: 0.0017 s/iter. Inference: 0.0379 s/iter. Eval: 0.0007 s/iter. Total: 0.0404 s/iter. ETA=0:01:41
[03/07 18:58:15] d2.evaluation.evaluator INFO: Inference done 2740/5123. Dataloading: 0.0017 s/iter. Inference: 0.0380 s/iter. Eval: 0.0007 s/iter. Total: 0.0405 s/iter. ETA=0:01:36
[03/07 18:58:20] d2.evaluation.evaluator INFO: Inference done 2865/5123. Dataloading: 0.0017 s/iter. Inference: 0.0380 s/iter. Eval: 0.0007 s/iter. Total: 0.0405 s/iter. ETA=0:01:31
[03/07 18:58:25] d2.evaluation.evaluator INFO: Inference done 2986/5123. Dataloading: 0.0017 s/iter. Inference: 0.0380 s/iter. Eval: 0.0007 s/iter. Total: 0.0405 s/iter. ETA=0:01:26
[03/07 18:58:30] d2.evaluation.evaluator INFO: Inference done 3108/5123. Dataloading: 0.0017 s/iter. Inference: 0.0381 s/iter. Eval: 0.0007 s/iter. Total: 0.0405 s/iter. ETA=0:01:21
[03/07 18:58:35] d2.evaluation.evaluator INFO: Inference done 3223/5123. Dataloading: 0.0017 s/iter. Inference: 0.0382 s/iter. Eval: 0.0007 s/iter. Total: 0.0406 s/iter. ETA=0:01:17
[03/07 18:58:40] d2.evaluation.evaluator INFO: Inference done 3346/5123. Dataloading: 0.0017 s/iter. Inference: 0.0382 s/iter. Eval: 0.0007 s/iter. Total: 0.0407 s/iter. ETA=0:01:12
[03/07 18:58:45] d2.evaluation.evaluator INFO: Inference done 3461/5123. Dataloading: 0.0017 s/iter. Inference: 0.0383 s/iter. Eval: 0.0006 s/iter. Total: 0.0408 s/iter. ETA=0:01:07
[03/07 18:58:50] d2.evaluation.evaluator INFO: Inference done 3582/5123. Dataloading: 0.0017 s/iter. Inference: 0.0383 s/iter. Eval: 0.0006 s/iter. Total: 0.0408 s/iter. ETA=0:01:02
[03/07 18:58:55] d2.evaluation.evaluator INFO: Inference done 3703/5123. Dataloading: 0.0017 s/iter. Inference: 0.0384 s/iter. Eval: 0.0006 s/iter. Total: 0.0408 s/iter. ETA=0:00:57
[03/07 18:59:01] d2.evaluation.evaluator INFO: Inference done 3830/5123. Dataloading: 0.0017 s/iter. Inference: 0.0383 s/iter. Eval: 0.0006 s/iter. Total: 0.0408 s/iter. ETA=0:00:52
[03/07 18:59:06] d2.evaluation.evaluator INFO: Inference done 3945/5123. Dataloading: 0.0017 s/iter. Inference: 0.0384 s/iter. Eval: 0.0006 s/iter. Total: 0.0408 s/iter. ETA=0:00:48
[03/07 18:59:11] d2.evaluation.evaluator INFO: Inference done 4065/5123. Dataloading: 0.0017 s/iter. Inference: 0.0385 s/iter. Eval: 0.0006 s/iter. Total: 0.0409 s/iter. ETA=0:00:43
[03/07 18:59:16] d2.evaluation.evaluator INFO: Inference done 4191/5123. Dataloading: 0.0017 s/iter. Inference: 0.0384 s/iter. Eval: 0.0006 s/iter. Total: 0.0408 s/iter. ETA=0:00:38
[03/07 18:59:21] d2.evaluation.evaluator INFO: Inference done 4315/5123. Dataloading: 0.0017 s/iter. Inference: 0.0384 s/iter. Eval: 0.0006 s/iter. Total: 0.0408 s/iter. ETA=0:00:32
[03/07 18:59:26] d2.evaluation.evaluator INFO: Inference done 4437/5123. Dataloading: 0.0017 s/iter. Inference: 0.0384 s/iter. Eval: 0.0006 s/iter. Total: 0.0408 s/iter. ETA=0:00:28
[03/07 18:59:31] d2.evaluation.evaluator INFO: Inference done 4560/5123. Dataloading: 0.0017 s/iter. Inference: 0.0384 s/iter. Eval: 0.0006 s/iter. Total: 0.0408 s/iter. ETA=0:00:22
[03/07 18:59:36] d2.evaluation.evaluator INFO: Inference done 4682/5123. Dataloading: 0.0017 s/iter. Inference: 0.0385 s/iter. Eval: 0.0006 s/iter. Total: 0.0408 s/iter. ETA=0:00:18
[03/07 18:59:41] d2.evaluation.evaluator INFO: Inference done 4804/5123. Dataloading: 0.0017 s/iter. Inference: 0.0385 s/iter. Eval: 0.0006 s/iter. Total: 0.0409 s/iter. ETA=0:00:13
[03/07 18:59:46] d2.evaluation.evaluator INFO: Inference done 4910/5123. Dataloading: 0.0017 s/iter. Inference: 0.0385 s/iter. Eval: 0.0007 s/iter. Total: 0.0410 s/iter. ETA=0:00:08
[03/07 18:59:51] d2.evaluation.evaluator INFO: Inference done 5032/5123. Dataloading: 0.0017 s/iter. Inference: 0.0385 s/iter. Eval: 0.0007 s/iter. Total: 0.0410 s/iter. ETA=0:00:03
[03/07 18:59:56] d2.evaluation.evaluator INFO: Total inference time: 0:03:30.945871 (0.041216 s / iter per device, on 2 devices)
[03/07 18:59:56] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:17 (0.038506 s / iter per device, on 2 devices)
[03/07 19:01:41] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/07 19:02:05] d2.evaluation.coco_evaluation INFO: Saving results to ./output/t1/inference/coco_instances_results.json
[03/07 19:02:26] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/07 19:02:45] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/07 19:03:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 27.53 seconds.
[03/07 19:03:14] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/07 19:03:18] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 4.40 seconds.
[03/07 19:05:39] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 9.867 | 14.499 | 10.742 | 2.770 | 7.704 | 12.234 |
[03/07 19:05:39] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP     | category       | AP     | category   | AP     |
|:--------------|:-------|:---------------|:-------|:-----------|:-------|
| aeroplane     | 53.186 | bicycle        | 38.915 | bird       | 35.706 |
| boat          | 22.031 | bottle         | 24.437 | bus        | 53.259 |
| car           | 40.832 | cat            | 64.405 | chair      | 19.395 |
| cow           | 41.186 | diningtable    | 19.223 | dog        | 52.563 |
| horse         | 47.268 | motorbike      | 40.571 | person     | 41.473 |
| pottedplant   | 18.747 | sheep          | 41.831 | sofa       | 35.733 |
| train         | 54.728 | tvmonitor      | 43.909 | truck      | 0.000  |
| traffic light | 0.000  | fire hydrant   | 0.000  | stop sign  | 0.000  |
| parking meter | 0.000  | bench          | 0.000  | elephant   | 0.000  |
| bear          | 0.000  | zebra          | 0.000  | giraffe    | 0.000  |
| backpack      | 0.000  | umbrella       | 0.000  | handbag    | 0.000  |
| tie           | 0.000  | suitcase       | 0.000  | microwave  | 0.000  |
| oven          | 0.000  | toaster        | 0.000  | sink       | 0.000  |
| refrigerator  | 0.000  | frisbee        | 0.000  | skis       | 0.000  |
| snowboard     | 0.000  | sports ball    | 0.000  | kite       | 0.000  |
| baseball bat  | 0.000  | baseball glove | 0.000  | skateboard | 0.000  |
| surfboard     | 0.000  | tennis racket  | 0.000  | banana     | 0.000  |
| apple         | 0.000  | sandwich       | 0.000  | orange     | 0.000  |
| broccoli      | 0.000  | carrot         | 0.000  | hot dog    | 0.000  |
| pizza         | 0.000  | donut          | 0.000  | cake       | 0.000  |
| bed           | 0.000  | toilet         | 0.000  | laptop     | 0.000  |
| mouse         | 0.000  | remote         | 0.000  | keyboard   | 0.000  |
| cell phone    | 0.000  | book           | 0.000  | clock      | 0.000  |
| vase          | 0.000  | scissors       | 0.000  | teddy bear | 0.000  |
| hair drier    | 0.000  | toothbrush     | 0.000  | wine glass | 0.000  |
| cup           | 0.000  | fork           | 0.000  | knife      | 0.000  |
| spoon         | 0.000  | bowl           | 0.000  | unknown    | nan    |
[03/07 19:05:43] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[03/07 19:05:43] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/07 19:05:43] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/07 19:05:43] d2.evaluation.testing INFO: copypaste: 9.8675,14.4987,10.7423,2.7703,7.7044,12.2344
[03/07 19:05:43] d2.utils.events INFO:  iter: 54001     lr: N/A  max_mem: 1406M
[03/07 19:08:20] detectron2 INFO: Rank of current process: 0. World size: 2
[03/07 19:08:21] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/07 19:08:21] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4'], resume=True)
[03/07 19:08:21] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/07 19:08:21] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/07 19:08:21] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/07 19:08:23] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/07 19:08:25] d2.data.build INFO: Valid classes: range(0, 20)
[03/07 19:08:25] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/07 19:08:25] d2.data.build INFO: Distribution of instances among all 81 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |
[03/07 19:08:25] d2.data.build INFO: Number of datapoints: 16551
[03/07 19:08:25] d2.data.build INFO: Using training sampler TrainingSampler
[03/07 19:08:25] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/07 19:08:25] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/07 19:08:26] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/07 19:08:26] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/07 19:08:26] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/07 19:08:26] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/07 19:08:26] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/07 19:08:26] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/07 19:08:26] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/07 19:08:28] d2.data.build INFO: Known classes: range(0, 20)
[03/07 19:08:28] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/07 19:08:28] d2.data.build INFO: Distribution of instances among all 81 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |
[03/07 19:08:28] d2.data.build INFO: Number of datapoints: 10246
[03/07 19:08:28] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/07 19:08:28] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/07 19:08:28] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[03/07 19:08:28] d2.data.common INFO: Serialized dataset takes 6.49 MiB
[03/07 19:08:28] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/07 19:08:28] d2.evaluation.coco_evaluation INFO: Trying to convert 'voc_coco_2007_test' to COCO format ...
[03/07 19:08:28] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './output/t1/inference/voc_coco_2007_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[03/07 19:08:29] d2.evaluation.evaluator INFO: Start inference on 5123 batches
[03/07 19:08:32] d2.evaluation.evaluator INFO: Inference done 11/5123. Dataloading: 0.0008 s/iter. Inference: 0.0362 s/iter. Eval: 0.0003 s/iter. Total: 0.0373 s/iter. ETA=0:03:10
[03/07 19:08:37] d2.evaluation.evaluator INFO: Inference done 139/5123. Dataloading: 0.0012 s/iter. Inference: 0.0378 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:03:16
[03/07 19:08:42] d2.evaluation.evaluator INFO: Inference done 262/5123. Dataloading: 0.0013 s/iter. Inference: 0.0379 s/iter. Eval: 0.0009 s/iter. Total: 0.0401 s/iter. ETA=0:03:14
[03/07 19:08:47] d2.evaluation.evaluator INFO: Inference done 378/5123. Dataloading: 0.0013 s/iter. Inference: 0.0391 s/iter. Eval: 0.0007 s/iter. Total: 0.0411 s/iter. ETA=0:03:14
[03/07 19:08:52] d2.evaluation.evaluator INFO: Inference done 500/5123. Dataloading: 0.0013 s/iter. Inference: 0.0392 s/iter. Eval: 0.0006 s/iter. Total: 0.0411 s/iter. ETA=0:03:10
[03/07 19:08:57] d2.evaluation.evaluator INFO: Inference done 620/5123. Dataloading: 0.0013 s/iter. Inference: 0.0394 s/iter. Eval: 0.0006 s/iter. Total: 0.0412 s/iter. ETA=0:03:05
[03/07 19:09:02] d2.evaluation.evaluator INFO: Inference done 740/5123. Dataloading: 0.0013 s/iter. Inference: 0.0393 s/iter. Eval: 0.0007 s/iter. Total: 0.0413 s/iter. ETA=0:03:01
[03/07 19:09:07] d2.evaluation.evaluator INFO: Inference done 863/5123. Dataloading: 0.0013 s/iter. Inference: 0.0393 s/iter. Eval: 0.0007 s/iter. Total: 0.0413 s/iter. ETA=0:02:55
[03/07 19:09:12] d2.evaluation.evaluator INFO: Inference done 993/5123. Dataloading: 0.0013 s/iter. Inference: 0.0389 s/iter. Eval: 0.0006 s/iter. Total: 0.0409 s/iter. ETA=0:02:49
[03/07 19:09:17] d2.evaluation.evaluator INFO: Inference done 1117/5123. Dataloading: 0.0013 s/iter. Inference: 0.0389 s/iter. Eval: 0.0006 s/iter. Total: 0.0409 s/iter. ETA=0:02:43
[03/07 19:09:22] d2.evaluation.evaluator INFO: Inference done 1246/5123. Dataloading: 0.0013 s/iter. Inference: 0.0388 s/iter. Eval: 0.0006 s/iter. Total: 0.0407 s/iter. ETA=0:02:37
[03/07 19:09:27] d2.evaluation.evaluator INFO: Inference done 1360/5123. Dataloading: 0.0013 s/iter. Inference: 0.0389 s/iter. Eval: 0.0007 s/iter. Total: 0.0410 s/iter. ETA=0:02:34
[03/07 19:09:32] d2.evaluation.evaluator INFO: Inference done 1486/5123. Dataloading: 0.0013 s/iter. Inference: 0.0389 s/iter. Eval: 0.0006 s/iter. Total: 0.0409 s/iter. ETA=0:02:28
[03/07 19:09:37] d2.evaluation.evaluator INFO: Inference done 1601/5123. Dataloading: 0.0013 s/iter. Inference: 0.0391 s/iter. Eval: 0.0006 s/iter. Total: 0.0411 s/iter. ETA=0:02:24
[03/07 19:09:42] d2.evaluation.evaluator INFO: Inference done 1719/5123. Dataloading: 0.0013 s/iter. Inference: 0.0392 s/iter. Eval: 0.0006 s/iter. Total: 0.0412 s/iter. ETA=0:02:20
[03/07 19:09:47] d2.evaluation.evaluator INFO: Inference done 1837/5123. Dataloading: 0.0013 s/iter. Inference: 0.0393 s/iter. Eval: 0.0006 s/iter. Total: 0.0413 s/iter. ETA=0:02:15
[03/07 19:09:52] d2.evaluation.evaluator INFO: Inference done 1963/5123. Dataloading: 0.0013 s/iter. Inference: 0.0392 s/iter. Eval: 0.0006 s/iter. Total: 0.0412 s/iter. ETA=0:02:10
[03/07 19:09:57] d2.evaluation.evaluator INFO: Inference done 2075/5123. Dataloading: 0.0013 s/iter. Inference: 0.0394 s/iter. Eval: 0.0006 s/iter. Total: 0.0414 s/iter. ETA=0:02:06
[03/07 19:10:02] d2.evaluation.evaluator INFO: Inference done 2203/5123. Dataloading: 0.0013 s/iter. Inference: 0.0393 s/iter. Eval: 0.0005 s/iter. Total: 0.0412 s/iter. ETA=0:02:00
[03/07 19:10:07] d2.evaluation.evaluator INFO: Inference done 2330/5123. Dataloading: 0.0013 s/iter. Inference: 0.0392 s/iter. Eval: 0.0005 s/iter. Total: 0.0411 s/iter. ETA=0:01:54
[03/07 19:10:12] d2.evaluation.evaluator INFO: Inference done 2452/5123. Dataloading: 0.0013 s/iter. Inference: 0.0393 s/iter. Eval: 0.0005 s/iter. Total: 0.0411 s/iter. ETA=0:01:49
[03/07 19:10:17] d2.evaluation.evaluator INFO: Inference done 2573/5123. Dataloading: 0.0013 s/iter. Inference: 0.0393 s/iter. Eval: 0.0005 s/iter. Total: 0.0412 s/iter. ETA=0:01:44
[03/07 19:10:22] d2.evaluation.evaluator INFO: Inference done 2705/5123. Dataloading: 0.0013 s/iter. Inference: 0.0391 s/iter. Eval: 0.0005 s/iter. Total: 0.0410 s/iter. ETA=0:01:39
[03/07 19:10:27] d2.evaluation.evaluator INFO: Inference done 2839/5123. Dataloading: 0.0013 s/iter. Inference: 0.0390 s/iter. Eval: 0.0005 s/iter. Total: 0.0408 s/iter. ETA=0:01:33
[03/07 19:10:32] d2.evaluation.evaluator INFO: Inference done 2959/5123. Dataloading: 0.0013 s/iter. Inference: 0.0390 s/iter. Eval: 0.0005 s/iter. Total: 0.0409 s/iter. ETA=0:01:28
[03/07 19:10:37] d2.evaluation.evaluator INFO: Inference done 3074/5123. Dataloading: 0.0013 s/iter. Inference: 0.0391 s/iter. Eval: 0.0006 s/iter. Total: 0.0410 s/iter. ETA=0:01:23
[03/07 19:10:42] d2.evaluation.evaluator INFO: Inference done 3202/5123. Dataloading: 0.0013 s/iter. Inference: 0.0390 s/iter. Eval: 0.0006 s/iter. Total: 0.0409 s/iter. ETA=0:01:18
[03/07 19:10:47] d2.evaluation.evaluator INFO: Inference done 3317/5123. Dataloading: 0.0013 s/iter. Inference: 0.0391 s/iter. Eval: 0.0005 s/iter. Total: 0.0410 s/iter. ETA=0:01:14
[03/07 19:10:52] d2.evaluation.evaluator INFO: Inference done 3438/5123. Dataloading: 0.0013 s/iter. Inference: 0.0391 s/iter. Eval: 0.0005 s/iter. Total: 0.0410 s/iter. ETA=0:01:09
[03/07 19:10:57] d2.evaluation.evaluator INFO: Inference done 3567/5123. Dataloading: 0.0013 s/iter. Inference: 0.0390 s/iter. Eval: 0.0005 s/iter. Total: 0.0410 s/iter. ETA=0:01:03
[03/07 19:11:02] d2.evaluation.evaluator INFO: Inference done 3689/5123. Dataloading: 0.0013 s/iter. Inference: 0.0391 s/iter. Eval: 0.0005 s/iter. Total: 0.0410 s/iter. ETA=0:00:58
[03/07 19:11:07] d2.evaluation.evaluator INFO: Inference done 3821/5123. Dataloading: 0.0013 s/iter. Inference: 0.0390 s/iter. Eval: 0.0005 s/iter. Total: 0.0409 s/iter. ETA=0:00:53
[03/07 19:11:12] d2.evaluation.evaluator INFO: Inference done 3949/5123. Dataloading: 0.0013 s/iter. Inference: 0.0389 s/iter. Eval: 0.0005 s/iter. Total: 0.0408 s/iter. ETA=0:00:47
[03/07 19:11:18] d2.evaluation.evaluator INFO: Inference done 4073/5123. Dataloading: 0.0013 s/iter. Inference: 0.0389 s/iter. Eval: 0.0005 s/iter. Total: 0.0408 s/iter. ETA=0:00:42
[03/07 19:11:23] d2.evaluation.evaluator INFO: Inference done 4189/5123. Dataloading: 0.0013 s/iter. Inference: 0.0390 s/iter. Eval: 0.0005 s/iter. Total: 0.0409 s/iter. ETA=0:00:38
[03/07 19:11:28] d2.evaluation.evaluator INFO: Inference done 4323/5123. Dataloading: 0.0013 s/iter. Inference: 0.0389 s/iter. Eval: 0.0005 s/iter. Total: 0.0408 s/iter. ETA=0:00:32
[03/07 19:11:33] d2.evaluation.evaluator INFO: Inference done 4447/5123. Dataloading: 0.0013 s/iter. Inference: 0.0389 s/iter. Eval: 0.0005 s/iter. Total: 0.0407 s/iter. ETA=0:00:27
[03/07 19:11:38] d2.evaluation.evaluator INFO: Inference done 4573/5123. Dataloading: 0.0013 s/iter. Inference: 0.0389 s/iter. Eval: 0.0005 s/iter. Total: 0.0407 s/iter. ETA=0:00:22
[03/07 19:11:43] d2.evaluation.evaluator INFO: Inference done 4690/5123. Dataloading: 0.0013 s/iter. Inference: 0.0389 s/iter. Eval: 0.0005 s/iter. Total: 0.0408 s/iter. ETA=0:00:17
[03/07 19:11:48] d2.evaluation.evaluator INFO: Inference done 4803/5123. Dataloading: 0.0013 s/iter. Inference: 0.0390 s/iter. Eval: 0.0005 s/iter. Total: 0.0409 s/iter. ETA=0:00:13
[03/07 19:11:53] d2.evaluation.evaluator INFO: Inference done 4922/5123. Dataloading: 0.0013 s/iter. Inference: 0.0390 s/iter. Eval: 0.0005 s/iter. Total: 0.0409 s/iter. ETA=0:00:08
[03/07 19:11:58] d2.evaluation.evaluator INFO: Inference done 5049/5123. Dataloading: 0.0013 s/iter. Inference: 0.0390 s/iter. Eval: 0.0005 s/iter. Total: 0.0409 s/iter. ETA=0:00:03
[03/07 19:12:00] d2.evaluation.evaluator INFO: Total inference time: 0:03:28.775577 (0.040792 s / iter per device, on 2 devices)
[03/07 19:12:00] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:18 (0.038876 s / iter per device, on 2 devices)
[03/07 19:12:12] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/07 19:12:12] d2.evaluation.coco_evaluation INFO: Saving results to ./output/t1/inference/coco_instances_results.json
[03/07 19:12:18] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[03/07 19:12:21] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[03/07 19:12:42] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 20.93 seconds.
[03/07 19:12:43] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[03/07 19:12:48] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 4.32 seconds.
[03/07 19:12:48] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 9.867 | 14.499 | 10.742 | 2.770 | 7.704 | 12.234 |
[03/07 19:12:48] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP     | category       | AP     | category   | AP     |
|:--------------|:-------|:---------------|:-------|:-----------|:-------|
| aeroplane     | 53.186 | bicycle        | 38.915 | bird       | 35.706 |
| boat          | 22.031 | bottle         | 24.437 | bus        | 53.259 |
| car           | 40.832 | cat            | 64.405 | chair      | 19.395 |
| cow           | 41.186 | diningtable    | 19.223 | dog        | 52.563 |
| horse         | 47.268 | motorbike      | 40.571 | person     | 41.473 |
| pottedplant   | 18.747 | sheep          | 41.831 | sofa       | 35.733 |
| train         | 54.728 | tvmonitor      | 43.909 | truck      | 0.000  |
| traffic light | 0.000  | fire hydrant   | 0.000  | stop sign  | 0.000  |
| parking meter | 0.000  | bench          | 0.000  | elephant   | 0.000  |
| bear          | 0.000  | zebra          | 0.000  | giraffe    | 0.000  |
| backpack      | 0.000  | umbrella       | 0.000  | handbag    | 0.000  |
| tie           | 0.000  | suitcase       | 0.000  | microwave  | 0.000  |
| oven          | 0.000  | toaster        | 0.000  | sink       | 0.000  |
| refrigerator  | 0.000  | frisbee        | 0.000  | skis       | 0.000  |
| snowboard     | 0.000  | sports ball    | 0.000  | kite       | 0.000  |
| baseball bat  | 0.000  | baseball glove | 0.000  | skateboard | 0.000  |
| surfboard     | 0.000  | tennis racket  | 0.000  | banana     | 0.000  |
| apple         | 0.000  | sandwich       | 0.000  | orange     | 0.000  |
| broccoli      | 0.000  | carrot         | 0.000  | hot dog    | 0.000  |
| pizza         | 0.000  | donut          | 0.000  | cake       | 0.000  |
| bed           | 0.000  | toilet         | 0.000  | laptop     | 0.000  |
| mouse         | 0.000  | remote         | 0.000  | keyboard   | 0.000  |
| cell phone    | 0.000  | book           | 0.000  | clock      | 0.000  |
| vase          | 0.000  | scissors       | 0.000  | teddy bear | 0.000  |
| hair drier    | 0.000  | toothbrush     | 0.000  | wine glass | 0.000  |
| cup           | 0.000  | fork           | 0.000  | knife      | 0.000  |
| spoon         | 0.000  | bowl           | 0.000  | unknown    | nan    |
[03/07 19:12:50] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[03/07 19:12:50] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/07 19:12:50] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/07 19:12:50] d2.evaluation.testing INFO: copypaste: 9.8675,14.4987,10.7423,2.7703,7.7044,12.2344
[03/07 19:12:51] d2.utils.events INFO:  iter: 54001     lr: N/A  max_mem: 1406M
[03/07 20:11:52] detectron2 INFO: Rank of current process: 0. World size: 2
[03/07 20:11:53] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/07 20:11:53] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4'], resume=True)
[03/07 20:11:53] detectron2 INFO: Contents of args.config_file=./configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/07 20:11:53] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/07 20:11:54] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/07 20:11:55] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/07 20:11:57] d2.data.build INFO: Valid classes: range(0, 20)
[03/07 20:11:57] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/07 20:11:57] d2.data.build INFO: Distribution of instances among all 81 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |
[03/07 20:11:57] d2.data.build INFO: Number of datapoints: 16551
[03/07 20:11:57] d2.data.build INFO: Using training sampler TrainingSampler
[03/07 20:11:58] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/07 20:11:58] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/07 20:11:58] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/07 20:11:58] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./output/t1/model_final.pth ...
[03/07 20:11:58] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/t1/model_final.pth ...
[03/07 20:11:58] fvcore.common.checkpoint INFO: Loading trainer from ./output/t1/model_final.pth ...
[03/07 20:11:58] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[03/07 20:11:59] d2.engine.train_loop INFO: Starting training from iteration 54000
[03/07 20:11:59] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[03/07 20:12:00] d2.data.build INFO: Known classes: range(0, 20)
[03/07 20:12:00] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/07 20:12:01] d2.data.build INFO: Distribution of instances among all 81 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |
[03/07 20:12:01] d2.data.build INFO: Number of datapoints: 10246
[03/07 20:12:01] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/07 20:12:01] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/07 20:12:01] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[03/07 20:12:01] d2.data.common INFO: Serialized dataset takes 6.49 MiB
[03/07 20:12:01] d2.evaluation.evaluator INFO: Start inference on 5123 batches
[03/07 20:12:03] d2.evaluation.evaluator INFO: Inference done 11/5123. Dataloading: 0.0008 s/iter. Inference: 0.0373 s/iter. Eval: 0.0014 s/iter. Total: 0.0394 s/iter. ETA=0:03:21
[03/07 20:12:08] d2.evaluation.evaluator INFO: Inference done 131/5123. Dataloading: 0.0014 s/iter. Inference: 0.0389 s/iter. Eval: 0.0013 s/iter. Total: 0.0417 s/iter. ETA=0:03:28
[03/07 20:12:13] d2.evaluation.evaluator INFO: Inference done 252/5123. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0013 s/iter. Total: 0.0417 s/iter. ETA=0:03:22
[03/07 20:12:18] d2.evaluation.evaluator INFO: Inference done 374/5123. Dataloading: 0.0015 s/iter. Inference: 0.0386 s/iter. Eval: 0.0013 s/iter. Total: 0.0415 s/iter. ETA=0:03:17
[03/07 20:12:23] d2.evaluation.evaluator INFO: Inference done 498/5123. Dataloading: 0.0015 s/iter. Inference: 0.0383 s/iter. Eval: 0.0014 s/iter. Total: 0.0412 s/iter. ETA=0:03:10
[03/07 20:12:28] d2.evaluation.evaluator INFO: Inference done 623/5123. Dataloading: 0.0015 s/iter. Inference: 0.0381 s/iter. Eval: 0.0013 s/iter. Total: 0.0410 s/iter. ETA=0:03:04
[03/07 20:12:33] d2.evaluation.evaluator INFO: Inference done 749/5123. Dataloading: 0.0015 s/iter. Inference: 0.0379 s/iter. Eval: 0.0013 s/iter. Total: 0.0408 s/iter. ETA=0:02:58
[03/07 20:12:38] d2.evaluation.evaluator INFO: Inference done 875/5123. Dataloading: 0.0016 s/iter. Inference: 0.0377 s/iter. Eval: 0.0013 s/iter. Total: 0.0407 s/iter. ETA=0:02:52
[03/07 20:12:43] d2.evaluation.evaluator INFO: Inference done 1000/5123. Dataloading: 0.0016 s/iter. Inference: 0.0376 s/iter. Eval: 0.0013 s/iter. Total: 0.0406 s/iter. ETA=0:02:47
[03/07 20:12:48] d2.evaluation.evaluator INFO: Inference done 1128/5123. Dataloading: 0.0016 s/iter. Inference: 0.0375 s/iter. Eval: 0.0013 s/iter. Total: 0.0404 s/iter. ETA=0:02:41
[03/07 20:12:53] d2.evaluation.evaluator INFO: Inference done 1257/5123. Dataloading: 0.0016 s/iter. Inference: 0.0373 s/iter. Eval: 0.0013 s/iter. Total: 0.0403 s/iter. ETA=0:02:35
[03/07 20:12:58] d2.evaluation.evaluator INFO: Inference done 1386/5123. Dataloading: 0.0016 s/iter. Inference: 0.0372 s/iter. Eval: 0.0013 s/iter. Total: 0.0402 s/iter. ETA=0:02:30
[03/07 20:13:04] d2.evaluation.evaluator INFO: Inference done 1515/5123. Dataloading: 0.0016 s/iter. Inference: 0.0371 s/iter. Eval: 0.0013 s/iter. Total: 0.0401 s/iter. ETA=0:02:24
[03/07 20:13:09] d2.evaluation.evaluator INFO: Inference done 1640/5123. Dataloading: 0.0016 s/iter. Inference: 0.0371 s/iter. Eval: 0.0013 s/iter. Total: 0.0401 s/iter. ETA=0:02:19
[03/07 20:13:14] d2.evaluation.evaluator INFO: Inference done 1767/5123. Dataloading: 0.0016 s/iter. Inference: 0.0371 s/iter. Eval: 0.0013 s/iter. Total: 0.0400 s/iter. ETA=0:02:14
[03/07 20:13:19] d2.evaluation.evaluator INFO: Inference done 1896/5123. Dataloading: 0.0016 s/iter. Inference: 0.0370 s/iter. Eval: 0.0013 s/iter. Total: 0.0400 s/iter. ETA=0:02:08
[03/07 20:13:24] d2.evaluation.evaluator INFO: Inference done 2027/5123. Dataloading: 0.0016 s/iter. Inference: 0.0369 s/iter. Eval: 0.0013 s/iter. Total: 0.0399 s/iter. ETA=0:02:03
[03/07 20:13:29] d2.evaluation.evaluator INFO: Inference done 2157/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0013 s/iter. Total: 0.0398 s/iter. ETA=0:01:57
[03/07 20:13:34] d2.evaluation.evaluator INFO: Inference done 2285/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0013 s/iter. Total: 0.0397 s/iter. ETA=0:01:52
[03/07 20:13:39] d2.evaluation.evaluator INFO: Inference done 2413/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0013 s/iter. Total: 0.0397 s/iter. ETA=0:01:47
[03/07 20:13:44] d2.evaluation.evaluator INFO: Inference done 2539/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0013 s/iter. Total: 0.0397 s/iter. ETA=0:01:42
[03/07 20:13:49] d2.evaluation.evaluator INFO: Inference done 2664/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0013 s/iter. Total: 0.0397 s/iter. ETA=0:01:37
[03/07 20:13:54] d2.evaluation.evaluator INFO: Inference done 2790/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0013 s/iter. Total: 0.0397 s/iter. ETA=0:01:32
[03/07 20:13:59] d2.evaluation.evaluator INFO: Inference done 2918/5123. Dataloading: 0.0016 s/iter. Inference: 0.0367 s/iter. Eval: 0.0013 s/iter. Total: 0.0397 s/iter. ETA=0:01:27
[03/07 20:14:04] d2.evaluation.evaluator INFO: Inference done 3048/5123. Dataloading: 0.0016 s/iter. Inference: 0.0367 s/iter. Eval: 0.0013 s/iter. Total: 0.0397 s/iter. ETA=0:01:22
[03/07 20:14:09] d2.evaluation.evaluator INFO: Inference done 3179/5123. Dataloading: 0.0016 s/iter. Inference: 0.0366 s/iter. Eval: 0.0013 s/iter. Total: 0.0396 s/iter. ETA=0:01:17
[03/07 20:14:14] d2.evaluation.evaluator INFO: Inference done 3300/5123. Dataloading: 0.0016 s/iter. Inference: 0.0367 s/iter. Eval: 0.0013 s/iter. Total: 0.0397 s/iter. ETA=0:01:12
[03/07 20:14:19] d2.evaluation.evaluator INFO: Inference done 3424/5123. Dataloading: 0.0016 s/iter. Inference: 0.0367 s/iter. Eval: 0.0013 s/iter. Total: 0.0397 s/iter. ETA=0:01:07
[03/07 20:14:24] d2.evaluation.evaluator INFO: Inference done 3545/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0013 s/iter. Total: 0.0398 s/iter. ETA=0:01:02
[03/07 20:14:29] d2.evaluation.evaluator INFO: Inference done 3668/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0013 s/iter. Total: 0.0398 s/iter. ETA=0:00:57
[03/07 20:14:34] d2.evaluation.evaluator INFO: Inference done 3797/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0013 s/iter. Total: 0.0398 s/iter. ETA=0:00:52
[03/07 20:14:39] d2.evaluation.evaluator INFO: Inference done 3926/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0013 s/iter. Total: 0.0397 s/iter. ETA=0:00:47
[03/07 20:14:44] d2.evaluation.evaluator INFO: Inference done 4052/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0013 s/iter. Total: 0.0398 s/iter. ETA=0:00:42
[03/07 20:14:49] d2.evaluation.evaluator INFO: Inference done 4180/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0013 s/iter. Total: 0.0397 s/iter. ETA=0:00:37
[03/07 20:14:54] d2.evaluation.evaluator INFO: Inference done 4305/5123. Dataloading: 0.0015 s/iter. Inference: 0.0368 s/iter. Eval: 0.0013 s/iter. Total: 0.0398 s/iter. ETA=0:00:32
[03/07 20:14:59] d2.evaluation.evaluator INFO: Inference done 4431/5123. Dataloading: 0.0016 s/iter. Inference: 0.0368 s/iter. Eval: 0.0013 s/iter. Total: 0.0398 s/iter. ETA=0:00:27
[03/07 20:15:04] d2.evaluation.evaluator INFO: Inference done 4562/5123. Dataloading: 0.0015 s/iter. Inference: 0.0368 s/iter. Eval: 0.0013 s/iter. Total: 0.0397 s/iter. ETA=0:00:22
[03/07 20:15:09] d2.evaluation.evaluator INFO: Inference done 4696/5123. Dataloading: 0.0015 s/iter. Inference: 0.0367 s/iter. Eval: 0.0013 s/iter. Total: 0.0397 s/iter. ETA=0:00:16
[03/07 20:15:14] d2.evaluation.evaluator INFO: Inference done 4830/5123. Dataloading: 0.0015 s/iter. Inference: 0.0367 s/iter. Eval: 0.0013 s/iter. Total: 0.0396 s/iter. ETA=0:00:11
[03/07 20:15:19] d2.evaluation.evaluator INFO: Inference done 4947/5123. Dataloading: 0.0015 s/iter. Inference: 0.0367 s/iter. Eval: 0.0013 s/iter. Total: 0.0397 s/iter. ETA=0:00:06
[03/07 20:15:24] d2.evaluation.evaluator INFO: Inference done 5067/5123. Dataloading: 0.0015 s/iter. Inference: 0.0368 s/iter. Eval: 0.0013 s/iter. Total: 0.0397 s/iter. ETA=0:00:02
[03/07 20:15:27] d2.evaluation.evaluator INFO: Total inference time: 0:03:23.839557 (0.039828 s / iter per device, on 2 devices)
[03/07 20:15:27] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:08 (0.036803 s / iter per device, on 2 devices)
[03/07 20:15:28] d2.evaluation.pascal_voc_evaluation INFO: Evaluating voc_coco_2007_test using 2012 metric. Note that results do not use the official Matlab API.
[03/07 20:15:28] d2.evaluation.pascal_voc_evaluation INFO: aeroplane has 20644 predictions.
[03/07 20:15:30] d2.evaluation.pascal_voc_evaluation INFO: bicycle has 24509 predictions.
[03/07 20:15:31] d2.evaluation.pascal_voc_evaluation INFO: bird has 45642 predictions.
[03/07 20:15:33] d2.evaluation.pascal_voc_evaluation INFO: boat has 35094 predictions.
[03/07 20:15:34] d2.evaluation.pascal_voc_evaluation INFO: bottle has 81118 predictions.
[03/07 20:15:37] d2.evaluation.pascal_voc_evaluation INFO: bus has 18367 predictions.
[03/07 20:15:38] d2.evaluation.pascal_voc_evaluation INFO: car has 89197 predictions.
[03/07 20:15:41] d2.evaluation.pascal_voc_evaluation INFO: cat has 21026 predictions.
[03/07 20:15:42] d2.evaluation.pascal_voc_evaluation INFO: chair has 138431 predictions.
[03/07 20:15:47] d2.evaluation.pascal_voc_evaluation INFO: cow has 15131 predictions.
[03/07 20:15:48] d2.evaluation.pascal_voc_evaluation INFO: diningtable has 41884 predictions.
[03/07 20:15:50] d2.evaluation.pascal_voc_evaluation INFO: dog has 31103 predictions.
[03/07 20:15:51] d2.evaluation.pascal_voc_evaluation INFO: horse has 22805 predictions.
[03/07 20:15:52] d2.evaluation.pascal_voc_evaluation INFO: motorbike has 19264 predictions.
[03/07 20:15:53] d2.evaluation.pascal_voc_evaluation INFO: person has 238452 predictions.
[03/07 20:16:03] d2.evaluation.pascal_voc_evaluation INFO: pottedplant has 57792 predictions.
[03/07 20:16:05] d2.evaluation.pascal_voc_evaluation INFO: sheep has 18366 predictions.
[03/07 20:16:06] d2.evaluation.pascal_voc_evaluation INFO: sofa has 34400 predictions.
[03/07 20:16:08] d2.evaluation.pascal_voc_evaluation INFO: train has 27832 predictions.
[03/07 20:16:09] d2.evaluation.pascal_voc_evaluation INFO: tvmonitor has 43534 predictions.
[03/07 20:16:10] d2.evaluation.pascal_voc_evaluation INFO: truck has 1 predictions.
[03/07 20:16:11] d2.evaluation.pascal_voc_evaluation INFO: traffic light has 1 predictions.
[03/07 20:16:11] d2.evaluation.pascal_voc_evaluation INFO: fire hydrant has 1 predictions.
[03/07 20:16:11] d2.evaluation.pascal_voc_evaluation INFO: stop sign has 1 predictions.
[03/07 20:16:11] d2.evaluation.pascal_voc_evaluation INFO: parking meter has 1 predictions.
[03/07 20:16:12] d2.evaluation.pascal_voc_evaluation INFO: bench has 1 predictions.
[03/07 20:16:12] d2.evaluation.pascal_voc_evaluation INFO: elephant has 1 predictions.
[03/07 20:16:12] d2.evaluation.pascal_voc_evaluation INFO: bear has 1 predictions.
[03/07 20:16:13] d2.evaluation.pascal_voc_evaluation INFO: zebra has 1 predictions.
[03/07 20:16:13] d2.evaluation.pascal_voc_evaluation INFO: giraffe has 1 predictions.
[03/07 20:16:13] d2.evaluation.pascal_voc_evaluation INFO: backpack has 1 predictions.
[03/07 20:16:13] d2.evaluation.pascal_voc_evaluation INFO: umbrella has 1 predictions.
[03/07 20:16:14] d2.evaluation.pascal_voc_evaluation INFO: handbag has 1 predictions.
[03/07 20:16:14] d2.evaluation.pascal_voc_evaluation INFO: tie has 1 predictions.
[03/07 20:16:14] d2.evaluation.pascal_voc_evaluation INFO: suitcase has 1 predictions.
[03/07 20:16:14] d2.evaluation.pascal_voc_evaluation INFO: microwave has 1 predictions.
[03/07 20:16:15] d2.evaluation.pascal_voc_evaluation INFO: oven has 1 predictions.
[03/07 20:16:15] d2.evaluation.pascal_voc_evaluation INFO: toaster has 1 predictions.
[03/07 20:16:15] d2.evaluation.pascal_voc_evaluation INFO: sink has 1 predictions.
[03/07 20:16:16] d2.evaluation.pascal_voc_evaluation INFO: refrigerator has 1 predictions.
[03/07 20:16:16] d2.evaluation.pascal_voc_evaluation INFO: frisbee has 1 predictions.
[03/07 20:16:16] d2.evaluation.pascal_voc_evaluation INFO: skis has 1 predictions.
[03/07 20:16:16] d2.evaluation.pascal_voc_evaluation INFO: snowboard has 1 predictions.
[03/07 20:16:17] d2.evaluation.pascal_voc_evaluation INFO: sports ball has 1 predictions.
[03/07 20:16:17] d2.evaluation.pascal_voc_evaluation INFO: kite has 1 predictions.
[03/07 20:16:17] d2.evaluation.pascal_voc_evaluation INFO: baseball bat has 1 predictions.
[03/07 20:16:18] d2.evaluation.pascal_voc_evaluation INFO: baseball glove has 1 predictions.
[03/07 20:16:18] d2.evaluation.pascal_voc_evaluation INFO: skateboard has 6 predictions.
[03/07 20:16:18] d2.evaluation.pascal_voc_evaluation INFO: surfboard has 1 predictions.
[03/07 20:16:18] d2.evaluation.pascal_voc_evaluation INFO: tennis racket has 1 predictions.
[03/07 20:16:18] d2.evaluation.pascal_voc_evaluation INFO: banana has 1 predictions.
[03/07 20:16:19] d2.evaluation.pascal_voc_evaluation INFO: apple has 1 predictions.
[03/07 20:16:19] d2.evaluation.pascal_voc_evaluation INFO: sandwich has 1 predictions.
[03/07 20:16:19] d2.evaluation.pascal_voc_evaluation INFO: orange has 1 predictions.
[03/07 20:16:20] d2.evaluation.pascal_voc_evaluation INFO: broccoli has 1 predictions.
[03/07 20:16:20] d2.evaluation.pascal_voc_evaluation INFO: carrot has 1 predictions.
[03/07 20:16:20] d2.evaluation.pascal_voc_evaluation INFO: hot dog has 1 predictions.
[03/07 20:16:20] d2.evaluation.pascal_voc_evaluation INFO: pizza has 1 predictions.
[03/07 20:16:21] d2.evaluation.pascal_voc_evaluation INFO: donut has 1 predictions.
[03/07 20:16:21] d2.evaluation.pascal_voc_evaluation INFO: cake has 1 predictions.
[03/07 20:16:21] d2.evaluation.pascal_voc_evaluation INFO: bed has 1 predictions.
[03/07 20:16:22] d2.evaluation.pascal_voc_evaluation INFO: toilet has 1 predictions.
[03/07 20:16:22] d2.evaluation.pascal_voc_evaluation INFO: laptop has 1 predictions.
[03/07 20:16:22] d2.evaluation.pascal_voc_evaluation INFO: mouse has 1 predictions.
[03/07 20:16:23] d2.evaluation.pascal_voc_evaluation INFO: remote has 1 predictions.
[03/07 20:16:23] d2.evaluation.pascal_voc_evaluation INFO: keyboard has 1 predictions.
[03/07 20:16:23] d2.evaluation.pascal_voc_evaluation INFO: cell phone has 1 predictions.
[03/07 20:16:23] d2.evaluation.pascal_voc_evaluation INFO: book has 1 predictions.
[03/07 20:16:24] d2.evaluation.pascal_voc_evaluation INFO: clock has 1 predictions.
[03/07 20:16:24] d2.evaluation.pascal_voc_evaluation INFO: vase has 1 predictions.
[03/07 20:16:24] d2.evaluation.pascal_voc_evaluation INFO: scissors has 1 predictions.
[03/07 20:16:24] d2.evaluation.pascal_voc_evaluation INFO: teddy bear has 1 predictions.
[03/07 20:16:25] d2.evaluation.pascal_voc_evaluation INFO: hair drier has 1 predictions.
[03/07 20:16:25] d2.evaluation.pascal_voc_evaluation INFO: toothbrush has 1 predictions.
[03/07 20:16:25] d2.evaluation.pascal_voc_evaluation INFO: wine glass has 1 predictions.
[03/07 20:16:26] d2.evaluation.pascal_voc_evaluation INFO: cup has 1 predictions.
[03/07 20:16:26] d2.evaluation.pascal_voc_evaluation INFO: fork has 1 predictions.
[03/07 20:16:26] d2.evaluation.pascal_voc_evaluation INFO: knife has 1 predictions.
[03/07 20:16:26] d2.evaluation.pascal_voc_evaluation INFO: spoon has 1 predictions.
[03/07 20:16:27] d2.evaluation.pascal_voc_evaluation INFO: bowl has 3 predictions.
[03/07 20:16:27] d2.evaluation.pascal_voc_evaluation INFO: unknown has 1 predictions.
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: Wilderness Impact: {0.1: {50: 0.0188987400839944}, 0.2: {50: 0.02809047869542346}, 0.3: {50: 0.0415700652396614}, 0.4: {50: 0.061481481481481484}, 0.5: {50: 0.09458405692824073}, 0.6: {50: 0.09131502489100306}, 0.7: {50: 0.07811077629140242}, 0.8: {50: 0.07381768062346149}, 0.9: {50: 0.07761648002212083}}
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: avg_precision: {0.1: {50: 0}, 0.2: {50: 0}, 0.3: {50: 0}, 0.4: {50: 0}, 0.5: {50: 0}, 0.6: {50: 0}, 0.7: {50: 0}, 0.8: {50: 0}, 0.9: {50: 0}}
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: Absolute OSE (total_num_unk_det_as_known): {50: 81311.0}
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: total_num_unk 23320
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor', 'truck', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'bed', 'toilet', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'unknown']
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: AP50: ['79.2', '55.3', '56.8', '41.2', '24.5', '68.5', '56.1', '77.3', '19.2', '59.3', '14.3', '69.0', '73.4', '63.4', '46.9', '29.0', '63.9', '42.5', '77.7', '54.5', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', 'nan', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', 'nan', '0.0']
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: Precisions50: ['1.6', '2.0', '1.2', '1.1', '1.3', '1.9', '2.7', '2.3', '1.2', '1.9', '1.5', '2.0', '1.7', '2.3', '5.4', '1.2', '1.6', '1.3', '1.2', '1.2', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0']
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: Recall50: ['96.7', '73.9', '80.5', '79.9', '48.8', '89.4', '75.6', '94.3', '48.2', '93.5', '44.4', '94.8', '95.3', '82.5', '71.5', '72.7', '90.6', '81.5', '93.7', '82.2', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', 'nan', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', 'nan', '0.0']
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: Current class AP50: 53.59260222109053
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: Current class Precisions50: 1.8262987289104324
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: Current class Recall50: 79.5022107076468
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: Known AP50: 53.59260222109053
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: Known Precisions50: 1.8262987289104324
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: Known Recall50: 79.5022107076468
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: Unknown AP50: 0.0
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: Unknown Precisions50: 0
[03/07 20:16:30] d2.evaluation.pascal_voc_evaluation INFO: Unknown Recall50: 0
[03/07 20:16:30] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[03/07 20:16:30] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/07 20:16:30] d2.evaluation.testing INFO: copypaste: AP for all classes,AP50 for all classes
[03/07 20:16:30] d2.evaluation.testing INFO: copypaste: nan,nan
[03/07 20:16:30] d2.utils.events INFO:  iter: 54001     lr: N/A  max_mem: 1406M
[03/08 13:35:05] detectron2 INFO: Rank of current process: 0. World size: 2
[03/08 13:35:06] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/08 13:35:06] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=False)
[03/08 13:35:06] detectron2 INFO: Contents of args.config_file=configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/08 13:35:06] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: ./output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/08 13:35:06] detectron2 INFO: Full config saved to ./output/t1/config.yaml
[03/08 13:35:07] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/08 13:35:09] d2.data.build INFO: Valid classes: range(0, 20)
[03/08 13:35:09] d2.data.build INFO: Removing earlier seen class objects and the unknown objects...
[03/08 13:35:09] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |[0m
[03/08 13:35:09] d2.data.build INFO: Number of datapoints: 16551
[03/08 13:35:09] d2.data.build INFO: Using training sampler TrainingSampler
[03/08 13:35:09] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/08 13:35:09] d2.data.common INFO: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/08 13:35:09] d2.data.common INFO: Serialized dataset takes 7.81 MiB
[03/08 13:35:09] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[03/08 13:35:09] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/wxf/.torch/iopath_cache/detectron2/ImageNetPretrained/torchvision/R-50.pkl ...
[03/08 13:35:09] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[03/08 13:35:10] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[03/08 13:35:10] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mhead.head_series.0.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.0.class_logits.{bias, weight}[0m
[34mhead.head_series.0.cls_module.0.weight[0m
[34mhead.head_series.0.cls_module.1.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.0.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.0.linear1.{bias, weight}[0m
[34mhead.head_series.0.linear2.{bias, weight}[0m
[34mhead.head_series.0.norm1.{bias, weight}[0m
[34mhead.head_series.0.norm2.{bias, weight}[0m
[34mhead.head_series.0.norm3.{bias, weight}[0m
[34mhead.head_series.0.reg_module.0.weight[0m
[34mhead.head_series.0.reg_module.1.{bias, weight}[0m
[34mhead.head_series.0.reg_module.3.weight[0m
[34mhead.head_series.0.reg_module.4.{bias, weight}[0m
[34mhead.head_series.0.reg_module.6.weight[0m
[34mhead.head_series.0.reg_module.7.{bias, weight}[0m
[34mhead.head_series.0.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.1.bboxes_delta.{bias, weight}[0m
[34mhead.head_series.1.class_logits.{bias, weight}[0m
[34mhead.head_series.1.cls_module.0.weight[0m
[34mhead.head_series.1.cls_module.1.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.dynamic_layer.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm1.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm2.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.norm3.{bias, weight}[0m
[34mhead.head_series.1.inst_interact.out_layer.{bias, weight}[0m
[34mhead.head_series.1.linear1.{bias, weight}[0m
[34mhead.head_series.1.linear2.{bias, weight}[0m
[34mhead.head_series.1.norm1.{bias, weight}[0m
[34mhead.head_series.1.norm2.{bias, weight}[0m
[34mhead.head_series.1.norm3.{bias, weight}[0m
[34mhead.head_series.1.norm4.{bias, weight}[0m
[34mhead.head_series.1.reg_module.0.weight[0m
[34mhead.head_series.1.reg_module.1.{bias, weight}[0m
[34mhead.head_series.1.reg_module.3.weight[0m
[34mhead.head_series.1.reg_module.4.{bias, weight}[0m
[34mhead.head_series.1.reg_module.6.weight[0m
[34mhead.head_series.1.reg_module.7.{bias, weight}[0m
[34mhead.head_series.1.self_attn.out_proj.{bias, weight}[0m
[34mhead.head_series.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mhead.head_series.1.self_attn_post.out_proj.{bias, weight}[0m
[34mhead.head_series.1.self_attn_post.{in_proj_bias, in_proj_weight}[0m
[34mrpn_head.rpn_head.anchor_deltas.{bias, weight}[0m
[34mrpn_head.rpn_head.conv.{bias, weight}[0m
[34mrpn_head.rpn_head.objectness_logits.{bias, weight}[0m
[34mrpn_head.rpn_head.proposal_feats.{bias, weight}[0m
[34mrpn_head.rpn_head.scales.0.scale[0m
[34mrpn_head.rpn_head.scales.1.scale[0m
[34mrpn_head.rpn_head.scales.2.scale[0m
[34mrpn_head.rpn_head.scales.3.scale[0m
[34mrpn_head.rpn_head.scales.4.scale[0m
[03/08 13:35:10] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[03/08 13:35:10] d2.engine.train_loop INFO: Starting training from iteration 0
[03/08 13:35:23] d2.utils.events INFO:  eta: 8:41:17  iter: 19  total_loss: 19.47  loss_ce: 1.82  loss_giou: 2.076  loss_bbox: 4.236  loss_ce_0: 1.837  loss_giou_0: 2.08  loss_bbox_0: 4.232  loss_rpn_cls: 1.133  loss_rpn_reg: 1.999  time: 0.5863  last_time: 0.5689  data_time: 0.1144  last_data_time: 0.0167   lr: 5.2025e-06  max_mem: 4604M
[03/08 13:35:32] d2.utils.events INFO:  eta: 8:34:48  iter: 39  total_loss: 18.52  loss_ce: 1.486  loss_giou: 2.074  loss_bbox: 4.011  loss_ce_0: 1.519  loss_giou_0: 2.072  loss_bbox_0: 4.139  loss_rpn_cls: 1.131  loss_rpn_reg: 2  time: 0.5145  last_time: 0.3123  data_time: 0.0104  last_data_time: 0.0071   lr: 1.0152e-05  max_mem: 4724M
[03/08 13:35:39] d2.utils.events INFO:  eta: 6:03:13  iter: 59  total_loss: 17.27  loss_ce: 1.46  loss_giou: 2.202  loss_bbox: 2.73  loss_ce_0: 1.389  loss_giou_0: 2.099  loss_bbox_0: 4.152  loss_rpn_cls: 1.126  loss_rpn_reg: 1.999  time: 0.4482  last_time: 0.2829  data_time: 0.0099  last_data_time: 0.0086   lr: 1.5102e-05  max_mem: 4724M
[03/08 13:35:46] d2.utils.events INFO:  eta: 4:53:30  iter: 79  total_loss: 15.01  loss_ce: 1.43  loss_giou: 1.717  loss_bbox: 2.17  loss_ce_0: 1.357  loss_giou_0: 2.153  loss_bbox_0: 2.97  loss_rpn_cls: 1.117  loss_rpn_reg: 1.999  time: 0.4169  last_time: 0.2753  data_time: 0.0111  last_data_time: 0.0127   lr: 2.0053e-05  max_mem: 4724M
[03/08 13:35:52] d2.utils.events INFO:  eta: 4:50:01  iter: 99  total_loss: 12.61  loss_ce: 1.586  loss_giou: 1.487  loss_bbox: 1.815  loss_ce_0: 1.514  loss_giou_0: 1.507  loss_bbox_0: 1.818  loss_rpn_cls: 1.089  loss_rpn_reg: 1.997  time: 0.3992  last_time: 0.2989  data_time: 0.0111  last_data_time: 0.0091   lr: 2.5002e-05  max_mem: 4724M
[03/08 13:35:59] d2.utils.events INFO:  eta: 4:48:02  iter: 119  total_loss: 12.09  loss_ce: 1.507  loss_giou: 1.401  loss_bbox: 1.735  loss_ce_0: 1.431  loss_giou_0: 1.317  loss_bbox_0: 1.627  loss_rpn_cls: 1.051  loss_rpn_reg: 1.99  time: 0.3871  last_time: 0.2934  data_time: 0.0093  last_data_time: 0.0079   lr: 2.9953e-05  max_mem: 4724M
[03/08 13:36:06] d2.utils.events INFO:  eta: 4:46:54  iter: 139  total_loss: 11.68  loss_ce: 1.492  loss_giou: 1.208  loss_bbox: 1.795  loss_ce_0: 1.455  loss_giou_0: 1.183  loss_bbox_0: 1.752  loss_rpn_cls: 0.8883  loss_rpn_reg: 1.859  time: 0.3783  last_time: 0.4299  data_time: 0.0101  last_data_time: 0.0111   lr: 3.4902e-05  max_mem: 4724M
[03/08 13:36:12] d2.utils.events INFO:  eta: 4:43:37  iter: 159  total_loss: 11.1  loss_ce: 1.555  loss_giou: 1.36  loss_bbox: 1.797  loss_ce_0: 1.589  loss_giou_0: 1.309  loss_bbox_0: 1.818  loss_rpn_cls: 0.4942  loss_rpn_reg: 1.225  time: 0.3710  last_time: 0.2783  data_time: 0.0100  last_data_time: 0.0073   lr: 3.9852e-05  max_mem: 4724M
[03/08 13:36:19] d2.utils.events INFO:  eta: 4:44:45  iter: 179  total_loss: 10.34  loss_ce: 1.516  loss_giou: 1.186  loss_bbox: 1.663  loss_ce_0: 1.568  loss_giou_0: 1.171  loss_bbox_0: 1.575  loss_rpn_cls: 0.4905  loss_rpn_reg: 1.147  time: 0.3674  last_time: 0.4284  data_time: 0.0105  last_data_time: 0.0080   lr: 4.4802e-05  max_mem: 4724M
[03/08 13:36:25] d2.utils.events INFO:  eta: 4:41:28  iter: 199  total_loss: 9.288  loss_ce: 1.398  loss_giou: 1.172  loss_bbox: 1.423  loss_ce_0: 1.411  loss_giou_0: 1.115  loss_bbox_0: 1.214  loss_rpn_cls: 0.476  loss_rpn_reg: 0.9993  time: 0.3627  last_time: 0.4318  data_time: 0.0112  last_data_time: 0.0027   lr: 4.9752e-05  max_mem: 4724M
[03/08 13:36:32] d2.utils.events INFO:  eta: 4:42:02  iter: 219  total_loss: 9.359  loss_ce: 1.469  loss_giou: 1.151  loss_bbox: 1.511  loss_ce_0: 1.46  loss_giou_0: 1.011  loss_bbox_0: 1.332  loss_rpn_cls: 0.4408  loss_rpn_reg: 0.9651  time: 0.3604  last_time: 0.4668  data_time: 0.0111  last_data_time: 0.0207   lr: 5e-05  max_mem: 4724M
[03/08 13:36:38] d2.utils.events INFO:  eta: 4:41:04  iter: 239  total_loss: 9.148  loss_ce: 1.374  loss_giou: 1.116  loss_bbox: 1.472  loss_ce_0: 1.383  loss_giou_0: 1.047  loss_bbox_0: 1.24  loss_rpn_cls: 0.5163  loss_rpn_reg: 0.9213  time: 0.3555  last_time: 0.2851  data_time: 0.0102  last_data_time: 0.0105   lr: 5e-05  max_mem: 4724M
[03/08 13:36:45] d2.utils.events INFO:  eta: 4:40:30  iter: 259  total_loss: 8.667  loss_ce: 1.356  loss_giou: 1.15  loss_bbox: 1.191  loss_ce_0: 1.298  loss_giou_0: 1.055  loss_bbox_0: 1.136  loss_rpn_cls: 0.4984  loss_rpn_reg: 0.8651  time: 0.3539  last_time: 0.3053  data_time: 0.0113  last_data_time: 0.0080   lr: 5e-05  max_mem: 4724M
[03/08 13:36:52] d2.utils.events INFO:  eta: 4:40:24  iter: 279  total_loss: 8.385  loss_ce: 1.324  loss_giou: 1.049  loss_bbox: 1.212  loss_ce_0: 1.282  loss_giou_0: 0.9618  loss_bbox_0: 1.103  loss_rpn_cls: 0.5126  loss_rpn_reg: 0.8858  time: 0.3528  last_time: 0.4211  data_time: 0.0105  last_data_time: 0.0098   lr: 5e-05  max_mem: 4724M
[03/08 13:36:58] d2.utils.events INFO:  eta: 4:39:28  iter: 299  total_loss: 8.093  loss_ce: 1.392  loss_giou: 0.8922  loss_bbox: 1.128  loss_ce_0: 1.342  loss_giou_0: 0.902  loss_bbox_0: 1.059  loss_rpn_cls: 0.5018  loss_rpn_reg: 0.8752  time: 0.3506  last_time: 0.3048  data_time: 0.0104  last_data_time: 0.0124   lr: 5e-05  max_mem: 4724M
[03/08 13:37:05] d2.utils.events INFO:  eta: 4:39:08  iter: 319  total_loss: 8.074  loss_ce: 1.353  loss_giou: 0.9629  loss_bbox: 1.116  loss_ce_0: 1.278  loss_giou_0: 0.9052  loss_bbox_0: 1.073  loss_rpn_cls: 0.4947  loss_rpn_reg: 0.8319  time: 0.3495  last_time: 0.3083  data_time: 0.0106  last_data_time: 0.0163   lr: 5e-05  max_mem: 4724M
[03/08 13:37:12] d2.utils.events INFO:  eta: 4:38:47  iter: 339  total_loss: 8.144  loss_ce: 1.411  loss_giou: 0.9569  loss_bbox: 1.151  loss_ce_0: 1.334  loss_giou_0: 1.004  loss_bbox_0: 1.041  loss_rpn_cls: 0.4958  loss_rpn_reg: 0.8115  time: 0.3482  last_time: 0.3162  data_time: 0.0098  last_data_time: 0.0084   lr: 5e-05  max_mem: 4724M
[03/08 13:37:19] d2.utils.events INFO:  eta: 4:39:32  iter: 359  total_loss: 7.944  loss_ce: 1.337  loss_giou: 1.115  loss_bbox: 1.105  loss_ce_0: 1.26  loss_giou_0: 1.005  loss_bbox_0: 0.9921  loss_rpn_cls: 0.5155  loss_rpn_reg: 0.8226  time: 0.3472  last_time: 0.3223  data_time: 0.0117  last_data_time: 0.0148   lr: 5e-05  max_mem: 4724M
[03/08 13:37:25] d2.utils.events INFO:  eta: 4:39:10  iter: 379  total_loss: 7.668  loss_ce: 1.347  loss_giou: 0.8664  loss_bbox: 1.025  loss_ce_0: 1.284  loss_giou_0: 0.8301  loss_bbox_0: 0.9987  loss_rpn_cls: 0.4786  loss_rpn_reg: 0.765  time: 0.3471  last_time: 0.3170  data_time: 0.0103  last_data_time: 0.0077   lr: 5e-05  max_mem: 4724M
[03/08 13:37:32] d2.utils.events INFO:  eta: 4:38:43  iter: 399  total_loss: 7.353  loss_ce: 1.303  loss_giou: 0.8891  loss_bbox: 0.9745  loss_ce_0: 1.298  loss_giou_0: 0.8469  loss_bbox_0: 0.8935  loss_rpn_cls: 0.5089  loss_rpn_reg: 0.7798  time: 0.3463  last_time: 0.4432  data_time: 0.0109  last_data_time: 0.0072   lr: 5e-05  max_mem: 4724M
[03/08 13:37:39] d2.utils.events INFO:  eta: 4:38:37  iter: 419  total_loss: 7.395  loss_ce: 1.35  loss_giou: 0.905  loss_bbox: 1.034  loss_ce_0: 1.29  loss_giou_0: 0.7879  loss_bbox_0: 0.8495  loss_rpn_cls: 0.4846  loss_rpn_reg: 0.7574  time: 0.3456  last_time: 0.2801  data_time: 0.0112  last_data_time: 0.0063   lr: 5e-05  max_mem: 4724M
[03/08 13:37:45] d2.utils.events INFO:  eta: 4:38:16  iter: 439  total_loss: 7.421  loss_ce: 1.284  loss_giou: 0.8824  loss_bbox: 1.01  loss_ce_0: 1.235  loss_giou_0: 0.8452  loss_bbox_0: 0.9941  loss_rpn_cls: 0.4628  loss_rpn_reg: 0.7637  time: 0.3441  last_time: 0.3075  data_time: 0.0098  last_data_time: 0.0088   lr: 5e-05  max_mem: 4724M
[03/08 13:37:52] d2.utils.events INFO:  eta: 4:37:54  iter: 459  total_loss: 7.553  loss_ce: 1.277  loss_giou: 1.007  loss_bbox: 0.9908  loss_ce_0: 1.228  loss_giou_0: 0.9257  loss_bbox_0: 0.9021  loss_rpn_cls: 0.5093  loss_rpn_reg: 0.7802  time: 0.3429  last_time: 0.3053  data_time: 0.0100  last_data_time: 0.0105   lr: 5e-05  max_mem: 4724M
[03/08 13:37:58] d2.utils.events INFO:  eta: 4:37:26  iter: 479  total_loss: 7.413  loss_ce: 1.253  loss_giou: 0.9468  loss_bbox: 1.025  loss_ce_0: 1.158  loss_giou_0: 0.9026  loss_bbox_0: 0.8753  loss_rpn_cls: 0.4716  loss_rpn_reg: 0.7711  time: 0.3420  last_time: 0.4215  data_time: 0.0087  last_data_time: 0.0072   lr: 5e-05  max_mem: 4724M
[03/08 13:38:05] d2.utils.events INFO:  eta: 4:36:42  iter: 499  total_loss: 7.382  loss_ce: 1.277  loss_giou: 0.8492  loss_bbox: 0.9244  loss_ce_0: 1.193  loss_giou_0: 0.8346  loss_bbox_0: 0.869  loss_rpn_cls: 0.4706  loss_rpn_reg: 0.7938  time: 0.3416  last_time: 0.3242  data_time: 0.0106  last_data_time: 0.0135   lr: 5e-05  max_mem: 4724M
[03/08 13:38:12] d2.utils.events INFO:  eta: 4:36:51  iter: 519  total_loss: 7.393  loss_ce: 1.231  loss_giou: 0.8451  loss_bbox: 0.9289  loss_ce_0: 1.177  loss_giou_0: 0.8283  loss_bbox_0: 0.9608  loss_rpn_cls: 0.4456  loss_rpn_reg: 0.787  time: 0.3419  last_time: 0.3003  data_time: 0.0101  last_data_time: 0.0086   lr: 5e-05  max_mem: 4724M
[03/08 13:38:19] d2.utils.events INFO:  eta: 4:36:56  iter: 539  total_loss: 7.475  loss_ce: 1.242  loss_giou: 0.8285  loss_bbox: 1.065  loss_ce_0: 1.172  loss_giou_0: 0.8325  loss_bbox_0: 0.9634  loss_rpn_cls: 0.4779  loss_rpn_reg: 0.7653  time: 0.3414  last_time: 0.3221  data_time: 0.0110  last_data_time: 0.0044   lr: 5e-05  max_mem: 4724M
[03/08 13:38:26] d2.utils.events INFO:  eta: 4:37:01  iter: 559  total_loss: 7.358  loss_ce: 1.278  loss_giou: 0.8816  loss_bbox: 1.044  loss_ce_0: 1.192  loss_giou_0: 0.8099  loss_bbox_0: 0.9509  loss_rpn_cls: 0.4749  loss_rpn_reg: 0.7308  time: 0.3417  last_time: 0.3156  data_time: 0.0112  last_data_time: 0.0076   lr: 5e-05  max_mem: 4724M
[03/08 13:38:32] d2.utils.events INFO:  eta: 4:36:55  iter: 579  total_loss: 7.207  loss_ce: 1.235  loss_giou: 0.9749  loss_bbox: 0.963  loss_ce_0: 1.167  loss_giou_0: 0.8505  loss_bbox_0: 0.881  loss_rpn_cls: 0.4763  loss_rpn_reg: 0.7804  time: 0.3414  last_time: 0.2985  data_time: 0.0114  last_data_time: 0.0081   lr: 5e-05  max_mem: 4724M
[03/08 13:38:39] d2.utils.events INFO:  eta: 4:35:51  iter: 599  total_loss: 7.03  loss_ce: 1.201  loss_giou: 0.8729  loss_bbox: 0.9902  loss_ce_0: 1.113  loss_giou_0: 0.8746  loss_bbox_0: 0.9306  loss_rpn_cls: 0.4865  loss_rpn_reg: 0.7467  time: 0.3406  last_time: 0.3099  data_time: 0.0103  last_data_time: 0.0077   lr: 5e-05  max_mem: 4724M
[03/08 13:38:46] d2.utils.events INFO:  eta: 4:36:05  iter: 619  total_loss: 7.169  loss_ce: 1.18  loss_giou: 0.9624  loss_bbox: 0.9431  loss_ce_0: 1.128  loss_giou_0: 0.9047  loss_bbox_0: 0.8824  loss_rpn_cls: 0.4663  loss_rpn_reg: 0.7967  time: 0.3408  last_time: 0.3066  data_time: 0.0099  last_data_time: 0.0075   lr: 5e-05  max_mem: 4724M
[03/08 13:38:52] d2.utils.events INFO:  eta: 4:35:37  iter: 639  total_loss: 7.07  loss_ce: 1.154  loss_giou: 0.8925  loss_bbox: 0.8724  loss_ce_0: 1.098  loss_giou_0: 0.8654  loss_bbox_0: 0.8721  loss_rpn_cls: 0.4857  loss_rpn_reg: 0.7575  time: 0.3402  last_time: 0.2706  data_time: 0.0095  last_data_time: 0.0076   lr: 5e-05  max_mem: 4724M
[03/08 13:38:59] d2.utils.events INFO:  eta: 4:35:50  iter: 659  total_loss: 6.627  loss_ce: 1.194  loss_giou: 0.8146  loss_bbox: 0.8705  loss_ce_0: 1.112  loss_giou_0: 0.8087  loss_bbox_0: 0.7587  loss_rpn_cls: 0.4737  loss_rpn_reg: 0.6982  time: 0.3398  last_time: 0.3164  data_time: 0.0115  last_data_time: 0.0070   lr: 5e-05  max_mem: 4724M
[03/08 13:39:05] d2.utils.events INFO:  eta: 4:35:26  iter: 679  total_loss: 6.956  loss_ce: 1.155  loss_giou: 0.8853  loss_bbox: 0.9281  loss_ce_0: 1.103  loss_giou_0: 0.8244  loss_bbox_0: 0.8999  loss_rpn_cls: 0.4904  loss_rpn_reg: 0.7458  time: 0.3391  last_time: 0.3149  data_time: 0.0113  last_data_time: 0.0151   lr: 5e-05  max_mem: 4724M
[03/08 13:39:12] d2.utils.events INFO:  eta: 4:35:18  iter: 699  total_loss: 6.861  loss_ce: 1.175  loss_giou: 0.816  loss_bbox: 0.8983  loss_ce_0: 1.079  loss_giou_0: 0.8022  loss_bbox_0: 0.8941  loss_rpn_cls: 0.48  loss_rpn_reg: 0.7288  time: 0.3389  last_time: 0.3097  data_time: 0.0112  last_data_time: 0.0114   lr: 5e-05  max_mem: 4724M
[03/08 13:39:19] d2.utils.events INFO:  eta: 4:35:31  iter: 719  total_loss: 6.716  loss_ce: 1.167  loss_giou: 0.8108  loss_bbox: 0.8237  loss_ce_0: 1.091  loss_giou_0: 0.8009  loss_bbox_0: 0.8307  loss_rpn_cls: 0.5079  loss_rpn_reg: 0.7346  time: 0.3388  last_time: 0.3168  data_time: 0.0117  last_data_time: 0.0071   lr: 5e-05  max_mem: 4724M
[03/08 13:39:26] d2.utils.events INFO:  eta: 4:36:24  iter: 739  total_loss: 7.048  loss_ce: 1.193  loss_giou: 0.8144  loss_bbox: 0.877  loss_ce_0: 1.127  loss_giou_0: 0.8075  loss_bbox_0: 0.8666  loss_rpn_cls: 0.4811  loss_rpn_reg: 0.7172  time: 0.3395  last_time: 0.2813  data_time: 0.0107  last_data_time: 0.0112   lr: 5e-05  max_mem: 4724M
[03/08 13:39:33] d2.utils.events INFO:  eta: 4:36:20  iter: 759  total_loss: 6.637  loss_ce: 1.221  loss_giou: 0.7921  loss_bbox: 0.8352  loss_ce_0: 1.115  loss_giou_0: 0.8084  loss_bbox_0: 0.8174  loss_rpn_cls: 0.4671  loss_rpn_reg: 0.7347  time: 0.3395  last_time: 0.2745  data_time: 0.0104  last_data_time: 0.0205   lr: 5e-05  max_mem: 4724M
[03/08 13:39:39] d2.utils.events INFO:  eta: 4:36:11  iter: 779  total_loss: 6.526  loss_ce: 1.139  loss_giou: 0.7387  loss_bbox: 0.8503  loss_ce_0: 1.101  loss_giou_0: 0.7088  loss_bbox_0: 0.8423  loss_rpn_cls: 0.4571  loss_rpn_reg: 0.6331  time: 0.3388  last_time: 0.3189  data_time: 0.0105  last_data_time: 0.0085   lr: 5e-05  max_mem: 4724M
[03/08 13:39:46] d2.utils.events INFO:  eta: 4:36:18  iter: 799  total_loss: 6.315  loss_ce: 1.055  loss_giou: 0.7805  loss_bbox: 0.771  loss_ce_0: 1.014  loss_giou_0: 0.7451  loss_bbox_0: 0.7654  loss_rpn_cls: 0.4702  loss_rpn_reg: 0.6974  time: 0.3390  last_time: 0.3215  data_time: 0.0111  last_data_time: 0.0114   lr: 5e-05  max_mem: 4724M
[03/08 13:39:53] d2.utils.events INFO:  eta: 4:36:09  iter: 819  total_loss: 6.401  loss_ce: 1.143  loss_giou: 0.7781  loss_bbox: 0.7699  loss_ce_0: 1.112  loss_giou_0: 0.7911  loss_bbox_0: 0.7442  loss_rpn_cls: 0.484  loss_rpn_reg: 0.706  time: 0.3389  last_time: 0.2813  data_time: 0.0101  last_data_time: 0.0075   lr: 5e-05  max_mem: 4724M
[03/08 13:40:00] d2.utils.events INFO:  eta: 4:35:56  iter: 839  total_loss: 6.705  loss_ce: 1.127  loss_giou: 0.807  loss_bbox: 0.8069  loss_ce_0: 1.091  loss_giou_0: 0.8075  loss_bbox_0: 0.7858  loss_rpn_cls: 0.5148  loss_rpn_reg: 0.7229  time: 0.3384  last_time: 0.2981  data_time: 0.0106  last_data_time: 0.0112   lr: 5e-05  max_mem: 4724M
[03/08 13:40:07] d2.utils.events INFO:  eta: 4:35:50  iter: 859  total_loss: 6.387  loss_ce: 1.165  loss_giou: 0.6895  loss_bbox: 0.7568  loss_ce_0: 1.1  loss_giou_0: 0.6818  loss_bbox_0: 0.7811  loss_rpn_cls: 0.4727  loss_rpn_reg: 0.6785  time: 0.3387  last_time: 0.2953  data_time: 0.0106  last_data_time: 0.0082   lr: 5e-05  max_mem: 4724M
[03/08 13:40:13] d2.utils.events INFO:  eta: 4:35:42  iter: 879  total_loss: 6.857  loss_ce: 1.137  loss_giou: 0.9014  loss_bbox: 0.8214  loss_ce_0: 1.1  loss_giou_0: 0.926  loss_bbox_0: 0.8294  loss_rpn_cls: 0.5125  loss_rpn_reg: 0.6931  time: 0.3379  last_time: 0.3145  data_time: 0.0111  last_data_time: 0.0117   lr: 5e-05  max_mem: 4724M
[03/08 13:40:20] d2.utils.events INFO:  eta: 4:35:37  iter: 899  total_loss: 6.868  loss_ce: 1.164  loss_giou: 0.833  loss_bbox: 0.8679  loss_ce_0: 1.109  loss_giou_0: 0.8417  loss_bbox_0: 0.8408  loss_rpn_cls: 0.5  loss_rpn_reg: 0.6946  time: 0.3378  last_time: 0.3242  data_time: 0.0114  last_data_time: 0.0074   lr: 5e-05  max_mem: 4724M
[03/08 13:40:27] d2.utils.events INFO:  eta: 4:35:38  iter: 919  total_loss: 6.725  loss_ce: 1.124  loss_giou: 0.7825  loss_bbox: 0.8612  loss_ce_0: 1.096  loss_giou_0: 0.7558  loss_bbox_0: 0.8176  loss_rpn_cls: 0.4692  loss_rpn_reg: 0.6864  time: 0.3379  last_time: 0.2900  data_time: 0.0101  last_data_time: 0.0086   lr: 5e-05  max_mem: 4724M
[03/08 13:40:34] d2.utils.events INFO:  eta: 4:35:37  iter: 939  total_loss: 6.656  loss_ce: 1.109  loss_giou: 0.7826  loss_bbox: 0.8685  loss_ce_0: 1.038  loss_giou_0: 0.7356  loss_bbox_0: 0.8199  loss_rpn_cls: 0.4542  loss_rpn_reg: 0.7026  time: 0.3382  last_time: 0.3021  data_time: 0.0115  last_data_time: 0.0121   lr: 5e-05  max_mem: 4724M
[03/08 13:40:40] d2.utils.events INFO:  eta: 4:35:31  iter: 959  total_loss: 6.183  loss_ce: 1.104  loss_giou: 0.7393  loss_bbox: 0.7634  loss_ce_0: 1.017  loss_giou_0: 0.7523  loss_bbox_0: 0.7442  loss_rpn_cls: 0.4503  loss_rpn_reg: 0.6849  time: 0.3381  last_time: 0.4390  data_time: 0.0128  last_data_time: 0.0227   lr: 5e-05  max_mem: 4724M
[03/08 13:40:47] d2.utils.events INFO:  eta: 4:35:14  iter: 979  total_loss: 6.78  loss_ce: 1.043  loss_giou: 0.8333  loss_bbox: 0.8909  loss_ce_0: 1.062  loss_giou_0: 0.7964  loss_bbox_0: 0.8173  loss_rpn_cls: 0.4748  loss_rpn_reg: 0.7229  time: 0.3375  last_time: 0.2810  data_time: 0.0101  last_data_time: 0.0074   lr: 5e-05  max_mem: 4724M
[03/08 13:40:53] d2.utils.events INFO:  eta: 4:35:03  iter: 999  total_loss: 6.253  loss_ce: 1.086  loss_giou: 0.7718  loss_bbox: 0.7505  loss_ce_0: 1.035  loss_giou_0: 0.7656  loss_bbox_0: 0.7638  loss_rpn_cls: 0.485  loss_rpn_reg: 0.6874  time: 0.3372  last_time: 0.3169  data_time: 0.0095  last_data_time: 0.0067   lr: 5e-05  max_mem: 4724M
[03/08 13:41:00] d2.utils.events INFO:  eta: 4:33:49  iter: 1019  total_loss: 6.075  loss_ce: 1.147  loss_giou: 0.7166  loss_bbox: 0.7665  loss_ce_0: 1.126  loss_giou_0: 0.7225  loss_bbox_0: 0.6994  loss_rpn_cls: 0.4654  loss_rpn_reg: 0.6371  time: 0.3368  last_time: 0.2912  data_time: 0.0100  last_data_time: 0.0047   lr: 5e-05  max_mem: 4724M
[03/08 13:41:07] d2.utils.events INFO:  eta: 4:33:19  iter: 1039  total_loss: 6.267  loss_ce: 1.158  loss_giou: 0.7583  loss_bbox: 0.7943  loss_ce_0: 1.109  loss_giou_0: 0.7413  loss_bbox_0: 0.7307  loss_rpn_cls: 0.4566  loss_rpn_reg: 0.6824  time: 0.3369  last_time: 0.3348  data_time: 0.0104  last_data_time: 0.0089   lr: 5e-05  max_mem: 4724M
[03/08 13:41:13] d2.utils.events INFO:  eta: 4:33:08  iter: 1059  total_loss: 6.398  loss_ce: 1.149  loss_giou: 0.7899  loss_bbox: 0.7921  loss_ce_0: 1.056  loss_giou_0: 0.7573  loss_bbox_0: 0.7403  loss_rpn_cls: 0.4455  loss_rpn_reg: 0.6785  time: 0.3369  last_time: 0.2842  data_time: 0.0126  last_data_time: 0.0189   lr: 5e-05  max_mem: 4724M
[03/08 13:41:20] d2.utils.events INFO:  eta: 4:32:33  iter: 1079  total_loss: 5.932  loss_ce: 1.069  loss_giou: 0.7286  loss_bbox: 0.715  loss_ce_0: 1.002  loss_giou_0: 0.7407  loss_bbox_0: 0.6975  loss_rpn_cls: 0.448  loss_rpn_reg: 0.6643  time: 0.3365  last_time: 0.2921  data_time: 0.0109  last_data_time: 0.0174   lr: 5e-05  max_mem: 4724M
[03/08 13:41:26] d2.utils.events INFO:  eta: 4:32:23  iter: 1099  total_loss: 5.902  loss_ce: 1.014  loss_giou: 0.685  loss_bbox: 0.708  loss_ce_0: 0.9515  loss_giou_0: 0.6829  loss_bbox_0: 0.7069  loss_rpn_cls: 0.4419  loss_rpn_reg: 0.6645  time: 0.3364  last_time: 0.2741  data_time: 0.0105  last_data_time: 0.0065   lr: 5e-05  max_mem: 4724M
[03/08 13:41:33] d2.utils.events INFO:  eta: 4:32:04  iter: 1119  total_loss: 6.006  loss_ce: 1.048  loss_giou: 0.7124  loss_bbox: 0.696  loss_ce_0: 0.9727  loss_giou_0: 0.7102  loss_bbox_0: 0.6855  loss_rpn_cls: 0.4623  loss_rpn_reg: 0.6649  time: 0.3362  last_time: 0.2688  data_time: 0.0093  last_data_time: 0.0170   lr: 5e-05  max_mem: 4724M
[03/08 13:41:39] d2.utils.events INFO:  eta: 4:31:58  iter: 1139  total_loss: 5.974  loss_ce: 0.9861  loss_giou: 0.7624  loss_bbox: 0.7519  loss_ce_0: 0.983  loss_giou_0: 0.7381  loss_bbox_0: 0.699  loss_rpn_cls: 0.4656  loss_rpn_reg: 0.6764  time: 0.3358  last_time: 0.2837  data_time: 0.0119  last_data_time: 0.0088   lr: 5e-05  max_mem: 4724M
[03/08 13:41:46] d2.utils.events INFO:  eta: 4:32:08  iter: 1159  total_loss: 6.269  loss_ce: 1.033  loss_giou: 0.7196  loss_bbox: 0.7102  loss_ce_0: 0.9739  loss_giou_0: 0.6889  loss_bbox_0: 0.6956  loss_rpn_cls: 0.4602  loss_rpn_reg: 0.661  time: 0.3358  last_time: 0.4061  data_time: 0.0116  last_data_time: 0.0113   lr: 5e-05  max_mem: 4724M
[03/08 13:41:53] d2.utils.events INFO:  eta: 4:31:50  iter: 1179  total_loss: 6.484  loss_ce: 1.053  loss_giou: 0.8621  loss_bbox: 0.8025  loss_ce_0: 0.9908  loss_giou_0: 0.8552  loss_bbox_0: 0.8109  loss_rpn_cls: 0.4789  loss_rpn_reg: 0.7338  time: 0.3355  last_time: 0.3284  data_time: 0.0099  last_data_time: 0.0085   lr: 5e-05  max_mem: 4724M
[03/08 13:42:00] d2.utils.events INFO:  eta: 4:31:58  iter: 1199  total_loss: 5.954  loss_ce: 1.037  loss_giou: 0.603  loss_bbox: 0.67  loss_ce_0: 0.9974  loss_giou_0: 0.6385  loss_bbox_0: 0.7004  loss_rpn_cls: 0.4375  loss_rpn_reg: 0.682  time: 0.3355  last_time: 0.3290  data_time: 0.0097  last_data_time: 0.0103   lr: 5e-05  max_mem: 4724M
[03/08 13:42:07] d2.utils.events INFO:  eta: 4:31:43  iter: 1219  total_loss: 5.856  loss_ce: 1.047  loss_giou: 0.6549  loss_bbox: 0.6487  loss_ce_0: 0.9744  loss_giou_0: 0.6734  loss_bbox_0: 0.7036  loss_rpn_cls: 0.433  loss_rpn_reg: 0.6721  time: 0.3358  last_time: 0.2952  data_time: 0.0101  last_data_time: 0.0156   lr: 5e-05  max_mem: 4724M
[03/08 13:42:13] d2.utils.events INFO:  eta: 4:32:00  iter: 1239  total_loss: 5.916  loss_ce: 1.081  loss_giou: 0.6815  loss_bbox: 0.6408  loss_ce_0: 1.003  loss_giou_0: 0.6911  loss_bbox_0: 0.6747  loss_rpn_cls: 0.4414  loss_rpn_reg: 0.6496  time: 0.3356  last_time: 0.3288  data_time: 0.0115  last_data_time: 0.0015   lr: 5e-05  max_mem: 4724M
[03/08 13:42:20] d2.utils.events INFO:  eta: 4:32:22  iter: 1259  total_loss: 5.671  loss_ce: 1.01  loss_giou: 0.6935  loss_bbox: 0.6403  loss_ce_0: 0.9991  loss_giou_0: 0.6852  loss_bbox_0: 0.6483  loss_rpn_cls: 0.4451  loss_rpn_reg: 0.6285  time: 0.3356  last_time: 0.2790  data_time: 0.0109  last_data_time: 0.0077   lr: 5e-05  max_mem: 4724M
[03/08 13:42:27] d2.utils.events INFO:  eta: 4:32:23  iter: 1279  total_loss: 5.997  loss_ce: 0.9894  loss_giou: 0.6611  loss_bbox: 0.759  loss_ce_0: 0.933  loss_giou_0: 0.6884  loss_bbox_0: 0.7197  loss_rpn_cls: 0.4138  loss_rpn_reg: 0.6576  time: 0.3357  last_time: 0.3222  data_time: 0.0116  last_data_time: 0.0133   lr: 5e-05  max_mem: 4724M
[03/08 13:42:34] d2.utils.events INFO:  eta: 4:32:42  iter: 1299  total_loss: 5.821  loss_ce: 0.9865  loss_giou: 0.7795  loss_bbox: 0.6539  loss_ce_0: 0.9167  loss_giou_0: 0.7508  loss_bbox_0: 0.6427  loss_rpn_cls: 0.4381  loss_rpn_reg: 0.6772  time: 0.3358  last_time: 0.3382  data_time: 0.0125  last_data_time: 0.0093   lr: 5e-05  max_mem: 4724M
[03/08 13:42:41] d2.utils.events INFO:  eta: 4:32:49  iter: 1319  total_loss: 6.015  loss_ce: 0.9908  loss_giou: 0.689  loss_bbox: 0.7143  loss_ce_0: 0.9176  loss_giou_0: 0.69  loss_bbox_0: 0.6932  loss_rpn_cls: 0.4333  loss_rpn_reg: 0.645  time: 0.3357  last_time: 0.4206  data_time: 0.0103  last_data_time: 0.0098   lr: 5e-05  max_mem: 4724M
[03/08 13:42:47] d2.utils.events INFO:  eta: 4:32:51  iter: 1339  total_loss: 5.724  loss_ce: 1.014  loss_giou: 0.6393  loss_bbox: 0.6571  loss_ce_0: 0.9533  loss_giou_0: 0.6555  loss_bbox_0: 0.6916  loss_rpn_cls: 0.4244  loss_rpn_reg: 0.6606  time: 0.3358  last_time: 0.3209  data_time: 0.0139  last_data_time: 0.0096   lr: 5e-05  max_mem: 4724M
[03/08 13:42:54] d2.utils.events INFO:  eta: 4:32:37  iter: 1359  total_loss: 5.459  loss_ce: 1.002  loss_giou: 0.649  loss_bbox: 0.6199  loss_ce_0: 0.9494  loss_giou_0: 0.6526  loss_bbox_0: 0.6467  loss_rpn_cls: 0.4177  loss_rpn_reg: 0.6566  time: 0.3356  last_time: 0.3296  data_time: 0.0120  last_data_time: 0.0187   lr: 5e-05  max_mem: 4724M
[03/08 13:43:01] d2.utils.events INFO:  eta: 4:32:37  iter: 1379  total_loss: 5.885  loss_ce: 1.005  loss_giou: 0.7301  loss_bbox: 0.7283  loss_ce_0: 0.9328  loss_giou_0: 0.7303  loss_bbox_0: 0.7467  loss_rpn_cls: 0.4161  loss_rpn_reg: 0.6763  time: 0.3356  last_time: 0.3154  data_time: 0.0112  last_data_time: 0.0094   lr: 5e-05  max_mem: 4724M
[03/08 13:43:07] d2.utils.events INFO:  eta: 4:32:32  iter: 1399  total_loss: 5.638  loss_ce: 1.003  loss_giou: 0.6153  loss_bbox: 0.6696  loss_ce_0: 0.9401  loss_giou_0: 0.6113  loss_bbox_0: 0.6847  loss_rpn_cls: 0.4275  loss_rpn_reg: 0.6352  time: 0.3354  last_time: 0.3021  data_time: 0.0135  last_data_time: 0.0229   lr: 5e-05  max_mem: 4724M
[03/08 13:43:14] d2.utils.events INFO:  eta: 4:32:29  iter: 1419  total_loss: 5.488  loss_ce: 0.9983  loss_giou: 0.6657  loss_bbox: 0.6067  loss_ce_0: 0.9037  loss_giou_0: 0.657  loss_bbox_0: 0.6104  loss_rpn_cls: 0.4049  loss_rpn_reg: 0.6782  time: 0.3354  last_time: 0.2845  data_time: 0.0118  last_data_time: 0.0084   lr: 5e-05  max_mem: 4724M
[03/08 13:43:21] d2.utils.events INFO:  eta: 4:32:41  iter: 1439  total_loss: 5.461  loss_ce: 0.9783  loss_giou: 0.655  loss_bbox: 0.6132  loss_ce_0: 0.9339  loss_giou_0: 0.664  loss_bbox_0: 0.6303  loss_rpn_cls: 0.4002  loss_rpn_reg: 0.6905  time: 0.3356  last_time: 0.4370  data_time: 0.0125  last_data_time: 0.0190   lr: 5e-05  max_mem: 4724M
[03/08 13:43:28] d2.utils.events INFO:  eta: 4:32:51  iter: 1459  total_loss: 5.755  loss_ce: 1.001  loss_giou: 0.6655  loss_bbox: 0.6562  loss_ce_0: 0.951  loss_giou_0: 0.6718  loss_bbox_0: 0.6721  loss_rpn_cls: 0.4126  loss_rpn_reg: 0.6548  time: 0.3355  last_time: 0.3412  data_time: 0.0107  last_data_time: 0.0138   lr: 5e-05  max_mem: 4724M
[03/08 13:43:34] d2.utils.events INFO:  eta: 4:32:49  iter: 1479  total_loss: 5.906  loss_ce: 1.04  loss_giou: 0.7465  loss_bbox: 0.7135  loss_ce_0: 0.9259  loss_giou_0: 0.7852  loss_bbox_0: 0.692  loss_rpn_cls: 0.4464  loss_rpn_reg: 0.6756  time: 0.3352  last_time: 0.2846  data_time: 0.0114  last_data_time: 0.0116   lr: 5e-05  max_mem: 4724M
[03/08 13:43:41] d2.utils.events INFO:  eta: 4:32:51  iter: 1499  total_loss: 5.742  loss_ce: 1.008  loss_giou: 0.6344  loss_bbox: 0.6458  loss_ce_0: 0.9338  loss_giou_0: 0.6584  loss_bbox_0: 0.6734  loss_rpn_cls: 0.4299  loss_rpn_reg: 0.6573  time: 0.3355  last_time: 0.3934  data_time: 0.0107  last_data_time: 0.0107   lr: 5e-05  max_mem: 4724M
[03/08 13:43:48] d2.utils.events INFO:  eta: 4:32:57  iter: 1519  total_loss: 5.422  loss_ce: 1.006  loss_giou: 0.6274  loss_bbox: 0.5712  loss_ce_0: 0.9325  loss_giou_0: 0.6659  loss_bbox_0: 0.6275  loss_rpn_cls: 0.4183  loss_rpn_reg: 0.6787  time: 0.3355  last_time: 0.2934  data_time: 0.0101  last_data_time: 0.0070   lr: 5e-05  max_mem: 4724M
[03/08 13:43:55] d2.utils.events INFO:  eta: 4:32:33  iter: 1539  total_loss: 5.758  loss_ce: 0.9923  loss_giou: 0.6422  loss_bbox: 0.6835  loss_ce_0: 0.9273  loss_giou_0: 0.6634  loss_bbox_0: 0.7031  loss_rpn_cls: 0.4332  loss_rpn_reg: 0.6579  time: 0.3353  last_time: 0.3380  data_time: 0.0118  last_data_time: 0.0249   lr: 5e-05  max_mem: 4724M
[03/08 13:44:01] d2.utils.events INFO:  eta: 4:32:32  iter: 1559  total_loss: 5.8  loss_ce: 0.9761  loss_giou: 0.7066  loss_bbox: 0.721  loss_ce_0: 0.9102  loss_giou_0: 0.6878  loss_bbox_0: 0.6893  loss_rpn_cls: 0.4252  loss_rpn_reg: 0.6547  time: 0.3353  last_time: 0.3062  data_time: 0.0123  last_data_time: 0.0212   lr: 5e-05  max_mem: 4724M
[03/08 13:44:08] d2.utils.events INFO:  eta: 4:32:36  iter: 1579  total_loss: 5.513  loss_ce: 0.9424  loss_giou: 0.6249  loss_bbox: 0.6308  loss_ce_0: 0.8963  loss_giou_0: 0.6335  loss_bbox_0: 0.6366  loss_rpn_cls: 0.4137  loss_rpn_reg: 0.6287  time: 0.3353  last_time: 0.2752  data_time: 0.0101  last_data_time: 0.0120   lr: 5e-05  max_mem: 4724M
[03/08 13:44:15] d2.utils.events INFO:  eta: 4:32:44  iter: 1599  total_loss: 5.098  loss_ce: 0.9209  loss_giou: 0.5793  loss_bbox: 0.5418  loss_ce_0: 0.8545  loss_giou_0: 0.6233  loss_bbox_0: 0.5535  loss_rpn_cls: 0.4175  loss_rpn_reg: 0.61  time: 0.3352  last_time: 0.3006  data_time: 0.0129  last_data_time: 0.0101   lr: 5e-05  max_mem: 4724M
[03/08 13:44:21] d2.utils.events INFO:  eta: 4:32:26  iter: 1619  total_loss: 5.693  loss_ce: 0.9726  loss_giou: 0.7121  loss_bbox: 0.6804  loss_ce_0: 0.9029  loss_giou_0: 0.69  loss_bbox_0: 0.7113  loss_rpn_cls: 0.389  loss_rpn_reg: 0.6766  time: 0.3351  last_time: 0.2993  data_time: 0.0121  last_data_time: 0.0104   lr: 5e-05  max_mem: 4724M
[03/08 13:44:28] d2.utils.events INFO:  eta: 4:32:51  iter: 1639  total_loss: 5.072  loss_ce: 1.008  loss_giou: 0.5503  loss_bbox: 0.5443  loss_ce_0: 0.9155  loss_giou_0: 0.5483  loss_bbox_0: 0.6115  loss_rpn_cls: 0.4024  loss_rpn_reg: 0.6031  time: 0.3351  last_time: 0.3021  data_time: 0.0106  last_data_time: 0.0018   lr: 5e-05  max_mem: 4724M
[03/08 13:44:35] d2.utils.events INFO:  eta: 4:32:56  iter: 1659  total_loss: 5.537  loss_ce: 0.9768  loss_giou: 0.6115  loss_bbox: 0.6156  loss_ce_0: 0.9388  loss_giou_0: 0.6373  loss_bbox_0: 0.6472  loss_rpn_cls: 0.4084  loss_rpn_reg: 0.6583  time: 0.3351  last_time: 0.2955  data_time: 0.0106  last_data_time: 0.0054   lr: 5e-05  max_mem: 4724M
[03/08 13:44:41] d2.utils.events INFO:  eta: 4:32:29  iter: 1679  total_loss: 5.647  loss_ce: 0.9681  loss_giou: 0.6827  loss_bbox: 0.6309  loss_ce_0: 0.9132  loss_giou_0: 0.6715  loss_bbox_0: 0.6291  loss_rpn_cls: 0.4054  loss_rpn_reg: 0.6582  time: 0.3347  last_time: 0.3000  data_time: 0.0108  last_data_time: 0.0115   lr: 5e-05  max_mem: 4724M
[03/08 13:44:48] d2.utils.events INFO:  eta: 4:32:19  iter: 1699  total_loss: 5.36  loss_ce: 0.9222  loss_giou: 0.6404  loss_bbox: 0.5723  loss_ce_0: 0.9056  loss_giou_0: 0.6619  loss_bbox_0: 0.6058  loss_rpn_cls: 0.4037  loss_rpn_reg: 0.6638  time: 0.3346  last_time: 0.2739  data_time: 0.0097  last_data_time: 0.0096   lr: 5e-05  max_mem: 4724M
[03/08 13:44:54] d2.utils.events INFO:  eta: 4:31:54  iter: 1719  total_loss: 5.424  loss_ce: 0.9158  loss_giou: 0.5947  loss_bbox: 0.6371  loss_ce_0: 0.8689  loss_giou_0: 0.6381  loss_bbox_0: 0.6409  loss_rpn_cls: 0.4062  loss_rpn_reg: 0.6694  time: 0.3345  last_time: 0.2977  data_time: 0.0113  last_data_time: 0.0107   lr: 5e-05  max_mem: 4724M
[03/08 13:45:01] d2.utils.events INFO:  eta: 4:31:29  iter: 1739  total_loss: 5.302  loss_ce: 0.9288  loss_giou: 0.5994  loss_bbox: 0.6023  loss_ce_0: 0.857  loss_giou_0: 0.6433  loss_bbox_0: 0.6703  loss_rpn_cls: 0.3969  loss_rpn_reg: 0.614  time: 0.3347  last_time: 0.2992  data_time: 0.0116  last_data_time: 0.0247   lr: 5e-05  max_mem: 4724M
[03/08 13:45:06] d2.engine.hooks INFO: Overall training speed: 1751 iterations in 0:09:46 (0.3347 s / it)
[03/08 13:45:06] d2.engine.hooks INFO: Total training time: 0:09:53 (0:00:06 on hooks)
[03/08 13:45:06] d2.utils.events INFO:  eta: 4:31:24  iter: 1753  total_loss: 5.402  loss_ce: 0.923  loss_giou: 0.6435  loss_bbox: 0.6745  loss_ce_0: 0.8524  loss_giou_0: 0.6763  loss_bbox_0: 0.6951  loss_rpn_cls: 0.4123  loss_rpn_reg: 0.6391  time: 0.3346  last_time: 0.4146  data_time: 0.0112  last_data_time: 0.0085   lr: 5e-05  max_mem: 4724M
[03/08 13:54:19] detectron2 INFO: Rank of current process: 0. World size: 2
[03/08 13:54:20] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/08 13:54:20] detectron2 INFO: Command line arguments: Namespace(config_file='projects/Featurized-QueryRCNN/configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=['OUTPUT_DIR', 'projects/Featurized-QueryRCNN/output/t1', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.WEIGHTS', 'projects/Featurized-QueryRCNN/output/t1/model_final.pth'], resume=False)
[03/08 13:54:20] detectron2 INFO: Contents of args.config_file=projects/Featurized-QueryRCNN/configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/08 13:54:20] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: projects/Featurized-QueryRCNN/output/t1/model_final.pth
OUTPUT_DIR: projects/Featurized-QueryRCNN/output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/08 13:54:20] detectron2 INFO: Full config saved to projects/Featurized-QueryRCNN/output/t1/config.yaml
[03/08 13:54:21] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/08 13:54:21] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from projects/Featurized-QueryRCNN/output/t1/model_final.pth ...
[03/08 13:54:21] fvcore.common.checkpoint INFO: [Checkpointer] Loading from projects/Featurized-QueryRCNN/output/t1/model_final.pth ...
[03/08 13:54:23] d2.data.build INFO: Known classes: range(0, 20)
[03/08 13:54:23] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/08 13:54:23] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[03/08 13:54:23] d2.data.build INFO: Number of datapoints: 10246
[03/08 13:54:23] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/08 13:54:23] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/08 13:54:23] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[03/08 13:54:23] d2.data.common INFO: Serialized dataset takes 6.49 MiB
[03/08 13:54:23] d2.evaluation.evaluator INFO: Start inference on 5123 batches
[03/08 13:54:26] d2.evaluation.evaluator INFO: Inference done 11/5123. Dataloading: 0.0008 s/iter. Inference: 0.0416 s/iter. Eval: 0.0012 s/iter. Total: 0.0437 s/iter. ETA=0:03:43
[03/08 13:54:31] d2.evaluation.evaluator INFO: Inference done 150/5123. Dataloading: 0.0012 s/iter. Inference: 0.0338 s/iter. Eval: 0.0012 s/iter. Total: 0.0364 s/iter. ETA=0:03:00
[03/08 13:54:36] d2.evaluation.evaluator INFO: Inference done 289/5123. Dataloading: 0.0013 s/iter. Inference: 0.0337 s/iter. Eval: 0.0012 s/iter. Total: 0.0362 s/iter. ETA=0:02:54
[03/08 13:54:41] d2.evaluation.evaluator INFO: Inference done 430/5123. Dataloading: 0.0013 s/iter. Inference: 0.0334 s/iter. Eval: 0.0012 s/iter. Total: 0.0360 s/iter. ETA=0:02:48
[03/08 13:54:46] d2.evaluation.evaluator INFO: Inference done 574/5123. Dataloading: 0.0013 s/iter. Inference: 0.0332 s/iter. Eval: 0.0012 s/iter. Total: 0.0357 s/iter. ETA=0:02:42
[03/08 13:54:51] d2.evaluation.evaluator INFO: Inference done 713/5123. Dataloading: 0.0013 s/iter. Inference: 0.0332 s/iter. Eval: 0.0012 s/iter. Total: 0.0357 s/iter. ETA=0:02:37
[03/08 13:54:56] d2.evaluation.evaluator INFO: Inference done 853/5123. Dataloading: 0.0012 s/iter. Inference: 0.0333 s/iter. Eval: 0.0012 s/iter. Total: 0.0358 s/iter. ETA=0:02:32
[03/08 13:55:01] d2.evaluation.evaluator INFO: Inference done 996/5123. Dataloading: 0.0012 s/iter. Inference: 0.0332 s/iter. Eval: 0.0012 s/iter. Total: 0.0357 s/iter. ETA=0:02:27
[03/08 13:55:06] d2.evaluation.evaluator INFO: Inference done 1138/5123. Dataloading: 0.0012 s/iter. Inference: 0.0331 s/iter. Eval: 0.0012 s/iter. Total: 0.0356 s/iter. ETA=0:02:21
[03/08 13:55:11] d2.evaluation.evaluator INFO: Inference done 1283/5123. Dataloading: 0.0012 s/iter. Inference: 0.0330 s/iter. Eval: 0.0012 s/iter. Total: 0.0355 s/iter. ETA=0:02:16
[03/08 13:55:16] d2.evaluation.evaluator INFO: Inference done 1428/5123. Dataloading: 0.0012 s/iter. Inference: 0.0330 s/iter. Eval: 0.0012 s/iter. Total: 0.0354 s/iter. ETA=0:02:10
[03/08 13:55:21] d2.evaluation.evaluator INFO: Inference done 1573/5123. Dataloading: 0.0012 s/iter. Inference: 0.0329 s/iter. Eval: 0.0012 s/iter. Total: 0.0353 s/iter. ETA=0:02:05
[03/08 13:55:26] d2.evaluation.evaluator INFO: Inference done 1717/5123. Dataloading: 0.0012 s/iter. Inference: 0.0329 s/iter. Eval: 0.0012 s/iter. Total: 0.0353 s/iter. ETA=0:02:00
[03/08 13:55:31] d2.evaluation.evaluator INFO: Inference done 1861/5123. Dataloading: 0.0012 s/iter. Inference: 0.0329 s/iter. Eval: 0.0011 s/iter. Total: 0.0353 s/iter. ETA=0:01:55
[03/08 13:55:36] d2.evaluation.evaluator INFO: Inference done 2005/5123. Dataloading: 0.0012 s/iter. Inference: 0.0328 s/iter. Eval: 0.0011 s/iter. Total: 0.0352 s/iter. ETA=0:01:49
[03/08 13:55:41] d2.evaluation.evaluator INFO: Inference done 2148/5123. Dataloading: 0.0012 s/iter. Inference: 0.0328 s/iter. Eval: 0.0011 s/iter. Total: 0.0352 s/iter. ETA=0:01:44
[03/08 13:55:46] d2.evaluation.evaluator INFO: Inference done 2292/5123. Dataloading: 0.0012 s/iter. Inference: 0.0328 s/iter. Eval: 0.0011 s/iter. Total: 0.0352 s/iter. ETA=0:01:39
[03/08 13:55:51] d2.evaluation.evaluator INFO: Inference done 2427/5123. Dataloading: 0.0012 s/iter. Inference: 0.0329 s/iter. Eval: 0.0011 s/iter. Total: 0.0353 s/iter. ETA=0:01:35
[03/08 13:55:56] d2.evaluation.evaluator INFO: Inference done 2561/5123. Dataloading: 0.0012 s/iter. Inference: 0.0330 s/iter. Eval: 0.0011 s/iter. Total: 0.0354 s/iter. ETA=0:01:30
[03/08 13:56:01] d2.evaluation.evaluator INFO: Inference done 2696/5123. Dataloading: 0.0012 s/iter. Inference: 0.0331 s/iter. Eval: 0.0011 s/iter. Total: 0.0355 s/iter. ETA=0:01:26
[03/08 13:56:06] d2.evaluation.evaluator INFO: Inference done 2832/5123. Dataloading: 0.0012 s/iter. Inference: 0.0332 s/iter. Eval: 0.0012 s/iter. Total: 0.0356 s/iter. ETA=0:01:21
[03/08 13:56:11] d2.evaluation.evaluator INFO: Inference done 2968/5123. Dataloading: 0.0012 s/iter. Inference: 0.0332 s/iter. Eval: 0.0012 s/iter. Total: 0.0356 s/iter. ETA=0:01:16
[03/08 13:56:16] d2.evaluation.evaluator INFO: Inference done 3104/5123. Dataloading: 0.0012 s/iter. Inference: 0.0333 s/iter. Eval: 0.0012 s/iter. Total: 0.0357 s/iter. ETA=0:01:12
[03/08 13:56:21] d2.evaluation.evaluator INFO: Inference done 3238/5123. Dataloading: 0.0012 s/iter. Inference: 0.0334 s/iter. Eval: 0.0012 s/iter. Total: 0.0358 s/iter. ETA=0:01:07
[03/08 13:56:26] d2.evaluation.evaluator INFO: Inference done 3373/5123. Dataloading: 0.0012 s/iter. Inference: 0.0334 s/iter. Eval: 0.0012 s/iter. Total: 0.0358 s/iter. ETA=0:01:02
[03/08 13:56:31] d2.evaluation.evaluator INFO: Inference done 3512/5123. Dataloading: 0.0012 s/iter. Inference: 0.0334 s/iter. Eval: 0.0012 s/iter. Total: 0.0358 s/iter. ETA=0:00:57
[03/08 13:56:36] d2.evaluation.evaluator INFO: Inference done 3658/5123. Dataloading: 0.0012 s/iter. Inference: 0.0334 s/iter. Eval: 0.0012 s/iter. Total: 0.0358 s/iter. ETA=0:00:52
[03/08 13:56:41] d2.evaluation.evaluator INFO: Inference done 3804/5123. Dataloading: 0.0012 s/iter. Inference: 0.0333 s/iter. Eval: 0.0012 s/iter. Total: 0.0357 s/iter. ETA=0:00:47
[03/08 13:56:46] d2.evaluation.evaluator INFO: Inference done 3949/5123. Dataloading: 0.0012 s/iter. Inference: 0.0333 s/iter. Eval: 0.0012 s/iter. Total: 0.0357 s/iter. ETA=0:00:41
[03/08 13:56:51] d2.evaluation.evaluator INFO: Inference done 4094/5123. Dataloading: 0.0012 s/iter. Inference: 0.0333 s/iter. Eval: 0.0012 s/iter. Total: 0.0356 s/iter. ETA=0:00:36
[03/08 13:56:56] d2.evaluation.evaluator INFO: Inference done 4239/5123. Dataloading: 0.0012 s/iter. Inference: 0.0332 s/iter. Eval: 0.0011 s/iter. Total: 0.0356 s/iter. ETA=0:00:31
[03/08 13:57:01] d2.evaluation.evaluator INFO: Inference done 4383/5123. Dataloading: 0.0012 s/iter. Inference: 0.0332 s/iter. Eval: 0.0011 s/iter. Total: 0.0356 s/iter. ETA=0:00:26
[03/08 13:57:06] d2.evaluation.evaluator INFO: Inference done 4528/5123. Dataloading: 0.0012 s/iter. Inference: 0.0332 s/iter. Eval: 0.0011 s/iter. Total: 0.0355 s/iter. ETA=0:00:21
[03/08 13:57:11] d2.evaluation.evaluator INFO: Inference done 4674/5123. Dataloading: 0.0012 s/iter. Inference: 0.0332 s/iter. Eval: 0.0011 s/iter. Total: 0.0355 s/iter. ETA=0:00:15
[03/08 13:57:16] d2.evaluation.evaluator INFO: Inference done 4819/5123. Dataloading: 0.0012 s/iter. Inference: 0.0331 s/iter. Eval: 0.0011 s/iter. Total: 0.0355 s/iter. ETA=0:00:10
[03/08 13:57:21] d2.evaluation.evaluator INFO: Inference done 4964/5123. Dataloading: 0.0012 s/iter. Inference: 0.0331 s/iter. Eval: 0.0011 s/iter. Total: 0.0354 s/iter. ETA=0:00:05
[03/08 13:57:26] d2.evaluation.evaluator INFO: Inference done 5109/5123. Dataloading: 0.0012 s/iter. Inference: 0.0331 s/iter. Eval: 0.0011 s/iter. Total: 0.0354 s/iter. ETA=0:00:00
[03/08 13:57:27] d2.evaluation.evaluator INFO: Total inference time: 0:03:01.626226 (0.035488 s / iter per device, on 2 devices)
[03/08 13:57:27] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:49 (0.033081 s / iter per device, on 2 devices)
[03/08 13:57:28] d2.evaluation.pascal_voc_evaluation INFO: Evaluating voc_coco_2007_test using 2012 metric. Note that results do not use the official Matlab API.
[03/08 13:57:28] d2.evaluation.pascal_voc_evaluation INFO: aeroplane has 20644 predictions.
[03/08 13:57:30] d2.evaluation.pascal_voc_evaluation INFO: bicycle has 24509 predictions.
[03/08 13:57:31] d2.evaluation.pascal_voc_evaluation INFO: bird has 45642 predictions.
[03/08 13:57:32] d2.evaluation.pascal_voc_evaluation INFO: boat has 35094 predictions.
[03/08 13:57:33] d2.evaluation.pascal_voc_evaluation INFO: bottle has 81118 predictions.
[03/08 13:57:36] d2.evaluation.pascal_voc_evaluation INFO: bus has 18367 predictions.
[03/08 13:57:37] d2.evaluation.pascal_voc_evaluation INFO: car has 89197 predictions.
[03/08 13:57:39] d2.evaluation.pascal_voc_evaluation INFO: cat has 21026 predictions.
[03/08 13:57:40] d2.evaluation.pascal_voc_evaluation INFO: chair has 138431 predictions.
[03/08 13:57:45] d2.evaluation.pascal_voc_evaluation INFO: cow has 15131 predictions.
[03/08 13:57:45] d2.evaluation.pascal_voc_evaluation INFO: diningtable has 41884 predictions.
[03/08 13:57:47] d2.evaluation.pascal_voc_evaluation INFO: dog has 31103 predictions.
[03/08 13:57:48] d2.evaluation.pascal_voc_evaluation INFO: horse has 22805 predictions.
[03/08 13:57:48] d2.evaluation.pascal_voc_evaluation INFO: motorbike has 19264 predictions.
[03/08 13:57:49] d2.evaluation.pascal_voc_evaluation INFO: person has 238452 predictions.
[03/08 13:57:58] d2.evaluation.pascal_voc_evaluation INFO: pottedplant has 57792 predictions.
[03/08 13:58:00] d2.evaluation.pascal_voc_evaluation INFO: sheep has 18366 predictions.
[03/08 13:58:01] d2.evaluation.pascal_voc_evaluation INFO: sofa has 34400 predictions.
[03/08 13:58:02] d2.evaluation.pascal_voc_evaluation INFO: train has 27832 predictions.
[03/08 13:58:03] d2.evaluation.pascal_voc_evaluation INFO: tvmonitor has 43534 predictions.
[03/08 13:58:04] d2.evaluation.pascal_voc_evaluation INFO: truck has 1 predictions.
[03/08 13:58:04] d2.evaluation.pascal_voc_evaluation INFO: traffic light has 1 predictions.
[03/08 13:58:05] d2.evaluation.pascal_voc_evaluation INFO: fire hydrant has 1 predictions.
[03/08 13:58:05] d2.evaluation.pascal_voc_evaluation INFO: stop sign has 1 predictions.
[03/08 13:58:05] d2.evaluation.pascal_voc_evaluation INFO: parking meter has 1 predictions.
[03/08 13:58:05] d2.evaluation.pascal_voc_evaluation INFO: bench has 1 predictions.
[03/08 13:58:05] d2.evaluation.pascal_voc_evaluation INFO: elephant has 1 predictions.
[03/08 13:58:06] d2.evaluation.pascal_voc_evaluation INFO: bear has 1 predictions.
[03/08 13:58:06] d2.evaluation.pascal_voc_evaluation INFO: zebra has 1 predictions.
[03/08 13:58:06] d2.evaluation.pascal_voc_evaluation INFO: giraffe has 1 predictions.
[03/08 13:58:06] d2.evaluation.pascal_voc_evaluation INFO: backpack has 1 predictions.
[03/08 13:58:07] d2.evaluation.pascal_voc_evaluation INFO: umbrella has 1 predictions.
[03/08 13:58:07] d2.evaluation.pascal_voc_evaluation INFO: handbag has 1 predictions.
[03/08 13:58:07] d2.evaluation.pascal_voc_evaluation INFO: tie has 1 predictions.
[03/08 13:58:07] d2.evaluation.pascal_voc_evaluation INFO: suitcase has 1 predictions.
[03/08 13:58:08] d2.evaluation.pascal_voc_evaluation INFO: microwave has 1 predictions.
[03/08 13:58:08] d2.evaluation.pascal_voc_evaluation INFO: oven has 1 predictions.
[03/08 13:58:08] d2.evaluation.pascal_voc_evaluation INFO: toaster has 1 predictions.
[03/08 13:58:08] d2.evaluation.pascal_voc_evaluation INFO: sink has 1 predictions.
[03/08 13:58:08] d2.evaluation.pascal_voc_evaluation INFO: refrigerator has 1 predictions.
[03/08 13:58:09] d2.evaluation.pascal_voc_evaluation INFO: frisbee has 1 predictions.
[03/08 13:58:09] d2.evaluation.pascal_voc_evaluation INFO: skis has 1 predictions.
[03/08 13:58:09] d2.evaluation.pascal_voc_evaluation INFO: snowboard has 1 predictions.
[03/08 13:58:09] d2.evaluation.pascal_voc_evaluation INFO: sports ball has 1 predictions.
[03/08 13:58:10] d2.evaluation.pascal_voc_evaluation INFO: kite has 1 predictions.
[03/08 13:58:10] d2.evaluation.pascal_voc_evaluation INFO: baseball bat has 1 predictions.
[03/08 13:58:10] d2.evaluation.pascal_voc_evaluation INFO: baseball glove has 1 predictions.
[03/08 13:58:10] d2.evaluation.pascal_voc_evaluation INFO: skateboard has 6 predictions.
[03/08 13:58:11] d2.evaluation.pascal_voc_evaluation INFO: surfboard has 1 predictions.
[03/08 13:58:11] d2.evaluation.pascal_voc_evaluation INFO: tennis racket has 1 predictions.
[03/08 13:58:11] d2.evaluation.pascal_voc_evaluation INFO: banana has 1 predictions.
[03/08 13:58:11] d2.evaluation.pascal_voc_evaluation INFO: apple has 1 predictions.
[03/08 13:58:11] d2.evaluation.pascal_voc_evaluation INFO: sandwich has 1 predictions.
[03/08 13:58:12] d2.evaluation.pascal_voc_evaluation INFO: orange has 1 predictions.
[03/08 13:58:12] d2.evaluation.pascal_voc_evaluation INFO: broccoli has 1 predictions.
[03/08 13:58:12] d2.evaluation.pascal_voc_evaluation INFO: carrot has 1 predictions.
[03/08 13:58:12] d2.evaluation.pascal_voc_evaluation INFO: hot dog has 1 predictions.
[03/08 13:58:13] d2.evaluation.pascal_voc_evaluation INFO: pizza has 1 predictions.
[03/08 13:58:13] d2.evaluation.pascal_voc_evaluation INFO: donut has 1 predictions.
[03/08 13:58:13] d2.evaluation.pascal_voc_evaluation INFO: cake has 1 predictions.
[03/08 13:58:13] d2.evaluation.pascal_voc_evaluation INFO: bed has 1 predictions.
[03/08 13:58:13] d2.evaluation.pascal_voc_evaluation INFO: toilet has 1 predictions.
[03/08 13:58:14] d2.evaluation.pascal_voc_evaluation INFO: laptop has 1 predictions.
[03/08 13:58:14] d2.evaluation.pascal_voc_evaluation INFO: mouse has 1 predictions.
[03/08 13:58:14] d2.evaluation.pascal_voc_evaluation INFO: remote has 1 predictions.
[03/08 13:58:14] d2.evaluation.pascal_voc_evaluation INFO: keyboard has 1 predictions.
[03/08 13:58:15] d2.evaluation.pascal_voc_evaluation INFO: cell phone has 1 predictions.
[03/08 13:58:15] d2.evaluation.pascal_voc_evaluation INFO: book has 1 predictions.
[03/08 13:58:15] d2.evaluation.pascal_voc_evaluation INFO: clock has 1 predictions.
[03/08 13:58:15] d2.evaluation.pascal_voc_evaluation INFO: vase has 1 predictions.
[03/08 13:58:15] d2.evaluation.pascal_voc_evaluation INFO: scissors has 1 predictions.
[03/08 13:58:16] d2.evaluation.pascal_voc_evaluation INFO: teddy bear has 1 predictions.
[03/08 13:58:16] d2.evaluation.pascal_voc_evaluation INFO: hair drier has 1 predictions.
[03/08 13:58:16] d2.evaluation.pascal_voc_evaluation INFO: toothbrush has 1 predictions.
[03/08 13:58:16] d2.evaluation.pascal_voc_evaluation INFO: wine glass has 1 predictions.
[03/08 13:58:17] d2.evaluation.pascal_voc_evaluation INFO: cup has 1 predictions.
[03/08 13:58:17] d2.evaluation.pascal_voc_evaluation INFO: fork has 1 predictions.
[03/08 13:58:17] d2.evaluation.pascal_voc_evaluation INFO: knife has 1 predictions.
[03/08 13:58:17] d2.evaluation.pascal_voc_evaluation INFO: spoon has 1 predictions.
[03/08 13:58:18] d2.evaluation.pascal_voc_evaluation INFO: bowl has 3 predictions.
[03/08 13:58:18] d2.evaluation.pascal_voc_evaluation INFO: unknown has 1 predictions.
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: Wilderness Impact: {0.1: {50: 0.0188987400839944}, 0.2: {50: 0.02809047869542346}, 0.3: {50: 0.0415700652396614}, 0.4: {50: 0.061481481481481484}, 0.5: {50: 0.09458405692824073}, 0.6: {50: 0.09131502489100306}, 0.7: {50: 0.07811077629140242}, 0.8: {50: 0.07381768062346149}, 0.9: {50: 0.07761648002212083}}
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: avg_precision: {0.1: {50: 0}, 0.2: {50: 0}, 0.3: {50: 0}, 0.4: {50: 0}, 0.5: {50: 0}, 0.6: {50: 0}, 0.7: {50: 0}, 0.8: {50: 0}, 0.9: {50: 0}}
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: Absolute OSE (total_num_unk_det_as_known): {50: 81311.0}
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: total_num_unk 23320
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor', 'truck', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'bed', 'toilet', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'unknown']
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: AP50: ['79.2', '55.3', '56.8', '41.2', '24.5', '68.5', '56.1', '77.3', '19.2', '59.3', '14.3', '69.0', '73.4', '63.4', '46.9', '29.0', '63.9', '42.5', '77.7', '54.5', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', 'nan', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', 'nan', '0.0']
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: Precisions50: ['1.6', '2.0', '1.2', '1.1', '1.3', '1.9', '2.7', '2.3', '1.2', '1.9', '1.5', '2.0', '1.7', '2.3', '5.4', '1.2', '1.6', '1.3', '1.2', '1.2', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0']
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: Recall50: ['96.7', '73.9', '80.5', '79.9', '48.8', '89.4', '75.6', '94.3', '48.2', '93.5', '44.4', '94.8', '95.3', '82.5', '71.5', '72.7', '90.6', '81.5', '93.7', '82.2', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', 'nan', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', 'nan', '0.0']
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: Current class AP50: 53.59260222109053
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: Current class Precisions50: 1.8262987289104324
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: Current class Recall50: 79.5022107076468
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: Known AP50: 53.59260222109053
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: Known Precisions50: 1.8262987289104324
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: Known Recall50: 79.5022107076468
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: Unknown AP50: 0.0
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: Unknown Precisions50: 0
[03/08 13:58:20] d2.evaluation.pascal_voc_evaluation INFO: Unknown Recall50: 0
[03/08 13:58:20] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[03/08 13:58:20] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/08 13:58:20] d2.evaluation.testing INFO: copypaste: AP for all classes,AP50 for all classes
[03/08 13:58:20] d2.evaluation.testing INFO: copypaste: nan,nan
[03/08 14:08:18] detectron2 INFO: Rank of current process: 0. World size: 2
[03/08 14:08:19] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/08 14:08:19] detectron2 INFO: Command line arguments: Namespace(config_file='projects/Featurized-QueryRCNN/configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=['OUTPUT_DIR', 'projects/Featurized-QueryRCNN/output/t1', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.WEIGHTS', 'projects/Featurized-QueryRCNN/output/t1/model_final.pth'], resume=False)
[03/08 14:08:19] detectron2 INFO: Contents of args.config_file=projects/Featurized-QueryRCNN/configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/08 14:08:19] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: projects/Featurized-QueryRCNN/output/t1/model_final.pth
OUTPUT_DIR: projects/Featurized-QueryRCNN/output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NMS_THRESHOLD: 0.6
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  USE_NMS: true
VERSION: 2
VIS_PERIOD: 0

[03/08 14:08:19] detectron2 INFO: Full config saved to projects/Featurized-QueryRCNN/output/t1/config.yaml
[03/08 14:08:20] d2.engine.defaults INFO: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/08 14:08:20] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from projects/Featurized-QueryRCNN/output/t1/model_final.pth ...
[03/08 14:08:20] fvcore.common.checkpoint INFO: [Checkpointer] Loading from projects/Featurized-QueryRCNN/output/t1/model_final.pth ...
[03/08 14:08:22] d2.data.build INFO: Known classes: range(0, 20)
[03/08 14:08:22] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/08 14:08:22] d2.data.build INFO: Distribution of instances among all 81 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |
[03/08 14:08:22] d2.data.build INFO: Number of datapoints: 10246
[03/08 14:08:22] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/08 14:08:22] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/08 14:08:22] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[03/08 14:08:22] d2.data.common INFO: Serialized dataset takes 6.49 MiB
[03/08 14:08:22] d2.evaluation.evaluator INFO: Start inference on 5123 batches
[03/08 14:08:25] d2.evaluation.evaluator INFO: Inference done 11/5123. Dataloading: 0.0009 s/iter. Inference: 0.0373 s/iter. Eval: 0.0007 s/iter. Total: 0.0389 s/iter. ETA=0:03:18
[03/08 14:08:30] d2.evaluation.evaluator INFO: Inference done 151/5123. Dataloading: 0.0013 s/iter. Inference: 0.0339 s/iter. Eval: 0.0007 s/iter. Total: 0.0360 s/iter. ETA=0:02:58
[03/08 14:08:35] d2.evaluation.evaluator INFO: Inference done 286/5123. Dataloading: 0.0013 s/iter. Inference: 0.0344 s/iter. Eval: 0.0007 s/iter. Total: 0.0365 s/iter. ETA=0:02:56
[03/08 14:08:40] d2.evaluation.evaluator INFO: Inference done 426/5123. Dataloading: 0.0013 s/iter. Inference: 0.0343 s/iter. Eval: 0.0007 s/iter. Total: 0.0363 s/iter. ETA=0:02:50
[03/08 14:08:45] d2.evaluation.evaluator INFO: Inference done 565/5123. Dataloading: 0.0013 s/iter. Inference: 0.0342 s/iter. Eval: 0.0007 s/iter. Total: 0.0363 s/iter. ETA=0:02:45
[03/08 14:08:50] d2.evaluation.evaluator INFO: Inference done 702/5123. Dataloading: 0.0013 s/iter. Inference: 0.0342 s/iter. Eval: 0.0007 s/iter. Total: 0.0363 s/iter. ETA=0:02:40
[03/08 14:08:55] d2.evaluation.evaluator INFO: Inference done 843/5123. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:02:35
[03/08 14:09:00] d2.evaluation.evaluator INFO: Inference done 984/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:02:29
[03/08 14:09:05] d2.evaluation.evaluator INFO: Inference done 1124/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:02:24
[03/08 14:09:10] d2.evaluation.evaluator INFO: Inference done 1264/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:02:19
[03/08 14:09:15] d2.evaluation.evaluator INFO: Inference done 1404/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:02:14
[03/08 14:09:20] d2.evaluation.evaluator INFO: Inference done 1546/5123. Dataloading: 0.0013 s/iter. Inference: 0.0339 s/iter. Eval: 0.0007 s/iter. Total: 0.0360 s/iter. ETA=0:02:08
[03/08 14:09:25] d2.evaluation.evaluator INFO: Inference done 1682/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:02:04
[03/08 14:09:30] d2.evaluation.evaluator INFO: Inference done 1821/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:59
[03/08 14:09:35] d2.evaluation.evaluator INFO: Inference done 1961/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:54
[03/08 14:09:40] d2.evaluation.evaluator INFO: Inference done 2099/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:49
[03/08 14:09:45] d2.evaluation.evaluator INFO: Inference done 2239/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:44
[03/08 14:09:50] d2.evaluation.evaluator INFO: Inference done 2380/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:38
[03/08 14:09:55] d2.evaluation.evaluator INFO: Inference done 2515/5123. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:34
[03/08 14:10:00] d2.evaluation.evaluator INFO: Inference done 2653/5123. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:29
[03/08 14:10:05] d2.evaluation.evaluator INFO: Inference done 2793/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:24
[03/08 14:10:10] d2.evaluation.evaluator INFO: Inference done 2932/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:19
[03/08 14:10:15] d2.evaluation.evaluator INFO: Inference done 3072/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:14
[03/08 14:10:20] d2.evaluation.evaluator INFO: Inference done 3211/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:08
[03/08 14:10:25] d2.evaluation.evaluator INFO: Inference done 3352/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:03
[03/08 14:10:30] d2.evaluation.evaluator INFO: Inference done 3488/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:00:59
[03/08 14:10:35] d2.evaluation.evaluator INFO: Inference done 3620/5123. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:54
[03/08 14:10:40] d2.evaluation.evaluator INFO: Inference done 3754/5123. Dataloading: 0.0013 s/iter. Inference: 0.0342 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:49
[03/08 14:10:45] d2.evaluation.evaluator INFO: Inference done 3888/5123. Dataloading: 0.0013 s/iter. Inference: 0.0342 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:44
[03/08 14:10:50] d2.evaluation.evaluator INFO: Inference done 4027/5123. Dataloading: 0.0013 s/iter. Inference: 0.0342 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:39
[03/08 14:10:55] d2.evaluation.evaluator INFO: Inference done 4167/5123. Dataloading: 0.0013 s/iter. Inference: 0.0342 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:34
[03/08 14:11:00] d2.evaluation.evaluator INFO: Inference done 4306/5123. Dataloading: 0.0013 s/iter. Inference: 0.0342 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:29
[03/08 14:11:05] d2.evaluation.evaluator INFO: Inference done 4446/5123. Dataloading: 0.0013 s/iter. Inference: 0.0342 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:24
[03/08 14:11:10] d2.evaluation.evaluator INFO: Inference done 4587/5123. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:19
[03/08 14:11:15] d2.evaluation.evaluator INFO: Inference done 4725/5123. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:14
[03/08 14:11:20] d2.evaluation.evaluator INFO: Inference done 4865/5123. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:09
[03/08 14:11:25] d2.evaluation.evaluator INFO: Inference done 5003/5123. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:04
[03/08 14:11:30] d2.evaluation.evaluator INFO: Total inference time: 0:03:05.826430 (0.036308 s / iter per device, on 2 devices)
[03/08 14:11:30] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:54 (0.034176 s / iter per device, on 2 devices)
[03/08 14:11:31] d2.evaluation.pascal_voc_evaluation INFO: Evaluating voc_coco_2007_test using 2012 metric. Note that results do not use the official Matlab API.
[03/08 14:11:31] d2.evaluation.pascal_voc_evaluation INFO: aeroplane has 11223 predictions.
[03/08 14:11:32] d2.evaluation.pascal_voc_evaluation INFO: bicycle has 13124 predictions.
[03/08 14:11:33] d2.evaluation.pascal_voc_evaluation INFO: bird has 24714 predictions.
[03/08 14:11:34] d2.evaluation.pascal_voc_evaluation INFO: boat has 20481 predictions.
[03/08 14:11:34] d2.evaluation.pascal_voc_evaluation INFO: bottle has 46241 predictions.
[03/08 14:11:36] d2.evaluation.pascal_voc_evaluation INFO: bus has 10997 predictions.
[03/08 14:11:36] d2.evaluation.pascal_voc_evaluation INFO: car has 49190 predictions.
[03/08 14:11:38] d2.evaluation.pascal_voc_evaluation INFO: cat has 9232 predictions.
[03/08 14:11:38] d2.evaluation.pascal_voc_evaluation INFO: chair has 67377 predictions.
[03/08 14:11:40] d2.evaluation.pascal_voc_evaluation INFO: cow has 7893 predictions.
[03/08 14:11:41] d2.evaluation.pascal_voc_evaluation INFO: diningtable has 20930 predictions.
[03/08 14:11:42] d2.evaluation.pascal_voc_evaluation INFO: dog has 14790 predictions.
[03/08 14:11:42] d2.evaluation.pascal_voc_evaluation INFO: horse has 10968 predictions.
[03/08 14:11:43] d2.evaluation.pascal_voc_evaluation INFO: motorbike has 10468 predictions.
[03/08 14:11:43] d2.evaluation.pascal_voc_evaluation INFO: person has 120786 predictions.
[03/08 14:11:48] d2.evaluation.pascal_voc_evaluation INFO: pottedplant has 30906 predictions.
[03/08 14:11:49] d2.evaluation.pascal_voc_evaluation INFO: sheep has 9107 predictions.
[03/08 14:11:49] d2.evaluation.pascal_voc_evaluation INFO: sofa has 16184 predictions.
[03/08 14:11:50] d2.evaluation.pascal_voc_evaluation INFO: train has 14584 predictions.
[03/08 14:11:50] d2.evaluation.pascal_voc_evaluation INFO: tvmonitor has 24776 predictions.
[03/08 14:11:51] d2.evaluation.pascal_voc_evaluation INFO: truck has 1 predictions.
[03/08 14:11:51] d2.evaluation.pascal_voc_evaluation INFO: traffic light has 1 predictions.
[03/08 14:11:51] d2.evaluation.pascal_voc_evaluation INFO: fire hydrant has 1 predictions.
[03/08 14:11:52] d2.evaluation.pascal_voc_evaluation INFO: stop sign has 1 predictions.
[03/08 14:11:52] d2.evaluation.pascal_voc_evaluation INFO: parking meter has 1 predictions.
[03/08 14:11:52] d2.evaluation.pascal_voc_evaluation INFO: bench has 1 predictions.
[03/08 14:11:52] d2.evaluation.pascal_voc_evaluation INFO: elephant has 1 predictions.
[03/08 14:11:53] d2.evaluation.pascal_voc_evaluation INFO: bear has 1 predictions.
[03/08 14:11:53] d2.evaluation.pascal_voc_evaluation INFO: zebra has 1 predictions.
[03/08 14:11:53] d2.evaluation.pascal_voc_evaluation INFO: giraffe has 1 predictions.
[03/08 14:11:53] d2.evaluation.pascal_voc_evaluation INFO: backpack has 1 predictions.
[03/08 14:11:53] d2.evaluation.pascal_voc_evaluation INFO: umbrella has 1 predictions.
[03/08 14:11:54] d2.evaluation.pascal_voc_evaluation INFO: handbag has 1 predictions.
[03/08 14:11:54] d2.evaluation.pascal_voc_evaluation INFO: tie has 1 predictions.
[03/08 14:11:54] d2.evaluation.pascal_voc_evaluation INFO: suitcase has 1 predictions.
[03/08 14:11:54] d2.evaluation.pascal_voc_evaluation INFO: microwave has 1 predictions.
[03/08 14:11:55] d2.evaluation.pascal_voc_evaluation INFO: oven has 1 predictions.
[03/08 14:11:55] d2.evaluation.pascal_voc_evaluation INFO: toaster has 1 predictions.
[03/08 14:11:55] d2.evaluation.pascal_voc_evaluation INFO: sink has 1 predictions.
[03/08 14:11:55] d2.evaluation.pascal_voc_evaluation INFO: refrigerator has 1 predictions.
[03/08 14:11:55] d2.evaluation.pascal_voc_evaluation INFO: frisbee has 1 predictions.
[03/08 14:11:56] d2.evaluation.pascal_voc_evaluation INFO: skis has 1 predictions.
[03/08 14:11:56] d2.evaluation.pascal_voc_evaluation INFO: snowboard has 1 predictions.
[03/08 14:11:56] d2.evaluation.pascal_voc_evaluation INFO: sports ball has 1 predictions.
[03/08 14:11:56] d2.evaluation.pascal_voc_evaluation INFO: kite has 1 predictions.
[03/08 14:11:57] d2.evaluation.pascal_voc_evaluation INFO: baseball bat has 1 predictions.
[03/08 14:11:57] d2.evaluation.pascal_voc_evaluation INFO: baseball glove has 1 predictions.
[03/08 14:11:57] d2.evaluation.pascal_voc_evaluation INFO: skateboard has 6 predictions.
[03/08 14:11:57] d2.evaluation.pascal_voc_evaluation INFO: surfboard has 1 predictions.
[03/08 14:11:57] d2.evaluation.pascal_voc_evaluation INFO: tennis racket has 1 predictions.
[03/08 14:11:58] d2.evaluation.pascal_voc_evaluation INFO: banana has 1 predictions.
[03/08 14:11:58] d2.evaluation.pascal_voc_evaluation INFO: apple has 1 predictions.
[03/08 14:11:58] d2.evaluation.pascal_voc_evaluation INFO: sandwich has 1 predictions.
[03/08 14:11:58] d2.evaluation.pascal_voc_evaluation INFO: orange has 1 predictions.
[03/08 14:11:58] d2.evaluation.pascal_voc_evaluation INFO: broccoli has 1 predictions.
[03/08 14:11:59] d2.evaluation.pascal_voc_evaluation INFO: carrot has 1 predictions.
[03/08 14:11:59] d2.evaluation.pascal_voc_evaluation INFO: hot dog has 1 predictions.
[03/08 14:11:59] d2.evaluation.pascal_voc_evaluation INFO: pizza has 1 predictions.
[03/08 14:11:59] d2.evaluation.pascal_voc_evaluation INFO: donut has 1 predictions.
[03/08 14:12:00] d2.evaluation.pascal_voc_evaluation INFO: cake has 1 predictions.
[03/08 14:12:00] d2.evaluation.pascal_voc_evaluation INFO: bed has 1 predictions.
[03/08 14:12:00] d2.evaluation.pascal_voc_evaluation INFO: toilet has 1 predictions.
[03/08 14:12:00] d2.evaluation.pascal_voc_evaluation INFO: laptop has 1 predictions.
[03/08 14:12:01] d2.evaluation.pascal_voc_evaluation INFO: mouse has 1 predictions.
[03/08 14:12:01] d2.evaluation.pascal_voc_evaluation INFO: remote has 1 predictions.
[03/08 14:12:01] d2.evaluation.pascal_voc_evaluation INFO: keyboard has 1 predictions.
[03/08 14:12:01] d2.evaluation.pascal_voc_evaluation INFO: cell phone has 1 predictions.
[03/08 14:12:01] d2.evaluation.pascal_voc_evaluation INFO: book has 1 predictions.
[03/08 14:12:02] d2.evaluation.pascal_voc_evaluation INFO: clock has 1 predictions.
[03/08 14:12:02] d2.evaluation.pascal_voc_evaluation INFO: vase has 1 predictions.
[03/08 14:12:02] d2.evaluation.pascal_voc_evaluation INFO: scissors has 1 predictions.
[03/08 14:12:02] d2.evaluation.pascal_voc_evaluation INFO: teddy bear has 1 predictions.
[03/08 14:12:02] d2.evaluation.pascal_voc_evaluation INFO: hair drier has 1 predictions.
[03/08 14:12:03] d2.evaluation.pascal_voc_evaluation INFO: toothbrush has 1 predictions.
[03/08 14:12:03] d2.evaluation.pascal_voc_evaluation INFO: wine glass has 1 predictions.
[03/08 14:12:03] d2.evaluation.pascal_voc_evaluation INFO: cup has 1 predictions.
[03/08 14:12:03] d2.evaluation.pascal_voc_evaluation INFO: fork has 1 predictions.
[03/08 14:12:04] d2.evaluation.pascal_voc_evaluation INFO: knife has 1 predictions.
[03/08 14:12:04] d2.evaluation.pascal_voc_evaluation INFO: spoon has 1 predictions.
[03/08 14:12:04] d2.evaluation.pascal_voc_evaluation INFO: bowl has 3 predictions.
[03/08 14:12:04] d2.evaluation.pascal_voc_evaluation INFO: unknown has 1 predictions.
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: Wilderness Impact: {0.1: {50: 0.019163355924281374}, 0.2: {50: 0.027491408934707903}, 0.3: {50: 0.04013536780858517}, 0.4: {50: 0.05578289898772345}, 0.5: {50: 0.07129979802908923}, 0.6: {50: 0.06989566598110859}, 0.7: {50: 0.06233417919993398}, 0.8: {50: 0.061792929227027296}, 0.9: {50: 0.06530169439910927}}
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: avg_precision: {0.1: {50: 0}, 0.2: {50: 0}, 0.3: {50: 0}, 0.4: {50: 0}, 0.5: {50: 0}, 0.6: {50: 0}, 0.7: {50: 0}, 0.8: {50: 0}, 0.9: {50: 0}}
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: Absolute OSE (total_num_unk_det_as_known): {50: 34319.0}
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: total_num_unk 23320
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor', 'truck', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'bed', 'toilet', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'unknown']
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: AP50: ['81.5', '57.7', '58.6', '42.7', '25.4', '70.3', '58.0', '79.6', '20.7', '61.0', '15.8', '71.1', '74.7', '66.5', '49.1', '31.4', '65.9', '45.3', '79.7', '56.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', 'nan', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', 'nan', '0.0']
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: Precisions50: ['2.9', '3.6', '2.2', '1.8', '2.2', '3.1', '4.7', '5.2', '2.4', '3.7', '2.9', '4.2', '3.5', '4.2', '10.4', '2.2', '3.2', '2.7', '2.3', '2.1', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0']
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: Recall50: ['96.1', '73.0', '79.5', '77.1', '47.9', '88.7', '74.1', '93.9', '47.2', '93.5', '43.1', '94.4', '93.9', '81.0', '70.4', '71.5', '89.6', '81.3', '93.7', '82.1', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', 'nan', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', 'nan', '0.0']
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: Current class AP50: 55.5474604632261
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: Current class Precisions50: 3.476965566793514
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: Current class Recall50: 78.60232472309409
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: Known AP50: 55.5474604632261
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: Known Precisions50: 3.476965566793514
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: Known Recall50: 78.60232472309409
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: Unknown AP50: 0.0
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: Unknown Precisions50: 0
[03/08 14:12:06] d2.evaluation.pascal_voc_evaluation INFO: Unknown Recall50: 0
[03/08 14:12:06] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[03/08 14:12:06] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/08 14:12:06] d2.evaluation.testing INFO: copypaste: AP for all classes,AP50 for all classes
[03/08 14:12:06] d2.evaluation.testing INFO: copypaste: nan,nan
