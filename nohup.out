Command Line Args: Namespace(config_file='projects/Featurized-QueryRCNN/configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=['OUTPUT_DIR', 'projects/Featurized-QueryRCNN/output/t1', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.WEIGHTS', 'projects/Featurized-QueryRCNN/output/t1/model_final.pth'], resume=False)
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 1
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 0
INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 1
INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.
[03/08 14:08:18 detectron2]: Rank of current process: 0. World size: 2
[03/08 14:08:19 detectron2]: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/08 14:08:19 detectron2]: Command line arguments: Namespace(config_file='projects/Featurized-QueryRCNN/configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=['OUTPUT_DIR', 'projects/Featurized-QueryRCNN/output/t1', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.WEIGHTS', 'projects/Featurized-QueryRCNN/output/t1/model_final.pth'], resume=False)
[03/08 14:08:19 detectron2]: Contents of args.config_file=projects/Featurized-QueryRCNN/configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/08 14:08:19 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: projects/Featurized-QueryRCNN/output/t1/model_final.pth
OUTPUT_DIR: projects/Featurized-QueryRCNN/output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NMS_THRESHOLD: 0.6
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  USE_NMS: true
VERSION: 2
VIS_PERIOD: 0

[03/08 14:08:19 detectron2]: Full config saved to projects/Featurized-QueryRCNN/output/t1/config.yaml
[03/08 14:08:20 d2.engine.defaults]: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[03/08 14:08:20 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from projects/Featurized-QueryRCNN/output/t1/model_final.pth ...
[03/08 14:08:20 fvcore.common.checkpoint]: [Checkpointer] Loading from projects/Featurized-QueryRCNN/output/t1/model_final.pth ...
[03/08 14:08:22 d2.data.build]: Known classes: range(0, 20)
[03/08 14:08:22 d2.data.build]: Labelling known instances the corresponding label, and unknown instances as unknown...
[03/08 14:08:22 d2.data.build]: Distribution of instances among all 81 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |
[03/08 14:08:22 d2.data.build]: Number of datapoints: 10246
[03/08 14:08:22 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/08 14:08:22 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/08 14:08:22 d2.data.common]: Serializing 10246 elements to byte tensors and concatenating them all ...
[03/08 14:08:22 d2.data.common]: Serialized dataset takes 6.49 MiB
[03/08 14:08:22 d2.evaluation.evaluator]: Start inference on 5123 batches
[03/08 14:08:25 d2.evaluation.evaluator]: Inference done 11/5123. Dataloading: 0.0009 s/iter. Inference: 0.0373 s/iter. Eval: 0.0007 s/iter. Total: 0.0389 s/iter. ETA=0:03:18
[03/08 14:08:30 d2.evaluation.evaluator]: Inference done 151/5123. Dataloading: 0.0013 s/iter. Inference: 0.0339 s/iter. Eval: 0.0007 s/iter. Total: 0.0360 s/iter. ETA=0:02:58
[03/08 14:08:35 d2.evaluation.evaluator]: Inference done 286/5123. Dataloading: 0.0013 s/iter. Inference: 0.0344 s/iter. Eval: 0.0007 s/iter. Total: 0.0365 s/iter. ETA=0:02:56
[03/08 14:08:40 d2.evaluation.evaluator]: Inference done 426/5123. Dataloading: 0.0013 s/iter. Inference: 0.0343 s/iter. Eval: 0.0007 s/iter. Total: 0.0363 s/iter. ETA=0:02:50
[03/08 14:08:45 d2.evaluation.evaluator]: Inference done 565/5123. Dataloading: 0.0013 s/iter. Inference: 0.0342 s/iter. Eval: 0.0007 s/iter. Total: 0.0363 s/iter. ETA=0:02:45
[03/08 14:08:50 d2.evaluation.evaluator]: Inference done 702/5123. Dataloading: 0.0013 s/iter. Inference: 0.0342 s/iter. Eval: 0.0007 s/iter. Total: 0.0363 s/iter. ETA=0:02:40
[03/08 14:08:55 d2.evaluation.evaluator]: Inference done 843/5123. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:02:35
[03/08 14:09:00 d2.evaluation.evaluator]: Inference done 984/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:02:29
[03/08 14:09:05 d2.evaluation.evaluator]: Inference done 1124/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:02:24
[03/08 14:09:10 d2.evaluation.evaluator]: Inference done 1264/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:02:19
[03/08 14:09:15 d2.evaluation.evaluator]: Inference done 1404/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:02:14
[03/08 14:09:20 d2.evaluation.evaluator]: Inference done 1546/5123. Dataloading: 0.0013 s/iter. Inference: 0.0339 s/iter. Eval: 0.0007 s/iter. Total: 0.0360 s/iter. ETA=0:02:08
[03/08 14:09:25 d2.evaluation.evaluator]: Inference done 1682/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:02:04
[03/08 14:09:30 d2.evaluation.evaluator]: Inference done 1821/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:59
[03/08 14:09:35 d2.evaluation.evaluator]: Inference done 1961/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:54
[03/08 14:09:40 d2.evaluation.evaluator]: Inference done 2099/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:49
[03/08 14:09:45 d2.evaluation.evaluator]: Inference done 2239/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:44
[03/08 14:09:50 d2.evaluation.evaluator]: Inference done 2380/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:38
[03/08 14:09:55 d2.evaluation.evaluator]: Inference done 2515/5123. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:34
[03/08 14:10:00 d2.evaluation.evaluator]: Inference done 2653/5123. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:29
[03/08 14:10:05 d2.evaluation.evaluator]: Inference done 2793/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:24
[03/08 14:10:10 d2.evaluation.evaluator]: Inference done 2932/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:19
[03/08 14:10:15 d2.evaluation.evaluator]: Inference done 3072/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:14
[03/08 14:10:20 d2.evaluation.evaluator]: Inference done 3211/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:08
[03/08 14:10:25 d2.evaluation.evaluator]: Inference done 3352/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:01:03
[03/08 14:10:30 d2.evaluation.evaluator]: Inference done 3488/5123. Dataloading: 0.0013 s/iter. Inference: 0.0340 s/iter. Eval: 0.0007 s/iter. Total: 0.0361 s/iter. ETA=0:00:59
[03/08 14:10:35 d2.evaluation.evaluator]: Inference done 3620/5123. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:54
[03/08 14:10:40 d2.evaluation.evaluator]: Inference done 3754/5123. Dataloading: 0.0013 s/iter. Inference: 0.0342 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:49
[03/08 14:10:45 d2.evaluation.evaluator]: Inference done 3888/5123. Dataloading: 0.0013 s/iter. Inference: 0.0342 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:44
[03/08 14:10:50 d2.evaluation.evaluator]: Inference done 4027/5123. Dataloading: 0.0013 s/iter. Inference: 0.0342 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:39
[03/08 14:10:55 d2.evaluation.evaluator]: Inference done 4167/5123. Dataloading: 0.0013 s/iter. Inference: 0.0342 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:34
[03/08 14:11:00 d2.evaluation.evaluator]: Inference done 4306/5123. Dataloading: 0.0013 s/iter. Inference: 0.0342 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:29
[03/08 14:11:05 d2.evaluation.evaluator]: Inference done 4446/5123. Dataloading: 0.0013 s/iter. Inference: 0.0342 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:24
[03/08 14:11:10 d2.evaluation.evaluator]: Inference done 4587/5123. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:19
[03/08 14:11:15 d2.evaluation.evaluator]: Inference done 4725/5123. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:14
[03/08 14:11:20 d2.evaluation.evaluator]: Inference done 4865/5123. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:09
[03/08 14:11:25 d2.evaluation.evaluator]: Inference done 5003/5123. Dataloading: 0.0013 s/iter. Inference: 0.0341 s/iter. Eval: 0.0007 s/iter. Total: 0.0362 s/iter. ETA=0:00:04
[03/08 14:11:30 d2.evaluation.evaluator]: Total inference time: 0:03:05.826430 (0.036308 s / iter per device, on 2 devices)
[03/08 14:11:30 d2.evaluation.evaluator]: Total inference pure compute time: 0:02:54 (0.034176 s / iter per device, on 2 devices)
/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 0
/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 1
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 2 nodes.
INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:3 with 2 nodes.
[03/08 14:11:31 d2.evaluation.pascal_voc_evaluation]: Evaluating voc_coco_2007_test using 2012 metric. Note that results do not use the official Matlab API.
[03/08 14:11:31 d2.evaluation.pascal_voc_evaluation]: aeroplane has 11223 predictions.
[03/08 14:11:32 d2.evaluation.pascal_voc_evaluation]: bicycle has 13124 predictions.
[03/08 14:11:33 d2.evaluation.pascal_voc_evaluation]: bird has 24714 predictions.
[03/08 14:11:34 d2.evaluation.pascal_voc_evaluation]: boat has 20481 predictions.
[03/08 14:11:34 d2.evaluation.pascal_voc_evaluation]: bottle has 46241 predictions.
[03/08 14:11:36 d2.evaluation.pascal_voc_evaluation]: bus has 10997 predictions.
[03/08 14:11:36 d2.evaluation.pascal_voc_evaluation]: car has 49190 predictions.
[03/08 14:11:38 d2.evaluation.pascal_voc_evaluation]: cat has 9232 predictions.
[03/08 14:11:38 d2.evaluation.pascal_voc_evaluation]: chair has 67377 predictions.
[03/08 14:11:40 d2.evaluation.pascal_voc_evaluation]: cow has 7893 predictions.
[03/08 14:11:41 d2.evaluation.pascal_voc_evaluation]: diningtable has 20930 predictions.
[03/08 14:11:42 d2.evaluation.pascal_voc_evaluation]: dog has 14790 predictions.
[03/08 14:11:42 d2.evaluation.pascal_voc_evaluation]: horse has 10968 predictions.
[03/08 14:11:43 d2.evaluation.pascal_voc_evaluation]: motorbike has 10468 predictions.
[03/08 14:11:43 d2.evaluation.pascal_voc_evaluation]: person has 120786 predictions.
[03/08 14:11:48 d2.evaluation.pascal_voc_evaluation]: pottedplant has 30906 predictions.
[03/08 14:11:49 d2.evaluation.pascal_voc_evaluation]: sheep has 9107 predictions.
[03/08 14:11:49 d2.evaluation.pascal_voc_evaluation]: sofa has 16184 predictions.
[03/08 14:11:50 d2.evaluation.pascal_voc_evaluation]: train has 14584 predictions.
[03/08 14:11:50 d2.evaluation.pascal_voc_evaluation]: tvmonitor has 24776 predictions.
[03/08 14:11:51 d2.evaluation.pascal_voc_evaluation]: truck has 1 predictions.
[03/08 14:11:51 d2.evaluation.pascal_voc_evaluation]: traffic light has 1 predictions.
[03/08 14:11:51 d2.evaluation.pascal_voc_evaluation]: fire hydrant has 1 predictions.
[03/08 14:11:52 d2.evaluation.pascal_voc_evaluation]: stop sign has 1 predictions.
[03/08 14:11:52 d2.evaluation.pascal_voc_evaluation]: parking meter has 1 predictions.
[03/08 14:11:52 d2.evaluation.pascal_voc_evaluation]: bench has 1 predictions.
[03/08 14:11:52 d2.evaluation.pascal_voc_evaluation]: elephant has 1 predictions.
[03/08 14:11:53 d2.evaluation.pascal_voc_evaluation]: bear has 1 predictions.
[03/08 14:11:53 d2.evaluation.pascal_voc_evaluation]: zebra has 1 predictions.
[03/08 14:11:53 d2.evaluation.pascal_voc_evaluation]: giraffe has 1 predictions.
[03/08 14:11:53 d2.evaluation.pascal_voc_evaluation]: backpack has 1 predictions.
[03/08 14:11:53 d2.evaluation.pascal_voc_evaluation]: umbrella has 1 predictions.
[03/08 14:11:54 d2.evaluation.pascal_voc_evaluation]: handbag has 1 predictions.
[03/08 14:11:54 d2.evaluation.pascal_voc_evaluation]: tie has 1 predictions.
[03/08 14:11:54 d2.evaluation.pascal_voc_evaluation]: suitcase has 1 predictions.
[03/08 14:11:54 d2.evaluation.pascal_voc_evaluation]: microwave has 1 predictions.
[03/08 14:11:55 d2.evaluation.pascal_voc_evaluation]: oven has 1 predictions.
[03/08 14:11:55 d2.evaluation.pascal_voc_evaluation]: toaster has 1 predictions.
[03/08 14:11:55 d2.evaluation.pascal_voc_evaluation]: sink has 1 predictions.
[03/08 14:11:55 d2.evaluation.pascal_voc_evaluation]: refrigerator has 1 predictions.
[03/08 14:11:55 d2.evaluation.pascal_voc_evaluation]: frisbee has 1 predictions.
[03/08 14:11:56 d2.evaluation.pascal_voc_evaluation]: skis has 1 predictions.
[03/08 14:11:56 d2.evaluation.pascal_voc_evaluation]: snowboard has 1 predictions.
[03/08 14:11:56 d2.evaluation.pascal_voc_evaluation]: sports ball has 1 predictions.
[03/08 14:11:56 d2.evaluation.pascal_voc_evaluation]: kite has 1 predictions.
[03/08 14:11:57 d2.evaluation.pascal_voc_evaluation]: baseball bat has 1 predictions.
[03/08 14:11:57 d2.evaluation.pascal_voc_evaluation]: baseball glove has 1 predictions.
[03/08 14:11:57 d2.evaluation.pascal_voc_evaluation]: skateboard has 6 predictions.
[03/08 14:11:57 d2.evaluation.pascal_voc_evaluation]: surfboard has 1 predictions.
[03/08 14:11:57 d2.evaluation.pascal_voc_evaluation]: tennis racket has 1 predictions.
[03/08 14:11:58 d2.evaluation.pascal_voc_evaluation]: banana has 1 predictions.
[03/08 14:11:58 d2.evaluation.pascal_voc_evaluation]: apple has 1 predictions.
[03/08 14:11:58 d2.evaluation.pascal_voc_evaluation]: sandwich has 1 predictions.
[03/08 14:11:58 d2.evaluation.pascal_voc_evaluation]: orange has 1 predictions.
[03/08 14:11:58 d2.evaluation.pascal_voc_evaluation]: broccoli has 1 predictions.
[03/08 14:11:59 d2.evaluation.pascal_voc_evaluation]: carrot has 1 predictions.
[03/08 14:11:59 d2.evaluation.pascal_voc_evaluation]: hot dog has 1 predictions.
[03/08 14:11:59 d2.evaluation.pascal_voc_evaluation]: pizza has 1 predictions.
[03/08 14:11:59 d2.evaluation.pascal_voc_evaluation]: donut has 1 predictions.
[03/08 14:12:00 d2.evaluation.pascal_voc_evaluation]: cake has 1 predictions.
[03/08 14:12:00 d2.evaluation.pascal_voc_evaluation]: bed has 1 predictions.
[03/08 14:12:00 d2.evaluation.pascal_voc_evaluation]: toilet has 1 predictions.
[03/08 14:12:00 d2.evaluation.pascal_voc_evaluation]: laptop has 1 predictions.
[03/08 14:12:01 d2.evaluation.pascal_voc_evaluation]: mouse has 1 predictions.
[03/08 14:12:01 d2.evaluation.pascal_voc_evaluation]: remote has 1 predictions.
[03/08 14:12:01 d2.evaluation.pascal_voc_evaluation]: keyboard has 1 predictions.
[03/08 14:12:01 d2.evaluation.pascal_voc_evaluation]: cell phone has 1 predictions.
[03/08 14:12:01 d2.evaluation.pascal_voc_evaluation]: book has 1 predictions.
[03/08 14:12:02 d2.evaluation.pascal_voc_evaluation]: clock has 1 predictions.
[03/08 14:12:02 d2.evaluation.pascal_voc_evaluation]: vase has 1 predictions.
[03/08 14:12:02 d2.evaluation.pascal_voc_evaluation]: scissors has 1 predictions.
[03/08 14:12:02 d2.evaluation.pascal_voc_evaluation]: teddy bear has 1 predictions.
[03/08 14:12:02 d2.evaluation.pascal_voc_evaluation]: hair drier has 1 predictions.
[03/08 14:12:03 d2.evaluation.pascal_voc_evaluation]: toothbrush has 1 predictions.
[03/08 14:12:03 d2.evaluation.pascal_voc_evaluation]: wine glass has 1 predictions.
[03/08 14:12:03 d2.evaluation.pascal_voc_evaluation]: cup has 1 predictions.
[03/08 14:12:03 d2.evaluation.pascal_voc_evaluation]: fork has 1 predictions.
[03/08 14:12:04 d2.evaluation.pascal_voc_evaluation]: knife has 1 predictions.
[03/08 14:12:04 d2.evaluation.pascal_voc_evaluation]: spoon has 1 predictions.
[03/08 14:12:04 d2.evaluation.pascal_voc_evaluation]: bowl has 3 predictions.
[03/08 14:12:04 d2.evaluation.pascal_voc_evaluation]: unknown has 1 predictions.
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: Wilderness Impact: {0.1: {50: 0.019163355924281374}, 0.2: {50: 0.027491408934707903}, 0.3: {50: 0.04013536780858517}, 0.4: {50: 0.05578289898772345}, 0.5: {50: 0.07129979802908923}, 0.6: {50: 0.06989566598110859}, 0.7: {50: 0.06233417919993398}, 0.8: {50: 0.061792929227027296}, 0.9: {50: 0.06530169439910927}}
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: avg_precision: {0.1: {50: 0}, 0.2: {50: 0}, 0.3: {50: 0}, 0.4: {50: 0}, 0.5: {50: 0}, 0.6: {50: 0}, 0.7: {50: 0}, 0.8: {50: 0}, 0.9: {50: 0}}
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: Absolute OSE (total_num_unk_det_as_known): {50: 34319.0}
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: total_num_unk 23320
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor', 'truck', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'bed', 'toilet', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'unknown']
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: AP50: ['81.5', '57.7', '58.6', '42.7', '25.4', '70.3', '58.0', '79.6', '20.7', '61.0', '15.8', '71.1', '74.7', '66.5', '49.1', '31.4', '65.9', '45.3', '79.7', '56.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', 'nan', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', 'nan', '0.0']
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: Precisions50: ['2.9', '3.6', '2.2', '1.8', '2.2', '3.1', '4.7', '5.2', '2.4', '3.7', '2.9', '4.2', '3.5', '4.2', '10.4', '2.2', '3.2', '2.7', '2.3', '2.1', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0']
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: Recall50: ['96.1', '73.0', '79.5', '77.1', '47.9', '88.7', '74.1', '93.9', '47.2', '93.5', '43.1', '94.4', '93.9', '81.0', '70.4', '71.5', '89.6', '81.3', '93.7', '82.1', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', 'nan', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', 'nan', '0.0']
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: Current class AP50: 55.5474604632261
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: Current class Precisions50: 3.476965566793514
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: Current class Recall50: 78.60232472309409
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: Known AP50: 55.5474604632261
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: Known Precisions50: 3.476965566793514
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: Known Recall50: 78.60232472309409
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: Unknown AP50: 0.0
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: Unknown Precisions50: 0
[03/08 14:12:06 d2.evaluation.pascal_voc_evaluation]: Unknown Recall50: 0
[03/08 14:12:06 d2.engine.defaults]: Evaluation results for voc_coco_2007_test in csv format:
[03/08 14:12:06 d2.evaluation.testing]: copypaste: Task: bbox
[03/08 14:12:06 d2.evaluation.testing]: copypaste: AP for all classes,AP50 for all classes
[03/08 14:12:06 d2.evaluation.testing]: copypaste: nan,nan
/data/wxf/algorithm_code/detectron2/detectron2/evaluation/pascal_voc_evaluation.py:469: RuntimeWarning: invalid value encountered in true_divide
  rec = tp / float(npos)
Command Line Args: Namespace(config_file='projects/Featurized-QueryRCNN/configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['OUTPUT_DIR', 'projects/Featurized-QueryRCNN/output/t1'], resume=False)
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 1
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 3
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 2
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 0
INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 3
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 2
INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 1
INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[03/08 14:22:58 detectron2]: Rank of current process: 0. World size: 4
[03/08 14:23:00 detectron2]: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/data/wxf/algorithm_code/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.94
CUDA_HOME               /usr/local/cuda-11.3
Pillow                  9.4.0
torchvision             0.11.0+cu111 @/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/08 14:23:00 detectron2]: Command line arguments: Namespace(config_file='projects/Featurized-QueryRCNN/configs/OW/t1_train.yaml', dist_url='tcp://127.0.0.1:50164', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['OUTPUT_DIR', 'projects/Featurized-QueryRCNN/output/t1'], resume=False)
[03/08 14:23:00 detectron2]: Contents of args.config_file=projects/Featurized-QueryRCNN/configs/OW/t1_train.yaml:
_BASE_: "queryrcnn.cascade.res50.100pro.3x.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  # WEIGHTS: "/data/yu/code/OW-DETR/dino_resnet50_pretrain.pth"
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
  SparseRCNN:
    NUM_PROPOSALS: 100
    # NUM_CLASSES: 21
    # TEST_TOPK: 100
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', ) # voc_coco_2007_test, t1_voc_coco_2007_test, t1_voc_coco_2007_val
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.00005
  STEPS: (36000, 48000)
  MAX_ITER: 54000
  WARMUP_ITERS: 200
OUTPUT_DIR: "./output/t1"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20

[03/08 14:23:00 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_coco_2007_test
  TRAIN:
  - t1_voc_coco_2007_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: QueryRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  QueryRCNN:
    RCNNHead: rcnnhead_wmha
    RPN:
      CLS_WEIGHT: 1.0
      FEAT_BRANCH: true
      FPN_STRIDES:
      - 8
      - 16
      - 32
      - 64
      - 128
      NUM_CLASSES: 1
      NUM_PROPOSALS: 100
      OJT_ALPHA: 0.2
      REG_WEIGHT: 2.0
      RPN_TYPE: anchor_free
      TOPK_INDICES: 1000
      USE_FOCAL: true
    WITH_POS: false
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SparseRCNN:
    ACTIVATION: relu
    ALPHA: 0.25
    BBOX_WEIGHTS:
    - 2.0
    - 2.0
    - 1.0
    - 1.0
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: true
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 80
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 2
    NUM_PROPOSALS: 100
    NUM_REG: 3
    PRIOR_PROB: 0.01
    USE_FOCAL: true
  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl
OUTPUT_DIR: projects/Featurized-QueryRCNN/output/t1
OWOD:
  CUR_INTRODUCED_CLS: 20
  ENERGY_SAVE_PATH: ''
  FEATURE_STORE_SAVE_PATH: ''
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: false
  TEMPERATURE: 1.5
SEED: 40244023
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 5.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 54000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 36000
  - 48000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    CVPODS_TTA: true
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 640
    - 700
    - 900
    - 1000
    - 1100
    - 1200
    - 1300
    - 1400
    - 1800
    - 800
    SCALE_FILTER: true
    SCALE_RANGES:
    - - 96
      - 10000
    - - 96
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 64
      - 10000
    - - 0
      - 10000
    - - 0
      - 10000
    - - 0
      - 256
    - - 0
      - 256
    - - 0
      - 192
    - - 0
      - 192
    - - 0
      - 96
    - - 0
      - 10000
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NMS_THRESHOLD: 0.6
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  USE_NMS: true
VERSION: 2
VIS_PERIOD: 0

[03/08 14:23:00 detectron2]: Full config saved to projects/Featurized-QueryRCNN/output/t1/config.yaml
INFO:queryrcnn.dataset_mapper:TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice')]
INFO:queryrcnn.dataset_mapper:Full TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice')], crop: None
[03/08 14:23:01 d2.engine.defaults]: Model:
QueryRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (rpn_head): QGN(
    (rpn_head): StaRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (proposal_feats): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
  )
  (head): DynamicHead(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (head_series): ModuleList(
      (0): RCNNHead(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
      (1): RCNNHeadWMHA(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (inst_interact): DynamicConv(
          (dynamic_layer): Linear(in_features=256, out_features=32768, bias=True)
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (activation): ReLU(inplace=True)
          (out_layer): Linear(in_features=12544, out_features=256, bias=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.0, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.0, inplace=False)
        (dropout4): Dropout(p=0.0, inplace=False)
        (self_attn_post): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (cls_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (reg_module): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=False)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=256, out_features=256, bias=False)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): ReLU(inplace=True)
          (6): Linear(in_features=256, out_features=256, bias=False)
          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (8): ReLU(inplace=True)
        )
        (class_logits): Linear(in_features=256, out_features=80, bias=True)
        (bboxes_delta): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
INFO:queryrcnn.dataset_mapper:TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice')]
INFO:queryrcnn.dataset_mapper:Full TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice')], crop: None
INFO:queryrcnn.dataset_mapper:TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice')]
INFO:queryrcnn.dataset_mapper:Full TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice')], crop: None
INFO:queryrcnn.dataset_mapper:TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice')]
INFO:queryrcnn.dataset_mapper:Full TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice')], crop: None
[03/08 14:23:03 d2.data.build]: Valid classes: range(0, 20)
[03/08 14:23:03 d2.data.build]: Removing earlier seen class objects and the unknown objects...
[03/08 14:23:03 d2.data.build]: Distribution of instances among all 81 categories:
|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 1285         |    bicycle    | 1208         |    bird    | 1820         |
|     boat      | 1397         |    bottle     | 2116         |    bus     | 909          |
|      car      | 4008         |      cat      | 1616         |   chair    | 4338         |
|      cow      | 1058         |  diningtable  | 1057         |    dog     | 2079         |
|     horse     | 1156         |   motorbike   | 1141         |   person   | 15576        |
|  pottedplant  | 1724         |     sheep     | 1347         |    sofa    | 1211         |
|     train     | 984          |   tvmonitor   | 1193         |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 47223        |               |              |            |              |
[03/08 14:23:03 d2.data.build]: Number of datapoints: 16551
[03/08 14:23:03 d2.data.build]: Using training sampler TrainingSampler
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 0
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 1
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 3
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 2
INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:3 with 4 nodes.
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 4 nodes.
INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:3 with 4 nodes.
INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:3 with 4 nodes.
[03/08 14:23:03 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/08 14:23:03 d2.data.common]: Serializing 16551 elements to byte tensors and concatenating them all ...
[03/08 14:23:04 d2.data.common]: Serialized dataset takes 7.81 MiB
INFO:iopath.common.file_io:URL https://dl.fbaipublicfiles.com/detectron2/ImageNetPretrained/torchvision/R-50.pkl cached in /home/wxf/.torch/iopath_cache/detectron2/ImageNetPretrained/torchvision/R-50.pkl
INFO:iopath.common.file_io:URL https://dl.fbaipublicfiles.com/detectron2/ImageNetPretrained/torchvision/R-50.pkl cached in /home/wxf/.torch/iopath_cache/detectron2/ImageNetPretrained/torchvision/R-50.pkl
INFO:iopath.common.file_io:URL https://dl.fbaipublicfiles.com/detectron2/ImageNetPretrained/torchvision/R-50.pkl cached in /home/wxf/.torch/iopath_cache/detectron2/ImageNetPretrained/torchvision/R-50.pkl
[03/08 14:23:04 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
INFO:iopath.common.file_io:URL https://dl.fbaipublicfiles.com/detectron2/ImageNetPretrained/torchvision/R-50.pkl cached in /home/wxf/.torch/iopath_cache/detectron2/ImageNetPretrained/torchvision/R-50.pkl
[03/08 14:23:04 fvcore.common.checkpoint]: [Checkpointer] Loading from /home/wxf/.torch/iopath_cache/detectron2/ImageNetPretrained/torchvision/R-50.pkl ...
[03/08 14:23:04 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[03/08 14:23:04 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
WARNING [03/08 14:23:04 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
backbone.fpn_lateral2.{bias, weight}
backbone.fpn_lateral3.{bias, weight}
backbone.fpn_lateral4.{bias, weight}
backbone.fpn_lateral5.{bias, weight}
backbone.fpn_output2.{bias, weight}
backbone.fpn_output3.{bias, weight}
backbone.fpn_output4.{bias, weight}
backbone.fpn_output5.{bias, weight}
backbone.top_block.p6.{bias, weight}
backbone.top_block.p7.{bias, weight}
head.head_series.0.bboxes_delta.{bias, weight}
head.head_series.0.class_logits.{bias, weight}
head.head_series.0.cls_module.0.weight
head.head_series.0.cls_module.1.{bias, weight}
head.head_series.0.inst_interact.dynamic_layer.{bias, weight}
head.head_series.0.inst_interact.norm1.{bias, weight}
head.head_series.0.inst_interact.norm2.{bias, weight}
head.head_series.0.inst_interact.norm3.{bias, weight}
head.head_series.0.inst_interact.out_layer.{bias, weight}
head.head_series.0.linear1.{bias, weight}
head.head_series.0.linear2.{bias, weight}
head.head_series.0.norm1.{bias, weight}
head.head_series.0.norm2.{bias, weight}
head.head_series.0.norm3.{bias, weight}
head.head_series.0.reg_module.0.weight
head.head_series.0.reg_module.1.{bias, weight}
head.head_series.0.reg_module.3.weight
head.head_series.0.reg_module.4.{bias, weight}
head.head_series.0.reg_module.6.weight
head.head_series.0.reg_module.7.{bias, weight}
head.head_series.0.self_attn.out_proj.{bias, weight}
head.head_series.0.self_attn.{in_proj_bias, in_proj_weight}
head.head_series.1.bboxes_delta.{bias, weight}
head.head_series.1.class_logits.{bias, weight}
head.head_series.1.cls_module.0.weight
head.head_series.1.cls_module.1.{bias, weight}
head.head_series.1.inst_interact.dynamic_layer.{bias, weight}
head.head_series.1.inst_interact.norm1.{bias, weight}
head.head_series.1.inst_interact.norm2.{bias, weight}
head.head_series.1.inst_interact.norm3.{bias, weight}
head.head_series.1.inst_interact.out_layer.{bias, weight}
head.head_series.1.linear1.{bias, weight}
head.head_series.1.linear2.{bias, weight}
head.head_series.1.norm1.{bias, weight}
head.head_series.1.norm2.{bias, weight}
head.head_series.1.norm3.{bias, weight}
head.head_series.1.norm4.{bias, weight}
head.head_series.1.reg_module.0.weight
head.head_series.1.reg_module.1.{bias, weight}
head.head_series.1.reg_module.3.weight
head.head_series.1.reg_module.4.{bias, weight}
head.head_series.1.reg_module.6.weight
head.head_series.1.reg_module.7.{bias, weight}
head.head_series.1.self_attn.out_proj.{bias, weight}
head.head_series.1.self_attn.{in_proj_bias, in_proj_weight}
head.head_series.1.self_attn_post.out_proj.{bias, weight}
head.head_series.1.self_attn_post.{in_proj_bias, in_proj_weight}
rpn_head.rpn_head.anchor_deltas.{bias, weight}
rpn_head.rpn_head.conv.{bias, weight}
rpn_head.rpn_head.objectness_logits.{bias, weight}
rpn_head.rpn_head.proposal_feats.{bias, weight}
rpn_head.rpn_head.scales.0.scale
rpn_head.rpn_head.scales.1.scale
rpn_head.rpn_head.scales.2.scale
rpn_head.rpn_head.scales.3.scale
rpn_head.rpn_head.scales.4.scale
WARNING [03/08 14:23:04 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  stem.fc.{bias, weight}
[03/08 14:23:04 d2.engine.train_loop]: Starting training from iteration 0
/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
INFO:root:Reducer buckets have been rebuilt in this iteration.
/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
INFO:root:Reducer buckets have been rebuilt in this iteration.
/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
INFO:root:Reducer buckets have been rebuilt in this iteration.
/home/wxf/.conda/envs/qrcnn/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
INFO:root:Reducer buckets have been rebuilt in this iteration.
[03/08 14:23:17 d2.utils.events]:  eta: 8:09:31  iter: 19  total_loss: 19.21  loss_ce: 1.816  loss_giou: 2.089  loss_bbox: 4.171  loss_ce_0: 1.846  loss_giou_0: 2.092  loss_bbox_0: 4.157  loss_rpn_cls: 1.132  loss_rpn_reg: 1.999  time: 0.5487  last_time: 0.6270  data_time: 0.1421  last_data_time: 0.0073   lr: 5.2025e-06  max_mem: 2838M
[03/08 14:23:26 d2.utils.events]:  eta: 8:00:41  iter: 39  total_loss: 18.24  loss_ce: 1.532  loss_giou: 2.109  loss_bbox: 3.876  loss_ce_0: 1.533  loss_giou_0: 2.094  loss_bbox_0: 4.007  loss_rpn_cls: 1.128  loss_rpn_reg: 1.999  time: 0.4872  last_time: 0.2245  data_time: 0.0138  last_data_time: 0.0128   lr: 1.0152e-05  max_mem: 2986M
[03/08 14:23:31 d2.utils.events]:  eta: 7:28:34  iter: 59  total_loss: 16.95  loss_ce: 1.43  loss_giou: 2.163  loss_bbox: 2.607  loss_ce_0: 1.449  loss_giou_0: 2.061  loss_bbox_0: 4.15  loss_rpn_cls: 1.124  loss_rpn_reg: 1.999  time: 0.4012  last_time: 0.2276  data_time: 0.0128  last_data_time: 0.0136   lr: 1.5102e-05  max_mem: 2986M
[03/08 14:23:36 d2.utils.events]:  eta: 3:49:22  iter: 79  total_loss: 14.77  loss_ce: 1.475  loss_giou: 1.693  loss_bbox: 2.014  loss_ce_0: 1.487  loss_giou_0: 2.156  loss_bbox_0: 2.554  loss_rpn_cls: 1.116  loss_rpn_reg: 1.999  time: 0.3599  last_time: 0.2292  data_time: 0.0124  last_data_time: 0.0041   lr: 2.0053e-05  max_mem: 2986M
[03/08 14:23:40 d2.utils.events]:  eta: 3:41:34  iter: 99  total_loss: 13.28  loss_ce: 1.569  loss_giou: 1.473  loss_bbox: 1.839  loss_ce_0: 1.507  loss_giou_0: 1.59  loss_bbox_0: 1.882  loss_rpn_cls: 1.093  loss_rpn_reg: 1.997  time: 0.3333  last_time: 0.2397  data_time: 0.0139  last_data_time: 0.0233   lr: 2.5002e-05  max_mem: 2986M
[03/08 14:23:45 d2.utils.events]:  eta: 3:42:16  iter: 119  total_loss: 12.63  loss_ce: 1.584  loss_giou: 1.588  loss_bbox: 1.966  loss_ce_0: 1.508  loss_giou_0: 1.373  loss_bbox_0: 1.744  loss_rpn_cls: 1.056  loss_rpn_reg: 1.996  time: 0.3188  last_time: 0.2471  data_time: 0.0116  last_data_time: 0.0055   lr: 2.9953e-05  max_mem: 2986M
[03/08 14:23:50 d2.utils.events]:  eta: 3:40:44  iter: 139  total_loss: 12.13  loss_ce: 1.609  loss_giou: 1.251  loss_bbox: 1.849  loss_ce_0: 1.506  loss_giou_0: 1.169  loss_bbox_0: 1.605  loss_rpn_cls: 0.967  loss_rpn_reg: 1.991  time: 0.3071  last_time: 0.2438  data_time: 0.0147  last_data_time: 0.0057   lr: 3.4902e-05  max_mem: 2986M
[03/08 14:23:55 d2.utils.events]:  eta: 3:40:08  iter: 159  total_loss: 11.96  loss_ce: 1.577  loss_giou: 1.381  loss_bbox: 1.734  loss_ce_0: 1.489  loss_giou_0: 1.348  loss_bbox_0: 1.845  loss_rpn_cls: 0.5675  loss_rpn_reg: 1.791  time: 0.2987  last_time: 0.2511  data_time: 0.0142  last_data_time: 0.0219   lr: 3.9852e-05  max_mem: 2986M
[03/08 14:24:00 d2.utils.events]:  eta: 3:39:36  iter: 179  total_loss: 10.41  loss_ce: 1.515  loss_giou: 1.211  loss_bbox: 1.677  loss_ce_0: 1.496  loss_giou_0: 1.209  loss_bbox_0: 1.657  loss_rpn_cls: 0.4851  loss_rpn_reg: 1.252  time: 0.2918  last_time: 0.2508  data_time: 0.0121  last_data_time: 0.0037   lr: 4.4802e-05  max_mem: 3035M
[03/08 14:24:05 d2.utils.events]:  eta: 3:38:26  iter: 199  total_loss: 9.711  loss_ce: 1.397  loss_giou: 1.272  loss_bbox: 1.496  loss_ce_0: 1.378  loss_giou_0: 1.197  loss_bbox_0: 1.343  loss_rpn_cls: 0.5614  loss_rpn_reg: 1.112  time: 0.2859  last_time: 0.2412  data_time: 0.0147  last_data_time: 0.0044   lr: 4.9752e-05  max_mem: 3035M
[03/08 14:24:09 d2.utils.events]:  eta: 3:38:21  iter: 219  total_loss: 10.51  loss_ce: 1.451  loss_giou: 1.278  loss_bbox: 1.765  loss_ce_0: 1.467  loss_giou_0: 1.207  loss_bbox_0: 1.623  loss_rpn_cls: 0.5928  loss_rpn_reg: 0.996  time: 0.2814  last_time: 0.2475  data_time: 0.0152  last_data_time: 0.0075   lr: 5e-05  max_mem: 3035M
[03/08 14:24:14 d2.utils.events]:  eta: 3:37:36  iter: 239  total_loss: 9.891  loss_ce: 1.457  loss_giou: 1.272  loss_bbox: 1.704  loss_ce_0: 1.368  loss_giou_0: 1.126  loss_bbox_0: 1.386  loss_rpn_cls: 0.5654  loss_rpn_reg: 0.9767  time: 0.2778  last_time: 0.2476  data_time: 0.0164  last_data_time: 0.0077   lr: 5e-05  max_mem: 3035M
[03/08 14:24:19 d2.utils.events]:  eta: 3:37:22  iter: 259  total_loss: 8.838  loss_ce: 1.371  loss_giou: 1.113  loss_bbox: 1.245  loss_ce_0: 1.307  loss_giou_0: 1.087  loss_bbox_0: 1.146  loss_rpn_cls: 0.5395  loss_rpn_reg: 0.8863  time: 0.2748  last_time: 0.2355  data_time: 0.0143  last_data_time: 0.0130   lr: 5e-05  max_mem: 3035M
[03/08 14:24:24 d2.utils.events]:  eta: 3:36:44  iter: 279  total_loss: 8.643  loss_ce: 1.379  loss_giou: 1.042  loss_bbox: 1.335  loss_ce_0: 1.336  loss_giou_0: 0.9252  loss_bbox_0: 1.154  loss_rpn_cls: 0.5461  loss_rpn_reg: 0.8561  time: 0.2717  last_time: 0.2160  data_time: 0.0131  last_data_time: 0.0069   lr: 5e-05  max_mem: 3035M
[03/08 14:24:28 d2.utils.events]:  eta: 3:35:58  iter: 299  total_loss: 8.276  loss_ce: 1.437  loss_giou: 0.9991  loss_bbox: 1.091  loss_ce_0: 1.425  loss_giou_0: 0.9197  loss_bbox_0: 1.011  loss_rpn_cls: 0.5527  loss_rpn_reg: 0.7934  time: 0.2692  last_time: 0.2310  data_time: 0.0136  last_data_time: 0.0213   lr: 5e-05  max_mem: 3035M
[03/08 14:24:33 d2.utils.events]:  eta: 3:35:06  iter: 319  total_loss: 8.215  loss_ce: 1.363  loss_giou: 1.023  loss_bbox: 1.201  loss_ce_0: 1.323  loss_giou_0: 0.9572  loss_bbox_0: 1.065  loss_rpn_cls: 0.5809  loss_rpn_reg: 0.7728  time: 0.2669  last_time: 0.2137  data_time: 0.0092  last_data_time: 0.0248   lr: 5e-05  max_mem: 3035M
[03/08 14:24:38 d2.utils.events]:  eta: 3:34:46  iter: 339  total_loss: 8.185  loss_ce: 1.365  loss_giou: 0.9646  loss_bbox: 1.105  loss_ce_0: 1.34  loss_giou_0: 0.9349  loss_bbox_0: 1.06  loss_rpn_cls: 0.5455  loss_rpn_reg: 0.7692  time: 0.2650  last_time: 0.2531  data_time: 0.0134  last_data_time: 0.0144   lr: 5e-05  max_mem: 3035M
[03/08 14:24:43 d2.utils.events]:  eta: 3:34:34  iter: 359  total_loss: 8.295  loss_ce: 1.3  loss_giou: 1.1  loss_bbox: 1.24  loss_ce_0: 1.285  loss_giou_0: 1.03  loss_bbox_0: 1.135  loss_rpn_cls: 0.5689  loss_rpn_reg: 0.8222  time: 0.2635  last_time: 0.2265  data_time: 0.0137  last_data_time: 0.0114   lr: 5e-05  max_mem: 3035M
[03/08 14:24:48 d2.utils.events]:  eta: 3:34:05  iter: 379  total_loss: 8.233  loss_ce: 1.316  loss_giou: 1.027  loss_bbox: 1.25  loss_ce_0: 1.265  loss_giou_0: 0.9533  loss_bbox_0: 1.105  loss_rpn_cls: 0.5167  loss_rpn_reg: 0.7955  time: 0.2621  last_time: 0.2451  data_time: 0.0158  last_data_time: 0.0286   lr: 5e-05  max_mem: 3035M
[03/08 14:24:53 d2.utils.events]:  eta: 3:34:07  iter: 399  total_loss: 7.908  loss_ce: 1.343  loss_giou: 1.028  loss_bbox: 1.071  loss_ce_0: 1.304  loss_giou_0: 0.9125  loss_bbox_0: 0.9726  loss_rpn_cls: 0.4953  loss_rpn_reg: 0.7844  time: 0.2611  last_time: 0.2517  data_time: 0.0145  last_data_time: 0.0057   lr: 5e-05  max_mem: 3035M
[03/08 14:24:57 d2.utils.events]:  eta: 3:34:20  iter: 419  total_loss: 8.316  loss_ce: 1.325  loss_giou: 1.093  loss_bbox: 1.309  loss_ce_0: 1.277  loss_giou_0: 0.9828  loss_bbox_0: 1.095  loss_rpn_cls: 0.5501  loss_rpn_reg: 0.784  time: 0.2602  last_time: 0.2502  data_time: 0.0146  last_data_time: 0.0115   lr: 5e-05  max_mem: 3035M
[03/08 14:25:02 d2.utils.events]:  eta: 3:34:31  iter: 439  total_loss: 7.612  loss_ce: 1.327  loss_giou: 0.9027  loss_bbox: 1.098  loss_ce_0: 1.293  loss_giou_0: 0.803  loss_bbox_0: 0.9484  loss_rpn_cls: 0.5082  loss_rpn_reg: 0.7607  time: 0.2593  last_time: 0.2200  data_time: 0.0111  last_data_time: 0.0220   lr: 5e-05  max_mem: 3035M
[03/08 14:25:07 d2.utils.events]:  eta: 3:34:10  iter: 459  total_loss: 7.552  loss_ce: 1.298  loss_giou: 0.9369  loss_bbox: 0.9621  loss_ce_0: 1.259  loss_giou_0: 0.9255  loss_bbox_0: 0.9374  loss_rpn_cls: 0.5296  loss_rpn_reg: 0.7766  time: 0.2583  last_time: 0.2288  data_time: 0.0104  last_data_time: 0.0065   lr: 5e-05  max_mem: 3035M
[03/08 14:25:12 d2.utils.events]:  eta: 3:33:55  iter: 479  total_loss: 8.129  loss_ce: 1.274  loss_giou: 1.041  loss_bbox: 1.187  loss_ce_0: 1.248  loss_giou_0: 0.989  loss_bbox_0: 1.074  loss_rpn_cls: 0.5159  loss_rpn_reg: 0.7902  time: 0.2574  last_time: 0.2515  data_time: 0.0130  last_data_time: 0.0099   lr: 5e-05  max_mem: 3035M
[03/08 14:25:17 d2.utils.events]:  eta: 3:33:36  iter: 499  total_loss: 7.158  loss_ce: 1.269  loss_giou: 0.8294  loss_bbox: 0.8708  loss_ce_0: 1.23  loss_giou_0: 0.8234  loss_bbox_0: 0.8723  loss_rpn_cls: 0.5002  loss_rpn_reg: 0.7547  time: 0.2565  last_time: 0.2486  data_time: 0.0130  last_data_time: 0.0212   lr: 5e-05  max_mem: 3035M
[03/08 14:25:21 d2.utils.events]:  eta: 3:33:25  iter: 519  total_loss: 7.652  loss_ce: 1.262  loss_giou: 0.8711  loss_bbox: 1.029  loss_ce_0: 1.204  loss_giou_0: 0.829  loss_bbox_0: 0.9879  loss_rpn_cls: 0.5076  loss_rpn_reg: 0.7499  time: 0.2558  last_time: 0.2431  data_time: 0.0116  last_data_time: 0.0040   lr: 5e-05  max_mem: 3035M
[03/08 14:25:26 d2.utils.events]:  eta: 3:32:35  iter: 539  total_loss: 7.849  loss_ce: 1.275  loss_giou: 0.9538  loss_bbox: 1.137  loss_ce_0: 1.244  loss_giou_0: 0.8786  loss_bbox_0: 1.075  loss_rpn_cls: 0.5376  loss_rpn_reg: 0.7774  time: 0.2549  last_time: 0.2442  data_time: 0.0109  last_data_time: 0.0204   lr: 5e-05  max_mem: 3035M
[03/08 14:25:31 d2.utils.events]:  eta: 3:32:50  iter: 559  total_loss: 7.483  loss_ce: 1.272  loss_giou: 0.9162  loss_bbox: 1.063  loss_ce_0: 1.249  loss_giou_0: 0.8147  loss_bbox_0: 0.9283  loss_rpn_cls: 0.5098  loss_rpn_reg: 0.734  time: 0.2543  last_time: 0.2488  data_time: 0.0164  last_data_time: 0.0191   lr: 5e-05  max_mem: 3035M
[03/08 14:25:36 d2.utils.events]:  eta: 3:33:00  iter: 579  total_loss: 7.535  loss_ce: 1.238  loss_giou: 0.9753  loss_bbox: 1.041  loss_ce_0: 1.175  loss_giou_0: 0.9186  loss_bbox_0: 0.9133  loss_rpn_cls: 0.5302  loss_rpn_reg: 0.7708  time: 0.2538  last_time: 0.2319  data_time: 0.0108  last_data_time: 0.0109   lr: 5e-05  max_mem: 3035M
[03/08 14:25:41 d2.utils.events]:  eta: 3:32:42  iter: 599  total_loss: 7.477  loss_ce: 1.259  loss_giou: 0.9285  loss_bbox: 1.091  loss_ce_0: 1.2  loss_giou_0: 0.9269  loss_bbox_0: 1.004  loss_rpn_cls: 0.5482  loss_rpn_reg: 0.743  time: 0.2532  last_time: 0.2454  data_time: 0.0111  last_data_time: 0.0195   lr: 5e-05  max_mem: 3035M
[03/08 14:25:46 d2.utils.events]:  eta: 3:32:59  iter: 619  total_loss: 7.83  loss_ce: 1.206  loss_giou: 1.035  loss_bbox: 1.002  loss_ce_0: 1.138  loss_giou_0: 1.002  loss_bbox_0: 1.012  loss_rpn_cls: 0.5166  loss_rpn_reg: 0.7806  time: 0.2529  last_time: 0.2125  data_time: 0.0110  last_data_time: 0.0042   lr: 5e-05  max_mem: 3035M
